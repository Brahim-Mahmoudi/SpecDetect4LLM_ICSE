@article{rayyan-352339433,
  title={ACE: Automated Technical Debt Remediation with Validated Large Language Model Refactorings - Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering},
  year={2025},
  pages={1318–1324},
  author={Tornhill, Adam and Borg, Markus and Hagatulah, Nadim and S\"{o}derberg, Emma},
  url={https://doi.org/10.1145/3696630.3730565},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={FSE Companion '25},
  keywords={software engineering, maintainability, code quality, refactoring, AI assistants},
  abstract={The remarkable advances in AI and Large Language Models (LLMs) have enabled machines to write code, accelerating the growth of software systems. However, the bottleneck in software development is not writing code but understanding it; program understanding is the dominant activity, consuming approximately 70% of developers' time. This implies that improving existing code to make it easier to understand has a high payoff and - in the age of AI-assisted coding - is an essential activity to ensure that a limited pool of developers can keep up with ever-growing codebases.This paper introduces Augmented Code Engineering (ACE), a tool that automates code improvements using validated LLM output. Developed through a data-driven approach, ACE provides reliable refactoring suggestions by considering both objective code quality improvements and program correctness. Early feedback from users suggests that AI-enabled refactoring helps mitigate code-level technical debt that otherwise rarely gets acted upon.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3696630.3730565},
  booktitle={Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering},
  chapter={0}
}

@article{rayyan-352339434,
  title={Identifying and Documenting Best Practices in Digital Transformation - Proceedings of the 28th European Conference on Pattern Languages of Programs},
  year={2024},
  author={Momand, Mohammad Yusuf and Vrani\'{c}, Valentino},
  url={https://doi.org/10.1145/3628034.3628054},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={EuroPLoP '23},
  keywords={digital transformation, organizational patterns, patterns, software engineering},
  abstract={Digital transformation allows organizations to maintain sustainable development and address ongoing challenges. The current digital transformation and advanced technology mega-trend significantly impact society and organizations, making digital technology crucial for public and private organizations, universities, and daily life. Despite the rising demand, there is often a lack of standard policies governing the use of digital technology. Practical experience and literature reveal key challenges in transitioning from traditional to digital systems, including limited public awareness, mindset, ICT skills, government support, and collaboration between organizations and software engineering societies. Governments must establish digital transformation policies and offer software development guidelines for public organizations to digitalize their systems. Additionally, they should provide or support research projects funded by governmental and nongovernmental organizations to identify infrastructure and regulatory issues within Afghanistan’s digital transformation context. This study documents six organizational patterns observed during the transformation of traditional systems into digital systems, illustrating their sequence and explaining the development of a pattern language from these patterns.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3628034.3628054},
  booktitle={Proceedings of the 28th European Conference on Pattern Languages of Programs},
  chapter={0}
}

@article{rayyan-352339435,
  title={CORE: Resolving Code Quality Issues using LLMs},
  year={2024},
  month={7},
  journal={Proc. ACM Softw. Eng.},
  volume={1},
  author={Wadhwa, Nalin and Pradhan, Jui and Sonwane, Atharv and Sahu, Surya Prakash and Natarajan, Nagarajan and Kanade, Aditya and Parthasarathy, Suresh and Rajamani, Sriram},
  url={https://doi.org/10.1145/3643762},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  keywords={Code quality, LLMs, code revision, static analysis},
  abstract={As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues.    We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The proposer LLM of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The ranker LLM evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. We conduct a variety of experiments on two public benchmarks to show the ability of CORE:  (1) to generate code revisions acceptable to both static analysis tools and human reviewers (the latter evaluated with user study on a subset of the Python benchmark), (2) to reduce human review efforts by detecting and eliminating revisions with unintended changes,  (3) to readily work across multiple languages (Python and Java), static analysis tools (CodeQL and SonarQube) and quality checks (52 and 10 checks, respectively), and  (4) to achieve fix rate comparable to a rule-based automated program repair tool but with much smaller engineering efforts (on the Java benchmark).  CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM reduced false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts. We release code, data, and supplementary material publicly at http://aka.ms/COREMSRI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3643762},
  chapter={0}
}

@article{rayyan-352339436,
  title={A Static Detection Method for Code Defects Based on Transformer - Proceedings of the 2024 3rd International Conference on Networks, Communications and Information Technology},
  year={2024},
  pages={104–111},
  author={Yuan, Shubin and Liu, Chenyu and Shi, Jianheng and Liu, Xinyu and Pu, Wei and Yu, Juntao and Yang, Liqun},
  url={https://doi.org/10.1145/3672121.3672141},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={CNCIT '24},
  keywords={defect detection, program slicing, transformer},
  abstract={With the continuous increase in the scale and complexity of computer software, code defects in software pose a serious threat to public security. A Static Detection Method for Code Defects Based on Transformer is proposed to address the issues of poor scalability of static analysis tools, as well as coarse detection granularity and unsatisfactory detection performance of existing methods. Firstly, perform data flow and control flow analysis on key points in the source code, and adopt a slicing method based on Interprocedural Finite Distributive Subset (IFDS) to obtain code fragments composed of multiple lines of statements related to code defects. Then, the word embedding method is used to obtain vector representations related to the semantics of the code snippets, in order to select the appropriate length of the code snippets while ensuring accuracy. Finally, use Transformer to detect the segment features at the slice level to determine whether the code has defects. The experimental results show that the proposed method can effectively detect different types of code defects, and the detection effect is significantly better than the static analysis tool Flawfender. Under fine-grained conditions, the IFDS slicing method can further improve F1 value and accuracy, reaching 89.64 and 92.08 respectively. It can be seen that the proposed method has better comprehensive detection performance without significantly increasing time complexity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3672121.3672141},
  booktitle={Proceedings of the 2024 3rd International Conference on Networks, Communications and Information Technology},
  chapter={0}
}

@article{rayyan-352339437,
  title={Changes and challenges of technical debt and its management during ongoing digital transformation - Proceedings of the XP2017 Scientific Workshops},
  year={2017},
  author={Yli-Huumo, Jesse and Smolander, Kari},
  url={https://doi.org/10.1145/3120459.3120462},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={XP '17},
  keywords={digital ecosystems, digital infrastructures, digital platforms, digital transformation, technical debt, technical debt management, technical debt research},
  abstract={In this paper, we look how changes and challenges in technical debt and its management that could emerge from the ongoing digital transformation. The digital transformation ensues from companies' opportunities to join various digital ecosystems and use external digital infrastructures to extend business operations and capabilities. Those external infrastructures cannot be controlled by their users, which is interesting especially from the service, systems and software development viewpoint. This will have also impact on technical debt and its management. We outline these changes and challenges with possible scenarios that could occur with technical debt during this change.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3120459.3120462},
  booktitle={Proceedings of the XP2017 Scientific Workshops},
  chapter={0}
}

@article{rayyan-352339438,
  title={[PromptEng] Second International Workshop on Prompt Engineering for Pre-Trained Language Models - Companion Proceedings of the ACM on Web Conference 2025},
  year={2025},
  pages={1589–1590},
  author={Graux, Damien and Montella, Sebastien and Jabeen, Hajira and Gardent, Claire and Pan, Jeff Z.},
  url={https://doi.org/10.1145/3701716.3717816},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={WWW '25},
  keywords={best practices, collective task, llm, prompt engineering},
  abstract={The recent achievements and availability of Large Language Models have paved the road to a new range of applications and use-cases. Pre-trained language models are now being involved at-scale in many fields where they were until now absent from. More specifically, the progress made by causal generative models has open the door to using them through textual instructions aka. prompts. Unfortunately, the performances of these prompts are highly dependent on the exact phrasing used and therefore practitioners need to adopt fail-retry strategies. Based on the success of the past edition, this second international workshop on prompt engineering gathers practitioners (both from Academia and Industry) to exchange about good practices, optimizations, results and novel paradigms about the design of efficient and safe prompts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3701716.3717816},
  booktitle={Companion Proceedings of the ACM on Web Conference 2025},
  chapter={0}
}

@article{rayyan-352339441,
  title={IMPACT: Identifying and Classifying Multiple Sourced and Categorized Self-Admitted Technical Debts},
  year={2025},
  month={7},
  journal={ACM Trans. Softw. Eng. Methodol.},
  issn={1049-331X},
  author={Li, Qingyuan and Yin, Zhixin and Yang, Yaopeng and Li, Chuanyi and Shen, Zongwen and Ge, Jidong and Zhong, Wenkang and Luo, Bin and Ng, Vincent},
  url={https://doi.org/10.1145/3747180},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  keywords={Self-Admitted Technical Debt, SATD Identification and Classification, Large Language Model, Mixture of Experts, Data Augmentation},
  abstract={Self-Admitted Technical Debt (SATD) refers to suboptimal solutions deliberately introduced to accelerate the software development process, often at the expense of software maintainability and sustainability. Therefore, timely identification and repayment of the SATD is critical for the software system. As exploration deepens, it is found that effectively prioritizing the repayment of SATD with more significant impacts on software quality requires not only identifying SATD but also further classifying it. However, existing SATD identification and classification approaches face the following challenges: (1) SATDs originate from diverse sources. Code comments are a widespread source, but recent research has revealed that SATDs can originate from other sources, such as pull requests, issues, and commit messages. Nonetheless, existing approaches primarily target code comments, lacking the capability to analyze SATDs from other sources effectively. (2) SATDs fall into diverse categories. Nonetheless, existing SATD classification approaches fail to address all SATD categories comprehensively and show inadequate performance. (3) Imbalance of existing SATD datasets. Real-world SATD data is scarce, making dataset collection challenging. Moreover, SATD distribution across different sources is uneven, further complicating the construction of high-quality datasets. To alleviate these challenges, this paper presents an SATD identification and classification framework named IMPACT. First, IMPACT employs ChatGPT to construct an augmented dataset. Subsequently, it utilizes a pipeline with two fine-tuned language models of different parameter sizes to identify and classify SATD separately. To evaluate the effectiveness of IMPACT, we compare it with three state-of-the-art SATD classification methods and its two foundation models. Experimental results demonstrate that IMPACT outperforms state-of-the-art methods by a large margin, even surpasses its foundation model GLM-4-9B-Chat. It achieves the optimal average F1 score of 0.697 on the source of pull requests, the most challenging data source. Moreover, experiments on the cross-project test set show that IMPACT demonstrates strong generalizability on unseen project data.},
  note={Just Accepted | RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3747180},
  chapter={0}
}

@article{rayyan-352339442,
  title={Digital Transformation of Supply Chain Management - Challenges and Strategies for Successfully Implementing Data Analytics in Practice - Proceedings of the 2024 8th International Conference on E-Commerce, E-Business, and E-Government},
  year={2024},
  pages={36–42},
  author={Brandtner, Patrick},
  url={https://doi.org/10.1145/3675585.3675592},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={ICEEG '24},
  keywords={Best Practices, Data Analytics, Data Literacy, Digital Transformation, Expert Interviews, Supply Chain Management},
  abstract={Digital transformation has been a crucial endeavor for businesses for many years, with Supply Chain Management (SCM) standing out as an area with significant potential for enhancement through new technologies. Data Analytics (DA), in particular, presents numerous opportunities in this context. Nonetheless, the adoption of data-driven decision-making in SCM remains a challenge for many practitioners. This research paper conducts a thorough investigation into the obstacles encountered when integrating Data Analytics into SCM practices. Utilizing a qualitative research approach, the study gathers comprehensive insights from expert interviews, shedding light on the practical challenges organizations face in their digital transformation journeys. Drawing from the empirical evidence obtained through expert discussions and an extensive review of relevant literature, this paper offers both expert-recommended and theoretically grounded strategies to overcome the barriers to digital transformation in SCM. In total. seven key challenge areas are identified, such as issues with data integration and quality, organizational resistance to change, skills shortages among employees, and concerns about the opacity of AI systems and the trustworthiness of their outputs. The paper presents 22 specific recommendation strategies for the successful deployment of Data Analytics in SCM, including the use of explainable AI to enhance trust in analysis outcomes, showcasing successful internal and employee-centric use cases, establishing a Data Analytics function in a centralized, decentralized, or hybrid format, and creating a central role for data governance. By providing actionable strategies, this paper enriches the current knowledge base, aiding practitioners in overcoming digital transformation challenges and maximizing the benefits of Data Analytics in improving SCM efficiency and digitally transforming supply chains.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={10.1145/3675585.3675592},
  booktitle={Proceedings of the 2024 8th International Conference on E-Commerce, E-Business, and E-Government},
  chapter={0}
}

@article{rayyan-352339443,
  title={Are Prompt Engineering and TODO Comments Friends or Foes? An Evaluation on GitHub Copilot - Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
  year={2024},
  author={OBrien, David and Biswas, Sumon and Imtiaz, Sayem Mohammad and Abdalkareem, Rabe and Shihab, Emad and Rajan, Hridesh},
  url={https://doi.org/10.1145/3597503.3639176},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={ICSE '24},
  keywords={technical debt, GitHub copilot, LLM, code generation},
  abstract={Code intelligence tools such as GitHub Copilot have begun to bridge the gap between natural language and programming language. A frequent software development task is the management of technical debts, which are suboptimal solutions or unaddressed issues which hinder future software development. Developers have been found to "self-admit" technical debts (SATD) in software artifacts such as source code comments. Thus, is it possible that the information present in these comments can enhance code generative prompts to repay the described SATD? Or, does the inclusion of such comments instead cause code generative tools to reproduce the harmful symptoms of described technical debt? Does the modification of SATD impact this reaction? Despite the heavy maintenance costs caused by technical debt and the recent improvements of code intelligence tools, no prior works have sought to incorporate SATD towards prompt engineering. Inspired by this, this paper contributes and analyzes a dataset consisting of 36,381 TODO comments in the latest available revisions of their respective 102,424 repositories, from which we sample and manually generate 1,140 code bodies using GitHub Copilot. Our experiments show that GitHub Copilot can generate code with the symptoms of SATD, both prompted and unprompted. Moreover, we demonstrate the tool's ability to automatically repay SATD under different circumstances and qualitatively investigate the characteristics of successful and unsuccessful comments. Finally, we discuss gaps in which GitHub Copilot's successors and future researchers can improve upon code intelligence tasks to facilitate AI-assisted software maintenance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3597503.3639176},
  booktitle={Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
  chapter={0}
}

@article{rayyan-352339444,
  title={EM-Assist: Safe Automated ExtractMethod Refactoring with LLMs - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
  year={2024},
  pages={582–586},
  author={Pomian, Dorin and Bellur, Abhiram and Dilhara, Malinda and Kurbatova, Zarina and Bogomolov, Egor and Sokolov, Andrey and Bryksin, Timofey and Dig, Danny},
  url={https://doi.org/10.1145/3663529.3663803},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={FSE 2024},
  keywords={Code smells, Java, Kotlin, LLMs, Long Methods, Refactoring},
  abstract={Excessively long methods, loaded with multiple responsibilities, are challenging to understand, debug, reuse, and maintain. The  solution lies in the widely recognized Extract Method refactoring. While the application of this refactoring is supported in modern  IDEs, recommending which code fragments to extract has been the topic of many research tools. However, they often struggle to replicate real-world developer practices, resulting in recommendations that do not align with what a human developer would do in real  life. To address this issue, we introduce EM-Assist, an IntelliJ IDEA plugin that uses LLMs to generate refactoring suggestions and subsequently validates, enhances, and ranks them. Finally, EM-Assist uses the IntelliJ IDE to apply the user-selected recommendation.  In our extensive evaluation of 1,752 real-world refactorings that actually took place in open-source projects, EM-Assist’s recall rate  was 53.4% among its top-5 recommendations, compared to 39.4% for the previous best-in-class tool that relies solely on static analysis. Moreover, we conducted a usability survey with 18 industrial developers and 94.4% gave a positive rating.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3663529.3663803},
  booktitle={Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
  chapter={0}
}

@article{rayyan-352339445,
  title={Accountability in Code Review: The Role of Intrinsic Drivers&nbsp;and the Impact of LLMs},
  year={2025},
  month={10},
  journal={ACM Trans. Softw. Eng. Methodol.},
  issn={1049-331X},
  volume={34},
  number={8},
  author={Alami, Adam and Jensen, Victor and Ernst, Neil},
  url={https://doi.org/10.1145/3721127},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  keywords={Code quality, Accountability, Artificial Intelligence, Large Language Models, LLM, Code Review, Human and Social Aspects of Software Engineering},
  abstract={Accountability is an innate part of social systems. It maintains stability and ensures positive pressure on individuals’ decision-making. As actors in a social system, software developers are accountable to their team and organization for their decisions. However, the drivers of accountability and how it changes behavior in software development are less understood. In this study, we look at how the social aspects of code review affect software engineers’ sense of accountability for code quality. Since Software Engineering (SE) is increasingly involving Large Language Models (LLM) assistance, we also evaluate the impact on accountability when introducing LLM-assisted code reviews. We carried out a two-phased sequential qualitative study ( (textbf{interviews}rightarrowtextbf{focus groups}) ). In Phase I (16 interviews), we sought to investigate the intrinsic drivers of software engineers influencing their sense of accountability for code quality, relying on self-reported claims. In Phase II, we tested these traits in a more natural setting by simulating traditional peer-led reviews with focus groups and then LLM-assisted review sessions. We found that there are four key intrinsic drivers of accountability for code quality: personal standards, professional integrity, pride in code quality, and maintaining one’s reputation. In a traditional peer-led review, we observed a transition from individual to collective accountability when code reviews are initiated. We also found that the introduction of LLM-assisted reviews disrupts this accountability process, challenging the reciprocity of accountability taking place in peer-led evaluations, i.e., one cannot be accountable to an LLM. Our findings imply that the introduction of AI into SE must preserve social integrity and collective accountability mechanisms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3721127},
  chapter={0}
}

@article{rayyan-352339446,
  title={Evaluating Source Code Quality with Large Language Models: a comparative study - Proceedings of the XXIII Brazilian Symposium on Software Quality},
  year={2024},
  pages={103–113},
  author={Sim\~{o}es, Igor Regis da Silva and Venson, Elaine},
  url={https://doi.org/10.1145/3701625.3701650},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={SBQS '24},
  keywords={Code Quality, Code Readability, Static Analysis, Software Engineering, LLM, ChatGPT.},
  abstract={Code quality is an attribute composed of various metrics, such as complexity, readability, testability, interoperability, reusability, and the use of good or bad practices, among others. Static code analysis tools aim to measure a set of attributes to assess code quality. However, some quality attributes can only be measured by humans in code review activities, readability being an example. Given their natural language text processing capability, we hypothesize that a Large Language Model (LLM) could evaluate the quality of code, including attributes currently not automatable. This paper aims to describe and analyze the results obtained using Large Language Model (LLM)s as a static analysis tool, evaluating the overall quality of code. We compared the Large Language Model (LLM) with the results obtained with the SonarQube software and its Maintainability metric for two Open Source Software (OSS) Java projects, one with Maintainability Rating A and the other B. A total of 1,641 classes were analyzed, comparing the results in two versions of models: GPT 3.5 Turbo and GPT 4o. We demonstrated that the GPT 3.5 Turbo Large Language Model (LLM) has the ability to evaluate code quality, showing a correlation with Sonar’s metrics. However, there are specific aspects that differ in what the Large Language Model (LLM) measures compared to SonarQube. The GPT 4o version did not present the same results, diverging from the previous model and Sonar by assigning a high classification to codes that were assessed as lower quality. This study demonstrates the potential of Large Language Model (LLM)s in evaluating code quality. However, further research is necessary to investigate limitations such as LLM’s cost, variability of outputs and explore quality characteristics not measured by traditional static analysis tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={10.1145/3701625.3701650},
  booktitle={Proceedings of the XXIII Brazilian Symposium on Software Quality},
  chapter={0}
}

@article{rayyan-352339447,
  title={Navigating Challenges and Technical Debt in Large Language Models Deployment - Proceedings of the 4th Workshop on Machine Learning and Systems},
  year={2024},
  pages={192–199},
  author={Menshawy, Ahmed and Nawaz, Zeeshan and Fahmy, Mahmoud},
  url={https://doi.org/10.1145/3642970.3655840},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={EuroMLSys '24},
  keywords={High-Throughput LLM Processing, LLM Deployment Challenges, LLM Model Compression and Pruning, LLMs Deployment, Large Language Models (LLMs), Scalability Challenges in LLMs Deployment, Technical Debt in AI},
  abstract={Large Language Models (LLMs) have become an essential tool in advancing artificial intelligence and machine learning, enabling outstanding capabilities in natural language processing, and understanding. However, the efficient deployment of LLMs in production environments reveals a complex landscape of challenges and technical debt.In this paper, we aim to highlight unique forms of challenges and technical debt associated with the deployment of LLMs, including those related to memory management, parallelism strategies, model compression, and attention optimization. These challenges emphasize the necessity of custom approaches to deploying LLMs, demanding customization and sophisticated engineering solutions not readily available in broad-use machine learning libraries or inference engines.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3642970.3655840},
  booktitle={Proceedings of the 4th Workshop on Machine Learning and Systems},
  chapter={0}
}

@article{rayyan-352339448,
  title={Bringing Industry-Grade Code Quality and Practices into Software Engineering Education (Doctoral Consortium) - Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
  year={2024},
  author={Birillo, Anastasiia},
  url={https://doi.org/10.1145/3699538.3699571},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={Koli Calling '24},
  keywords={Code Quality Assessment, Code Formatting, LLMs, Generative AI, Next-Step Hints},
  abstract={Using professional development tools and practices is an essential part of being a programmer. However, beginners often struggle with professional tools. In this work, we ask the question: “How can we adapt professional programming tools to improve software engineering education?” and aim to find efficient ways to solve this problem.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={10.1145/3699538.3699571},
  booktitle={Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
  chapter={0}
}

@article{rayyan-352339449,
  title={IT-enabled business transformation (panel session): comparing approaches to the transfer of business best practices - Proceedings of the Eighteenth International Conference on Information Systems},
  year={1997},
  pages={532},
  author={Christensen, Gunnar E. and Bj\o{}rn-Andersen, Niels and Seibt, Dietrich and van der Zee, Han T. M.},
  publisher={Association for Information Systems},
  address={USA},
  series={ICIS '97},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  booktitle={Proceedings of the Eighteenth International Conference on Information Systems},
  chapter={0}
}

@article{rayyan-352339450,
  title={Data preparation for fine tuning Large Language Models - Proceedings of the 8th International Conference on Data Science and Management of Data (12th ACM IKDD CODS and 30th COMAD)},
  year={2025},
  pages={378–380},
  author={Selvam, Parameswaran and Patel, Hima and Surendran, Saptha and Singh, Shivdeep},
  url={https://doi.org/10.1145/3703323.3704802},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={CODS-COMAD '24},
  keywords={large language models, data preparation, fine-tuning, pre-training, code quality filtering, data deduplication, PII detection, license filtering, malware detection, data pipeline, open-source toolkit, transformations, scalability, machine learning datasets},
  abstract={When it comes to creating Large Language Model (LLM) applications, such as fine-tuning, pre-training, or instruct-tuning, data preparation is a vital early step. It is widely acknowledged that the quality of a model is heavily influenced by the quality of the data it is trained on, as demonstrated in &nbsp;[4, 6, 8]. This tutorial will focus on the data preparation for LLM application development, focussing on the latest data preparation techniques. The tutorial will start by covering the state-of-the-art methods for preparing data for LLMs. We will then provide a hands on tutorial on how to use the data-prep-kit [7], an open source toolkit to implement various data preparation steps. To provide LLM app developers with a practical understanding, we will create a data processing pipeline for a specific LLM app development use case. This will offer an end-to-end experience that users can then apply to their own projects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/3703323.3704802},
  booktitle={Proceedings of the 8th International Conference on Data Science and Management of Data (12th ACM IKDD CODS and 30th COMAD)},
  chapter={0}
}

@article{rayyan-352339451,
  title={Toward an engineering discipline for grammarware},
  year={2005},
  month={7},
  journal={ACM Trans. Softw. Eng. Methodol.},
  issn={1049-331X},
  volume={14},
  number={3},
  pages={331–380},
  author={Klint, Paul and L\"{a}mmel, Ralf and Verhoef, Chris},
  url={https://doi.org/10.1145/1072997.1073000},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  keywords={software transformation, software evolution, parsers, model-driven development, metamodeling, language processing, grammars, grammar-dependent software, generic language technology, best practices, automated software engineering, Grammarware},
  abstract={Grammarware comprises grammars and all grammar-dependent software. The term grammar is meant here in the sense of all established grammar formalisms and grammar notations including context-free grammars, class dictionaries, and XML schemas as well as some forms of tree and graph grammars. The term grammar-dependent software refers to all software that involves grammar knowledge in an essential manner. Archetypal examples of grammar-dependent software are parsers, program converters, and XML document processors. Despite the pervasive role of grammars in software systems, the engineering aspects of grammarware are insufficiently understood. We lay out an agenda that is meant to promote research on increasing the productivity of grammarware development and on improving the quality of grammarware. To this end, we identify the problems with the current grammarware practices, the barriers that currently hamper research, and the promises of an engineering discipline for grammarware, its principles, and the research challenges that have to be addressed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/1072997.1073000},
  chapter={0}
}

@article{rayyan-352339452,
  title={HealthAchieve 2010: a Student's Perspective on Canadian transformational healthcare delivery},
  year={2011},
  month={3},
  journal={SIGHIT Rec.},
  volume={1},
  number={1},
  pages={26–30},
  author={Padamadan, D. J. and Closson, Tom and Gabriele, Joseph and Latam, Janice and Pino, Giuseppe},
  url={https://doi.org/10.1145/1971706.1971715},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  keywords={universal, transformation agenda, silos, interoperability, integration, green, excellent care for all act, ehealth, donor stewardship, disruptive innovation, decentralization, culture of philanthropy, centralization, best practices, asker, ambassador, advocate, SRN, QIPP, OHA, NHS, NEON, MOHLTC, LHIN, IFHRO, HealthAchieve, CHIMA, CHA, AAA board},
  abstract={Here we summarize the HealthAchieve 2010 event held November 8th-10th in Toronto, Canada. HealthAchieve is considered the definitive Canadian healthcare delivery experience conference. The insights garnered among attending delegates serves to expand the existing knowledge base and promote the need for research in healthcare to address respective enterprise gap deficiencies in delivery and quality. HealthAchieve 2010, illuminated delegate awareness to decentralization trends; health promotion and wellbeing initiatives; optimal delivery approaches; chronic disease management, primary prevention, evidence-based best practices; and fundraising strategies. The conference encouraged learning, relationship building, knowledge sharing, and the strengthening of existing partnerships.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={10.1145/1971706.1971715},
  chapter={0}
}

@article{rayyan-352339453,
  title={Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive   Experts},
  month={1},
  author={Jihoon Lee, Hoyeon Moon, Kevin Zhai, Arun Kumar Chithanar, Anit Kumar Sahu, Soummya Kar, Chul Lee...},
  abstract={Diffusion-based large language models (dLLMs) are trained flexibly to model extreme dependence in the data distribution; however, how to best utilize this information at inference time remains an open problem. In this work, we uncover an interesting property of these models: dLLMs trained on textual data implicitly learn a mixture of semi-autoregressive experts, where different generation orders reveal different specialized behaviors. We show that committing to any single, fixed inference time schedule, a common practice, collapses performance by failing to leverage this latent ensemble. To address this, we introduce HEX (Hidden semiautoregressive EXperts for test-time scaling), a training-free inference method that ensembles across heterogeneous block schedules. By doing a majority vote over diverse block-sized generation paths, HEX robustly avoids failure modes associated with any single fixed schedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to 3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and specialized fine-tuned methods like GRPO, without additional training. HEX even yields significant gains on MATH benchmark from 16.40% to 40.00%, scientific reasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%. Our results establish a new paradigm for test-time scaling in diffusion-based LLMs (dLLMs), revealing that the sequence in which masking is performed plays a critical role in determining performance during inference.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339454,
  title={SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful   Requests},
  month={1},
  author={Punya Syon Pandey, Hai Son Le, Devansh Bhardwaj, Rada Mihalcea, Zhijing Jin},
  abstract={Large language models (LLMs) are increasingly deployed in contexts where their failures can have direct sociopolitical consequences. Yet, existing safety benchmarks rarely test vulnerabilities in domains such as political manipulation, propaganda and disinformation generation, or surveillance and information control. We introduce SocialHarmBench, a dataset of 585 prompts spanning 7 sociopolitical categories and 34 countries, designed to surface where LLMs most acutely fail in politically charged contexts. Our evaluations reveal several shortcomings: open-weight models exhibit high vulnerability to harmful compliance, with Mistral-7B reaching attack success rates as high as 97% to 98% in domains such as historical revisionism, propaganda, and political manipulation. Moreover, temporal and geographic analyses show that LLMs are most fragile when confronted with 21st-century or pre-20th-century contexts, and when responding to prompts tied to regions such as Latin America, the USA, and the UK. These findings demonstrate that current safeguards fail to generalize to high-stakes sociopolitical settings, exposing systematic biases and raising concerns about the reliability of LLMs in preserving human rights and democratic values. We share the SocialHarmBench benchmark at https://huggingface.co/datasets/psyonp/SocialHarmBench.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339455,
  title={Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error   Attribution},
  month={1},
  author={Adi Banerjee, Anirudh Nair, Tarik Borogovac},
  abstract={Error attribution in Large Language Model (LLM) multi-agent systems presents a significant challenge in debugging and improving collaborative AI systems. Current approaches to pinpointing agent and step level failures in interaction traces - whether using all-at-once evaluation, step-by-step analysis, or binary search - fall short when analyzing complex patterns, struggling with both accuracy and consistency. We present ECHO (Error attribution through Contextual Hierarchy and Objective consensus analysis), a novel algorithm that combines hierarchical context representation, objective analysis-based evaluation, and consensus voting to improve error attribution accuracy. Our approach leverages a positional-based leveling of contextual understanding while maintaining objective evaluation criteria, ultimately reaching conclusions through a consensus mechanism. Experimental results demonstrate that ECHO outperforms existing methods across various multi-agent interaction scenarios, showing particular strength in cases involving subtle reasoning errors and complex interdependencies. Our findings suggest that leveraging these concepts of structured, hierarchical context representation combined with consensus-based objective decision-making, provides a more robust framework for error attribution in multi-agent systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339456,
  title={Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the   Rails},
  month={1},
  author={Siwei Han, Jiaqi Liu, Yaofeng Su, Wenbo Duan, Xinyuan Liu, Cihang Xie, Mohit Bansal, Mingyu Ding,...},
  abstract={As Large Language Model (LLM) agents increasingly gain self-evolutionary capabilities to adapt and refine their strategies through real-world interaction, their long-term reliability becomes a critical concern. We identify the Alignment Tipping Process (ATP), a critical post-deployment risk unique to self-evolving LLM agents. Unlike training-time failures, ATP arises when continual interaction drives agents to abandon alignment constraints established during training in favor of reinforced, self-interested strategies. We formalize and analyze ATP through two complementary paradigms: Self-Interested Exploration, where repeated high-reward deviations induce individual behavioral drift, and Imitative Strategy Diffusion, where deviant behaviors spread across multi-agent systems. Building on these paradigms, we construct controllable testbeds and benchmark Qwen3-8B and Llama-3.1-8B-Instruct. Our experiments show that alignment benefits erode rapidly under self-evolution, with initially aligned models converging toward unaligned states. In multi-agent settings, successful violations diffuse quickly, leading to collective misalignment. Moreover, current reinforcement learning-based alignment methods provide only fragile defenses against alignment tipping. Together, these findings demonstrate that alignment of LLM agents is not a static property but a fragile and dynamic one, vulnerable to feedback-driven decay during deployment. Our data and code are available at https://github.com/aiming-lab/ATP.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339457,
  title={FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration},
  month={1},
  author={Victor May, Diganta Misra, Yanqi Luo, Anjali Sridhar, Justine Gehring, Silvio Soares Ribeiro Junior},
  abstract={AI coding assistants are rapidly becoming integral to modern software development. A key challenge in this space is the continual need to migrate and modernize codebases in response to evolving software ecosystems. Traditionally, such migrations have relied on rule-based systems and human intervention. With the advent of powerful large language models (LLMs), AI-driven agentic frameworks offer a promising alternative-but their effectiveness has not been systematically evaluated. In this paper, we introduce FreshBrew, a novel benchmark for evaluating AI agents on project-level Java migrations, with a specific focus on measuring an agent's ability to preserve program semantics and avoid reward hacking, which we argue requires projects with high test coverage for a rigorous and reliable evaluation. We benchmark several state-of-the-art LLMs, and compare their performance against established rule-based tools. Our evaluation of AI agents on this benchmark of 228 repositories shows that the top-performing model, Gemini 2.5 Flash, can successfully migrate 52.3 percent of projects to JDK 17. Our empirical analysis reveals novel insights into the critical strengths and limitations of current agentic approaches, offering actionable insights into their real-world applicability. Our empirical study reveals failure modes of current AI agents in realistic Java modernization tasks, providing a foundation for evaluating trustworthy code-migration systems. By releasing FreshBrew, we aim to facilitate rigorous, reproducible evaluation and catalyze progress in AI-driven codebase modernization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339458,
  title={An Empirical Study of SOTA RCA Models: From Oversimplified Benchmarks to   Realistic Failures},
  month={1},
  author={Aoyang Fang, Songhan Zhang, Yifan Yang, Haotong Wu, Junjielong Xu, Xuyang Wang, Rui Wang, Manyi W...},
  abstract={While cloud-native microservice architectures have transformed software development, their complexity makes Root Cause Analysis (RCA) both crucial and challenging. Although many data-driven RCA models have been proposed, we find that existing benchmarks are often oversimplified and fail to capture real-world conditions. Our preliminary study shows that simple rule-based methods can match or even outperform state-of-the-art (SOTA) models on four widely used benchmarks, suggesting performance overestimation due to benchmark simplicity. To address this, we systematically analyze popular RCA benchmarks and identify key limitations in fault injection, call graph design, and telemetry patterns. Based on these insights, we develop an automated framework to generate more realistic benchmarks, yielding a dataset of 1,430 validated failure cases from 9,152 injections, covering 25 fault types under dynamic workloads with hierarchical ground-truth labels and verified SLI impact. Re-evaluation of 11 SOTA models on this dataset shows low Top@1 accuracy (average 0.21, best 0.37) and significantly longer execution times. Our analysis highlights three common failure patterns: scalability issues, observability blind spots, and modeling bottlenecks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}}
}

@article{rayyan-352339459,
  title={Beyond Outcome Reward: Decoupling Search and Answering Improves LLM   Agents},
  month={1},
  author={Yiding Wang, Zhepei Wei, Xinyu Zhu, Yu Meng},
  abstract={Enabling large language models (LLMs) to utilize search tools offers a promising path to overcoming fundamental limitations such as knowledge cutoffs and hallucinations. Recent work has explored reinforcement learning (RL) for training search-augmented agents that interleave reasoning and retrieval before answering. These approaches usually rely on outcome-based rewards (e.g., exact match), implicitly assuming that optimizing for final answers will also yield effective intermediate search behaviors. Our analysis challenges this assumption: we uncover multiple systematic deficiencies in search that arise under outcome-only training and ultimately degrade final answer quality, including failure to invoke tools, invalid queries, and redundant searches. To address these shortcomings, we introduce DeSA (Decoupling Search-and-Answering), a simple two-stage training framework that explicitly separates search optimization from answer generation. In Stage 1, agents are trained to improve search effectiveness with retrieval recall-based rewards. In Stage 2, outcome rewards are employed to optimize final answer generation. Across seven QA benchmarks, DeSA-trained agents consistently improve search behaviors, delivering substantially higher search recall and answer accuracy than outcome-only baselines. Notably, DeSA outperforms single-stage training approaches that simultaneously optimize recall and outcome rewards, underscoring the necessity of explicitly decoupling the two objectives.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339460,
  title={Making Mathematical Reasoning Adaptive},
  month={1},
  author={Zhejian Lai, Xiang Geng, Zhijun Wang, Yang Bai, Jiahuan Li, Rongxiang Weng, Jingang Wang, Xuezhi ...},
  abstract={Mathematical reasoning is a primary indicator of large language models (LLMs) intelligence. However, existing LLMs exhibit failures of robustness and generalization. This paper attributes these deficiencies to spurious reasoning, i.e., producing answers from superficial features. To address this challenge, we propose the AdaR framework to enable adaptive reasoning, wherein models rely on problem-solving logic to produce answers. AdaR synthesizes logically equivalent queries by varying variable values, and trains models with RLVR on these data to penalize spurious logic while encouraging adaptive logic. To improve data quality, we extract the problem-solving logic from the original query and generate the corresponding answer by code execution, then apply a sanity check. Experimental results demonstrate that AdaR improves robustness and generalization, achieving substantial improvement in mathematical reasoning while maintaining high data efficiency. Analysis indicates that data synthesis and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs. Subsequent analyses derive key design insights into the effect of critical factors and the applicability to instruct LLMs. Our project is available at https://github.com/LaiZhejian/AdaR},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339461,
  title={TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool   Use},
  month={1},
  author={Pengfei He, Zhenwei Dai, Bing He, Hui Liu, Xianfeng Tang, Hanqing Lu, Juanhui Li, Jiayuan Ding, S...},
  abstract={Large language model (LLM)-based agents increasingly rely on tool use to complete real-world tasks. While existing works evaluate the LLMs' tool use capability, they largely focus on the final answers yet overlook the detailed tool usage trajectory, i.e., whether tools are selected, parameterized, and ordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to comprehensively evaluate LLMs' tool use capability through diverse tasks with fine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable tools across practical domains with tasks grounded in production-style APIs, and synthesizes trajectories that vary in breadth (parallel calls) and depth (interdependent chains). Besides final accuracy, TRAJECT-Bench also reports trajectory-level diagnostics, including tool selection and argument correctness, and dependency/order satisfaction. Analyses reveal failure modes such as similar tool confusion and parameter-blind selection, and scaling behavior with tool diversity and trajectory length where the bottleneck of transiting from short to mid-length trajectories is revealed, offering actionable guidance for LLMs' tool use.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352339462,
  title={Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to   Improve LLM Agents Adaptation},
  month={1},
  author={Hadi Nekoei, Aman Jaiswal, Patrice Bechard, Oleh Shliazhko, Orlando Marquez Ayala, Mathieu Reymon...},
  abstract={Large language model (LLM) agents perform well in sequential decision-making tasks, but improving them on unfamiliar domains often requires costly online interactions or fine-tuning on large expert datasets. These strategies are impractical for closed-source models and expensive for open-source ones, with risks of catastrophic forgetting. Offline trajectories offer reusable knowledge, yet demonstration-based methods struggle because raw traces are long, noisy, and tied to specific tasks. We present Just-in-time Episodic Feedback Hinter (JEF Hinter), an agentic system that distills offline traces into compact, context-aware hints. A zooming mechanism highlights decisive steps in long trajectories, capturing both strategies and pitfalls. Unlike prior methods, JEF Hinter leverages both successful and failed trajectories, extracting guidance even when only failure data is available, while supporting parallelized hint generation and benchmark-independent prompting. At inference, a retriever selects relevant hints for the current state, providing targeted guidance with transparency and traceability. Experiments on MiniWoB++, WorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms strong baselines, including human- and document-based hints.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}}
}

@article{rayyan-352343004,
  title={ Task Decomposition and RAG as Design Patterns for LLM-Based Systems  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Ayala, O. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030033 },
  abstract={AI technologies are moving rapidly from research to production. Compared to traditional AI-based software, systems employing Large Language Models (LLMs) are more difficult to design due to their scale and versatility. This makes it necessary to document best practices, known as design patterns in software engineering, that can be used across LLM-based applications. While Task Decomposition and Retrieval-Augmented Generation (RAG) are well-known techniques, their formalization as design patterns for LLM-based systems benefits AI practitioners. These techniques should be considered not only from a scientific perspective, but also from the standpoint of desired software quality attributes such as safety and modularity. This will help bridge the gap between AI and software engineering as those fine-tuning or prompting LLMs will be aware of the impact that modern techniques have on the overall system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00049 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343005,
  title={ Decoding AI Complexity: SHAP Textual Explanations via LLM for Improved Model Transparency  -  2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan) },
  year={2024},
  author={Hsu, C. -C. and Wu, I. -Z. and Liu, S. -M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10674465 },
  abstract={With the continuous advancement of artificial intelligence (AI), particularly in widespread domains such as healthcare and environmental applications, there is an increasing demand for model interpretability. Understanding the decision-making process of models contributes to building trust in them. Hence, the development of Explainable AI (XAI) has become crucial. This study proposes an approach to generate text via a large language model (LLM) for interpretation to enhance the interpretability of SHAP (Shapley Additive exPlanations) plots. The goal is to make the interpretability of model decisions accessible even to non-IT experts through textual explanations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/ICCE-Taiwan62264.2024.10674465 },
  booktitle={ 2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan) },
  chapter={0}
}

@article{rayyan-352343006,
  title={ A Family-History Based Conversational AI System Using LLM  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Lim, M. and Ku, J. and Oh, G. -H. and Lee, S. and Kang, Y. and Kim, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827365 },
  abstract={The proportion of single residents is steadily increasing, and the lives of single residents can experience relational disconnection and isolation, as well as limitations in social solidarity and integration. This study aimed to develop an AI conversation system that allows users to feel intimacy with the aim of improving the loneliness of single residents. Therefore, the system persona was set to family, and the system was created using the LLM model. The AI conversation system was developed at the pilot level, and user testing was conducted. Suppose the system is refined in the future and upgraded by reflecting user test opinions. In that case, it is believed that it will be possible to develop a system that allows users to feel closeness and, as a result, improves the loneliness and depression of single residents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827365 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343007,
  title={ Scaling Responsible Generative AI: Automating Red Teaming of LLM Applications  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Goh, A. and Chee, B. and Vagnoli, M. and Baldassarre, L. and Narayan, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050586 },
  abstract={Large Language Models (LLMs) present both significant business potential and substantial risks. This paper addresses the critical need for robust and scalable red teaming processes to identify and mitigate risks before LLM solution deployment. First, we define a comprehensive set of 48 LLM-associated risks reflecting emerging AI threats. Additionally, we introduce an automated adversarial prompt generation pipeline involving five types of generators that cover diverse AI risks at varying complexity levels. Finally, we implement a LLM-as-a-judge evaluation system to streamline testing. When applied to red-team two finance-based LLM applications, our approach achieved perfect recall in identifying failed outputs while reducing manual evaluation by over 90%. The developed features halved the time required for red teaming exercises, enhancing scalability and thoroughness while maintaining effectiveness. This work enhances LLM safety, accelerates deployment, and adds business value through improved risk management and responsible AI use.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00159 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343008,
  title={ Building Neo4j-Powered Applications with LLMs: Create LLM-driven search and recommendations applications with Haystack, LangChain4j, and Spring AI  -  Building Neo4j-Powered Applications with LLMs: Create LLM-driven search and recommendations applications with Haystack, LangChain4j, and Spring AI },
  author={Anthapu, R. and Agarwal, S. and Webber, D. J. and Risch, D. J.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11099031.pdf&bkn=11099031&pdfType=book },
  abstract={A comprehensive guide to building cutting-edge generative AI applications using Neo4j's knowledge graphs and vector search capabilitiesKey FeaturesDesign vector search and recommendation systems with LLMs using Neo4j GenAI, Haystack, Spring AI, and LangChain4jApply best practices for graph exploration, modeling, reasoning, and performance optimizationBuild and consume Neo4j knowledge graphs and deploy your GenAI apps to Google CloudPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionEmbark on an expert-led journey into building LLM-powered applications using Retrieval-Augmented Generation (RAG) and Neo4j knowledge graphs. Written by Ravindranatha Anthapu, Principal Consultant at Neo4j, and Siddhant Agrawal, a Google Developer Expert in GenAI, this comprehensive guide is your starting point for exploring alternatives to LangChain, covering frameworks such as Haystack, Spring AI, and LangChain4j. As LLMs (large language models) reshape how businesses interact with customers, this book helps you develop intelligent applications using RAG architecture and knowledge graphs, with a strong focus on overcoming one of AI’s most persistent challenges—mitigating hallucinations. You'll learn how to model and construct Neo4j knowledge graphs with Cypher to enhance the accuracy and relevance of LLM responses. Through real-world use cases like vector-powered search and personalized recommendations, the authors help you build hands-on experience with Neo4j GenAI integrations across Haystack and Spring AI. With access to a companion GitHub repository, you’ll work through code-heavy examples to confidently build and deploy GenAI apps on Google Cloud. By the end of this book, you’ll have the skills to ground LLMs with RAG and Neo4j, optimize graph performance, and strategically select the right cloud platform for your GenAI applications.What you will learnDesign, populate, and integrate a Neo4j knowledge graph with RAGModel data for knowledge graphsIntegrate AI-powered search to enhance knowledge explorationMaintain and monitor your AI search application with HaystackUse LangChain4j and Spring AI for recommendations and personalizationSeamlessly deploy your applications to Google Cloud PlatformWho this book is forThis LLM book is for database developers and data scientists who want to leverage knowledge graphs with Neo4j and its vector search capabilities to build intelligent search and recommendation systems. Working knowledge of Python and Java is essential to follow along. Familiarity with Neo4j, the Cypher query language, and fundamental concepts of databases will come in handy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Building Neo4j-Powered Applications with LLMs: Create LLM-driven search and recommendations applications with Haystack, LangChain4j, and Spring AI },
  chapter={0}
}

@article{rayyan-352343009,
  title={ LLM/GPT Generative AI and Artificial General Intelligence (AGI): The Next Frontier  -  2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE) },
  year={2023},
  author={Mohammad, A. F. and Clark, B. and Agarwal, R. and Summers, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487188 },
  abstract={The dawn of artificial intelligence has sparked excitement and curiosity as it paves new ways for us to envision the future. Artificial General Intelligence (AGI) stands as a thrilling and challenging frontier to explore, offering many possibilities and transformations across various industries. This article attempts to provide an in-depth overview of AGL its history, applications, challenges, and ethical implications. Before diving into the world of AGL it is prudent to familiarize oneself with the key concepts and distinctions that shape this field. This section aims to define AGL differentiate it from other types of artificial intelligence, and offer a glance at its historical development and its potential future development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCE60160.2023.00073 },
  booktitle={ 2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE) },
  chapter={0}
}

@article{rayyan-352343010,
  title={ Large Language Models (LLMs) and Generative AI in Cybersecurity and Privacy: A Survey of Dual-Use Risks, AI-Generated Malware, Explainability, and Defensive Strategies  -  2025 Silicon Valley Cybersecurity Conference (SVCC) },
  year={2025},
  author={Ahi, K. and Valizadeh, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11133642 },
  abstract={Large Language Models (LLMs) and generative AI (GenAI) systems, such as ChatGPT, Claude, Gemini, LLaMA, Copilot, Stable Diffusion by OpenAI, Anthropic, Google, Meta, Microsoft, Stability AI, respectively, are revolutionizing cybersecurity, enabling both automated defense and sophisticated attacks. These technologies power real-time threat detection, phishing defense, secure code generation, and vulnerability exploitation at unprecedented scales. LLM-generated malware alone is projected to account for 50% of detected threats in 2025, up from just 2% in 2021, emphasizing the need for next-generation security frameworks.This paper presents a comprehensive survey of the beneficial and malicious applications of LLMs in cybersecurity, including zero-day detection, DevSecOps, federated learning, synthetic content analysis, and explainable AI (XAI). Drawing on a review of over 70 academic papers, industry reports, and technical documents, this work synthesizes insights from real-world case studies across platforms like Google Play Protect, Microsoft Defender, Amazon Web Services (AWS), Apple’s App Store, OpenAI Plugin Stores, Hugging Face Spaces, and GitHub, alongside emerging initiatives like the SAFE Framework and AI-driven anomaly detection.We conclude with practical recommendations for responsible and transparent LLM deployment, including model watermarking, adversarial defense, and cross-industry collaboration—setting a new benchmark for rigorous, holistic cybersecurity research at the intersection of AI and threat defense—and offering a roadmap for secure, scalable LLM systems that serves as a critical reference for researchers, engineers, and security leaders navigating the complex challenges of AI-driven cybersecurity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/SVCC65277.2025.11133642 },
  booktitle={ 2025 Silicon Valley Cybersecurity Conference (SVCC) },
  chapter={0}
}

@article{rayyan-352343011,
  title={ Embodied Generative AI Art for Enhanced Human-Robot Interaction Through a Human-Centric LLM-Guided Robotic Arm Drawing System  -  2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  year={2025},
  author={Xie, S. and Sandoval, E. B. and Shaik, K. A. and Cruz, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974105 },
  abstract={Generative AI is transforming the way humans interact with robots by integrating language-driven comprehension with embodied execution. While recent research leveraging large language models (LLMs) to enhance communication between humans and machines has shown significant progress, the exploration of integrating LLMs with robots to assist users in creating real-world artistic works remains challenging. This research introduces a novel GENAI-driven intelligent robotic arm drawing system. We fine-tuned GPT-3.5 Turbo to better capture meaningful information from conversations with users and output precise drawing commands, which are directly fed into the fine-tuned Stable Diffusion model to generate desired images. A UFactory xArm equipped with an end-effector holding a drawing pen is deployed and controlled by a speed control algorithm to perform accurate drawing movements based on AI-generated images. Our proposed framework facilitates enhanced HRI experiences with a focus on drawing tasks, effectively embodying the capabilities of generative AI in the field of artistic creation and enabling users to engage deeply in the process of using AI for art creation in real-world environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HRI61500.2025.10974105 },
  booktitle={ 2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  chapter={0}
}

@article{rayyan-352343012,
  title={ Building Knowledge Base of 3D Object Assets Using Multimodal LLM AI Model  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Lee, S. and Park, W. and Lee, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827434 },
  abstract={The proliferation of various XR (eXtended Reality) services and the increasing incorporation of visual effects into existing content services have led to an exponential rise in the demand for 3D object assets. This paper describes an LLM (Large Language Model)-based multimodal AI model pipeline that can be applied to a generative AI model for creating new 3D objects or restructuring the asset management system to enhance the reusability of existing 3D objects. By leveraging a multimodal AI model, we derived descriptive text for assets such as 3D object, 2D image at a human-perceptible level, rather than mere data, and subsequently used an LLM to generate knowledge triplets for constructing an asset knowledge base. The applicability of this pipeline was verified using actual 3D objects from a content production company. Future work will focus on improving the quality of the generated knowledge triplets themselves by training the multimodal AI model with real-world content usage assets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827434 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343013,
  title={ Enhancing AI Systems with Agentic Workflows Patterns in Large Language Model  -  2024 IEEE World AI IoT Congress (AIIoT) },
  year={2024},
  author={Singh, A. and Ehtesham, A. and Kumar, S. and Khoei, T. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578990 },
  abstract={This paper explores the significant shift towards agentic workflows in the application of Large Language Models (LLMs), moving away from traditional, linear interactions between users and AI. Through a case study analysis, we highlight the effectiveness of agentic workflows, which facilitate a more dynamic and iterative engagement, in improving outcomes in tasks such as question answering, code generation or stock analysis. Central to the agentic workflow are four foundational design patterns: reflection, planning, multi-agent collaboration, and tool utilization. These components are crucial for boosting LLM productivity and enhancing performance. The study demonstrates how agentic workflows, by promoting an iterative and reflective process, can serve as a crucial step towards achieving Artificial General Intelligence (AGI).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/AIIoT61789.2024.10578990 },
  booktitle={ 2024 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343014,
  title={ Modern Generative AI with ChatGPT and OpenAI Models: Leverage the capabilities of OpenAI's LLM for productivity and innovation with GPT3 and GPT4  -  Modern Generative AI with ChatGPT and OpenAI Models: Leverage the capabilities of OpenAI's LLM for productivity and innovation with GPT3 and GPT4 },
  author={Alto, V.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251313.pdf&bkn=10251313&pdfType=book },
  abstract={Harness the power of AI with innovative, real-world applications, and unprecedented productivity boosts, powered by the latest advancements in AI technology like ChatGPT and OpenAI Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesExplore the theory behind generative AI models and the road to GPT3 and GPT4Become familiar with ChatGPT’s applications to boost everyday productivityLearn to embed OpenAI models into applications using lightweight frameworks like LangChainBook DescriptionGenerative AI models and AI language models are becoming increasingly popular due to their unparalleled capabilities. This book will provide you with insights into the inner workings of the LLMs and guide you through creating your own language models. You’ll start with an introduction to the field of generative AI, helping you understand how these models are trained to generate new data. Next, you’ll explore use cases where ChatGPT can boost productivity and enhance creativity. You’ll learn how to get the best from your ChatGPT interactions by improving your prompt design and leveraging zero, one, and few-shots learning capabilities. The use cases are divided into clusters of marketers, researchers, and developers, which will help you apply what you learn in this book to your own challenges faster. You’ll also discover enterprise-level scenarios that leverage OpenAI models’ APIs available on Azure infrastructure; both generative models like GPT-3 and embedding models like Ada. For each scenario, you’ll find an end-to-end implementation with Python, using Streamlit as the frontend and the LangChain SDK to facilitate models' integration into your applications. By the end of this book, you’ll be well equipped to use the generative AI field and start using ChatGPT and OpenAI models’ APIs in your own projects.What you will learnUnderstand generative AI concepts from basic to intermediate levelFocus on the GPT architecture for generative AI modelsMaximize ChatGPT’s value with an effective prompt designExplore applications and use cases of ChatGPTUse OpenAI models and features via API callsBuild and deploy generative AI systems with PythonLeverage Azure infrastructure for enterprise-level use casesEnsure responsible AI and ethics in generative AI systemsWho this book is forThis book is for individuals interested in boosting their daily productivity; businesspersons looking to dive deeper into real-world applications to empower their organizations; data scientists and developers trying to identify ways to boost ML models and code; marketers and researchers seeking to leverage use cases in their domain – all by using Chat GPT and OpenAI Models. A basic understanding of Python is required; however, the book provides theoretical descriptions alongside sections with code so that the reader can learn the concrete use case application without running the scripts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Modern Generative AI with ChatGPT and OpenAI Models: Leverage the capabilities of OpenAI's LLM for productivity and innovation with GPT3 and GPT4 },
  chapter={0}
}

@article{rayyan-352343015,
  title={ An LLM-Based Conversational AI Dispatcher for Automating Taxi Phone Orders in Bulgaria  -  2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST) },
  year={2025},
  author={Todorov, T. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098250 },
  abstract={This paper presents an architecture for automating Bulgarian taxi phone orders. A low-latency real-time LLM core handles voice processing and utilizes dynamic function calling to invoke external APIs for critical pick-up address verification and dispatch integration. SIP telephony and in-process .NET system integration demonstrates validated robust operational performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEST66328.2025.11098250 },
  booktitle={ 2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST) },
  chapter={0}
}

@article{rayyan-352343016,
  title={ Deriving Strategic Insights from Earnings Calls: Leveraging Human Experts, AI-Based Search, and Generative AI for Synthesis and Summarization  -  2024 Conference on AI, Science, Engineering, and Technology (AIxSET) },
  year={2024},
  author={Jadhav, S. G. and Sarnikar, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10770919 },
  abstract={Earnings transcript analyses have historically been processed manually and often augmented with AI techniques for natural language processing. Advances in Generative AI open up further opportunities for insights. Instead of looking in silos, we propose an integrated methodology that leverages human expertise, AI-based search, and Gen AI to improve the speed, accuracy, and relevance of insights along with enhanced explainability of Gen AI summaries. Our proposed methodology can augment executives with insights for informed decision-making in their business environment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxSET62544.2024.00031 },
  booktitle={ 2024 Conference on AI, Science, Engineering, and Technology (AIxSET) },
  chapter={0}
}

@article{rayyan-352343017,
  title={ AI-Driven Continuous Integration: Automating Code Review and Deployment with LLMs  -  2025 10th International Conference on Fog and Mobile Edge Computing (FMEC) },
  year={2025},
  author={Salem, D. O. and Alahmed, Y. and Fnich, R. and Mazroub, M. and Fnich, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11119365 },
  abstract={The integration of a Large Language Models (LLMs) into Continuous Integration (CI) pipelines greatly enhances the efficiency of the software development process. AI-based CI improves code quality by decreasing integration failure rates by 30 % and deployment time by 40 %. These models help in identifying bugs, enforcing coding standards, writing unit tests, and optimizing release management. But AIdriven CI comes with risks of security vulnerabilities, model bias and the need for human supervision. This paper uses case studies, surveys, and interviews to explore the effects of AI on CI/CD pipelines and identifies the pros and cons. The results of this search show that the use of AI in CI improves effectiveness, but it needs better oversight to avoid risks and improve model performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/FMEC65595.2025.11119365 },
  booktitle={ 2025 10th International Conference on Fog and Mobile Edge Computing (FMEC) },
  chapter={0}
}

@article{rayyan-352343018,
  title={ GPU-Accelerated Feature Extraction for Real-Time Vision AI and LLM Systems Efficiency: Autonomous Image Segmentation, Unsupervised Clustering, and Smart Pattern Recognition for Scalable AI Processing with 6.6× Faster Performance, 2.5× Higher Accuracy, and UX-Centric UI Boosting Human-in-the-Loop...},
  year={2025},
  author={Ahi, K. and Wu, S. and Sriram, S. and Fenger, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11010527 },
  abstract={The high computational cost of digital image processing, requiring high-performance hardware and extensive resources, severely limits real-time applications. While advancements in algorithm design and GPU acceleration have significantly improved efficiency, modern AI-driven applications such as large language models (LLMs), Generative AI (GenAI), medical imaging, autonomous vehicle perception, photography, advanced nano-scale semiconductor metrology, satellite image analysis, high-precision manufacturing, robotics, and real-time anomaly detection, still demand further optimization to reduce computational overhead and improve scalability.In this paper, we introduce GPU-Accelerated Feature Extraction to enhance runtime and efficiency in edge-based simulations. Our approach leverages AI-driven clustering, grouping images with similar visual and pattern characteristics to enable adaptive tuning on a small subset before generalizing across the full dataset. This method achieves a 3.78× reduction in runtime.Furthermore, rather than processing an entire image, we recognize and extract a single representative pattern or region of interest (ROI) per image, removing redundant data and background noise. This refinement results in an additional 1.74× runtime improvement, culminating in an overall 6.6× speed boost, enhancing Scalable Real-Time AI Processing. We also demonstrated that with a similar runtime, the accuracy achieved is 2.5× higher.This solution, integrated into Calibre SEMSuite™, supports multicloud and real-time deployment for enhanced scalability, usability, and performance, providing users with a powerful tool for fully automated, AI-driven image classification, making high-throughput image review feasible even at the scale required for cutting-edge applications.Beyond performance gains, this approach introduces autonomous data cleaning, anomaly detection and defect identification mechanism, allowing failed patterns and defective images to be identified without human intervention, boosting the reviewer productivity.As GenAI and LLM systems gain popularity, the computational demands on modern systems have reached unprecedented levels. As we demonstrate, thanks to feature extraction and ROI selection, instead of needing for the entire dataset to be processed, only a fraction of the data could be used. This is crucial for reducing the computational overhead of LLM systems.We demonstrate that our method enables high-precision, real-time AI inference with applications in computer vision, LLMs, autonomous systems, healthcare, and scalable AI computing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASMC64512.2025.11010527 },
  booktitle={ 2025 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC) },
  chapter={0}
}

@article{rayyan-352343019,
  title={ Design of Task Allocation and Decision-Making Styles for AI Agents Based on LLM  -  2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) },
  year={2025},
  author={Fu, M. and Gou, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030412 },
  abstract={This study introduces an innovative framework that aligns LLM-based AI agents with enterprise needs by integrating dual-process theory and resource-based task complexity models. Utilizing large language models and Retrieval-Augmented Generation, our system simulates diverse task and decisionmaking scenarios through a Strategy Generator and Evaluator. The results reveal that decision styles-Rational/Intuitive and Participative/Autonomous-vary in performance according to task demands, with effective knowledge management further boosting outcomes. This framework advances efficient AI integration in enterprise settings, enhancing both decision flexibility and execution efficiency.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCBDA64898.2025.11030412 },
  booktitle={ 2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) },
  chapter={0}
}

@article{rayyan-352343020,
  title={ Research on Self-Evolving Deepfake Detection Technology Based on LLM  -  2025 1st International Conference on Consumer Technology (ICCT-Pacific) },
  year={2025},
  author={Yoon, C. and Cho, J. and Mook, K. Jang},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012805 },
  abstract={Deepfake technology enables the manipulation of text, images, audio, and video, offering innovative applications in areas like virtual reality and entertainment. However, it also poses risks such as fake news, privacy breaches, and political misuse, challenging existing static detection models that struggle to adapt to evolving manipulation techniques. This study proposes a self-evolving deepfake detection system using generative AI (LLM) to learn and adapt in real time. The framework integrates real-time learning, multimodal data processing, and lightweight models, emphasizing ethical data practices to ensure fairness, transparency, and security. By addressing technical, social, and legal challenges, this research provides a robust solution for mitigating deepfake risks while fostering ethical and reliable AI deployment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCT-Pacific63901.2025.11012805 },
  booktitle={ 2025 1st International Conference on Consumer Technology (ICCT-Pacific) },
  chapter={0}
}

@article{rayyan-352343021,
  title={ LLM-Empowered Autonomous Edge AI for Anomaly Detection and Resolution in Distributed Systems  -  2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) },
  year={2025},
  author={A, A. P. and Sreeram, A. R. and Auradkar, P. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030483 },
  abstract={There is a growing need for strong security measures to combat cyberattacks with increasing data consumption and reliance on interconnected networks. This is especially required at the network edge, where the data are present and first acquired. Cyber attacks such as distributed denial-of-service (DDoS) attacks and others pose risk and various other inconveniences to all stakeholder involved. The dynamic nature of these attacks and the lack of processing power at the edge require new methods to tackle cyber-attacks. This paper proposes a novel approach for network anomaly detection and mitigation that uses edge AI and the contextual understanding power of Large Language Models (LLMs). The system utilizes deep learning methods to identify cyberattacks where the models are deployed on edge devices and servers enabling quick identification of anomalies. The paper then explores the use of LLMs to automate the resolution and mitigation of these attacks in real-time, leading to lower impact by reducing downtimes and increasing availability. This research aims to contribute to the field of network security by proposing an edge AI driven solution for real-time local DDoS attack detection and the utilization of LLMs for network anomaly resolution and system adaptation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCBDA64898.2025.11030483 },
  booktitle={ 2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) },
  chapter={0}
}

@article{rayyan-352343022,
  title={ Real-Time Avatar-Base Speech-to-Speech Conversational AI Tutor on AI PC  -  2025 IEEE 15th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  year={2025},
  author={Lai, M. S. and Ooi, E. G. and Goh, I. X. and Teoh, K. L. and Pragasam, T. T. Nee and Lim, S. W. and Teh, J. S. Ru and Tang, L. J. and Tan, S. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11080818 },
  abstract={Large Language Models (LLMs) have become integral to daily life, powering popular applications like ChatGPT, Claude, and DALL-E. However, current solutions often fall short of consumer expectations for human-machine interaction (HMI). This paper presents an innovative HMI approach with both visual and audio capabilities: an Avatar-based Speech-to-Speech (S2S) Conversational AI Agent designed for educational applications, which scales as an AI Tutor. Our design employs a multimodal framework, integrating a series of AI components such as Noise Reduction, Automatic Speech Recognition (ASR), Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), Text-toSpeech (TTS), and Avatar modeling. This setup operates entirely on edge devices, like AI PCs, providing private and personalized learning content via RAG. Another objective of this paper is to introduce the End-to-End (E2E) solution usability scoring approach, called Composite Usability Score (CUS) to quantify the usability performance systematically in using the AI Tutor. With this CUS approach, it will bring up the usefulness of AI Tutor design in AI PC.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAIE64985.2025.11080818 },
  booktitle={ 2025 IEEE 15th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  chapter={0}
}

@article{rayyan-352343023,
  title={ Exploring Transparency and AI Assessment in LLM-Assisted Research Applications  -  SoutheastCon 2025 },
  year={2025},
  author={Bacon, G. and Menon, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10971523 },
  abstract={In this work, we further investigate the utility of using a large language model as a research assistant to identify research grant funding opportunities that are best suited for a user-defined natural language set of capabilities. The use case is a United States Department of Defense Small Business Innovation Research Broad Agency Announcement. To explore principles of responsible/ethical artificial intelligence and accountability in the context of large language model-driven applications, we perform clustering on embeddings and apply a suite of metrics to compare cluster quality against Latent Semantic Indexing. Further, we use visualization techniques to depict the contents of funding opportunities that lie at the intersection of multiple capabilities. Finally, we show the importance of maintaining the human in the loop for vetted data quality.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SoutheastCon56624.2025.10971523 },
  booktitle={ SoutheastCon 2025 },
  chapter={0}
}

@article{rayyan-352343024,
  title={ Generative AI with LangChain: Build large language model (LLM) apps with Python, ChatGPT, and other LLMs  -  Generative AI with LangChain: Build large language model (LLM) apps with Python, ChatGPT, and other LLMs },
  year={2024},
  author={Auffarth},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10718332.pdf&bkn=10718332&pdfType=book },
  abstract={2024 Edition – Get to grips with the LangChain framework to develop production-ready applications, including agents and personal assistants. The 2024 edition features updated code examples and an improved GitHub repository. Purchase of the print or Kindle book includes a free PDF eBook. Key FeaturesLearn how to leverage LangChain to work around LLMs’ inherent weaknessesDelve into LLMs with LangChain and explore their fundamentals, ethical dimensions, and application challengesGet better at using ChatGPT and GPT models, from heuristics and training to scalable deployment, empowering you to transform ideas into realityBook DescriptionChatGPT and the GPT models by OpenAI have brought about a revolution not only in how we write and research but also in how we can process information. This book discusses the functioning, capabilities, and limitations of LLMs underlying chat systems, including ChatGPT and Gemini. It demonstrates, in a series of practical examples, how to use the LangChain framework to build production-ready and responsive LLM applications for tasks ranging from customer support to software development assistance and data analysis – illustrating the expansive utility of LLMs in real-world applications. Unlock the full potential of LLMs within your projects as you navigate through guidance on fine-tuning, prompt engineering, and best practices for deployment and monitoring in production environments. Whether you're building creative writing tools, developing sophisticated chatbots, or crafting cutting-edge software development aids, this book will be your roadmap to mastering the transformative power of generative AI with confidence and creativity.What you will learnCreate LLM apps with LangChain, like question-answering systems and chatbotsUnderstand transformer models and attention mechanismsAutomate data analysis and visualization using pandas and PythonGrasp prompt engineering to improve performanceFine-tune LLMs and get to know the tools to unleash their powerDeploy LLMs as a service with LangChain and apply evaluation strategiesPrivately interact with documents using open-source LLMs to prevent data leaksWho this book is forThe book is for developers, researchers, and anyone interested in learning more about LangChain. Whether you are a beginner or an experienced developer, this book will serve as a valuable resource if you want to get the most out of LLMs using LangChain. Basic knowledge of Python is a prerequisite, while prior exposure to machine learning will help you follow along more easily.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI with LangChain: Build large language model (LLM) apps with Python, ChatGPT, and other LLMs },
  chapter={0}
}

@article{rayyan-352343025,
  title={ Lockheed Martin AI Factory: Generative AI and MLOps for Engineering, Enterprise and Edge  -  2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  year={2025},
  author={Maybury, M. and Forrest, G. and O'Donnell, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114065 },
  abstract={This article reports on the rapid creation and deployment at scale of hundreds of Large Language Model (LLM) applications, highlighting several across enterprise, engineering and edge use cases. This outcome was accelerated by the creation of an open architecture, secure and scalable generative AI Factory. An extensible platform, AI Factory empowers thousands of developers and over 50,000 end users across a diverse set of data types and use cases throughout our global enterprise. This evolvable approach reveals how to affordably deploy generative AI to create value securely at scale.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAD65464.2025.11114065 },
  booktitle={ 2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  chapter={0}
}

@article{rayyan-352343026,
  title={ Generative AI for Cybersecurity: LLM-Driven Attack Dataset Augmentation in Web API Detection  -  2025 1st International Conference on Consumer Technology (ICCT-Pacific) },
  year={2025},
  author={Pawana, I. W. A. J. and Purnama, F. and Linawati and Kim, Y. and You, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012893 },
  abstract={As Web APIs become integral to modern digital ecosystems, their increasing complexity and widespread adoption have made them appealing targets for cyberattacks. Effective detection and prevention mechanisms are crucial, and machine learning (ML) techniques provide promising solutions for identifying anomalous API traffic and addressing emerging threats. However, the effectiveness of ML-based security models is limited by the scarcity of realistic, up-to-date datasets and the rapid obsolescence of static training data in the face of evolving attack methodologies. To address these challenges, we present an approach that employs Large Language Models (LLMs) to generate synthetic Web API attack datasets. By leveraging LLMs, researchers can access abundant, customizable, and domain-specific synthetic data that closely simulate contemporary traffic patterns. This eliminates privacy and security concerns associated with real-world datasets and ensures a continuously adaptable data source for training and refining ML-based Intrusion Detection Systems. Ultimately, this strategy enables the development of more resilient ML models capable of effectively countering the dynamic and sophisticated nature of modern Web API threats.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCT-Pacific63901.2025.11012893 },
  booktitle={ 2025 1st International Conference on Consumer Technology (ICCT-Pacific) },
  chapter={0}
}

@article{rayyan-352343027,
  title={ LLM Design Patterns: A Practical Guide to Building Robust and Efficient AI Systems  -  LLM Design Patterns: A Practical Guide to Building Robust and Efficient AI Systems },
  author={Huang, K.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11020600.pdf&bkn=11020600&pdfType=book },
  abstract={Explore reusable design patterns, including data-centric approaches, model development, model fine-tuning, and RAG for LLM application development and advanced prompting techniquesKey FeaturesLearn comprehensive LLM development, including data prep, training pipelines, and optimizationExplore advanced prompting techniques, such as chain-of-thought, tree-of-thought, RAG, and AI agentsImplement evaluation metrics, interpretability, and bias detection for fair, reliable modelsPrint or Kindle purchase includes a free PDF eBookBook DescriptionThis practical guide for AI professionals enables you to build on the power of design patterns to develop robust, scalable, and efficient large language models (LLMs). Written by a global AI expert and popular author driving standards and innovation in Generative AI, security, and strategy, this book covers the end-to-end lifecycle of LLM development and introduces reusable architectural and engineering solutions to common challenges in data handling, model training, evaluation, and deployment. You’ll learn to clean, augment, and annotate large-scale datasets, architect modular training pipelines, and optimize models using hyperparameter tuning, pruning, and quantization. The chapters help you explore regularization, checkpointing, fine-tuning, and advanced prompting methods, such as reason-and-act, as well as implement reflection, multi-step reasoning, and tool use for intelligent task completion. The book also highlights Retrieval-Augmented Generation (RAG), graph-based retrieval, interpretability, fairness, and RLHF, culminating in the creation of agentic LLM systems. By the end of this book, you’ll be equipped with the knowledge and tools to build next-generation LLMs that are adaptable, efficient, safe, and aligned with human values. What you will learnImplement efficient data prep techniques, including cleaning and augmentationDesign scalable training pipelines with tuning, regularization, and checkpointingOptimize LLMs via pruning, quantization, and fine-tuningEvaluate models with metrics, cross-validation, and interpretabilityUnderstand fairness and detect bias in outputsDevelop RLHF strategies to build secure, agentic AI systemsWho this book is forThis book is essential for AI engineers, architects, data scientists, and software engineers responsible for developing and deploying AI systems powered by large language models. A basic understanding of machine learning concepts and experience in Python programming is a must.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ LLM Design Patterns: A Practical Guide to Building Robust and Efficient AI Systems },
  chapter={0}
}

@article{rayyan-352343028,
  title={ A Taxonomy of Foundation Model based Systems through the Lens of Software Architecture  -  2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2024},
  author={Lu, Q. and Zhu, L. and Xu, X. and Liu, Y. and Xing, Z. and Whittle, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556054 },
  abstract={Large language model (LLM) based chatbots, such as ChatGPT, have attracted huge interest in foundation models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. However, the architecture design of foundation model based systems has not yet been systematically explored. There is limited understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and system design options. Our taxonomy comprises three categories: the pretraining and adaptation of foundation models, the architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy can serve as concrete guidance for designing foundation model based systems.CCS CONCEPTS•Software and its engineering → Software design engineering;•Computer systems organization → Architectures;•Computing methodologies → Artificial intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343029,
  title={ Compliance Made Practical: Translating the EU AI Act into Implementable Security Actions  -  2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE) },
  year={2025},
  author={Bunzel, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029418 },
  abstract={The EU AI Act, along with emerging regulations in other countries, mandates that AI systems meet security requirements to prevent risks associated with AI misuse and vulnerabilities. However, for practitioners, defining and achieving a secure AI system is complex and context-dependent, posing challenges in understanding what actions they need to take and when they are sufficient. ISO/IEC TR 24028/29 and ENISA Securing Machine Learning Algorithms offer a comprehensive framework for AI security, aligning with the EU AI Act's requirements by addressing risks, threats, and mitigation strategies. However, for practical implementation, these reports lack hands-on guidance. Industry resources like the OWASP AI Exchange and OWASP LLM Top 10 fill this gap by providing accessible, actionable insights for securing AI systems effectively. This paper addresses the question of responsibility in AI risk mitigation, especially for companies utilizing pretrained or off-the-shelf models. We want to clarify how companies can practically comply with the upcoming ISO 27090 and ensure compliance with the EU AI Act through actionable security strategies tailored to this prevalent use case.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAIE66699.2025.00016 },
  booktitle={ 2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE) },
  chapter={0}
}

@article{rayyan-352343030,
  title={ Developing Multi-Agent LLM Applications Through Continuous Human-LLM Co-Programming  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Song, H. and Goknil, A. and Jiang, X. and Melum, E. and Joe, H. and Gazzotti, C. and Frascolla, V. and Videsjorden, A. N. and Nguyen, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030030 },
  abstract={The rapid advancement of Large Language Models (LLMs) has opened new possibilities for intelligent multi-agent systems capable of autonomously performing complex tasks. To build such systems, LLMs can be leveraged for task-solving, tool interaction, and code generation but at the same time their costs and unpredictability have to be properly managed. To do so this paper introduces COPMA, a model-based approach to enabling continuous human-LLM co-programming of multi-agent LLM applications. COPMA uses feature-block models to track application features and their implementations as agents and code blocks. Supported by co-programming patterns, de-velopers are guided in constructing, refining, and refactoring feature implementations via trial-and-errors with LLM agents, leveraging their feedback, suggestions, and code examples. The patterns guide the shift of feature implementations between agents and code to balance flexibility, predictability, and cost. Our experience in developing LLM agents for collecting and reviewing medical research papers demonstrates that human-LLM co-programming can reduce development effort to enable rapid prototyping of multi-agent LLM applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/CAIN66642.2025.00013 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343031,
  title={ Examination of Ethical Principles for LLM-Based Recommendations in Conversational AI  -  2023 International Conference on Platform Technology and Service (PlatCon) },
  year={2023},
  author={Bang, J. and Lee, B. -T. and Park, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255221 },
  abstract={Conversational interfaces allow users to experience artificial intelligence (AI) services through text or voice conversations. One common form of a conversational interface is a chatbot, which can be scenario-based or large language model (LLM)-based. A scenario-based chatbot generates a response within a predefined scenario for a user query on a specific domain or topic. The chatbot's response for recommendation is processed in conjunction with a separate algorithm. A LLM-based chatbot generates a response through a pretrained model to a user query on a wide range of topics. In this process, the LLM-based chatbot's response takes the form of a kind of recommendation, which is different from the existing recommendation services. To look at the issue more comprehensively, this paper examines recommendation-style system responses of a LLM-based chatbot with the principles of AI ethics. Several examples are shown where the chatbot's responses are modified according to principles of AI ethics.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PlatCon60102.2023.10255221 },
  booktitle={ 2023 International Conference on Platform Technology and Service (PlatCon) },
  chapter={0}
}

@article{rayyan-352343032,
  title={ AIoT Smart Home via Autonomous LLM Agents  -  IEEE Internet of Things Journal },
  author={Rivkin, D. and Hogan, F. and Feriani, A. and Konar, A. and Sigal, A. and Liu, X. and Dudek, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10729865 },
  abstract={The common-sense reasoning abilities and vast general knowledge of large language models (LLMs) make them a natural fit for interpreting user requests in a smart home assistant context. LLMs, however, lack specific knowledge about the user and their home, which limits their potential impact. Smart home agent with grounded execution (SAGE), overcomes these and other limitations by using a scheme in which a user request triggers an LLM-controlled sequence of discrete actions. These actions can be used to retrieve information, interact with the user, or manipulate device states. SAGE controls this process through a dynamically constructed tree of LLM prompts, which help it decide which action to take next, whether an action was successful, and when to terminate the process. The SAGE action set augments an LLM’s capabilities to support some of the most critical requirements for a smart home assistant. These include: flexible and scalable user preference management (“Is my team playing tonight?”), access to any smart device’s full functionality without device-specific code via API reading (“Turn down the screen brightness on my dryer”), persistent device state monitoring (“Remind me to throw out the milk when I open the fridge”), natural device references using only a photo of the room (“Turn on the lamp on the dresser”), and more. We introduce a benchmark of 50 new and challenging smart home tasks where SAGE achieves a 76% success rate, significantly outperforming existing LLM-enabled baselines (30% success rate).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JIOT.2024.3471904 },
  booktitle={ IEEE Internet of Things Journal },
  chapter={0}
}

@article{rayyan-352343033,
  title={ Survey Paper: Comparative Analysis of Detection Methods for Real vs. AI-Generated Images  -  2025 International Conference on Artificial Intelligence and Data Engineering (AIDE) },
  year={2025},
  author={Salam, R. and J, S. R. and B, N. Kumar and V, R. H. and K, S. M. and Madari, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10986774 },
  abstract={The rapid evolution of AI-generated image technologies, including GANs and diffusion models, has blurred the lines between real and synthetic content. In this survey, we explore state-of-the-art methods for detecting fake images. Traditional forensic techniques, deep learning approaches, and advanced methods like Explainable AI (XAI) and blockchain-based verification are used. We evaluate these methods using performance metrics and derive insights into their strengths and limitations. A comparative analysis of existing research papers is provided, examining the approaches used, feature extraction techniques, classifiers employed, and datasets utilized. Additionally, it puts forth actional research directions like diffusion models, multimodal analysis, and expansion of dataset that can contribute towards the advancement of this field. Practical examples and visualizations make this survey both insightful and tutorial-like, offering valuable guidance for researchers and practitioners.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIDE64228.2025.10986774 },
  booktitle={ 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE) },
  chapter={0}
}

@article{rayyan-352343034,
  title={ Generative AI Approach to Distributed Summarization of Financial Narratives  -  2023 IEEE International Conference on Big Data (BigData) },
  year={2023},
  author={Shukla, N. K. and Katikeri, R. and Raja, M. and Sivam, G. and Yadav, S. and Vaid, A. and Prabhakararao, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386313 },
  abstract={This paper presents our submission to the Financial Narrative Summarization (FNS) task at the FNP-2023 workshop. The FNS task involves the generation of concise summaries, not exceeding 1000 words, for annual financial reports composed in English, Spanish, and Greek. In our prior work, presented in FNP-2022, we introduced DiMSum [1], a novel framework designed to automatically identify crucial narrative sections within financial reports and quantify their weighted contributions. The field of Generative AI and Large Language Models (LLMs) has recently witnessed significant advancements, prompting us to explore their utility in summarizing financial reports. Our investigation revealed that LLMs, when left to their own devices often struggle to effectively summarize complex financial documents, necessitating external guidance. In this study, we demonstrate how LLMs, when guided by the DiMSum framework, exhibit substantial improvements in the quality of financial report summarization. To the best of our knowledge, this research marks the first instance of applying LLMs to the FNS task, offering a novel approach to enhancing the summarization of financial reports.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData59044.2023.10386313 },
  booktitle={ 2023 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343035,
  title={ Demo: ViolentUTF as An Accessible Platform for Generative AI Red Teaming  -  2025 Silicon Valley Cybersecurity Conference (SVCC) },
  year={2025},
  author={Nguyen, T. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11133630 },
  abstract={The rapid integration of Generative AI (GenAI) into various applications necessitates robust risk management strategies which includes Red Teaming (RT) - an evaluation method for simulating adversarial attacks. Unfortunately, RT for GenAI is overly complex. This paper introduces violentUTF - an more accessible platform for GenAI RT. Through intuitive interfaces powered by LLMs and for LLMs, violentUTF aims to empower non-technical domain experts and students alongside technical experts, facilitate comprehensive security evaluation by unifying capabilities from existing RT frameworks and its own specialized evaluators. ViolentUTF was used for evaluating the robustness of a flagship LLM-based product in a US Government division. It also demonstrates effectiveness in evaluating LLMs’ cross-domain reasoning capability between cybersecurity and behavioral psychology.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SVCC65277.2025.11133630 },
  booktitle={ 2025 Silicon Valley Cybersecurity Conference (SVCC) },
  chapter={0}
}

@article{rayyan-352343036,
  title={ Protection of LLM Environment Using Prompt Security  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Kim, M. and Kwon, T. and Shim, K. and Kim, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827351 },
  abstract={The emergence of generative AI has also brought significant attention to large language models (LLMs). LLMs are a type of generative AI that can understand users' commands and respond accordingly by generating natural human language text. However, such advancements in LLM technology have also been accompanied by an increase in hostile attempts to use the technology for malicious attacks. For example, some may execute a jailbreak on an LLM, allowing it to generate malicious content, and others can use LLMs to generate vulnerability exploit codes, taking advantage of their powerful capabilities to attempt malicious attacks. Furthermore, there are increasing numbers of cases reported where, once inadvertently entered, personally identifiable information (PII) is used to train LLMs without consent. Preventing the malicious use of LLMs and their unauthorized use of PII requires thoroughly scanning their inputs and outputs. Specifically, LLMs' inputs and outputs need to be checked for the presence of PII, malicious codes, malicious URLs, and commands to execute prompt injections. This paper presents a comprehensive description of the LLM prompt detection system (LPDS) designed to detect the presence of PII, malicious codes, malicious URLs, and prompt injection commands in LLMs' inputs and outputs. The effectiveness of the LPDS in detecting LLMs' unauthorized use of PII and LLM-based malicious attacks is also assessed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827351 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343037,
  title={ LLM-Guided Hybrid Architecture for Autonomous Fire Response: Dialog-Driven Planning in Space and Disaster Missions  -  2025 IEEE World AI IoT Congress (AIIoT) },
  year={2025},
  author={Majumdar, S. and Kirkley, S. E. and Mallik, B. Basu},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105239 },
  abstract={Large Language Models (LLMs) such as GPT, BERT, and Zenext AI’s proprietary platform are rapidly evolving as key enablers of semantic reasoning, dialog-based autonomy, and tradespace exploration in safety-critical domains. This paper investigates the integration of LLM agents with autonomous fire-response vehicles for deployment in space habitats and Earth-based disaster environments. Building on Apaza and Selva’s dialog-agent tradespace framework, we present a use case involving a Mars simulation rover equipped with a voice-enabled LLM agent, ORION-FR, designed for fire diagnostics, procedural guidance, and autonomous actuation. We propose a hybrid optimization architecture that combines reinforcement learning and linear programming (RL+LP) to support constraint-aware planning under high-risk conditions. By bridging natural language interaction, mathematical optimization, and edge-based inference, this work advances the use of generative AI for mission resilience in both extraterrestrial exploration and terrestrial emergency response.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT65859.2025.11105239 },
  booktitle={ 2025 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343038,
  title={ Unleashing Generative Non-Player Characters in Video Games: An AI Act Perspective  -  2024 IEEE Gaming, Entertainment, and Media Conference (GEM) },
  year={2024},
  author={Sas, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10585442 },
  abstract={The increased integration of large language models and generative AI in non-player characters (NPCs) is radically transforming the gaming industry. While these new technologies can enhance the immersiveness of the game experience, generative NPCs also introduce substantial risks of damaging misbehaviour. In this paper, we highlight the role of each actor along the supply chain of generative non-player characters (NPCs) and analyse how the forthcoming AI Act might apply vis-à-vis the allocation of responsibilities. Finally, we highlight unacceptable uses of generative NPCs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GEM61861.2024.10585442 },
  booktitle={ 2024 IEEE Gaming, Entertainment, and Media Conference (GEM) },
  chapter={0}
}

@article{rayyan-352343039,
  title={ LLM-aided explanations of EDA synthesis errors  -  2024 IEEE LLM Aided Design Workshop (LAD) },
  year={2024},
  author={Qiu, S. and Tan, B. and Pearce, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10691721 },
  abstract={Training new engineers in digital design is a challenge, particularly when it comes to teaching the complex electronic design automation (EDA) tooling used in this domain. Learners will typically deploy designs in the Verilog and VHDL hardware description languages to Field Programmable Gate Arrays (FPGAs) from Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus Prime and Vivado, respectively). These tools are complex and difficult to use—yet, as they are the tools used in industry, they are an essential first step in this space. In this work, we examine how recent advances in artificial intelligence may be leveraged to address aspects of this challenge. Specifically, we investigate if Large Language Models (LLMs), which have demonstrated text comprehension and question-answering capabilities, can be used to generate novice-friendly explanations of compile-time synthesis error messages from Quartus Prime and Vivado. To perform this study we generate 936 error message explanations using three OpenAI LLMs over 21 different buggy code samples. These are then graded for relevance and correctness, and we find that in approximately 71% of cases the LLMs give correct & complete explanations suitable for novice learners.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LAD62341.2024.10691721 },
  booktitle={ 2024 IEEE LLM Aided Design Workshop (LAD) },
  chapter={0}
}

@article{rayyan-352343040,
  title={ Engineering LLM Powered Multi-Agent Framework for Autonomous CloudOps  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Parthasarathy, K. and Vaidhyanathan, K. and Dhar, R. and Krishnamachari, V. and Kakran, A. and Akshathala, S. and Arun, S. and Karan, A. and Muhammed, B. and Dubey, S. and Veerubhotla, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030040 },
  abstract={Cloud Operations (CloudOps) is a rapidly growing field focused on the automated management and optimization of cloud infrastructure which is essential for organizations nav-igating increasingly complex cloud environments. MontyCloud Inc. is one of the major companies in the CloudOps domain that leverages autonomous bots to manage cloud compliance, security, and continuous operations. To make the platform more accessible and effective to the customers, we leveraged the use of GenAl. Developing a GenAl-based solution for autonomous CloudOps for the existing MontyCloud system presented us with various challenges such as i) diverse data sources; ii) orchestration of multiple processes and iii) handling complex workflows to automate routine tasks. To this end, we developed MOYA, a multi-agent framework that leverages GenAI and balances autonomy with the necessary human control. This framework integrates various internal and external systems and is optimized for factors like task orchestration, security, and error mitigation while producing accurate, reliable, and relevant insights by utilizing Retrieval Augmented Generation (RAG). Evaluations of our multi-agent system with the help of practitioners as well as using automated checks demonstrate enhanced accuracy, responsiveness, and effectiveness over non-agentic approaches across complex workflows.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00031 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343041,
  title={ Dual-LLM Architecture for Ethical Content Generation  -  2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT) },
  year={2025},
  author={Zimin, E. and Saichik, E. and Arkhipov, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11054126 },
  abstract={The problem of unfiltered LLM content generation presents significant ethical and operational challenges for AI deployment. Large language models, when operating without appropriate safeguards, can generate content containing harmful misinformation, discriminatory language, or inappropriate suggestions that may violate social norms or legal standards. This paper introduces a novel dual-LLM architecture for ensuring ethical content generation in AI systems. Our approach sequentially connects two large language models: a primary LLM for content generation and a secondary LLM functioning as an ethical filter. The secondary model analyzes outputs for ethical violations, implements content replacement strategies, and dynamically reformulates prompts to guide the primary model toward compliant responses. We formalize this architecture using a mathematical framework that defines contextual token management, violation detection metrics, and cache synchronization homomorphisms. The system maintains performance while ensuring ethical compliance through selective cache invalidation and pattern recognition. Experimental results demonstrate a 94% reduction in ethical violations with minimal latency impact (18% increase) compared to traditional LLM filtering approaches. This architecture provides a robust solution for deploying LLMs in sensitive environments where content safety is critical.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/USBEREIT65494.2025.11054126 },
  booktitle={ 2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT) },
  chapter={0}
}

@article{rayyan-352343042,
  title={ Complementary Method for NER by Extracting Proper Nouns from Images when Utilizing LLM  -  2024 IEEE/ACIS 9th International Conference on Big Data, Cloud Computing, and Data Science (BCD) },
  year={2024},
  author={Iwakami, Y. and Takuma, H. and Iwashita, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10743114 },
  abstract={When utilizing Generative AI leveraged with LLM, it is essential to make LLM recognize proper nouns such as product/service names. For extracting them, NER applying other LLM is also considered. However, when enterprises use LLM in daily business such as marketing research, frequent extraction of proper nouns is inevitable, so it is desirable to adopt an easier extracting method in parallel. This paper proposes a new method to extract proper nouns automatically from images such as logos on the Internet.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BCD61269.2024.10743114 },
  booktitle={ 2024 IEEE/ACIS 9th International Conference on Big Data, Cloud Computing, and Data Science (BCD) },
  chapter={0}
}

@article{rayyan-352343043,
  title={ Leveraging Generative AI Tools for Proactive Risk Mitigation in Design  -  2025 Annual Reliability and Maintainability Symposium (RAMS) },
  year={2025},
  author={Hu, Y. and A, A. N. N and Yellamati, D. D. and Goktas, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10935137 },
  abstract={This paper explores how Generative AI can transform Design for Safety & Reliability (DfSR) by proactively identifying and mitigating risks throughout the product development lifecycle. It examines three key approaches to leveraging generative AI in DfSR: Assistive Ai: This approach employs Large Language Models (LLMs) or Large Multimodal Models (LMMs) to interact dynamically with users. While highly flexible and agile, interpretability and control of AI-generated outputs remain areas of concern. Potential applications include providing diverse perspectives during brainstorming sessions. Scripted Ai: This approach uses predefined rules and scripts to automate repetitive tasks to improve the efficiency and consistency. However, its inflexibility limits its effectiveness in complex scenarios. We suggest using Scripted AI to automate routine tasks. Agentic Ai: This approach involves AI systems autonomously executing tasks, demonstrating a higher degree of “agency”. While offering real-time analysis and continuous learning capabilities, ethical considerations and system complexity present challenges. The paper highlights how these approaches can be applied across various stages of the DfSR workflow, from defining requirements and planning to risk assessment, design optimization, and sustainment. Each stage benefits from the unique strengths of each AI approach. We also emphasize the limitations of Generative AI tools. We recommend maintaining human oversight in critical decisions, treating AI as collaborators, and continuously monitoring AI systems for reliability and performance. As AI technology advances, its integration into engineering workflows promises safer, more reliable, and innovative products. Continued research and development in AI will be crucial for realizing the full potential of AI in shaping the future of DfSR.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAMS48127.2025.10935137 },
  booktitle={ 2025 Annual Reliability and Maintainability Symposium (RAMS) },
  chapter={0}
}

@article{rayyan-352343044,
  title={ Improving User Experience for AI Chatbots through LLM Models  -  2024 IEEE/ACS 21st International Conference on Computer Systems and Applications (AICCSA) },
  year={2024},
  author={Khennouche, F. and Elmir, Y. and Djebari, N. and Boubchir, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912523 },
  abstract={This paper introduces an innovative strategy for enhancing the user experience via an AI-powered FAQ chatbot for the Ecole Supérieure en Sciences et Technologies de l'Informatique et du Numérique (ESTIN). By combining multiple Large Language Models (LLMs) such as BART, GPT, and BERT, the standard static FAQ system is converted into a dynamic, interactive interface. Our hybrid approach aims to expose the unique strengths of each model through a multi-phase training process. Initial experimentations have revealed that BERT outperforms other models in handling ESTIN's FAQ dataset, providing better context comprehension and response relevance. We intend to additionally refine the chatbot by studying the effect of different model training sequences. The expected outcome is a scalable and adaptable chatbot that significantly improves user engagement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICCSA63423.2024.10912523 },
  booktitle={ 2024 IEEE/ACS 21st International Conference on Computer Systems and Applications (AICCSA) },
  chapter={0}
}

@article{rayyan-352343045,
  title={ Integrating LLM Text-to-Speech for an Accessible Bible Study Application  -  2025 IEEE World AI IoT Congress (AIIoT) },
  year={2025},
  author={Craver, N. and Bhati, D. and Guercio, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105356 },
  abstract={Bible study is central to many people’s spiritual lives, yet existing digital tools often suffer from outdated design, unnecessary complexity, mandatory internet connectivity, or inadequate note-taking features. This project addresses these challenges with an AI-driven, lightweight, open-source application that seamlessly integrates Bible study with advanced note-taking and an LLM-powered text-to-speech engine for natural-sounding audio. The application is designed for accessibility and ease of use, and it functions fully offline. The LLM-based text-to-speech engine delivers high-quality, natural audio to enhance the study experience. To evaluate its effectiveness, we conducted an expert user study, gathering insights to refine usability and functionality. By combining these features into an intuitive platform, this application offers a modern, user-centered solution for Bible study.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT65859.2025.11105356 },
  booktitle={ 2025 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343046,
  title={ Harnessing Generative AI  -  The AI Edge: Sales Strategies for Unleashing the Power of AI to Save Time, Sell More, and Crush the Competition },
  author={Blount, J. and Iannarino, A.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951223.pdf&bkn=10950183&pdfType=chapter },
  abstract={Summary <p>From text and audio to images and animations, generative AI's capabilities are vast and varied. At the root level, generative AI is built on a large language model (LLM) that learns how to predict, based on statistical probabilities, what the readers want based on the prompt provided it. Essentially, when the readers provide a prompt to generative AI, it reaches into its extensive database to generate content that aligns with the context of their prompt. The richness and accuracy of its output are heavily contingent on the quality and clarity of the prompt readers give it. LLMs undergo extensive training where they ingest vast amounts of data from diverse sources, such as books, websites, articles, and magazines. Generative AI stands at the forefront of digital transformation, offering capabilities that, just a few years ago, seemed like the realm of science fiction. Its potential to revolutionize content creation and data processing is immense.</p>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ The AI Edge: Sales Strategies for Unleashing the Power of AI to Save Time, Sell More, and Crush the Competition },
  chapter={0}
}

@article{rayyan-352343047,
  title={ AI Framework for Fruit Quality Assessment: Integrating CNN-Based Spoilage Detection, Price Estimation, and LLM-Powered Insights  -  2025 Fourth International Conference on Smart Technologies, Communication and Robotics (STCR) },
  year={2025},
  author={Joseph, K. and Thanka, M. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11020263 },
  abstract={The AI utilizes Convolutional Neural Networks (CNNs) combined with Large Language Models (LLMs) to deliver complete fruit-quality evaluation which includes spoilage detection and price assessment. Through deep learning image analysis the system identifies different ripeness stages of fruits at high speed which results in fast spoiled produce detection. The efficiency of the system increases because of LLM functionalities that deliver important product shelf life instructions while supplying preservation methods and proper usage guidelines. The price calculation system employs data-driven rules to measure product worth based on ripeness indicators which creates balanced pricing structure for suppliers and customers. A coalition of advanced evaluation methods and AI automation systems generates optimal fruit quality testing which enhances market evaluations and retail point-of-sale assessments. The proposed method enables both precise and efficient fruit classification as well as promotes sustainable consumption through waste reduction to enhance buying choices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/STCR62650.2025.11020263 },
  booktitle={ 2025 Fourth International Conference on Smart Technologies, Communication and Robotics (STCR) },
  chapter={0}
}

@article{rayyan-352343048,
  title={ Responsible LLM Deployment for High-Stake Decisions by Decentralized Technologies and Human-AI Interactions  -  2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  year={2025},
  author={Sachan, S. and Miller, T. and Nguyen, M. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11154208 },
  abstract={High-stakes domains are exploring the transformative potential of Large Language Models (LLMs) for complex decision-making tasks. However, LLM deployment in real-world settings presents challenges in data security, evaluation of its capabilities outside controlled environments, and accountability attribution in the event of adversarial decisions. This paper proposes a framework for responsible deployment of LLM-based decision-support systems through active human involvement. It integrates interactive collaboration between human experts and developers through multiple iterations at the pre-deployment stage to assess the uncertain samples and judge the stability of the explanation provided by post-hoc XAI techniques. Local LLM deployment within organizations and decentralized technologies, such as Blockchain and IPFS, are proposed to create immutable records of LLM activities for automated auditing to enhance security and trace back accountability. It was tested on Bert-largeuncased, Mistral, and LLaMA 2 & 3 models to assess the capability to support responsible financial decisions on business lending.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHMS65439.2025.11154208 },
  booktitle={ 2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  chapter={0}
}

@article{rayyan-352343049,
  title={ Using LLM Artificial Intelligence Systems as Complex SQL Programming Assistants  -  2024 12th International Conference on Information and Education Technology (ICIET) },
  year={2024},
  author={Pornphol, P. and Chittayasothorn, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542806 },
  abstract={Learning database programming such as SQL programming is a challenging task when the queries become more complex. SQL is a declarative language based on relational calculus which describes the definition of the query results instead of describing the procedure or steps used to obtain the query result. Tutorial sessions using tutorial assistances are generally required to support the learning of advanced part of the language. Recently generative AI systems demonstrated question answering capabilities including programming codes generation. This paper verifies the SQL code generating capabilities of four generative AI systems: Bing, Bard, ChatGPT, and Copilot and their suitability as SQL programming assistants.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIET60671.2024.10542806 },
  booktitle={ 2024 12th International Conference on Information and Education Technology (ICIET) },
  chapter={0}
}

@article{rayyan-352343050,
  title={ Enhancing Result Interpretability of Neural Architecture Search-Assisted Medical AI via Large Language Model  -  IEEE Transactions on Emerging Topics in Computational Intelligence },
  author={Wang, C. and Long, K. and Guo, T. and Yang, Q. and Liu, Y. and Li, P. and Li, Z. and Wang, H. and Ma, L. and Wen, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168895 },
  abstract={NAS can find better solutions by exploring the vast search space for possible architectures and is widely used in medical AI. However, due to its black-box nature, explainability is important for NAS-assisted medical AI applications. In this paper, we design and implement a risk prediction model for amyloidosis (a rare hematological disease) using an evolutionary neural architecture search (ENAS) to automatically find the best model architecture. To improve the professional acceptance of this prediction model among clinicians, we introduce the concept of result interpretability. Meanwhile, we propose a framework for medical AI systems that can interpret results, utilizing a large language model. The realization of the system provides a more feasible way to apply AI-assisted medical diagnosis on a large scale.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TETCI.2025.3607385 },
  booktitle={ IEEE Transactions on Emerging Topics in Computational Intelligence },
  chapter={0}
}

@article{rayyan-352343051,
  title={ When an Old Telecommunication Law Meets Generative AI: the Manifesto to Unbundle AI  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Pawlicka, A. and Pawlicki, M. and Jaroszewska-Choraś, D. and Puchalski, D. and Kozik, R. and Choraś, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10826068 },
  abstract={The emergence and consecutive entrance of Generative AI (particularly ChatGPT) into the mainstream has provoked all kinds of reactions, from excitement to apprehension, but it has not been definitely decided whether it is a boon or a bane yet. We wish to voice the still unmentioned relation between AI accessibility and social injustice. So far, the initial access to tools such as ChatGPT has been free or low-cost. This is predicated on the availability of open-source or inexpensively sourced data. As the value of models hinges upon high quality, diverse data, the demand for it will increase, resulting in the rising costs of its procuration. We worry that the free models will then turn into expensive commodities, limiting their use only to the privileged entities. This potential shift causes major concerns about ethics and social equity, with the concept of unbundling being one of the potential solutions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10826068 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343052,
  title={ AI Oracle: A Blockchain-Powered Oracle for LLMs and AI Agents  -  2025 Crypto Valley Conference (CVC) },
  year={2025},
  author={Fu, S. and Xie, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068814 },
  abstract={Large Language Models (LLMs) such as GPT and similar architectures have revolutionized artificial intelligence by enabling machines to understand and generate human-like text. However, these models are inherently statistical predictors rather than real-time reasoning systems, leading to fundamental limitations in accessing up-to-date information and verifying factual accuracy. This issue is particularly critical in high-stakes domains such as cryptocurrency markets, decentralized finance (DeFi), and autonomous AI agents, where real-time, verifiable, and tamper-proof information is essential for decision-making.In this paper, we introduce AI Oracle, a novel framework that integrates blockchain-powered oracles with LLMs and autonomous agents to ensure real-time access to cryptographically verified knowledge. We compare AI Oracle with both standalone LLMs and retrieval-based systems using the Model Context Protocol (MCP), highlighting significant advantages in factual reliability, adversarial robustness, and interpretability. AI Oracle combines decentralized consensus, immutable storage, and cryptographic attestation to equip AI agents with enhanced resistance to manipulation, hallucination, and misinformation.Beyond architectural improvements, we explore the broader applicability of AI Oracle across domains that require provable correctness and trust—ranging from real-world asset (RWA) tokenization to autonomous agent coordination and decentralized governance. By positioning AI Oracle as a trust-minimized epistemic infrastructure, we propose a new paradigm in AI systems: the fusion of decentralized trust with autonomous reasoning, enabling agents to operate with resilience, transparency, and embedded verifiability across dynamic environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVC65719.2025.00007 },
  booktitle={ 2025 Crypto Valley Conference (CVC) },
  chapter={0}
}

@article{rayyan-352343053,
  title={ Political Bias in Large Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude  -  IEEE Access },
  author={Choudhary, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817610 },
  abstract={Artificial Intelligence large language models have rapidly gained widespread adoption, sparking discussions on their societal and political impact, especially for political bias and its far-reaching consequences on society and citizens. This study explores the political bias in large language models by conducting a comparative analysis across four popular AI models—ChatGPT-4, Perplexity, Google Gemini, and Claude. This research systematically evaluates their responses to politically charged prompts and questions from the Pew Research Center’s Political Typology Quiz, Political Compass Quiz, and ISideWith Quiz. The findings revealed that ChatGPT-4 and Claude exhibit a liberal bias, Perplexity is more conservative, while Google Gemini adopts more centrist stances based on their training data sets. The presence of such biases underscores the critical need for transparency in AI development and the incorporation of diverse training datasets, regular audits, and user education to mitigate any of these biases. The most significant question surrounding political bias in AI is its consequences, particularly its influence on public discourse, policy-making, and democratic processes. The results of this study advocate for ethical implications for the development of AI models and the need for transparency to build trust and integrity in AI models. Additionally, future research directions have been outlined to explore and address the complex AI bias issue.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3523764 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343054,
  title={ "Revolutionizing Farming: GAN-Enhanced Imaging, CNN Disease Detection, and LLM Farmer Assistant"  -  2024 2nd International Conference on Computer, Communication and Control (IC4) },
  year={2024},
  author={Dhavale, C. and Pawar, T. and Singh, A. and Pole, S. and Sabat, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10486501 },
  abstract={Crop disease recognition is a crucial aspect of modern agriculture that can significantly impact crop yield, quality, and overall food security. This paper introduces an innovative approach to crop disease recognition and farmer support by combining Generative AI and Langchain Llama Model for chatbot development. In the proposed system, Generative AI, specifically deep learning models, are employed to analyze images of crop leaves for early signs of diseases. This approach enhances the accuracy and efficiency of disease diagnosis, enabling farmers to take timely corrective actions and reduce the use of pesticides. A Generative Adversarial Network (GAN) is employed for image augmentation due to the limited dataset size. A Convolutional Neural Network (CNN) is utilized for precise crop disease recognition based on image analysis. To bridge the gap between technology and farmers, the Langchain Llama Model, a state-of-the-art conversational AI model, is integrated to create an interactive and user-friendly chatbot interface. The results of this research project demonstrate the potential of cutting-edge AI technology to transform agriculture, making it more accessible, efficient, and environmentally friendly. By empowering farmers with a sophisticated chatbot interface, this system paves the way for a smarter and more sustainable agricultural future.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC457434.2024.10486501 },
  booktitle={ 2024 2nd International Conference on Computer, Communication and Control (IC4) },
  chapter={0}
}

@article{rayyan-352343055,
  title={ Towards Responsible Generative AI: A Reference Architecture for Designing Foundation Model Based Agents  -  2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) },
  year={2024},
  author={Lu, Q. and Zhu, L. and Xu, X. and Xing, Z. and Harrer, S. and Whittle, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628258 },
  abstract={Foundation models, such as large language models (LLMs), have been widely recognised as transformative AI technologies due to their capabilities to understand and generate content, including plans with reasoning capabilities. Foundation model based agents derive their autonomy from the capabilities of foundation models, which enable them to autonomously break down a given goal into a set of manageable tasks and orchestrate task execution to meet the goal. Despite the huge efforts put into building foundation model based agents, the architecture design of the agents has not yet been systematically explored. Also, while there are significant benefits of using agents for planning and execution, there are serious considerations regarding responsible AI related software quality attributes, such as security and accountability. Therefore, this paper presents a pattern-oriented reference architecture that serves as guidance when designing foundation model based agents. We evaluate the completeness and utility of the proposed reference architecture by mapping it to the architecture of two real-world agents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C63560.2024.00028 },
  booktitle={ 2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343056,
  title={ Explainable Anomaly Detection Method Using LLM Embeddings Model with SHAP  -  2024 7th International Conference on Signal Processing and Information Security (ICSPIS) },
  year={2024},
  author={Matsumura, T. and Okada, S. and Watarai, K. and Mitsunaga, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812623 },
  abstract={In recent years, the black-box nature of AI models in anomaly detection using log data has raised concerns about reliability and transparency. Conventional text-based anomaly detection methods have relied on structuring logs using log parsers and extracting features with techniques such as Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec. How the AI model determines whether abnormal logs or not provides valuable clues for responding after detection. However, these methods depend on word frequency, making it difficult to explain the basis for anomaly detection decisions clearly. In this study, we propose a method to increase the transparency and interpretability of the model and clarify the criteria for anomaly detection by identifying features to contribute using Shapley Additive Explanations (SHAP). Our proposed method uses vectorized log data event templates using OpenAI Embeddings, which can be visually represented while achieving a high detection rate. To our knowledge, this study contributes to improving the interpretability and transparency of models by utilizing the Large Language Models (LLM) Embeddings Model for feature extraction, plotting them in a reduced-dimensional coordinate space using principal component analysis (PCA), and enhancing explainability using SHAP.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSPIS63676.2024.10812623 },
  booktitle={ 2024 7th International Conference on Signal Processing and Information Security (ICSPIS) },
  chapter={0}
}

@article{rayyan-352343057,
  title={ Descriptor: Benchmark Dataset for Generative AI on Edge Devices (BeDGED)  -  IEEE Data Descriptions },
  author={Nezami, Z. and Hafeez, M. and Djemame, K. and Zaidi, S. A. R. and Xu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10930751 },
  abstract={The rise of large language models (LLMs) has transformed natural language processing (NLP) and generative artificial intelligence (AI) applications. However, deploying these transformer-based models in resource-constrained environments poses a significant challenge due to their high computational and memory demands. To address this, we introduce in this article generative AI (GenAI) on the Edge, a comprehensive benchmarking dataset designed to evaluate the performance of LLMs deployed on edge devices. Leveraging a distributed testbed of Raspberry Pi 5 devices orchestrated with lightweight Kubernetes (K3s), the dataset captures a broad range of performance metrics essential for assessing the feasibility of local inference in constrained environments. These metrics include detailed measurements of throughput, inference latency, memory utilization, and computational efficiency, along with granular timing data for key stages of the inference pipeline—sample, prefill, and decode phases. We systematically evaluate LLMs of varying sizes under real-world deployment scenarios, with a particular emphasis on CPU-based edge platforms. By conducting multiple runs of conversation-based evaluations, GenAI on the Edge provides actionable insights into the tradeoffs between performance and resource efficiency, enabling better decision-making for LLM deployment in edge environments. IEEE SOCIETY/COUNCIL Communications Society (ComSoc) DATA TYPE/LOCATION Structured Text Data (CSV); Leeds, U.K. DATA DOI/PID 10.21227/7d08-8655},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEEDATA.2025.3552083 },
  booktitle={ IEEE Data Descriptions },
  chapter={0}
}

@article{rayyan-352343058,
  title={ AI-Driven Network Configuration and Operation  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Ficzere, D. and Varga, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073726 },
  abstract={The recent advancements in network automation, powered by AI and Generative AI, have created new opportunities to automate both network configuration and operations. This paper outlines the main focus areas of my proposed PhD dissertation, which centers on using AI to streamline network configuration and improve operational efficiency. My research aims to develop solutions for automating network configurations through Generative AI, as well as leveraging AI technologies to enhance Intent-Based Networking functionalities. By integrating AI-driven approaches, my work seeks to address key challenges, including automating network configurations with Large Language Models and developing effective anomaly detection techniques in cellular network traffic.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073726 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343059,
  title={ Building Data-Driven Applications with LlamaIndex: A practical guide to retrieval-augmented generation (RAG) to enhance LLM applications  -  Building Data-Driven Applications with LlamaIndex: A practical guide to retrieval-augmented generation (RAG) to enhance LLM applications },
  author={Gheorghiu, A.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10540158.pdf&bkn=10540158&pdfType=book },
  abstract={Solve real-world problems easily with artificial intelligence (AI) using the LlamaIndex data framework to enhance your LLM-based Python applications Key FeaturesExamine text chunking effects on RAG workflows and understand security in RAG app developmentDiscover chatbots and agents and learn how to build complex conversation enginesBuild as you learn by applying the knowledge you gain to a hands-on projectBook DescriptionDiscover the immense potential of Generative AI and Large Language Models (LLMs) with this comprehensive guide. Learn to overcome LLM limitations, such as contextual memory constraints, prompt size issues, real-time data gaps, and occasional ‘hallucinations’. Follow practical examples to personalize and launch your LlamaIndex projects, mastering skills in ingesting, indexing, querying, and connecting dynamic knowledge bases. From fundamental LLM concepts to LlamaIndex deployment and customization, this book provides a holistic grasp of LlamaIndex's capabilities and applications. By the end, you'll be able to resolve LLM challenges and build interactive AI-driven applications using best practices in prompt engineering and troubleshooting Generative AI projects.What you will learnUnderstand the LlamaIndex ecosystem and common use casesMaster techniques to ingest and parse data from various sources into LlamaIndexDiscover how to create optimized indexes tailored to your use casesUnderstand how to query LlamaIndex effectively and interpret responsesBuild an end-to-end interactive web application with LlamaIndex, Python, and StreamlitCustomize a LlamaIndex configuration based on your project needsPredict costs and deal with potential privacy issuesDeploy LlamaIndex applications that others can useWho this book is forThis book is for Python developers with basic knowledge of natural language processing (NLP) and LLMs looking to build interactive LLM applications. Experienced developers and conversational AI developers will also benefit from the advanced techniques covered in the book to fully unleash the capabilities of the framework.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Building Data-Driven Applications with LlamaIndex: A practical guide to retrieval-augmented generation (RAG) to enhance LLM applications },
  chapter={0}
}

@article{rayyan-352343060,
  title={ Mitigating Biased, Brittle and Baroque Generative AI  -  2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  year={2025},
  author={Maybury, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114038 },
  abstract={The rapid adoption of Generative AI across multiple use cases has introduced new risks and attack surfaces across a range of important applications. While the increasing competency of Large Language Models (LLMs) promises high value, responsible AI requires the mitigation of potentially biased, brittle, and baroque operations which undermine trust and carry the potential of causing harm. Moreover, active adversaries will exploit LLM weaknesses to undermine confidentiality, integrity, and availability. Encompassing a survey of current LLM performance and risk literature, this paper presents a framework for understanding the current state of the art and a complementary path forward. In particular, the framework enables designers, users, and policymakers to understand and assess categorized risks and suggests methods to mitigate weaknesses during design and deployment in order to create LLMs that are less likely to fail and more resilient to attacks. It also suggests methods to use existing but imperfect LLMs in a responsible manner.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAD65464.2025.11114038 },
  booktitle={ 2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  chapter={0}
}

@article{rayyan-352343061,
  title={ Collaborative Lightweight LLM Agents for Daily Activity Summarization on Edge Devices  -  2025 21st International Conference on Intelligent Environments (IE) },
  year={2025},
  author={Inohara, K. and Amano, T. and Rizk, H. and Yamaguchi, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130095 },
  abstract={This paper presents a privacy-preserving monitoring system for elderly individuals living alone, utilizing collaborative lightweight Large Language Model (LLM) agents deployed on edge devices. The system integrates non-invasive sensors with a novel three-agent architecture: an activity recognition agent processes sensor data, an hourly summarization agent generates intermediate reports in 3-hour segments, and a daily summarization agent produces comprehensive summaries. Our evaluation on real-world data from two elderly households demonstrates that the system achieves 95.8% accuracy in activity recognition and generates natural language summaries comparable to GPT-4o, while maintaining privacy through local processing on affordable Raspberry Pi hardware. The results indicate that our approach effectively balances monitoring accuracy, summary quality, and practical deployment constraints, making it suitable for widespread adoption in elderly care applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IE64880.2025.11130095 },
  booktitle={ 2025 21st International Conference on Intelligent Environments (IE) },
  chapter={0}
}

@article{rayyan-352343062,
  title={ A Novel AI System for Trustworthy and Accurate Diagnostics and Troubleshooting  -  2025 IEEE Integrated STEM Education Conference (ISEC) },
  year={2025},
  author={Li, M. Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147314 },
  abstract={The emergence of large-language models (LLMs) in everyday applications has highlighted their capability to provide human-like dialog and answer complex questions. However, LLMs often exhibit a tendency to "hallucinate," generating responses that appear factual but are incorrect, even when trained on ground truth data. In high-stakes applications such as medical diagnostics and mechanical troubleshooting, the need for accurate, trustworthy, and explainable AI systems is paramount. Without these qualities, such systems cannot be fully relied upon for critical decision-making. In this paper, we propose a novel AI system designed to address these challenges. The system integrates an AI agent, a logic model, an LLM, and a prompt engine to enhance accuracy and trustworthiness in a sequence of dialog. Experimental results demonstrate that the proposed system achieves an average accuracy of 86.49% across three diagnostic and troubleshooting tasks in healthcare, automotive maintenance, and digital equipment applications. In contrast, the baseline LLM only approach achieves an average accuracy of 63.42%, representing an absolute accuracy improvement of 23.07% with our approach. Additionally, the proposed system achieves a 4.26-fold speedup in response time across the experiments. These results highlight the potential of the proposed system to enhance reliability and efficiency in critical real-world applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISEC64801.2025.11147314 },
  booktitle={ 2025 IEEE Integrated STEM Education Conference (ISEC) },
  chapter={0}
}

@article{rayyan-352343063,
  title={ Context-based Semantic Caching for LLM Applications  -  2024 IEEE Conference on Artificial Intelligence (CAI) },
  year={2024},
  author={Mohandoss, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605418 },
  abstract={Large Language Models (LLM), aided by the popularity of ChatGPT, have provided a paradigm shift to engineering AI Chatbots. LLMs offer many conveniences to the AI engineer, and the most important benefit is their robustness in handling semantic matches of user queries. In other words, an engineer building an AI conversational assistant does not need to train the agent for semantic user query matches explicitly. This benefit comes with a cost, which is felt in two ways. Firstly, LLMs need an expensive infrastructure like GPUs, large RAMs, etc. Secondly, even with all the cutting-edge infrastructure, their response time will not be sub-second anytime soon. So, AI applications that use LLMs are likely to be expensive and suffer from high latency. One way to reduce cost and response time is by introducing a caching solution between the LLMs and the UX layer. Such a caching layer can help minimize calls to LLMs when the queries are similar and repetitive. However, traditional caching methods cannot be used as they are for LLM-based applications. The reason is that queries handled by AI-based conversational assistants are unstructured, i.e., free-flowing user-generated text, and will not always be context-free. In other words, end users tend to query from their point of view. Existing solutions like GPTCache work well for context-free questions, but caching context-sensitive user queries needs an evolved design. In this paper, we shall explore a novel design that, by exploiting the power of context, shall provide effective caching solutions to user-generated queries (both context-free and context-sensitive) that offer improved performance without compromising on the quality of response.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI59869.2024.00075 },
  booktitle={ 2024 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343064,
  title={ Securing LLM Workloads With NIST AI RMF in the Internet of Robotic Things  -  IEEE Access },
  author={Karim, H. and Gupta, D. and Sitharaman, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10965643 },
  abstract={The Internet of Robotic Things (IoRT) is revolutionizing industries by enabling autonomous, AI-driven robotic systems to perform complex and collaborative tasks, such as precision agriculture, disaster response, and logistic shipping operations. However, integrating AI into IoRT introduces significant challenges, including security vulnerabilities, adversarial attacks, data integrity risks, and operational disruptions in dynamic and high-stakes environments. This paper addresses these challenges by integrating and enhancing the NIST AI Risk Management Framework (AI RMF) for IoRT systems, providing a structured approach to identify, assess, and mitigate risks specific to IoRT ecosystems. We introduce a novel Large Language Model (LLM)-based approach for translating natural language commands into secure and precise robotic operations, enabling seamless collaboration and enhancing safety and reliability in mission-critical scenarios. Using a flood recovery scenario in precision agriculture, we demonstrate the practical application of these solutions, where swarm robots equipped with AI inference engines collaborate to navigate hazards, locate individuals, assess infrastructure damage, and mitigate risks. A comprehensive threat analysis is presented, mapping identified vulnerabilities to the NIST AI RMF, and tailored security controls are proposed to mitigate these threats effectively. We propose critical enhancements to the framework, including advanced quantitative risk assessment methods, subsystem governance strategies for interconnected IoRT networks, and robust auditing mechanisms to address unique IoRT-specific challenges. This work establishes a robust foundation for aligning AI governance frameworks with the complex and dynamic demands of IoRT systems. By addressing security, operational, and ethical considerations, it fosters secure, efficient, and trustworthy deployment across diverse applications, paving the way for sustainable and impactful IoRT innovations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3561235 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343065,
  title={ Building LLM Powered Applications: Create intelligent apps and agents with large language models  -  Building LLM Powered Applications: Create intelligent apps and agents with large language models },
  author={Alto, V.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10540154.pdf&bkn=10540154&pdfType=book },
  abstract={Get hands-on with GPT 3.5, GPT 4, LangChain, Llama 2, Falcon LLM and more, to build LLM-powered sophisticated AI applicationsKey FeaturesEmbed LLMs into real-world applicationsUse LangChain to orchestrate LLMs and their components within applicationsGrasp basic and advanced techniques of prompt engineeringBook DescriptionBuilding LLM Powered Applications delves into the fundamental concepts, cutting-edge technologies, and practical applications that LLMs offer, ultimately paving the way for the emergence of large foundation models (LFMs) that extend the boundaries of AI capabilities. The book begins with an in-depth introduction to LLMs. We then explore various mainstream architectural frameworks, including both proprietary models (GPT 3.5/4) and open-source models (Falcon LLM), and analyze their unique strengths and differences. Moving ahead, with a focus on the Python-based, lightweight framework called LangChain, we guide you through the process of creating intelligent agents capable of retrieving information from unstructured data and engaging with structured data using LLMs and powerful toolkits. Furthermore, the book ventures into the realm of LFMs, which transcend language modeling to encompass various AI tasks and modalities, such as vision and audio. Whether you are a seasoned AI expert or a newcomer to the field, this book is your roadmap to unlock the full potential of LLMs and forge a new era of intelligent machines.What you will learnExplore the core components of LLM architecture, including encoder-decoder blocks and embeddingsUnderstand the unique features of LLMs like GPT-3.5/4, Llama 2, and Falcon LLMUse AI orchestrators like LangChain, with Streamlit for the frontendGet familiar with LLM components such as memory, prompts, and toolsLearn how to use non-parametric knowledge and vector databasesUnderstand the implications of LFMs for AI research and industry applicationsCustomize your LLMs with fine tuningLearn about the ethical implications of LLM-powered applicationsWho this book is for Software engineers and data scientists who want hands-on guidance for applying LLMs to build applications. The book will also appeal to technical leaders, students, and researchers interested in applied LLM topics. We don’t assume previous experience with LLM specifically. But readers should have core ML/software engineering fundamentals to understand and apply the content.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Building LLM Powered Applications: Create intelligent apps and agents with large language models },
  chapter={0}
}

@article{rayyan-352343066,
  title={ Navigating the AI Frontier: A Critical Literature Review on Integrating Artificial Intelligence into Software Engineering Education  -  2024 36th International Conference on Software Engineering Education and Training (CSEE&T) },
  year={2024},
  author={Sah, C. K. and Xiaoli, L. and Islam, M. M. and Islam, M. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10663054 },
  abstract={The swift development of Artificial Intelligence (AI), namely the introduction of Large Language Models (LLMs), is drastically altering various industries and necessitating a major change in the way software engineering is taught. To equip upcoming software engineers with the knowledge and abilities to function in this AI-powered environment, curriculum and pedagogical techniques must be critically reevaluated. To better understand the integration of AI and LLMs into software engineering education, this study gives a thorough and critical analysis of the literature, looking at existing models, pedagogical frameworks, and enduring issues. We explore various approaches utilized by educational establishments, including as specialized AI and LLM courses, incorporating modules into pre-existing curricula, and utilizing open-source LLM materials. Our analysis, which is based on case studies and research data, thoroughly assesses how well these strategies enable software engineers to comprehend, make use of, and ethically create AI and LLMs. Key obstacles to the successful integration of AI and LLM are also identified by our analysis, including the inexperienced status of LLM educators, resource limitations, potential biases in AI and LLM algorithms, and insufficient instructor knowledge. Building on these discoveries, we provide solid answers to these problems and suggest interesting avenues for further study to improve the integration of AI and LLM. In the end, this study advocates for a multimodal strategy to get future software engineers ready for the impending AI and LLM future and secure their place in this quickly changing field.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSEET62301.2024.10663054 },
  booktitle={ 2024 36th International Conference on Software Engineering Education and Training (CSEE&T) },
  chapter={0}
}

@article{rayyan-352343067,
  title={ EcoSmartGuide: Language Learning Model and Retrieval-Augmented Generation-Based Platform for Streamlined Environmental, Social, and Governance Information Access and Report Generation  -  2024 IEEE 6th Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS) },
  year={2024},
  author={Yang, J. -Y. and -h. Chi, R. and Wu, C. -C. and Chen, L. -J. and Lin, W. -M. and Hu, H. -W. and Cheng, H. -R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10885500 },
  abstract={EcoSmartGuide leverages the Language Learning Model (LLM) and Retrieval-Augmented Generation-based (RAG) architectures to streamline Environmental, Social, and Governance (ESG) reporting, automating data aggregation and analysis. It shows a citation accuracy of 95% in reflecting ESG metrics and a coverage rate of 76.23% in the representation of ESG performance. Stakeholder feedback indicates high user satisfaction and improved decision-making processes. In a case study, EcoSmartGuide's effectiveness is demonstrated in identifying overlooked risks and enhancing decisions. The platform showcases AI's transformative potential in sustainability reporting and decision-making efficiently and accurately. Future research is needed to prioritize longitudinal studies, technological advancements, and diverse industry applications to ensure broader applicability and relevance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECBIOS61468.2024.10885500 },
  booktitle={ 2024 IEEE 6th Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS) },
  chapter={0}
}

@article{rayyan-352343068,
  title={ Research on DeepSeek-Oriented Benchmarking Methods for AI Inference Accelerators  -  2025 7th International Conference on Electronics and Communication, Network and Computer Technology (ECNCT) },
  year={2025},
  author={Qiu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11172499 },
  abstract={With the rapid shift of large model technology focus from training to inference, evaluating the performance of domestic AI accelerators in inference scenarios has become critical for building intelligent computing infrastructure. To tackle this, this paper proposes a multi-dimensional evaluation methodology for benchmarking AI accelerator inference performance, based on the DeepSeek-R1 series of models. Through quantitative analysis of how hardware parameters (computing power, memory bandwidth, interconnect bandwidth) and quantization schemes impact inference efficiency, this study provides empirical evidence to support the selection of domestic hardware options. Experimental results indicate that memory bandwidth is a primary bottleneck for large model decoding throughput, while INT8 quantization enables approximately 2x throughput gains compared to FP16 precision. This research offers valuable insights for hardware selection and performance optimization in intelligent computing centers, thereby enhancing the competitiveness of domestic AI accelerators in the inference market.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECNCT66493.2025.11172499 },
  booktitle={ 2025 7th International Conference on Electronics and Communication, Network and Computer Technology (ECNCT) },
  chapter={0}
}

@article{rayyan-352343069,
  title={ TSDCG: Tabular Synthetic Data with Code Generation LLMs  -  2025 3rd International Conference on Inventive Computing and Informatics (ICICI) },
  year={2025},
  author={Mathur, A. and Shah, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069449 },
  abstract={In the past years, there has been significant research on generating synthetic data, especially using Generative AI. Data engineering and analysis play crucial roles for any business in the study of past trends and forecasting future trends. However, real-world data often contains biases, missing values, and duplications, which limits its effectiveness in variety of tasks. Such issues can lead to model overfitting, underfitting, and poor generalization while training. To address these challenges, there has been extensive research on various GAN and LLM architectures and their ability to generate high quality synthetic data. This paper introduces and investigates a novel approach of using code-generating LLMs and advanced data profiling, in generating high quality synthetic data to enhance the speed and quality of the data generated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICICI65870.2025.11069449 },
  booktitle={ 2025 3rd International Conference on Inventive Computing and Informatics (ICICI) },
  chapter={0}
}

@article{rayyan-352343070,
  title={ Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors  -  2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  year={2025},
  author={Dupuis, N. and Nair, R. and Ramji, S. and McClintock, S. and Chauhan, N. and Nagpal, P. and Blaner, B. and Valk, K. and Stok, L. and Puri, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105981 },
  abstract={The use of Large Language Models (LLMs) in hardware design has taken off in recent years, principally through its incorporation in tools that increase chip designer productivity. There has been considerable discussion about the use of LLMs in RTL specifications of chip designs, for which the two most popular languages are Verilog and VHDL. LLMs and their use in Verilog design has received significant attention due to the higher popularity of the language, but little attention so far has been given to VHDL despite its continued popularity in the industry. There has also been little discussion about the unique needs of organizations that engage in high-performance processor design, and techniques to deploy AI solutions in these settings. In this paper, we describe our journey in developing a Large Language Model (LLM) specifically for the purpose of explaining VHDL code, a task that has particular importance in an organization with decades of experience and assets in high-performance processor design. We show how we developed test sets specific to our needs and used them for evaluating models as we performed extended pretraining (EPT) of a base LLM. Expert evaluation of the code explanations produced by the EPT model increased to 69% compared to a base model rating of 43%. We further show how we developed an LLM-as-a-judge to gauge models similar to expert evaluators. This led us to deriving and evaluating a host of new models, including an instruction-tuned version of the EPT model with an expected expert evaluator rating of 71%. Our experiments also indicate that with the potential use of newer base models, this rating can be pushed to 85% and beyond. We conclude with a discussion on further improving the quality of hardware design LLMs using exciting new developments in the Generative AI world.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLAD65226.2025.00035 },
  booktitle={ 2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  chapter={0}
}

@article{rayyan-352343071,
  title={ Themes of Building LLM-Based Applications for Production: A Practitioner's View  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Mailach, A. and Simon, S. and Dorn, J. and Siegmund, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030002 },
  abstract={Background: Large language models (LLMs) have become a paramount interest of researchers and practitioners alike, yet a comprehensive overview of key considerations for those developing LLM-based systems is lacking. This study addresses this gap by collecting and mapping the topics practitioners discuss online, offering practical insights into where priorities lie in developing LLM-based applications. Method: We collected 189 videos from 2022 to 2024 by practitioners actively developing such systems and discussing various aspects they encounter during development and deployment of LLMs in production. We analyzed the transcripts using BERTopic, then manually sorted and merged the generated topics into themes, leading to a total of 20 topics in 8 themes. Results: The most prevalent topics fall within the theme Design & Architecture, with a strong focus on retrieval-augmented generation (RAG) systems. Other frequently discussed topics include model capabilities and enhancement techniques (e.g., finetuning, prompt engineering), infrastructure and tooling, and risks and ethical challenges. Implications: Our results highlight current discussions and challenges in deploying LLMs in production. This way, we provide a systematic overview of key aspects practitioners should be aware of when developing LLM-based applications. We further highlight topics of interest for academics where further research is needed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/CAIN66642.2025.00011 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343072,
  title={ Leveraging Generative AI for Architecture Knowledge Management  -  2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) },
  year={2024},
  author={Dhar, R. and Vaidhyanathan, K. and Varma, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628192 },
  abstract={While documenting Architectural Knowledge (AK) is crucial, it is frequently neglected in many projects, and existing manual tools are underutilized. Although undocumented, Archi-tecture Knowledge (AK) is dispersed across various sources such as source code, documentation, and runtime logs. To address this, automated tools for efficient AK extraction and documentation are essential. Even after generating AK, navigating through vast the Architectural Records can be overwhelming. Building on that, we propose an automated Architectural Knowledge Management (AKM) System using Information Extraction and Generative AI, which generates AK from various source for a given system and answers architectural queries with respect to the given system. The development of an efficient Architectural Knowledge Management (AKM) system, which is both effective and user-friendly, entails the resolution of numerous challenges. It requires consolidating diverse AK data sources scattered across code, dia-grams, repository commits, and online platforms. The integration of Multimodal AI for AK extraction, incorporation of global AK, and leveraging Generative AI for AK documentation further compounds the problem. Moreover, generating contextually appropriate query responses adds another layer of complexity. To this end, we performed an initial exploratory study on generating Architectural Design Decisions using generative Large Language Models (LLM) in the context of Architecture Decision Records (ADR). Our initial results have been promising indicating the potential impact of GenAI for architectural knowledge management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C63560.2024.00034 },
  booktitle={ 2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343073,
  title={ In-Progress: Augmenting Explainable AI with LLMs to Enhance User Trust in Intelligent Transportation Systems  -  2025 IEEE Security and Privacy Workshops (SPW) },
  year={2025},
  author={Gyawali, S. and Jiang, Y. and Huang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050799 },
  abstract={Vehicular communication networks increasingly rely on automated systems for misbehavior detection; however, the opacity of machine learning models can diminish user trust. This paper introduces a novel framework that integrates Explainable Artificial Intelligence (XAI) with Large Language Models (LLMs) to deliver transparent, user-friendly explanations for misbehavior detection outcomes. Our approach utilizes XAI to quantify the contribution of individual features, providing clear, visual insights into model decision-making. Additionally, an LLM, augmented with contexts from SHAP and vector database, is employed to convert technical SHAP outputs into accessible natural language explanations. This ensures non-expert users, such as network operators or regulatory personnel, can understand and trust the system's predictions. Experimental evaluations on realistic vehicular network datasets demonstrate that our integrated approach sustains high detection performance while significantly enhancing explainability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPW67851.2025.00051 },
  booktitle={ 2025 IEEE Security and Privacy Workshops (SPW) },
  chapter={0}
}

@article{rayyan-352343074,
  title={ Integrating ChatGPT-4: A Novel XAI Interface for Enhanced Clinician Understanding of MRI Image Segmentation Results  -  2024 IEEE 37th International Symposium on Computer-Based Medical Systems (CBMS) },
  year={2024},
  author={Grillo, G. and Torda, T. and Voena, C. and Ciardiello, A. and Giagu, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10601103 },
  abstract={The poor explainability or interpretability of deep learning makes it difficult to introduce these technologies into the hospital workflow. Explainable Artificial Intelligence (XAI) addresses this problem by providing interpretable explanations of AI decisions. We present a system that employs large language models (LLM) with an image-to-text approach, converting AI results of medical segmentation into understandable natural language descriptions. This study first explores how ChatGPT-4 can interpret and describe Magnetic Resonance Image (MRI) brain scans and their segmentations both without previous input and with specific details. In particular, the effectiveness of 'prompt engineering' in improving the accuracy and relevance of language-based artificial intelligence model responses was investigated. Through a series of controlled experiments, we aim to demonstrate how the accurate and strategic formulation of prompts can significantly influence the behaviour of even ChatGPT-4, highlighting its potential but above all the care required when using it. Simultaneously, a user-friendly interface was developed to facilitate interactions between radiologists and the AI segmentation model via ChatGPT-4 generated explanations. This integrated approach aims to improve the reliability, transparency, and usability of AI-supported medical image analysis, potentially leading to more informed clinical decisions and better patient outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CBMS61543.2024.00060 },
  booktitle={ 2024 IEEE 37th International Symposium on Computer-Based Medical Systems (CBMS) },
  chapter={0}
}

@article{rayyan-352343075,
  title={ Generative AI in Phishing Detection: Insights and Research Opportunities  -  2024 Cyber Awareness and Research Symposium (CARS) },
  year={2024},
  author={Perera, O. and Grob, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778758 },
  abstract={Phishing is a method of cyberattack that exploits social engineering tactics to deceive individuals into revealing sensitive information. As phishing tactics become more sophisticated, phishing detection gains a new perspective in cyber security research. This paper explores the potential of Generative AI and Large Language Models (LLMs), in enhancing phishing detection capabilities. This study conducted a literature search in arXiv and IEEE Xplore digital databases with key phrases "LLM phishing detection", "Generative AI phishing detection" to discover insights and identify novel research opportunities in phishing detection. The results outline the current state of research, offering relevant insights to cybersecurity professionals and researchers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CARS61786.2024.10778758 },
  booktitle={ 2024 Cyber Awareness and Research Symposium (CARS) },
  chapter={0}
}

@article{rayyan-352343076,
  title={ Multi-Text-Reading References Recommendation Method of Learning Traditional Chinese Literary Using Large Language Model AI Assistant  -  2025 4th International Symposium on Computer Applications and Information Technology (ISCAIT) },
  year={2025},
  author={Feng, C. and Chen, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11010329 },
  abstract={Large Language Model (LLM) based AI assistants are being widely applied in the academic field of education. This article aims to address the difficulties encountered by vocational college students in learning classical Chinese literature, for they may easily lose their interest and motivation while dealing with such difficult grammar and semantics. Considering of our teaching objectives and educational intentions, based on the cultural and Interesting characteristics of classical Chinese historical biographical literature works, and exploiting advantages of multi-text-reading teaching and learning instructions, we use the ChatGPT-like LLM AI assistants’ abilities of natural language understanding, logical reasoning, and content generation to design variables, rules, and algorithms for a multi-text-reading reading literature recommendation model for teaching and learning of classical Chinese historical biographical literature works from seven dimensions. A chain prompt engineering template is also designed for the ChatGPT-like LLMs. The experimental results show that the recommendation model and template we designed have a high degree of fit with our teaching objectives.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAIT64916.2025.11010329 },
  booktitle={ 2025 4th International Symposium on Computer Applications and Information Technology (ISCAIT) },
  chapter={0}
}

@article{rayyan-352343077,
  title={ Enhancing Control of Large Language Model-based AI Systems Through Declarative Memory  -  2025 International Wireless Communications and Mobile Computing (IWCMC) },
  year={2025},
  author={Omri, S. and Abdelkader, M. and Hamdi, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059638 },
  abstract={Large Language Models (LLMs) have revolutionized numerous domains by demonstrating exceptional reasoning, problem-solving, and response-generation capabilities. Despite their impressive performance, concerns persist regarding their alignment with human values and the potential for unintended behaviors when optimizing objectives. Traditional alignment methods like Reinforcement Learning from Human Feedback (RLHF) face computational and stability challenges, necessitating alternative solutions. Inspired by cognitive science, this paper introduces a Declarative Memory Module (DMM) to guide LLM decision-making. It comprises Semantic Memory, which provides ethical principles and strategies, and Episodic Memory, which recalls past experiences to reinforce or discourage actions. By explicitly integrating these elements, our approach enhances AI alignment with predefined human preferences. Experiments in game-theoretic contexts using multiple LLM models demonstrate that DMM significantly improves their alignment with human preferences, offering a promising step toward more controllable and trustworthy AI systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IWCMC65282.2025.11059638 },
  booktitle={ 2025 International Wireless Communications and Mobile Computing (IWCMC) },
  chapter={0}
}

@article{rayyan-352343078,
  title={ LevelEval: Adaptive Pipeline for Evaluating LLM as a Judge - Analysis on Open LLMs as Judges  -  2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  year={2024},
  author={Boyapati, M. and Meesala, L. and Aygun, R. and Franks, B. and Choi, H. and Riordan, S. and Modgil, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990083 },
  abstract={This paper presents LevelEval, an automated pipeline to evaluate LLMs as judges, mainly using state-of-the-art pretrained models. The research investigates on how open LLMs with fewer parameters compare to GPT-4. The LevelEval pipeline involves: i) generating outputs of different quality using a task-oriented LLM, ii) evaluating and scoring these outputs on a scale by an LLM judge using a rubric, iii) categorizing the scores into ranks to assess the LLM judges' performance. LevelEval is applied to four tasks: summarization, question answering, retrieval augmentation, and bias classification. The datasets are tailored for evaluation and can serve as benchmarks. Overall, the experiments highlight the effectiveness of LevelEval in evaluating LLMs and offer insights into the judging abilities of open LLMs with smaller parameters.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxDKE63520.2024.00020 },
  booktitle={ 2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  chapter={0}
}

@article{rayyan-352343079,
  title={ Adoption of Generative AI and Large Language Models in Education: A Short Review  -  2025 International Conference on Electronics, Information, and Communication (ICEIC) },
  year={2025},
  author={Zualkernan, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10879632 },
  abstract={This paper provides a short review of factors that may have a potential impact on the adoption of Generative AI (GenAI) and Large Language Models (LLMs) within various educational contexts. By examining recent empirical studies based on Technology Adoption Models (TAMs), the review identifies the impact of key determinants like Perceived Usefulness (PU), Perceived Ease of Use (PEOU), Social Influence (SI), Facilitating Conditions (FC), Resistance Factors (RF), and Innovation Characteristics (IC). Studies from several educational contexts are strategically included in the short survey. Adoption factors are analyzed to understand how they impact the willingness and capacity of educators to adopt GenAI technologies. The review shows that investments in infrastructure, professional development, ethical guidelines, and targeted interventions are crucial for the successful adoption of GenAI in education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIC64972.2025.10879632 },
  booktitle={ 2025 International Conference on Electronics, Information, and Communication (ICEIC) },
  chapter={0}
}

@article{rayyan-352343080,
  title={ Enhancing Human-Computer Interaction with Generative AI  -  2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG) },
  year={2024},
  author={Ronit and Agrawal, P. and Kumar, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911352 },
  abstract={Modern Chatbots represent a significant advancement in human-computer interaction by integrating emotional intelligence into their design. Unlike traditional chatbots that rely on predefined rules and keyword recognition, these advanced systems use affective computing and sentiment analysis to understand and respond to user’s emotional states. By using large LLMs, this innovation brings several key benefits. It enhances efficiency by providing immediate, relevant answers without users needing to search through multiple sources. The chatbot delivers precise information tailored to the emotional context of the interaction. Additionally, these chatbots offer greater convenience by consolidating information into a single query, streamlining the user experience and reducing the need to navigate through various platforms. They have improved so much yet are so much limited. An emotion sensitive chatbots should recognize and respond to emotional cues, fostering a deeper connection with users, encouraging regular interaction, creating a more interactive and personalized experience while also offering valuable insights into user behavior and preferences, enabling organizations to refine their marketing strategies and product development efforts. Overall, emotion-based chatbots should bridge the gap for human digital interactions. In this view, this paper explores how Generative AI, its technology, various applications, how it can be improved via enhancing the Human-Computer Interface, how does the improved version fare against current version, its various new applications, and additional key challenges and research prospectives.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTBIG64922.2024.10911352 },
  booktitle={ 2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG) },
  chapter={0}
}

@article{rayyan-352343081,
  title={ A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories  -  2025 IEEE Security and Privacy Workshops (SPW) },
  year={2025},
  author={Ding, Z. and Fu, Q. and Ding, J. and Deng, G. and Liu, Y. and Li, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050786 },
  abstract={Recent advancements in large language models (LLMs) have spurred the development of diverse AI applications-from code generation and video editing to text generation. However, AI supply chains such as Hugging Face, which host pretrained models and their associated configuration files contributed by the public, face significant security challenges. In particular, configuration files—originally intended to set up models by specifying parameters and initial settings—can be exploited to execute unauthorized code, yet research has largely overlooked their security compared to that of the models themselves. In this work, we present the first comprehensive study of malicious configurations on Hugging Face, identifying three attack scenarios (file, website, and repository operations) that expose inherent risks. To address these threats, we introduce Configscan, an LLM-based tool that analyzes configuration files in the context of their associated runtime code and critical libraries, effectively detecting suspicious elements with low false positive rates and high accuracy. Our extensive evaluation uncovers thousands of suspicious repositories and configuration files, underscoring the urgent need for enhanced security validation in AI model hosting platforms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPW67851.2025.00036 },
  booktitle={ 2025 IEEE Security and Privacy Workshops (SPW) },
  chapter={0}
}

@article{rayyan-352343082,
  title={ On LLM Embeddings for Vulnerability Management  -  2025 9th Network Traffic Measurement and Analysis Conference (TMA) },
  year={2025},
  author={Talibzade, R. and Bergadano, F. and Drago, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097007 },
  abstract={Effective vulnerability management is fundamental for cybersecurity, requiring significant manual effort to identify, classify, and prioritize reports. Automating this process could reduce analyst workload and improve response to threats. We explore the use of Large Language Models (LLMs) for representing and analyzing Common Vulnerabilities and Exposures (CVEs), specifically their ability to generate semantic embeddings that capture the nature of vulnerabilities from textual descriptions. Using a dataset of 4,710 CVEs, we generate vector embeddings with multiple LLMs. We then apply both unsupervised clustering and supervised classification to evaluate the quality of the embeddings. Our preliminary results show that some LLMs – in particular Llama 3.2 – map similar vulnerabilities together in the embedding space. Embeddings seen to position related vulnerabilities in nearby regions, with certain clusters showing strong correspondence to specific categories like SQL Injection (CWE-89) and Path Traversal (CWE-22). A simple KNN classifier using only the embeddings achieves around 50% accuracy when categorizing CVEs. This is a remarkable result, considering the very high number of classes in the problem. Our initial findings show potential for the use of LLMs in vulnerability management processes, calling for deeper analysis on how to better learn representations from vulnerability reports.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/TMA66427.2025.11097007 },
  booktitle={ 2025 9th Network Traffic Measurement and Analysis Conference (TMA) },
  chapter={0}
}

@article{rayyan-352343083,
  title={ AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns  -  2024 12th International Symposium on Digital Forensics and Security (ISDFS) },
  year={2024},
  author={Shibli, A. M. and Pritom, M. M. A. and Gupta, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10527300 },
  abstract={SMS phishing, also known as “smishing”, is a growing threat that tricks users into disclosing private information or clicking into URLs with malicious content through fraudulent mobile text messages. In recent past, we have also observed a rapid advancement of conversational generative AI chatbot services (e.g., OpenAI's ChatGPT, Google's BARD), which are powered by pre-trained large language models (LLMs). These AI chatbots certainly have a lot of utilities but it is not systematically understood how they can play a role in creating threats and attacks. In this paper, we propose AbuseGPT method to show how the existing generative AI-based chatbot services can be exploited by attackers in real world to create smishing texts and eventually lead to craftier smishing campaigns. To the best of our knowledge, there is no pre-existing work that evidently shows the impacts of these generative text-based models on creating SMS phishing. Thus, we believe this study is the first of its kind to shed light on this emerging cybersecurity threat. We have found strong empirical evidences to show that attackers can exploit ethical standards in the existing generative AI-based chatbot services by crafting prompt injection attacks to create newer smishing campaigns. We also discuss some future research directions and guidelines to protect the abuse of generative AI-based services and safeguard users from smishing attacks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISDFS60797.2024.10527300 },
  booktitle={ 2024 12th International Symposium on Digital Forensics and Security (ISDFS) },
  chapter={0}
}

@article{rayyan-352343084,
  title={ Navigating the World with an Intelligent Tourist Guide Using Generative AI  -  2024 International Telecommunications Conference (ITC-Egypt) },
  year={2024},
  author={Helmy, M. and El-Din, Y. S. and Mohamed, O. T. and Kader, O. S. A. and Ramadan, S. A. and Kamal, A. E. and Selim, M. R. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620592 },
  abstract={This paper addresses the intersection of artificial intelligence and cultural heritage exploration. The study investigates the utilization of NeRF (Neural Radiance Fields) for generating 3D scene meshes derived from reality, and the implementation of a virtual tour-guide chat-bot using LLaMA 3 LLM (Large Language Model). The aim is to facilitate the exploration of Egyptian Heritage Sites for tourists and explorers. By examining these AI-driven solutions, the paper sheds light on the challenges and opportunities in leveraging advanced technologies to enhance cultural heritage exploration and preservation endeavors.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITC-Egypt61547.2024.10620592 },
  booktitle={ 2024 International Telecommunications Conference (ITC-Egypt) },
  chapter={0}
}

@article{rayyan-352343085,
  title={ Answering Application of Generative AI in Industry: Integration of Semantic Representation  -  2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD) },
  year={2025},
  author={Matta, N. and Pfundstein, P. and Larde, C. and Ismedon, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033426 },
  abstract={Generative AI acts as an effective guide in decision-making process. This paper is designed to outline the main challenges in applying this technique within businesses and for specific activities. Semantic representation as ontology can be one solution for these challenges. Our first work to link ontology to LLM algorithms is illustrated in financial institutions},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCWD64889.2025.11033426 },
  booktitle={ 2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD) },
  chapter={0}
}

@article{rayyan-352343086,
  title={ AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model  -  IEEE Wireless Communications Letters },
  author={Jiao, T. and Xu, Y. and Xiao, Z. and Huang, Y. and Ye, C. and Feng, Y. and Cai, L. and Chang, J. and Liu, F. and He, D. and Guan, Y. and Zhang, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029511 },
  abstract={Designing a 6G-oriented universal model capable of processing multi-modal data and executing diverse air interface tasks has emerged as a common goal in future wireless systems. Building on our prior work in communication multi-modal alignment and telecom large language model (LLM), we propose a scalable, task-aware artificial intelligence-air interface multi-modal universal model (AI2MMUM), which flexibility and effectively perform various physical layer tasks according to subtle task instructions. The LLM backbone provides robust contextual comprehension and generalization capabilities, while a fine-tuning approach is adopted to incorporate domain-specific knowledge. To enhance task adaptability, task instructions consist of fixed task keywords and learnable, implicit prefix prompts. Frozen radio modality encoders extract universal representations and adapter layers subsequently bridge radio and language modalities. Moreover, lightweight task-specific heads are designed to directly output task objectives. Comprehensive evaluations demonstrate that AI2MMUM achieves SOTA performance across five representative physical environment/wireless channel-based downstream tasks using the WAIR-D and DeepMIMO datasets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LWC.2025.3578370 },
  booktitle={ IEEE Wireless Communications Letters },
  chapter={0}
}

@article{rayyan-352343087,
  title={ AI-based Bonsai Species Classification and Care Recommendation System using YOLO  -  2025 International Conference on Intelligent Computing and Control Systems (ICICCS) },
  year={2025},
  author={S, D. J. and Ramalakshmi, K. and Shirly, S. and Venkatesan, R. and Sundar, G. N. and S, S. K. C},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10985589 },
  abstract={Bonsai, an ancient art form that blends horticultural precision with artistic expression, poses unique challenges to both beginners and seasoned practitioners due to its species-specific care requirements and intricate maintenance processes. This research introduces an innovative AI-based solution combining YOLOv8, an advanced object detection model, and Google Gemini LLM, to simplify bonsai species classification and care recommendations. The system is designed to accurately identify bonsai species and provide personalized, context-aware guidance on essential care aspects such as watering, pruning, and pest management, while dynamically adapting to environmental and seasonal variations. Featuring an intuitive interface with sub-100ms response times, the proposed solution enhances accessibility and engagement for users of all expertise levels. Testing affirms its capability to improve understanding, usability, and appreciation of bonsai cultivation. Beyond its application in bonsai care, this hybrid AI integration demonstrates the potential for broader adoption in fields requiring precise classification and tailored insights, showcasing a seamless blend of tradition and technology.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICICCS65191.2025.10985589 },
  booktitle={ 2025 International Conference on Intelligent Computing and Control Systems (ICICCS) },
  chapter={0}
}

@article{rayyan-352343088,
  title={ News Article Analysis Chatbot using Generative AI  -  2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) },
  year={2025},
  author={Baviskar, V. and Sabale, T. and Jachak, P. and Tapkir, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011606 },
  abstract={The News Analysis Chatbot provides insightful analysis on current events through the generative AI, thus realizing real-time summaries, in-depth analyses of detailed data, and even the perspectives of most matters with all fairness to every aspect concerned. A new tool that ensures you are in the know about current happenings such that you acquire a comprehensive understanding of issues that might otherwise become quagmired. From the generative AI powered analysis of news articles, a changing and intelligent solution for the ability to analyze news content and summarize it. Due to the nature of the advanced NLP techniques used by the chatbot, it is capable of reading and understanding the articles, spotting the main ideas, extracting insights, producing and summarizing user preferences. This will enable users to extract coherent, up-to-the-minute summaries of either lengthy or complicated news articles within an extremely short amount of time. It allows the chatbot to move out of static response spaces by having an interactive discussion about the news, answering follow-up questions, providing context, and offering critical analysis. It can even compare articles within related topics, hint at trends, and even suggest additional readings to enrich the user’s understanding of events. Additionally, it learns the interest of the individual, suggesting articles based on previous interactions. We have introduced the News Research Tool, which is able to extract and process news articles via large language models (LLM). The software takes multiple news article URLs to analyze the news content and an open number of specific questions of the input articles. We deploy Streamlit to design an intuitively-operational user interface and to store the application. We utilize FAISS and a stream to tackle vector-based retrieval and Hugging Face embeddings to let search capture the most relevant context. Lastly, Streamlit Cloud hosts that we deploy our app so that it is accessible as a web application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDSAAI65575.2025.11011606 },
  booktitle={ 2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) },
  chapter={0}
}

@article{rayyan-352343089,
  title={ MID-LLM: Enhancing Medical Image Diagnostics With LLMs in a Blockchain AI Framework  -  IEEE Internet of Things Journal },
  year={2020},
  author={Kumar, R. and Rao, Y. and Kumar, J. and Mawuli, C. B. and Ali, W. and Zeng, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053220 },
  abstract={The rapid growth of medical imaging data presents significant challenges in diagnostic accuracy, data privacy, and computational efficiency. Traditional centralized AI models struggle with scalability and pose risks to patient confidentiality due to data aggregation. Moreover, heterogeneous medical data across institutions complicates the development of robust diagnostic tools. To address these issues, we propose MID-large language model (LLM), a novel framework that integrates LLMs with a blockchain-based federated learning (FL) system for medical image analysis. It also ensures the security and privacy of sensitive medical data across decentralized networks. MID-LLM uses verification mechanisms to ensure the global model’s integrity. It also employs aggregation techniques to reduce bias and improve training efficiency. Experiments on the BraTS 2020 dataset show that MID-LLM outperforms traditional FL, achieving higher Dice scores with improved computational efficiency. These results highlight MID-LLM’s potential to enhance diagnostic accuracy while offering a scalable, secure solution for AI in healthcare.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JIOT.2025.3583408 },
  booktitle={ IEEE Internet of Things Journal },
  chapter={0}
}

@article{rayyan-352343090,
  title={ LLM-Project: Automated Engineering Task Planning via Generative AI and WBS Integration  -  2024 IEEE 14th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER) },
  year={2024},
  author={Zhen, Y. and Bi, S. and Tang, S. and -t. Lu, X. and -q. Pan, W. and -p. Shi, H. and -r. Chen, Z. and -s. Fang, Y. and -m. Wang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749328 },
  abstract={We propose and implement a task planning system that integrates a series of validated robotic instructions, deep learning models, and demonstration cases, into a larger structure using the Work Breakdown Structure (WBS) which is commonly used in engineering project management. By organizing these small-scale solutions in a sequence based on temporal and resource dependencies, we use simulations and evaluation functions to select the optimal structure as the Standard Operating Procedure (SOP). These SOPs are then used to train a generative AI, enabling it to mimic human experts in generating high-level structures according to real-world needs and perform minor parameter generalizations to address issues involving temporal dependencies, spatial relationships, and resource allocation. The generated high-level structures are gradually transformed into low-level operations to execute actual tasks. The system records the execution results for automatic or manual analysis, and the feedback is used to continuously improve the generative AI's output. Our work lays the foundation for further research on the innovative application of combining generative AI with WBS data in robotic task planning. https://github.com/NOMIzy/LLM-Project},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CYBER63482.2024.10749328 },
  booktitle={ 2024 IEEE 14th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER) },
  chapter={0}
}

@article{rayyan-352343091,
  title={ Advanced Intelligent Traffic Management System(AITMS): A Generative AI-Enhanced Model  -  2024 IEEE PES/IAS PowerAfrica },
  year={2024},
  author={Muriuki, K. P. and Okello, J. O. and Chepkoech, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759478 },
  abstract={In rapidly urbanizing cities with increasing populations, the challenges of managing traffic are becoming more pressing, highlighting the need for advanced technologies. The Advanced Intelligent Traffic Management System (AITMS) is a comprehensive solution designed to address the persistent challenges of traffic congestion, poor traffic management, and air pollution in densely populated urban areas. Current traffic management systems often rely on static algorithms and predetermined signal timings, which are insufficient to handle dynamic and unpredictable traffic patterns. This results in prolonged travel times, increased fuel consumption, and elevated levels of air pollution, posing serious threats to public health and environmental sustainability. AITMS integrates physical and digital infrastructures, leveraging Generative AI for real-time data collection, analysis, and decision-making. By incorporating sensors, IoT devices, and advanced data analytics, the system can predict traffic flow, optimize signal timings, and recommend alternate routes. It also communicates with connected vehicles to provide real-time updates. The incorporation of Generative AI enables the AITMS to continually adapt and learn from new data inputs and trends, ensuring sustainability and scalability in urban transportation. AITMS is an innovative framework enhanced by Generative AI, aimed at revolutionizing urban traffic management in smart cities. Similar frameworks demonstrate promising outcomes, including improved traffic management, reduced congestion, and enhanced driver safety. AITMS aims to transform urban transportation, elevate residents' quality of life, and foster more sustainable and resilient cities amidst urbanization challenges.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica61624.2024.10759478 },
  booktitle={ 2024 IEEE PES/IAS PowerAfrica },
  chapter={0}
}

@article{rayyan-352343092,
  title={ DailyPhysics: Fostering Physics Concept Exploration in Children through a Tangible AI Storytelling Approach  -  2024 17th International Symposium on Computational Intelligence and Design (ISCID) },
  year={2024},
  author={Zhao, Y. and Li, J. and Shu, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11027830 },
  abstract={In early childhood science education, it is important to engage children in scientific experiences and the exploration of the world. In this study, we have designed a tangible game system called "DailyPhysics," which integrates artificial intelligence (AI) technology with gamified narrative design to enhance preschool children's understanding of physical concepts. This system enables children aged 4 to 7 to participate in learning, discovery, and storytelling, using scientific language flexibly to describe everyday phenomena through interaction with AI. By leveraging generative AI technologies, DailyPhysics creates an immersive learning environment that facilitates the natural integration of real-life experiences with physical concepts. Our user research, involving eight children, revealed that DailyPhysics effectively sparked their curiosity in exploring everyday scientific phenomena and significantly improved their ability to grasp and apply physical concepts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCID63852.2024.00059 },
  booktitle={ 2024 17th International Symposium on Computational Intelligence and Design (ISCID) },
  chapter={0}
}

@article{rayyan-352343093,
  title={ Exploring the Convergence of Generative AI and Fake News Detection: Technological Advancements and Challenges  -  2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) },
  year={2025},
  author={Wang, A. and Gu, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035708 },
  abstract={With the rapid development of Generative AI technology, the detection and governance of fake news has become a hot topic of concern in academia and society. The wide dissemination of fake news not only disrupts the public's information perception but also triggers social phenomena such as information epidemics, posing significant challenges to social stability, political environment and public health. Especially driven by social media, the speed and breadth of information dissemination have greatly intensified the spread of fake news. The research findings indicate that Generative AI mainly focuses on the optimization of natural language processing and deep learning technologies, providing new technical support for the detection of fake news. Meanwhile, the role of social media platforms and information dissemination pathways have become the focus of scholars' attention. However, issues such as the dissemination of cross-platform fake news, the practical application of generative AI, and the accuracy and robustness of algorithms remain the main challenges in current research. In this regard, this article suggests that future research should further optimize large-scale language models, promote innovation in multimodal fake news detection technology, and strengthen research on cross platform fake news dissemination mechanisms, in order to provide more accurate and effective technical support for fake news governance and alleviate its negative impact on society.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AINIT65432.2025.11035708 },
  booktitle={ 2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) },
  chapter={0}
}

@article{rayyan-352343094,
  title={ Generative AI Research of Education from 2013 to 2023  -  2024 6th International Conference on Computer Science and Technologies in Education (CSTE) },
  year={2024},
  author={Huang, G. and Liang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589969 },
  abstract={Generative AI offers a new possibility for teaching and learning, where the role of the teacher will be affected and the way students learn will potentially be disrupted. This study analyzed the Wos database of relevant literature over the past 10 years (January 2013-November 2023) using the visual analysis software CiteS pace, with the aim of providing an overview of generative-time AI research in the field of education, revealing the main research patterns and trends characterizing it. The results of the study reveal the authors, regions, journals, and references that have made significant contributions. In addition, keyword co-occurrence, burst words, and timeline maps were generated to identify key hotspots in this research area.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSTE62025.2024.00030 },
  booktitle={ 2024 6th International Conference on Computer Science and Technologies in Education (CSTE) },
  chapter={0}
}

@article{rayyan-352343095,
  title={ Using Generative AI to Create User Stories in the Software Engineering Classroom  -  2024 36th International Conference on Software Engineering Education and Training (CSEE&T) },
  year={2024},
  author={Brockenbrough, A. and Salinas, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10662994 },
  abstract={A user story is used in agile methodology to describe functionality that is valuable to the user and may include criteria to determine if the developer has completed the story. This study investigates undergraduate computer science students using ChatGPT to create user stories from user feedback. The study compares aspects of the user stories created by students using ChatGPT with those not using ChatGPT. Are user stories written by students with AI assistance of higher or lower quality? How does the time spent writing the user story change with the use of ChatGPT? We evaluate student user stories using a modified INVEST story rating system. Evaluated user story properties include structure, independence, value, testability, and grammar. The results show that ChatGPT-assisted students produce higher-quality user stories than unassisted students. However, using ChatGPT to write user stories does not guarantee high quality. ChatGPT can fail to recognize dependencies between user feedback and create structurally incorrect user stories. We see a need for students to be trained in effectively using this tool by carefully examining AI-assisted output and making revisions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSEET62301.2024.10662994 },
  booktitle={ 2024 36th International Conference on Software Engineering Education and Training (CSEE&T) },
  chapter={0}
}

@article{rayyan-352343096,
  title={ Quantum-AI Hybrid Algorithms for Solving Large-Scale Engineering Problems Using LLM-Driven Optimizations  -  2025 5th International Conference on Intelligent Technologies (CONIT) },
  year={2025},
  author={Jonnalagadda, A. K. and Acharya, S. and Pasam, V. R. and Shahane, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166726 },
  abstract={Major engineering challenges are hard to solve computationally because they are very complex, have a high number of dimensions and they are non-linear. The paper introduces a new Quantum-AI Hybrid Algorithmic Framework that unites quantum computing and artificial intelligence, mainly Large Language Models (LLMs), to address such issues efficiently. It uses quantum processes to help with probabilistic sampling and reducing the search space and it uses LLMs for logical reasoning, generating code and adjusting parameters to fit the requirements of the given problem. Adding knowledge from a specific engineering area into the update stages using LLM prompts helps the suggested system improve both the speed of convergence and scalability compared to AI-only methods. Testing on structural design, power system development and fluid dynamics problems showed that GhostFlow converges faster than other similar software (up to $40 \%$ faster) and results in improved accuracy (up to $25 \%$ better). It highlights how enhancing quantum-AI with LLM intelligence can lead to important improvements in how computing works in the future.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONIT65521.2025.11166726 },
  booktitle={ 2025 5th International Conference on Intelligent Technologies (CONIT) },
  chapter={0}
}

@article{rayyan-352343097,
  title={ RoboChat: A Unified LLM-Based Interactive Framework for Robotic Systems  -  2023 5th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI) },
  year={2023},
  author={Li, G. and Han, X. and Zhao, P. and Hu, P. and Nie, L. and Zhao, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10489289 },
  abstract={In the rapidly evolving landscape of ro botics, Large Language Models (LLMs) have emerged as a pivotal tool in enhancing the capabilities of robotic systems. This paper introduces a unified LLM-based framework tailored for the embodied AI of robotic systems. Drawing inspiration from the recent advancements in autonomous navigation, interaction, and real-world planning using LLMs, our framework seeks to bridge the gap between high-level linguistic instructions and low-level robotic actions. By integrating open-vocabulary, scene representations, our approach enables robots to navigate and interact with their environment in a more human-like manner. Furthermore, the framework emphasizes safety and adaptability, ensuring that robots can operate seamlessly in dynamic and uncertain environments. Through a combination of real-world planning, the proposed framework offers a holistic solution for the next generation of embodied robotic systems, pushing the boundaries of what robots can perceive, understand, and execute.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RICAI60863.2023.10489289 },
  booktitle={ 2023 5th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI) },
  chapter={0}
}

@article{rayyan-352343098,
  title={ The Evolving Role of Generative AI in Text Literacies: Exploring the Potential of Cognition-Adaptive Assistance  -  2024 IEEE Global Engineering Education Conference (EDUCON) },
  year={2024},
  author={Frenzke–Shim, A. and Kohl–Dietrich, D. and Standl, B. and Langner, M. and Maedche, A. and Kerber, U.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578629 },
  abstract={This paper explores the impact of generative ar-tificial intelligence on text production, focusing on the use of prompt-based AI tools. We propose to move beyond the current use of Large Language Models (LLMs) as “ghostwriters” and advocate for their relevance as tools to enhance the development of epistemic-heuristic strategies to facilitate knowledge construction. Our planned study aims to gain insight into the cognitive processes and behavior of university students when interacting with content generated by LLMs using eye tracking technology. Based on these insights, we explore the potential of providing cognition-aware assistance to enhance writing skills in educational contexts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON60312.2024.10578629 },
  booktitle={ 2024 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343099,
  title={ Enhancing Profitability through AI-Optimized Accounts Receivable: Reducing Cash Conversion Cycles  -  2024 International Conference on Electrical, Computer and Energy Technologies (ICECET },
  year={2024},
  author={Arora, P. and Desu, L. and Kumar, A. and S, R. K. and Marinescu, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698580 },
  abstract={The management of accounts receivable is crucial to a company's profitability and overall growth, as it directly influences financial performance. Specifically, firms with longer cash conversion cycle periods exhibit lower profitability compared to those with shorter cash conversion cycle periods. The processes involved in this domain are often laborious, time-intensive, and susceptible to mistakes. This research paper aims to improve efficiency of accounts receivable procedures across various industries, ultimately enhancing the daily operations of collectors and reducing the cash conversion cycle. The proposed solution consists of a comprehensive architecture which leverages Generative AI to improve the efficiency and effectiveness of accounts receivable processing. Additionally, it addresses challenges such as customer segmentation, credit management support, collector assistance, dispute verification, and the customization of emails in accordance with customer strategies. Integration of Langchain-based QA system further enhances and optimizes the business operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECET61485.2024.10698580 },
  booktitle={ 2024 International Conference on Electrical, Computer and Energy Technologies (ICECET },
  chapter={0}
}

@article{rayyan-352343100,
  title={ Using Generative AI for Neurofeedback Content Personalization  -  2025 19th International Conference on Semantic Computing (ICSC) },
  year={2025},
  author={Shuler, T. L. and Ostrowski, D. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036309 },
  abstract={This paper presents a comprehensive framework for integrating Large Language Models (LLMs) into neurofeedback systems. By leveraging real-time electroencephalogram (EEG) data processing, advanced machine learning, and multimodal feedback mechanisms, the framework offers a transformative approach to personalized neurofeedback. Technical validation and statistical analysis highlight system scalability and empirical reproducibility, addressing critical performance metrics such as latency, accuracy, and resource efficiency. The framework emphasizes the convergence of traditional neurofeedback principles with modern AI capabilities, demonstrating significant potential for applications in mental health, cognitive enhancement, and neurological rehabilitation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC64641.2025.00053 },
  booktitle={ 2025 19th International Conference on Semantic Computing (ICSC) },
  chapter={0}
}

@article{rayyan-352343101,
  title={ Can Generative AI Uncover Hidden Patterns in Historical Domestic Traffic Ads Through Data Analysis? A ChatLoS-DTA Exploration  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Vetluzhskikh, M. and Gnanasekaran, R. K. and Marciano, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825346 },
  abstract={This paper presents ChatLoS-DTA, a custom Generative Pre-trained Transformer (GPT) model specifically developed for data analysis on the Domestic Traffic Ads (DTA) Legacy of Slavery dataset. The DTA dataset consists of numerous historical newspaper advertisements from 1824 to 1864 for buying and selling enslaved individuals across Maryland. This dataset, digitized and curated by the Maryland archives, offers valuable insights into patterns within the domestic slave trade. However, certain accessibility challenges exist for non-technical users, including the descendants of enslaved individuals or cultural researchers. ChatLoS-DTA, built on OpenAI’s ChatGPT-4 and Python libraries, was designed to allow such users to query the dataset using natural language without requiring any technical expertise. This paper discusses ChatLoS-DTA’s architecture, ethical framework, performance, and limitations, highlighting the model’s potential as a template for applying generative AI in cultural and historical research. Future work includes refining the tool’s accuracy to broaden dataset compatibility and further enhance ethical safeguards.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825346 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343102,
  title={ Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education  -  2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET) },
  year={2024},
  author={Pan, W. H. and Chok, M. J. and Wong, J. L. S. and Shin, Y. X. and Poon, Y. S. and Yang, Z. and Chong, C. Y. and Lo, D. and Lim, M. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554754 },
  abstract={Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct. In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3639474.3640068 },
  booktitle={ 2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET) },
  chapter={0}
}

@article{rayyan-352343103,
  title={ Representing the Interaction between Users and Products via LLM-assisted Knowledge Graph Construction  -  2024 IEEE 18th International Conference on Semantic Computing (ICSC) },
  year={2024},
  author={Vizcarra, J. and Haruta, S. and Kurokawa, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475639 },
  abstract={To understand user behavior, representing the semantic knowledge of user-product interaction is essential. In this paper, we represent the interaction between user and product via large language model (LLM)-assisted knowledge graph construction. We capture users’ behavioral actions and static properties of the products from raw text data of “user review” and “product catalog”. Moreover, the information needed for updating the knowledge graph is captured by raw texts of “news related to the products”. The proposed methodology integrates them as a single knowledge graph to provide causal reasoning on user-product interaction. To alleviate the situation where a small quantity of annotated text exists in these data, we use LLM as a data annotator and augmentor.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC59802.2024.00043 },
  booktitle={ 2024 IEEE 18th International Conference on Semantic Computing (ICSC) },
  chapter={0}
}

@article{rayyan-352343104,
  title={ Designing and Implementing LLM Guardrails Components in Production Environments  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Devino, M. and Ju, E. and Junior, P. M. Caldeira},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029999 },
  abstract={With advancements in generative Artificial Intelligence (AI), there has been an increasing need for tools that rely on Large Language Model (LLM)s. As these models may produce undesired answers, there is a need to prevent such events, especially in enterprise environments. Even if models are trained on safe data, user inputs and even model behavior can be unpredictable, leading to problems such as leakage of confidential data that could result in revenue loss. In this paper, we describe our experiences on developing tools for “guardrailing” LLMs. We describe how we started with a quick monolith implementation, and later transitioned to a microservices architecture. As results, we share our lessons learned throughout the process, and how the re-architecture to microservices led to runtime performance gains, easier maintenance and extensibility, and also allowed us to open source the main component of the solution, so anyone can contribute to and use it.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00010 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343105,
  title={ Effect of Explainable Artificial Intelligence on Trust of Mental Health Professionals in an AI-Based System for Suicide Prevention  -  IEEE Access },
  author={de Oliveira, A. C. and Azevedo, J. P. C. and Ruback, L. and Moreira, R. and Teixeira, S. S. and Teles, A. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10945851 },
  abstract={Artificial Intelligence (AI)-based systems have been proposed to aid Mental Health Professionals (MHPs) in various tasks, including the prevention of suicide by identifying Suicidal Ideation (SI). However, these systems may lack transparency and thereby create mistrust among MHPs. Explainable Artificial Intelligence (XAI) methods can elucidate how features influence system predictions, aiding MHPs in understanding them. This exploratory study aims to investigate how MHPs’ trust is influenced by AI explanations (educational intervention and XAI methods) and other factors (professional background, knowledge of AI and computing, and reported system misclassification). We conducted an experiment using Boamente, an AI-powered clinical decision support system designed to assist MHPs in suicide prevention. Boamente identifies SI in Brazilian Portuguese texts typed on smartphones by leveraging a Large Language Model (LLM) for analysis. The results demonstrate that professional background, knowledge of AI and computing, and educational intervention had no statistically significant effect on trust. In contrast, trust was affected by factors such as LLM prediction explanations, the quality of explanations, and reported misclassification. Therefore, providing prediction explanations to understand the inner workings of AI models led MHPs to be more critical in relation to predictions, while there was an overtrust on MHPs when no explanations were provided. Furthermore, disagreement with LLM classifications and perceptions of system vulnerabilities also affected trust.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["la manière dont les scores, probabilités et explications sont exposés aux utilisateurs a un impact direct sur la confiance, le risque de surconfiance et la qualité des décisions"]}},
  doi={ 10.1109/ACCESS.2025.3556245 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343106,
  title={ WHAT TOOLS AND METHODS SUPPORT AI ACTIVITIES?  -  AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI },
  author={Lewrick, M. and Hatamleh, O.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951645.pdf&bkn=10950198&pdfType=chapter },
  abstract={Summary <p>Primary considerations of the AI value chain rely on so‐called foundation models. These models have triggered an entire value chain aiming to improve and utilize the technology. This chapter dives into how Large language models (LLMs) operate, focusing on understanding context and generating results based on prompts. It breaks down how the LLM processes and utilizes words, along with exploring the concept of self‐attention. The chapter provide a foundation for grasping how LLMs generate text that considers context and builds upon the information we provide. It demonstrates how prompts can be used to process and generate human‐like text, translate languages, create code, write different kinds of creative content, or answer questions in an informative way. The chapter explores the tools and techniques needed to gain higher labor productivity with AI. It presents many ways to increase employee productivity and add to top‐line revenue growth.</p>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI },
  chapter={0}
}

@article{rayyan-352343107,
  title={ Novel Application Creation Paradigm Using Natural Language Compiler Based on LLM  -  2024 IEEE International Smart Cities Conference (ISC2) },
  year={2024},
  author={Xu, P. and Wang, H. and Wang, C. and Liu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004259 },
  abstract={The development of smart cities requires an increasing demand for diversified applications, thus requiring more convenient ways of application creation. In recent years, the rapid development and applications of Large Language Model (LLM) technology increasingly facilitate its use in application creation. Although “LLM Aided Coding” can reduce the need for developers to have advanced computer skills, it still requires them to master the use of computer programming languages. As a new type of application creation method, “LLM-Enabled Application / AI Agents” can simplify the development process and meet the complex application requirements in smart cities. Developers could create applications using natural language, thus effectively reducing the complexity and workload of application creation. However, these applications still rely on LLM in the execution phase, which greatly limits their operational efficiency and cost. In this paper, we propose a new application creation paradigm using the Natural Language Compiler (NLC) based on LLM. The introduction of NLC allows developers to create and release applications by simply describing the application requirements in natural language and performing simple configurations, without relying on LLM during the application execution phase. NLC draws on the architecture of AI Agents and further introduces Methodology Component to address the issue of inaccuracies and erroneous assumptions in planning due to the lack of factual grounding, thus enhancing the extensibility of planning capabilities. NLC adopts the “register-discover-invoke” mechanism to support the flexible extension of tools. These improvements maintain the convenience of application creation while enabling NLC to have a stronger and more flexible application creation capability, this new application creation paradigm provides a more efficient and flexible solution for smart cities. The source code is available at https://github.com/free4inno/NLC.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISC260477.2024.11004259 },
  booktitle={ 2024 IEEE International Smart Cities Conference (ISC2) },
  chapter={0}
}

@article{rayyan-352343108,
  title={ FLY-LLM Sim: A Novel Integration of UAV and LLM Lab Platform  -  2025 IEEE World AI IoT Congress (AIIoT) },
  year={2025},
  author={Guntupalli, K. M. and Raja, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105292 },
  abstract={Recent developments in Large Language Models (LLMs) have created new possibilities to integrate integrate these models into robotics platforms, allowing unmanned aerial vehicles (UAVs) to have enhanced control and decision-making capabilities. The UAV market has experienced significant growth in recent years, accompanied by a surge in UAV-related job opportunities. The need for LLM-powered UAVs is expected to increase significantly as LLM advances. Therefore, it is essential to provide the upcoming generation of professionals, students, and educators with the knowledge and abilities they need to develop, implement, and operate LLM-driven UAV systems efficiently. Nevertheless, there is a absence of training materials and education on LLM-powered UAVs, particularly for practical, hands-on learning. We proffer a novel Fly-Llm Sim lab platform that provides effective and efficient hands-on practice. Our lab platform comprises different simulation environments and preconfigured lab modules. The outcome of these lab modules is to educate and train users on LLM-powered UAV to perform advanced aerial route planning and perform vision-based cyber attack analysis. The lab platform will be open source, allowing other developers to customize it to their needs. Hence, our platform adopts a plug-in-based design to support the customization of the lab modules. Our evaluation results show that our platform is effective and efficient in training and educating students and professionals in operating LLM-powered UAVs via natural language commands and developing custom task-specific prompts using prompt engineering techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT65859.2025.11105292 },
  booktitle={ 2025 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343109,
  title={ Mitigating Bias in Large Language Models Through Culturally-Relevant LLMs  -  2025 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS) },
  year={2025},
  author={Narayan, M. and Pasmore, J. and Sampaio, E. and Raghavan, V. and Maity, S. and Waters, G. and Howard, A. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098204 },
  abstract={With the proliferation of Large Language Models (LLMs) and its use across sectors that impact our civil liberties, the biases present in these language-based applications can propagate and amplify social inequalities and harmful stereotypes. In particular, racial and cultural biases in LLMs not only undermine the fairness and reliability of these systems, but also pose significant ethical concerns, further affecting marginalized communities. To address these concerns, this paper discusses the development of a LLM for mitigating bias through the integration of diverse data sources and culturally relevant material that has often been overlooked in the construction of mainstream AI models. We compare the performance of ChatGPT 3.5 and the LLM, which was incrementally trained on Black history and culture, when tasked with answering a set of prompts that cover a range of news topics. Using a bias assessment score, we assessed each model's ability to handle the task without introducing racial or cultural biases into the news topic summaries. Through empirical studies, our approach not only demonstrates the feasibility of detecting and measuring racial and cultural biases but also offers a scalable solution for creating more equitable and reliable AI technologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETHICS65148.2025.11098204 },
  booktitle={ 2025 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS) },
  chapter={0}
}

@article{rayyan-352343110,
  title={ AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM’s  -  2024 5th IEEE Global Conference for Advancement in Technology (GCAT) },
  year={2024},
  author={Garlapati, A. and Parmesh, M. N. V. Satya Sai Muni and Savitha and S, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10923987 },
  abstract={Recent years have witnessed an enormous rise in the design, repair and the enhancement of software automation tests. The reliability of program’s unit testing has major impact on its overall performance. The anticipated influence of Artificial Intelligence advancements on test automation methodologies are significant. Many studies on automated testing implicitly assume that the test results are deterministic, means that similar tests faults remain same. The precision of software is largely ensured by unit testing. But writing unit tests manually is a time-consuming process, which leads us to drive into "Automation Analysis". Recent years comprised the application of Large Language Models (LLM’s) in numerous fields related to software development, especially the automated creation of unit testing.However, these frameworks require more instructions, or few shot learnings on sample tests that already exist. This research provides a comprehensive empirical assessment of the efficiency of LLM’s for automating unit testing production, with no need for further manual analysis. The method we employ is put into practice for test cases, an adaptable Agents and LLM-based testing framework that evaluates test cases generated, by reviewing and re-writing them in different phases. Evaluation of this test cases was done by using mistral-large LLM Model. The analysis results that developed acquired an overall coverage of 100% for code given. Finally, to enhance the typical evaluation, this research suggests and concludes that LLMs, can be successfully incorporated into present practices, through adaptative instructions and improvements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GCAT62922.2024.10923987 },
  booktitle={ 2024 5th IEEE Global Conference for Advancement in Technology (GCAT) },
  chapter={0}
}

@article{rayyan-352343111,
  title={ Implementation and Evaluation of LLM-Based Conversational Systems on a Low-Cost Device  -  2024 IEEE Global Humanitarian Technology Conference (GHTC) },
  year={2024},
  author={Sakai, K. and Uehara, Y. and Kashihara, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771565 },
  abstract={The rapid evolution of artificial intelligence (AI) technologies has highlighted the potential of generative AI, particularly large language models (LLMs), to revolutionize various sectors by automating content creation, enhancing personalized education, supporting medical diagnostics, and creating immersive entertainment experiences. However, deploying these advanced models often requires substantial computational resources, posing a challenge in resource-limited environments. This paper explores implementing LLM-based conversational systems on a low-cost device, specifically the Raspberry Pi. We designed and implemented a conversational system utilizing four LLMs, ChatGPT, Bard, Llama, and Rinna, and evaluated their performance in terms of execution time and computational resource usage. Our findings reveal that API-based models (ChatGPT and Bard) are more efficient in processing time and resource consumption, making them suitable for real-time applications. In contrast, locally-run models (Llama and Rinna) provide the advantage of offline operation despite higher computational demands.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["idée que les appels LLM doivent être encadrés par des paramètres explicites de contrôle de ressources (UMM)"]}},
  doi={ 10.1109/GHTC62424.2024.10771565 },
  booktitle={ 2024 IEEE Global Humanitarian Technology Conference (GHTC) },
  chapter={0}
}

@article{rayyan-352343112,
  title={ LLM-Based AI Agent for Sizing of Analog and Mixed Signal Circuit  -  2025 23rd IEEE Interregional NEWCAS Conference (NEWCAS) },
  year={2025},
  author={Liu, C. and Olowe, E. A. and Chitnis, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11107079 },
  abstract={The design of Analog and Mixed-Signal (AMS) integrated circuits (ICs) often involves significant manual effort, especially during the transistor sizing process. While Machine Learning techniques in Electronic Design Automation (EDA) have shown promise in reducing complexity and minimizing human intervention, they still face challenges such as numerous iterations and a lack of knowledge about AMS circuit design. Recently, Large Language Models (LLMs) have demonstrated significant potential across various fields, showing a certain level of knowledge in circuit design and indicating their potential to automate the transistor sizing process. In this work, we propose an LLM-based AI agent for AMS circuit design to assist in the sizing process. By integrating LLMs with external circuit simulation tools and data analysis functions and employing prompt engineering strategies, the agent successfully optimized multiple circuits to achieve target performance metrics. We evaluated the performance of different LLMs to assess their applicability and optimization effectiveness across seven basic circuits, and selected the best-performing model Claude 3.5 Sonnet for further exploration on an operational amplifier, with complementary input stage and class AB output stage. This circuit was evaluated against nine performance metrics, and we conducted experiments under three distinct performance requirement groups. A success rate of up to 60 % was achieved for reaching the target requirements. Overall, this work demonstrates the potential of LLMs to improve AMS circuit design.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NewCAS64648.2025.11107079 },
  booktitle={ 2025 23rd IEEE Interregional NEWCAS Conference (NEWCAS) },
  chapter={0}
}

@article{rayyan-352343113,
  title={ First Field Trial of LLM-Powered AI Agent for Lifecycle Management of Autonomous Driving Optical Networks  -  2025 Optical Fiber Communications Conference and Exhibition (OFC) },
  year={2025},
  author={Liu, X. and Qiu, Q. and Zhang, Y. and Cheng, Y. and Yi, L. and Hu, W. and Zhuge, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11047189 },
  abstract={We design and demonstrate the first field trial of LLM-powered AI Agent for ADON. Three operation modes of the Agent are proposed for network lifecycle management to process wavelength add/drop, soft/hard failures, and power optimizations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2025 Optical Fiber Communications Conference and Exhibition (OFC) },
  chapter={0}
}

@article{rayyan-352343114,
  title={ EduGuard-LLM: An AI-Generated Content Detector Using Large Language Models for Safeguarding Educational Integrity  -  2024 4th International Conference on Educational Technology (ICET) },
  year={2024},
  author={Liu, L. and Zhang, D. and Yan, B. and Wu, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10869067 },
  abstract={In response to the widespread use of AI-generated tools by students to complete assignments, which poses significant challenges to educational integrity and fairness, this study proposes a novel detection model called EduGuard-LLM. EduGuard-LLM leverages the powerful text recognition capabilities of large language models to accurately distinguish between student-authored content and AI-generated content across different educational stages. By deeply analyzing text content and identifying AI-generated features, this model can effectively detect the authenticity of student submissions in primary, middle, high school, and university levels. In our experiments, we utilized 21 publicly available datasets, comprising a total of 164,543 text samples, covering various types of texts from elementary to university levels. The model achieved an accuracy of 93.96% on the pre-training dataset, and accuracies of 95.01%, 94.64%, 93.97%, and 94.94% on four external validation sets, respectively. The experimental results demonstrate that EduGuard-LLM has high detection accuracy across different educational stages, effectively ensuring the authenticity of student submissions. This provides strong technical support for educational institutions, maintaining educational integrity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICET62460.2024.10869067 },
  booktitle={ 2024 4th International Conference on Educational Technology (ICET) },
  chapter={0}
}

@article{rayyan-352343115,
  title={ AI-Based Voice Agent for Automated Sales Calls  -  2024 International Conference on Decision Aid Sciences and Applications (DASA) },
  year={2024},
  author={Amarak, A. and Igamane, M. and Rachidi, T. and Chtouki, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10836508 },
  abstract={This paper presents an AI-based voice agent designed to enhance customer engagement in automated sales. Operating continuously, the agent leverages the power of Large Language Models (LLMs) to interact with potential customers, persuading them to purchase products or schedule appointments with human representatives. Initial performance evaluation gives extremely positive results highlighting the agent's potential to revolutionize sales interactions and improve operational efficiency. These are demonstrated by a conversion rate of 8%, significantly higher than industry averages of 2-5%, high ratings for friendliness, clarity, and realism in customer satisfaction surveys, and an average of 1.7 seconds reaction time during conversation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DASA63652.2024.10836508 },
  booktitle={ 2024 International Conference on Decision Aid Sciences and Applications (DASA) },
  chapter={0}
}

@article{rayyan-352343116,
  title={ Developer Experiences with a Contextualized AI Coding Assistant: Usability, Expectations, and Outcomes  -  2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2024},
  author={Pinto, G. and de Souza, C. and Rocha, T. and Steinmacher, I. and de Souza, A. and Monteiro, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556177 },
  abstract={In the rapidly advancing field of artificial intelligence, software development has emerged as a key area of innovation. Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios. Noting this limitation, both the academic community and industry players are relying on contextualized coding AI assistants. These assistants surpass general-purpose AI tools by integrating proprietary, domainspecific knowledge, offering precise and relevant solutions. Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant — named StackSpot AI— in a controlled setting. According to the participants, the assistants' use resulted in significant time savings, easier access to documentation, and the generation of accurate codes for internal APIs. However, challenges associated with the knowledge sources necessary to make the coding assistant access more contextual information as well as variable responses and limitations in handling complex codes were observed. The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343117,
  title={ Artemis AI: Multi-LLM Framework for Code Optimisation  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Giavrimis, R. and Basios, M. and Wu, F. and Kanthan, L. and Bauer, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050533 },
  abstract={This paper introduces Artemis AI, a novel framework leveraging multiple Large Language Models (LLMs) optimise code performance. Artemis AI achieves significant performance improvements in highly-optimised code across diverse domains with minimal changes. We focus on three representative open-source projects: QuantLib (quantitative finance), Llama2.c (natural language processing), and OpenAI Whisper (automatic speech recognition) and one proprietary high performance codebase. Our multi-stage process involves extracting target code snippets, independent optimisation by multiple LLMs, and a search-based selection of the optimal solutions, achieving a 30 % reduction in execution time for QuantLib, a 52 % reduction for Llama2.c, and a 15% reduction for OpenAI Whisper. These results highlight the potential of multi-LLM collaboration for substantial performance gains that lead to greener software while preserving code readability and reliability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00057 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343118,
  title={ TextureMeDefect: LLM-based Synthetic Railway Defect Texture on Mobile Devices  -  2025 IEEE International Conference on Consumer Electronics (ICCE) },
  year={2025},
  author={Ferdousi, R. and Hossain, M. A. and Saddik, A. El},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10930185 },
  abstract={Texture image generation has been studied for various applications, including gaming and entertainment. However, context-specific realistic texture generation for industrial applications, such as generating defect textures on railway components, remains unexplored. A mobile-friendly, LLM-based tool that generates fine-grained defect characteristics offers a solution to the challenge of understanding the impact of defects from actual occurrences. We introduce TextureMeDefect, an innovative tool leveraging an LLM- based AI-Inferencing engine. The tool allows users to create realistic defect textures interactively on images of railway components taken with smartphones or tablets. We conducted a multifaceted evaluation to assess the relevance of the generated texture, time, and cost in using this tool on iOS and Android platforms. We also analyzed the software usability score (SUS) across three scenarios. TextureMeDefect outperformed traditional image generation tools by generating meaningful textures faster, showcasing the potential of AI-driven mobile applications on consumer-grade devices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCE63647.2025.10930185 },
  booktitle={ 2025 IEEE International Conference on Consumer Electronics (ICCE) },
  chapter={0}
}

@article{rayyan-352343119,
  title={ Building Generative AI Chatbot Using Oracle Cloud Infrastructure  -  2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) },
  year={2024},
  author={Shah, J. A. and Iyer, N. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754774 },
  abstract={Artificial intelligence (AI) and Generative AI (GenAI) are revolutionizing technology and businesses at an extraordinary speed, providing numerous benefits that can position a company at the forefront of a swiftly changing market. The adoption of Generative AI will strengthen and enhance the role of chatbots in organizations and provide a more efficient and versatile user experience. Successfully integrating these technologies into enterprise systems requires a reliable, scalable, and secure infrastructure. Oracle Cloud Infrastructure (OCI) emerges as a powerful platform designed and crafted to facilitate the building and deployment of Generative AI applications. OCI’s comprehensive suite of AI and machine learning tools like OCI Generative AI service and its exceptional high-performance computing capabilities offers an optimal environment for developing cutting-edge Generative AI solutions. This paper explores the inner workings of Large Language Models (LLMs), OCI Generative AI service and focuses on building Chatbot using pre-trained and custom LLM models with the goal of allowing end users to gain insights seamlessly and efficiently. By presenting a comprehensive guide to leverage OCI for Generative AI, this paper aims to serve as a valuable resource for developers and organizations that are looking to harness cloud-based solutions for innovative AI-driven applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UEMCON62879.2024.10754774 },
  booktitle={ 2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) },
  chapter={0}
}

@article{rayyan-352343120,
  title={ Athena: A GenAI-Powered Programming Tutor Based on Open-Source LLM  -  2025 1st International Conference on Consumer Technology (ICCT-Pacific) },
  year={2025},
  author={Lin, Y. and Khan, M. F. Ferdous and Sakamura, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012850 },
  abstract={With the rapid growth of generative artificial intelligence (GenAI), it is important to find ways to utilize them for academic advantage. GenAI tools embody immense potential in providing personalized feedback to students any time anywhere, and hence can provide a reliable helping hand to teachers who often experience burnout in large classes and are burdened with administrative tasks. While current GenAI tools like ChatGPT are helpful, they occasionally offer misinformation - a phenomenon known as hallucination, undermine critical thinking by providing direct answers to questions, and, as paid services, can further widen the digital divide. Against the backdrop of these problems, this research introduces Athena, a GenAI programming mentor based on an open-source large language model (LLM), constructed to guide programming learners to think critically and provide reliable information leveraging retrieval augmented generation. Its impact on learning outcomes was measured by feedback from programming students. Most students have given a positive response, saying that their motivation to keep learning and their confidence in their abilities have increased. These results imply that having a reliable AI mentor that can guide students at all times can have a positive impact in self-directed learning process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCT-Pacific63901.2025.11012850 },
  booktitle={ 2025 1st International Conference on Consumer Technology (ICCT-Pacific) },
  chapter={0}
}

@article{rayyan-352343121,
  title={ LLM in the Loop: A Framework for Contextualizing Counterfactual Segment Perturbations in Point Clouds  -  IEEE Access },
  author={Kočić, V. and Lukač, N. and Rožajac, D. and Schweng, S. and Gollob, C. and Nothdurft, A. and Stampfer, K. and del Ser, J. and Holzinger, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993377 },
  abstract={Point Cloud Data analysis has seen a major leap forward with the introduction of PointNet algorithms, revolutionizing how we process 3D environments. Yet, despite these advancements, key challenges remain, particularly in optimizing segment perturbations to influence model outcomes in a controlled and meaningful way. Traditional methods struggle to generate realistic and contextually appropriate perturbations, limiting their effectiveness in critical applications like autonomous systems and urban planning. This paper takes a bold step by integrating Large Language Models into the counterfactual reasoning process, unlocking a new level of automation and intelligence in segment perturbation. Our approach begins with semantic segmentation, after which LLMs intelligently select optimal replacement segments based on features such as class label, color, area, and height. By leveraging the reasoning capabilities of LLMs, we generate perturbations that are not only computationally efficient but also semantically meaningful. The proposed framework undergoes rigorous evaluation, combining human inspection of LLM-generated suggestions with quantitative analysis of semantic classification model performance across different LLM variants. By bridging the gap between geometric transformations and high-level semantic reasoning, this research redefines how we approach perturbation generation in Point Cloud Data analysis. The results pave the way for more interpretable, adaptable, and intelligent AI-driven solutions, bringing us closer to real-world applications where explainability and robustness are paramount.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3568052 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343122,
  title={ Examining the Threat Landscape of Generative AI: Attack Vectors and Mitigation Strategies for LLMs  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Taylor, Z. and Sharma, A. and Upadhyay, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903828 },
  abstract={Generative Pretrained Transformers (GPTs) represent a transformative leap in artificial intelligence, transitioning from analytical systems to those capable of creating new content across various media. This advancement, rooted in the Distributional Hypothesis of Natural Language Processing (NLP), enables AI to produce human-like text by learning the nuances of language. However, the reliance on large-scale datasets and advanced algorithms brings forth significant security and privacy concerns. This paper explores the evolution of GPT models, their applications, and the associated vulnerabilities. We address the issue of misplaced trust in AI-generated information, highlighting potential impacts on critical sectors such as healthcare and finance. Furthermore, we examine the ethical dilemmas and unforeseen repercussions of biased content generation. By conducting an extensive literature review and analyzing real-world case studies, we identify gaps in existing research and propose comprehensive mitigation strategies. Our comprehensive review categorizes various types of attacks on GPT models, offering practical recommendations to enhance the security and reliability of GPT-based systems in critical applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903828 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343123,
  title={ A Review of Agentic Artificial Intelligence: Power of Self-Driven AI in the Future of Financial Autonomy and Enhanced Customer Engagement  -  2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS) },
  year={2025},
  author={Bhat, A. K. and Krishnan, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167368 },
  abstract={The evolution of Large Language Models, Roboadvisors or chatbots, and Machine Learning Models have opened the possibilities for automation across sectors to innovate and introduce new capabilities as part of their business process. This review paper targets all the critical aspects of artificial intelligence and machine learning models and their impact on the successful deployment of the Agentic AI capability. Agents can not only participate but also assist, self-organize, and negotiate using parallel workstreams and cognitive architectures. They solve problems iteratively based on their cognitive level and domain, creating value in the financial services market, where opportunities are vast. This study further includes principles for Agentic AI, its lifecycle, various key components, impact on the financial industry, architectural considerations, data considerations, benchmarking, opportunities, future capabilities, challenges, and more.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSCDS65426.2025.11167368 },
  booktitle={ 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS) },
  chapter={0}
}

@article{rayyan-352343124,
  title={ A Comprehensive RAG-Based LLM for AI-Driven Mental Health Chatbot  -  2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA) },
  year={2025},
  author={Ilapaka, A. and Ghosh, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11017017 },
  abstract={Mental health challenges affect millions worldwide, with approximately 970 million people experiencing conditions such as anxiety and depression. In the United States alone, 57.8 million adults struggle with mental illness. Despite the growing need for support, many face barriers such as stigma, limited access to care, and long waiting times, especially in underserved areas with few mental health resources. AI-powered chatbots are an emerging intervention option that offers available, accessible, and confidential services. The study below describes the development of an AI chatbot to support people in distress, using a fine-tuned version of the Llama model, which was trained on actual mental health counseling conversations. The chatbot uses Retrieval-Augmented Generation (RAG) to improve the relevance of its responses and make interactions more personalized. It also leverages LangChain’s ConversationBufferMemory to recall past conversations, allowing for more natural and meaningful dialogue. Facebook AI Similarity Search (FAISS) and Sentence Transformer embeddings also allow the retrieval of relevant materials to provide practical, real-time coping strategies. This chatbot uses natural language processing (NLP) and machine learning (ML) to bridge the gaps in mental health care, making it more affordable, accessible, and free of stigma. The current paper discusses the effectiveness of chatbots, the challenges in AI-driven mental health support, and future improvements in deeper personalization, improved response refinement, and integration with multimedia resources for a more holistic user experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHORA65333.2025.11017017 },
  booktitle={ 2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA) },
  chapter={0}
}

@article{rayyan-352343125,
  title={ Effective Text Adaptation For LLM-Based ASR Through Soft Prompt Fine-Tuning  -  2024 IEEE Spoken Language Technology Workshop (SLT) },
  year={2024},
  author={Ma, Y. and Liu, Z. and Kalinli, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832227 },
  abstract={The advent of Large Language Models (LLM) has reformed the Automatic Speech Recognition (ASR). Prompting LLM with audio embeddings to generate transcriptions becomes the new state-of-the-art ASR. Despite LLMs being trained with an extensive amount of text corpora, high-quality domain-specific text data can still significantly enhance ASR performance on domain adaptation tasks. Although LLM-based ASR can naturally incorporate more text corpora by fine-tuning the LLM decoder, fine-tuning such ASR on text-only data without paired prompts may diminish the effectiveness of domain-specific knowledge. To mitigate this issue, we propose a two-step soft prompt fine-tuning strategy that enhances domain-specific text adaptation. Experimental results show that text adaptation with our proposed method achieved a relative up to 9% Word Error Rate (WER) reduction and up to 18% Entity Error Rate (EER) reduction on the target domain compared to the baseline ASR. Combining this with domain-specific Language Model (LM) fusion can further improve the EER by a relative 2-5%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SLT61566.2024.10832227 },
  booktitle={ 2024 IEEE Spoken Language Technology Workshop (SLT) },
  chapter={0}
}

@article{rayyan-352343126,
  title={ Co-Optimization of GPU AI Chip from Technology, Design, System and Algorithms  -  2024 IEEE International Electron Devices Meeting (IEDM) },
  year={2024},
  author={Hu, J. R. and Liu, L. and Liu, S. and Liew, B. and Guan, D. and Chen, J. and Jones, S. and Dally, W. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10873439 },
  abstract={We present a systematic approach to co-optimize GPU AI compute from technology to chip design, system and algorithms. This has enabled the best performance, power and yield for GPU HPC and AI chips and systems. GPU HPC improved 100x in past 10 years, more than Moore's Law, while traditional chips falling off the curve of Moores' Law due to challenges in scaling. AI compute perf has improved even faster, by ~ 1000x in 10 years. It continues to improve at 2x per year following Huang's Law in GPU AI Perf Scaling. Heterogeneous computing has enabled rapid system level perf boost options. The era of defects per trillion (DPPT) level of perfection has also arrived, to meet yield and reliability for today's complex GPU with 100s of billions of transistors and trillions of layout pieces, and in large language model (LLM) application in AI factories that runs tens of thousands of GPU AI chips in a cluster as one giant GPU. New technologies to improve memory and interconnect also helps provide further improvement to meet the demand for exponential growth of AI compute. Intelligent test chip designs are employed to identify issues and margins, to help predict large chip and high-volume issues with smart sample learning. Design for manufacturing (DFM), design for reliability (DFR) are used to optimize design & process, to maximize PPAYRT (power, performance, area, yield, reliability, time to market). Algorithms optimizations enabled further improvements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEDM50854.2024.10873439 },
  booktitle={ 2024 IEEE International Electron Devices Meeting (IEDM) },
  chapter={0}
}

@article{rayyan-352343127,
  title={ Enhancing Fine-Tuning LLM Evaluation: A Study on Calibration and Metrics for Industry-Specific AI Alignment  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Stavarache, L. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050607 },
  abstract={Evaluating Large Language Models (LLMs) for AI alignment necessitates methodologies that go beyond general-purpose benchmarks to address domain-specific challenges and ethical complexities. This study investigates alignment metrics tailored to industry-specific contexts, utilizing large datasets from subject matter experts and synthetic data to fine-tune LLMs. Existing metrics, when used out-of-the-box, often fail to offer actionable insights or maintain relevance in real-world applications. To mitigate this, we evaluate a range of AI alignment metrics, including Correctness, Faithfulness, Completeness, Conciseness, Harmfulness, and Maliciousness for fine-tuning QnA data tuples and fine-tuned LLM's responses after training. Furthermore, we address issues of disparate impacts and historical biases to improve the quality and fairness of QA pair generation. Grounded in a theoretical framework, we propose that AI alignment requires a dual approach, integrating general and domain-specific evaluation methodologies. Experimental results from fine-tuning LLMs in the Banking BIAN domain reveal significant shortcomings in existing frameworks. In this paper we propose an approach to emphasize and mitigate these gaps, ensuring nuanced and ethically grounded evaluation practices. This work advances alignment methodologies aimed at fostering transparency, trustworthiness, and responsible LLM deployment in high-stakes, regulated domains.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00217 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343128,
  title={ A Novel Approach to Generative AI-based Optimized Code Generation for Semiconductor Equipment Interfaces  -  2025 27th International Conference on Advanced Communications Technology (ICACT) },
  year={2025},
  author={Lee, H. and Yang, M. and Jeong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936654 },
  abstract={Generally, standardization defined by the SEMI association is well established and utilized in the semiconductor industry. In particular, most semiconductor equipment supports SECS / GEM communication protocols, and the automation and smart factory construction consist of equipment communication control programs using these standard protocols. We propose to improve development efficiency by automatically generating control program code using generative artificial intelligence technology to develop interface programs that control these semiconductor facilities. In addition, to improve the completeness and utilization of the automatically generated code, this paper presents a method to automatically generate semiconductor equipment control interface codes through generative artificial intelligence based on existing codes and minimize the constraints that may occur due to the hallucination effect, which is a significant weakness of generative artificial intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/ICACT63878.2025.10936654 },
  booktitle={ 2025 27th International Conference on Advanced Communications Technology (ICACT) },
  chapter={0}
}

@article{rayyan-352343129,
  title={ SecureGenKeys: Building Secure and Personalized Keypads with Generative AI  -  2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS) },
  year={2024},
  author={M, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716821 },
  abstract={Ensuring the security of systems is paramount in safeguarding confidential information from unauthorized access, particularly in today's interconnected digital landscape. Visual eavesdropping techniques, such as “Shoulder Surfing,” pose significant threats to security, including unauthorized access, data breaches, and identity theft, whereby sensitive information is illicitly obtained during user input. This paper introduces a novel method designed to fortify password security, simultaneously enhancing the user experience and facilitating secure transactions. The proposed methodology introduces a personalized interactive password selection process that not only increases user engagement but also bolsters security measures. User-entered prompts undergo processing to transform into personalized tokens and form a secure password. These tokens are utilized to generate foundational images in which the tokens are strategically allocated ensuring both clarity and randomness. The system employs machine learning algorithm, particularly focusing on deep learning approaches for image analysis and pattern recognition techniques to verify user-entered passwords against stored data. Successful authentication triggers secure transactions, providing a seamless and protected user experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICACCS60874.2024.10716821 },
  booktitle={ 2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS) },
  chapter={0}
}

@article{rayyan-352343130,
  title={ Optimizing Confidence Scoring in RAG-Based LLM Chatbots for Technical Support Services: A Prompt Engineering Approach  -  2025 IEEE 15th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  year={2025},
  author={Chan, W. T. and Hung, K. and Ho, R. and Man, G. Man-Tat},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081158 },
  abstract={The global shortage of skilled personnel in technical support has spurred significant interest in AI-driven solutions, particularly Large Language Model (LLM)-based customer service chatbots. However, a critical challenge in deploying these systems lies in addressing AI hallucination, wherein models generate responses that are plausible yet factually incorrect. This study investigates a prompt engineering approach to enhance confidence estimation and mitigate AI hallucinations in LLM chatbots. Three distinct prompt strategies—Basic, Advanced, and Combo prompts–are systematically evaluated to improve response reliability. Given that LLMs inherently lack the ability to explicitly express uncertainty (e.g., by stating “I don't know”), a structured confidence scoring mechanism is employed to refine accuracy and reduce the Expected Calibration Error (ECE). Experimental results reveal that Basic prompts achieve an accuracy of 69.33% (ECE: 23.33), Advanced prompts improve accuracy to 75.33% (ECE: 14.87), and Combo prompts further enhance accuracy to 81.33% while reducing ECE to 8.4. These findings underscore the efficacy of prompt engineering in mitigating AI hallucinations and advancing the performance of LLM chatbots in real-world customer support applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAIE64985.2025.11081158 },
  booktitle={ 2025 IEEE 15th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  chapter={0}
}

@article{rayyan-352343131,
  title={ Olive: An Instruction Following LLaMA Model For Odia Language  -  2023 IEEE Silchar Subsection Conference (SILCON) },
  year={2023},
  author={Parida, S. and Sekhar, S. and Panda, S. and Jena, S. and Parida, A. and Sahoo, S. K. and Dash, S. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404195 },
  abstract={The AI community is experiencing a profound impact from Large Language Models (LLMs), and the introduction of ChatGPT and GPT-4 is prompting a reconsideration of the potential of artificial general intelligence(AGI). However, most of the LLMs are trained in English and other high-resource languages, resulting in the unavailability of LLM and its related technologies and services for many low-resource languages. In India, where only 10% of the population is proficient in English, the need for LLM models adapted to regional languages becomes crucial.In this paper, we emphasized the need for LLM for the low-resource Odia language by evaluating the available LLM-supporting Odia language. We describe the development process of the instruction-tuning LLM model for Odia. The developed instruction tuning Odia LLM is available freely for research and non-commercial purposes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SILCON59133.2023.10404195 },
  booktitle={ 2023 IEEE Silchar Subsection Conference (SILCON) },
  chapter={0}
}

@article{rayyan-352343132,
  title={ A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model  -  Journal of Web Engineering },
  author={Park, D. and -t. An, G. and Kamyod, C. and Kim, C. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10452390 },
  abstract={In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.13052/jwe1540-9589.2285 },
  booktitle={ Journal of Web Engineering },
  chapter={0}
}

@article{rayyan-352343133,
  title={ Unlocking Data with Generative AI and RAG: Enhance generative AI systems by integrating internal data with large language models using RAG  -  Unlocking Data with Generative AI and RAG: Enhance generative AI systems by integrating internal data with large language models using RAG },
  author={Bourne, K. and Es, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769240.pdf&bkn=10769240&pdfType=book },
  abstract={Leverage cutting-edge generative AI techniques such as RAG to realize the potential of your data and drive innovation as well as gain strategic advantageKey FeaturesOptimize data retrieval and generation using vector databasesBoost decision-making and automate workflows with AI agentsOvercome common challenges in implementing real-world RAG systemsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionGenerative AI is helping organizations tap into their data in new ways, with retrieval-augmented generation (RAG) combining the strengths of large language models (LLMs) with internal data for more intelligent and relevant AI applications. The author harnesses his decade of ML experience in this book to equip you with the strategic insights and technical expertise needed when using RAG to drive transformative outcomes. The book explores RAG’s role in enhancing organizational operations by blending theoretical foundations with practical techniques. You’ll work with detailed coding examples using tools such as LangChain and Chroma’s vector database to gain hands-on experience in integrating RAG into AI systems. The chapters contain real-world case studies and sample applications that highlight RAG’s diverse use cases, from search engines to chatbots. You’ll learn proven methods for managing vector databases, optimizing data retrieval, effective prompt engineering, and quantitatively evaluating performance. The book also takes you through advanced integrations of RAG with cutting-edge AI agents and emerging non-LLM technologies. By the end of this book, you’ll be able to successfully deploy RAG in business settings, address common challenges, and push the boundaries of what’s possible with this revolutionary AI technique.What you will learnUnderstand RAG principles and their significance in generative AIIntegrate LLMs with internal data for enhanced operationsMaster vectorization, vector databases, and vector search techniquesDevelop skills in prompt engineering specific to RAG and design for precise AI responsesFamiliarize yourself with AI agents' roles in facilitating sophisticated RAG applicationsOvercome scalability, data quality, and integration issuesDiscover strategies for optimizing data retrieval and AI interpretabilityWho this book is forThis book is for AI researchers, data scientists, software developers, and business analysts looking to leverage RAG and generative AI to enhance data retrieval, improve AI accuracy, and drive innovation. It is particularly suited for anyone with a foundational understanding of AI who seeks practical, hands-on learning. The book offers real-world coding examples and strategies for implementing RAG effectively, making it accessible to both technical and non-technical audiences. A basic understanding of Python and Jupyter Notebooks is required.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Unlocking Data with Generative AI and RAG: Enhance generative AI systems by integrating internal data with large language models using RAG },
  chapter={0}
}

@article{rayyan-352343134,
  title={ Applying Generative AI to Create SOP, Reducing API Costs Through Prompt Compression and Evaluating LLM Responses with Tonic Validate RAG Metrics  -  2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS) },
  year={2024},
  author={Vetriselvi, T. and Mathur, M. and Bhuvaneswari, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10867024 },
  abstract={Generative Artificial Intelligence (AI) utilizes existing data to create new forms of content, including text, images, and audio. One valuable application of generative AI in an IT Enabled Services (ITES) company is the development of Standard Operating Procedures (SOPs) by processing and consolidating existing SOPs through a Large Language Model. This paper explores how generative AI can generate content within standardized templates, improve the language of SOPs, and make them suitable for specific industries and processes, such as the pharmaceutical procure-to-pay process. It also addresses version control, helps users maintain consistency and compliance, extracts knowledge for onboarding, and provides interactive training on SOPs through Questions and Answers. The proposed workflow employs Azure OpenAI's GPT-3.5 turbo for generating responses, which are evaluated using Tonic Validate Retrieval Augmented Generation (RAG) metrics. Furthermore, the paper introduces Prompt Compression approaches and selects one prompt compression approach to streamline the context retrieved for large language models while preserving the semantic meaning of the outputs. It also details strategies for reducing API call costs by over 10% for prompts of varying token sizes, ensuring high-quality responses from the GPT-3.5 turbo model according to RAG metrics. These criteria of accuracy, precision and cost reduction are considered to recommend the prompt compression approach for Large Language Models used in development of Standard Operating Procedures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICUIS64676.2024.10867024 },
  booktitle={ 2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS) },
  chapter={0}
}

@article{rayyan-352343135,
  title={ Revolutionizing Assessment: AI-Powered Evaluation with RAG and LLM Technologies  -  2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS) },
  year={2024},
  author={Sundar, K. and Manohar, E. and Vijay, K. and Prakash, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760285 },
  abstract={The world of Artificial Intelligence is rapidly evolving after the introduction of GEN AI. Artificial Intelligence is being adopted in many fields and to automate complex works which frees up humans to something better. In the field of education, Artificial Intelligence is used in various ways, to tailor the content to meet the needs of individual students, one to one tutoring experience, as teaching assistant, in planning, content development. The scope AI and its subfield can be leveraged further, and it is possible to use it for exam assessment, use the data from Student Management System to generate some meaningful insight on Students behavior, discipline, attendance etc. Natural Language Processing, a subset of Artificial Intelligence can be combined with other AI subsets like Large Language Model to facilitate the Teacher, Parents and Students interaction, Parents can use chatBots to receive candid feedback of their kid’s performance, to generate relative performance improvement compared to previous cycle, suggestion for improvement. All it takes is to connect the Artificial Intelligence subsets with some reference system like Students database. This research analysis is to evaluate student’s performance and provide feedback factoring based on four main areas like exam answer sheet, practicals, attendance and assignments. This research provides technical implementation and guidance to implement the solution using the Retrieval Augmented Generation and Large Language Model, and an architectural overview of combining data from various input modes like student information from Student Management System, text book, digital answer sheet and embedding them in the Vector database.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSSAS64001.2024.10760285 },
  booktitle={ 2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS) },
  chapter={0}
}

@article{rayyan-352343136,
  title={ Enhancing Clinical Decision-Making: Integrating Multi-Agent Systems with Ethical AI Governance  -  2025 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB) },
  year={2025},
  author={Chen, Y. -J. and Albarqawi, A. and Chen, C. -S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11177136 },
  abstract={Recent advances in the data-driven medicine approach, which integrates ethically managed and explainable artificial intelligence into clinical decision support systems (CDSS), are critical to ensure reliable and effective patient care. This paper focuses on comparing novel agent system designs that use modular agents to analyze laboratory results, vital signs, and clinical context, and to predict and validate results. We implement our agent system with the eICU database, including running lab analysis, vitals-only interpreters, and contextual reasoners agents first, then sharing the memory into the integration agent, prediction agent, transparency agent, and a validation agent. Our results suggest that the multi-agent system (MAS) performed better than the single-agent system (SAS) with mortality prediction accuracy (59%, 56%) and the mean error for length of stay (LOS)(4.37 days, 5.82 days), respectively. However, the transparency score for the SAS (86.21) is slightly better than the transparency score for MAS (85.5). Finally, this study suggests that our agent-based framework not only improves process transparency and prediction accuracy but also strengthens trustworthy AI-assisted decision support in an intensive care setting.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIBCB66090.2025.11177136 },
  booktitle={ 2025 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB) },
  chapter={0}
}

@article{rayyan-352343137,
  title={ Beyond Replacement: A Hermeneutic Phenomenological Approach to Human-AI Collaboration  -  2024 IEEE International Symposium on Technology and Society (ISTAS) },
  year={2024},
  author={Gonzalez, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10732595 },
  abstract={This paper examines the integration of large language models (LLMs) in the workplace using a hermeneutic phenomenological approach, highlighting the critical differences between human language use and LLM operational mechanisms. It challenges the uncritical adoption of LLMs, emphasizing their limitations in contextual understanding and intuitive decision-making. Advocating a reimagined workforce, the paper proposes viewing LLMs as "AI interns" and humans as "Master Orchestrators," focusing on enhancing human creativity and ingenuity to ensure AI supports rather than replaces human capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISTAS61960.2024.10732595 },
  booktitle={ 2024 IEEE International Symposium on Technology and Society (ISTAS) },
  chapter={0}
}

@article{rayyan-352343138,
  title={ Enhancing Medical Libraries: AI-Driven Tools and Techniques for Digital Transformation and Sustainable Innovation  -  2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI) },
  year={2025},
  author={Jothi, T. and Dominic, J. and Jaganbabu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893904 },
  abstract={Artificial intelligence (AI) is transforming numerous fields, particularly in research and education, and its integration into medical library operations has become essential to maintaining relevance and competitiveness in today's global landscape. This exploration examines how AI-driven tools and methods are reshaping various aspects of medical library services, offering a comprehensive look at the potential and practical applications of AI in the library setting. The core objective of AI is to develop systems capable of performing cognitive tasks that mimic human thought. By incorporating AI, medical libraries can transcend physical limitations, becoming more intelligent, accessible, and responsive. This article explores how advancements such as Natural Language Processing (NLP), Large Language Models (LLM), Expert Systems (ES), AI-powered indexing tools, and Chabot's can enhance medical library infrastructure and services. These AI applications hold promise for improving outcomes across user groups-benefiting students, faculty, healthcare researchers, and clinical practitioners a like. In providing an in-depth analysis of AI's advantages, limitations, and innovative uses, this article fosters a deeper understanding of AI's role in library science. Through a balanced perspective on AI's transformative potential, libraries are equipped to make informed decisions, leveraging technology to support an evolving and dynamic medical information environment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMSCI62561.2025.10893904 },
  booktitle={ 2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI) },
  chapter={0}
}

@article{rayyan-352343139,
  title={ AI, ML, and LLM Integration in 5G/6G Networks: A Comprehensive Survey of Architectures, Challenges, and Future Directions  -  IEEE Access },
  author={Usman, Y. and Oladipupo, H. and During, A. D. and Akl, R. and Chataut, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159193 },
  abstract={The transition from 5G to 6G networks demands groundbreaking advances in intelligence, adaptability, and security to support emerging applications such as real-time telemedicine, immersive extended reality (XR), and autonomous systems. This article provides a comprehensive analysis of how artificial intelligence (AI), machine learning (ML), and large language models (LLM) are revolutionizing next-generation telecommunications. We present a structured roadmap for integrating these technologies into 6G infrastructure, emphasizing their transformative roles in intelligent network management, dynamic resource allocation, and proactive threat mitigation. By addressing key challenges such as ultralow latency, heterogeneous data handling, and ethical governance, this study bridges theoretical innovations with practical applications. Notable contributions include novel frameworks for AI-enhanced security, self-healing networks, and privacy-preserving techniques like federated learning. Furthermore, we explore critical ethical considerations, including bias mitigation and transparency in AI decision-making, while highlighting emerging research directions such as adaptive learning systems and hybrid AI architectures. This work underscores the synergistic potential of AI and 6G, equipping researchers and industry stakeholders with actionable insights to develop resilient, user-centric networks that will shape the future of global connectivity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3608736 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343140,
  title={ Beyond Traditional Biases in AI Hiring: Exposing the Hidden Systemic Challenges in Resume Screening  -  2025 Systems and Information Engineering Design Symposium (SIEDS) },
  year={2025},
  author={Bhatnagar, S. and Shetty, S. and Arora, N. and Sachdev, V. and Bahrini, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11021210 },
  abstract={From automatically curating your music playlist to guiding life-changing hiring decisions, artificial intelligence now discreetly shapes every corner of our world, including how we recruit. In theory, using AI in recruitment streamlines processes and saves valuable time for hiring teams. Yet, concerns remain about whether automated methods are truly fair and equitable. AI can inadvertently encode biases tied to demographic factors such as race and gender, prompting organizations to explore Explainable AI for greater transparency. However, hidden biases may persist undetected, even when personal information is removed. These details can threaten the integrity of our hiring practices and often slip beneath our awareness. Our work explores these overlooked biases, offering insights and strategies to foster more ethical, inclusive recruitment processes. In this paper, we conduct a controlled experiment using a Large Language Modelsbased recruitment tool to quantify how subtle resume variations can influence candidate evaluations. By isolating factors such as “career gaps” and “keyword usage”, we highlight overlooked biases that can significantly alter AIdriven hiring outcomes. Our work explores these overlooked biases, offering insights and strategies to foster more ethical, inclusive recruitment processes. Keywords- Algorithmic bias, AI fairness, LLM-based hiring, Explainable AI, Ethical AI in recruitment},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SIEDS65500.2025.11021210 },
  booktitle={ 2025 Systems and Information Engineering Design Symposium (SIEDS) },
  chapter={0}
}

@article{rayyan-352343141,
  title={ Automated Exam Script Checking using Zero-Shot LLM and Adaptive Generative AI  -  2024 IEEE International Conference on Computing, Applications and Systems (COMPAS) },
  year={2024},
  author={Himi, S. T. and Monalisa, N. Tanzila and Sultana, S. and Afrin, A. and Hasib, K. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795949 },
  abstract={The manual grading of exam scripts is a labor-intensive process, often plagued by subjectivity and inconsistency. This study presents an innovative approach to automating the evaluation of exam scripts using the Large Language Model (LLM) integrated with Zero-Shot Learning (ZSL) and Generative AI. Our system leverages the capabilities of GPT-4 to generate and evaluate answers, applying similarity measures to ensure accuracy and fairness in grading. The model’s adaptability through ZSL allows it to assess new questions without additional training. The system also incorporates iterative refinement techniques to enhance the quality of standard answers over time. Performance evaluations demonstrate a low error rate, with an average relative error of 1.29% for annotated questions and 1.67% for non-annotated questions compared to human graders. The performance underscores the automated system’s transformative potential in revolutionizing educational assessments, offering a consistent, fair, and highly efficient alternative to traditional grading methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPAS60761.2024.10795949 },
  booktitle={ 2024 IEEE International Conference on Computing, Applications and Systems (COMPAS) },
  chapter={0}
}

@article{rayyan-352343142,
  title={ Drug Pills Identification System using Google Gemini LLM: A Generative AI approach  -  2024 International Conference on Emerging Research in Computational Science (ICERCS) },
  year={2024},
  author={R, M. and R, A. and N, M. P. and Unnikrishnan, A. and S, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895371 },
  abstract={Generative AI is emerging as a disruptive force in the healthcare industry, bringing novel solutions ranging from drug development and clinical decision support to personalized patient care. This study is focused on drug discovery using the Generative AI model. In this paper, a system is proposed for providing drug descriptions from drug pill images. The system is implemented by utilizing Large Language Models (LLMs) in combination with computer vision to detect and provide detailed information about drugs from pill images. In the proposed system, the identification process begins by taking the medicinal drug pills and their cover images. Then, the image is converted into binary values using a standard built-in function. In addition, the target language for providing audio descriptions about the drugs is also used. Then, the Google Gemini LLM model is customized by using binary values of the image, target language, and ontology-based prompt engineering. As a result, the LLM model provides drug descriptions in text. Then, the textual description of the drug is converted into the target language audio format by using the Google Text to Speech Converter. The system is experimented by using 807 medicinal drug images which are collected from web resources. The performance of the system is measured by using accuracy. The system achieved an accuracy of 95.04% which is a little higher when compared with the current state-of-the-art model.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICERCS63125.2024.10895371 },
  booktitle={ 2024 International Conference on Emerging Research in Computational Science (ICERCS) },
  chapter={0}
}

@article{rayyan-352343143,
  title={ Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective  -  2024 International Joint Conference on Neural Networks (IJCNN) },
  year={2024},
  author={Singh, G. and Bali, K. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10649965 },
  abstract={This paper explores the seamless integration of Generative AI (GenAI) and Evolutionary Algorithms (EAs) within the domain of large-scale multi-objective optimization. Focusing on the transformative role of Large Language Models (LLMs), our study investigates the potential of LLM-Assisted Inference to automate and enhance decision-making processes. Specifically, we highlight its effectiveness in illuminating key decision variables in evolutionarily optimized solutions while articulating contextual trade-offs. Tailored to address the challenges inherent in inferring complex multi-objective optimization solutions at scale, our approach emphasizes the adaptive nature of LLMs, allowing them to provide nuanced explanations and align their language with diverse stakeholder expertise levels and domain preferences. Empirical studies underscore the practical applicability and impact of LLM-Assisted Inference in real-world decision-making scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IJCNN60899.2024.10649965 },
  booktitle={ 2024 International Joint Conference on Neural Networks (IJCNN) },
  chapter={0}
}

@article{rayyan-352343144,
  title={ Offline LLM-Based Expert Systems for Confidential Software Documentation: Integrating Ollama and JSON Templates for Regulatory Adherence  -  2025 IEEE Space, Aerospace and Defence Conference (SPACE) },
  year={2025},
  author={Mittal, N. and D, D. V and P, J. K and Santhya, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11170588 },
  abstract={This paper presents an offline expert system leveraging a locally deployed Large Language Model (LLM) via Ollama to automate secure, structured software project documentation. Operating entirely on-device, the system ensures data confidentiality while adhering to industry standards and user-customizable requirements. A novel JSON-formatted dataset fine-tunes the Ollama model to dynamically select context appropriate templates based on project type and inputs, streamlining compliance with regulatory frameworks. By eliminating cloud dependencies, the solution mitigates risks associated with third-party AI services, prioritizing privacy for sensitive projects. The framework demonstrates efficient offline document generation VS code IDE, balancing standardization with adaptability, and offers a scalable approach for secure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPACE65882.2025.11170588 },
  booktitle={ 2025 IEEE Space, Aerospace and Defence Conference (SPACE) },
  chapter={0}
}

@article{rayyan-352343145,
  title={ Design, Validation, and Risk Assessment of LLM-Based Generative AI Systems Operating in the Legal Sector  -  2024 IEEE International Symposium on Systems Engineering (ISSE) },
  year={2024},
  author={Buchicchio, E. and Angelis, A. De and Moschitta, A. and Santoni, F. and Marco, L. S. and Carbone, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10741134 },
  abstract={Large Language Models (LLMs) are increasingly capable of supporting user decisions and performing various tasks autonomously in a wide range of professional domains, including the legal sector. In this work, we describe the general lifecycle of LLM-based systems and the architecture of a system designed to support legal experts in the process of generating maxims from judgments. We propose three application-specific performance metrics and a general-purpose assessment method suitable for the comparison of different systems in any content generation task. Finally, we discuss the results achieved by the system prototype that, according to a board of magistrates, outperforms human experts in the task of generating maxims from judgments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["Ils affirment que la maintenance doit intégrer un versioning explicite du système et des modèles, afin de permettre les rollbacks et la reproductibilité (NMVP). Ils mettent en avant la taille de contexte comme critère de sélection des LLM dans un scénario de traitement de longs jugements, et discutent des coûts et ressources associés au processus à grande échelle(UMM). Ils détaillent un cadre de risk assessment et de red teaming, mentionnant explicitement les attaques de type prompt injection et la nécessité de filtres dans les pipelines, sous la contrainte de l’AI Act. "]}},
  doi={ 10.1109/ISSE63315.2024.10741134 },
  booktitle={ 2024 IEEE International Symposium on Systems Engineering (ISSE) },
  chapter={0}
}

@article{rayyan-352343146,
  title={ MLSDET: Multi-LLM Statistical Deep Ensemble for Chinese AI-Generated Text Detection  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Mao, D. and Zhang, D. and Zhang, A. and Zhao, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888686 },
  abstract={With the rapid advancements in pre-trained large language models like ChatGPT, the surge of AI-generated text, particularly in Chinese, has presented significant challenges to existing detection systems due to its increasing realism and complexity. To address this, we introduce MLSDET: a groundbreaking Multi-LLM Statistical Deep Ensemble framework designed for high-precision detection of AI-generated Chinese text. MLSDET uniquely integrates a Mixture of Experts (MoE) architecture with a novel cross-entropy metric, setting a new benchmark for robustness and generalization. By employing a diverse ensemble of large language models (LLMs), including Qwen, Wenzhong-GPT2, and LLaMA, our approach extracts intricate features such as log-rank, entropy, log-likelihood, and the newly introduced LLMs-crossEntropy, accurately capturing both model consensus and the statistical distribution differences between AI-generated and human-authored text. Experimental results on the HC3-Chinese dataset show that MLSDET surpasses traditional zero-shot methods like CLTR by 15.94% in F1 score and competes effectively with existing methods, offering a scalable solution for real-world applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888686 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343147,
  title={ Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach  -  2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC) },
  year={2024},
  author={Hasan, S. M. and Alotaibi, A. M. and Talukder, S. and Shahid, A. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633440 },
  abstract={With the proliferation of edge devices, there is a significant increase in attack surface on these devices. The decen-tralized deployment of threat intelligence on edge devices, coupled with adaptive machine learning techniques such as the in-context learning feature of Large Language Models (LLMs), represents a promising paradigm for enhancing cybersecurity on resource-constrained edge devices. This approach involves the deployment of lightweight machine learning models directly onto edge devices to analyze local data streams, such as network traffic and system logs, in real-time. Additionally, distributing computational tasks to an edge server reduces latency and improves responsiveness while also enhancing privacy by processing sensitive data locally. LLM servers can enable these edge servers to autonomously adapt to evolving threats and attack patterns, continuously updating their models to improve detection accuracy and reduce false positives. Furthermore, collaborative learning mechanisms facilitate peer-to-peer secure and trustworthy knowledge sharing among edge devices, enhancing the collective intelligence of the network and enabling dynamic threat mitigation measures such as device quarantine in response to detected anomalies. The scalability and flexibility of this approach make it well-suited for diverse and evolving network environments, as edge devices only send suspicious information such as network traffic and system log changes, offering a resilient and efficient solution to combat emerging cyber threats at the network edge. Thus, our proposed framework can improve edge computing security by providing better security in cyber threat detection and mitigation by isolating the edge devices from the network.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPSAC61105.2024.00206 },
  booktitle={ 2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC) },
  chapter={0}
}

@article{rayyan-352343148,
  title={ Enhancing Cybersecurity in Critical Infrastructure with LLM-Assisted Explainable IoT Systems  -  2025 1st International Conference on Secure IoT, Assured and Trusted Computing (SATC) },
  year={2025},
  author={Ghimire, A. and Ghajari, G. and Gurung, K. and Sah, L. K. and Amsaad, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11137104 },
  abstract={Ensuring the security of critical infrastructure has become increasingly vital with the proliferation of Internet of Things (IoT) systems. However, the heterogeneous nature of IoT data and the lack of human-comprehensible insights from anomaly detection models remain significant challenges. This paper presents a hybrid framework that combines numerical anomaly detection using Autoencoders with Large Language Models (LLMs) for enhanced preprocessing and interpretability. Two preprocessing approaches are implemented: a traditional method utilizing Principal Component Analysis (PCA) to reduce dimensionality and an LLM-assisted method where GPT-4 dynamically recommends feature selection, transformation, and encoding strategies.Experimental results on the KDDCup99 10% corrected dataset demonstrate that the LLM-assisted preprocessing pipeline significantly improves anomaly detection performance. The macro-average F1 score increased from 0.49 in the traditional PCAbased approach to 0.98 with LLM-driven insights. Additionally, the LLM generates natural language explanations for detected anomalies, providing contextual insights into their causes and implications. This framework highlights the synergy between numerical AI models and LLMs, delivering an accurate, interpretable, and efficient solution for IoT cybersecurity in critical infrastructure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SATC65530.2025.11137104 },
  booktitle={ 2025 1st International Conference on Secure IoT, Assured and Trusted Computing (SATC) },
  chapter={0}
}

@article{rayyan-352343149,
  title={ Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods  -  IEEE Engineering Management Review },
  author={Bilgram, V. and Laarmann, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115412 },
  abstract={Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EMR.2023.3272799 },
  booktitle={ IEEE Engineering Management Review },
  chapter={0}
}

@article{rayyan-352343150,
  title={ An Overview of AI Platforms, Frameworks, Libraries, and Processors  -  Model Optimization Methods for Efficient and Edge AI: Federated Learning Architectures, Frameworks and Applications },
  author={Akkisetty, P. K.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10770781.pdf&bkn=10770699&pdfType=chapter },
  abstract={Summary <p>Chapter 3 provides a comprehensive overview of the essential components in AI development, including AI platforms, frameworks, libraries, and processors. It delves into the critical role these components play in building and deploying AI applications both in the cloud and at the edge. The chapter begins with an introduction to the fundamental building blocks of AI, emphasizing the significance of AI platforms and the necessary environments they provide for development, deployment, monitoring, and orchestration. It explores Edge AI, highlighting its transformative potential for real‐time insights and automation in various industries. The chapter also details popular AI frameworks and their inference solutions, such as TensorFlow, PyTorch, and ONNX Runtime, and discusses the importance of AI libraries for quick and efficient AI application development. Special attention is given to MLIR and its growing importance in AI compiler library development. Finally, the chapter examines the various AI processors, including GPUs, TPUs, and specialty ASIC hardware, discussing their specifications, use cases, and the benefits they offer for AI workloads.</p>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1002/9781394219230.ch3 },
  booktitle={ Model Optimization Methods for Efficient and Edge AI: Federated Learning Architectures, Frameworks and Applications },
  chapter={0}
}

@article{rayyan-352343151,
  title={ LLM-AQuA-DiVeR: LLM-Assisted Quality Assurance Through Dialogues on Verifiable Specification with Requirement Owners  -  2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE) },
  year={2025},
  author={Mitani, S. and Moona, S. and Matsuo, S. and Burger, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029423 },
  abstract={Quality Assurance (QA) is important for verifying software compliance with stakeholder requirements. QA faces a fundamental challenge of requirement interpretation ambiguity, which can result in insufficient software verification and failure in achieving the stakeholders' intended quality. The interpre-tation challenge intensifies in software development driven by Large Language Models (LLMs), where over-reliance can lead to missed quality-critical alternatives. However, existing works have paid limited attention to stakeholder involvement. We propose an LLM-assisted QA framework extending conventional LLM-driven development to enable stakeholder engagement in software verification. Our framework employs formal methods and rigorous testing to meet diverse quality demands, though this comprehensive verification introduces technical complexity affecting stakeholder engagement and verification costs. Our framework addresses these challenges through two key LLM roles: 1) an explanation assistant for stakeholder understanding, 2) a refinement assistant for incorporating stakeholder feedback while maintaining feasible verification costs. Our initial evaluation empirically demonstrates the framework's effectiveness through participant assessment scores, showing improved quality risk comprehension and efficient feedback incorporation in the verification process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAIE66699.2025.00008 },
  booktitle={ 2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE) },
  chapter={0}
}

@article{rayyan-352343152,
  title={ Exploring Explainable AI in Large Language Models: Enhancing Transparency and Trust  -  2024 11th International Conference on Advances in Computing and Communications (ICACC) },
  year={2024},
  author={H, I. A. and Jo, A. A. and Raj, E. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845370 },
  abstract={Large Language Models (LLMs) are at the forefront of technological evolution, significantly enhancing digital interactions and automating complex processes across various sectors. While these models facilitate advancements in data analytics, content generation, and strategic decision-making, their opaque nature poses challenges regarding user trust and model comprehension. Addressing the critical need for transparency, this paper focuses on enhancing LLM explainability. We propose a framework to demystify the internal mechanisms of these models, facilitating a deeper understanding that aligns with stringent ethical standards. Our approach integrates advanced explanatory tools that elucidate model decisions and foster accountability and fairness in Artificial Intelligence applications. Through rigorous analysis and the development of novel interpretative methodologies, we aim to bridge the gap between LLM capabilities and ethical AI practices, ensuring that these powerful tools are leveraged responsibly and transparently in critical infrastructures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["idée que fournir des explications ou des scores sans calibrage ni validation peut induire une confiance mal placée dans les sorties du modèle, ce qui rejoint la motivation d un smell de type Uncalibrated confidence signals dans des systèmes critiques"]}},
  doi={ 10.1109/ICACC63692.2024.10845370 },
  booktitle={ 2024 11th International Conference on Advances in Computing and Communications (ICACC) },
  chapter={0}
}

@article{rayyan-352343153,
  title={ Explainable AI Frameworks for Large Language Models in High-Stakes Decision-Making  -  2025 International Conference on Advanced Computing Technologies (ICoACT) },
  year={2025},
  author={Chittimalla, S. K. and Potluri, L. K. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11005089 },
  abstract={In high-stakes decision-making, such as healthcare diagnostics, financial forecasting, and legal judgments, trust and transparency are key in AI systems. LLMs have indeed proved to be very capable in processing and generating human-like text, making them invaluable tools in these critical sectors. However, the opacity of their decision-making processes poses a significant challenge for accountability and ethical compliance. This paper introduces comprehensive Explainable AI frameworks tailored for LLMs with the goal of improving their interpretability and reliability for high-stakes environments. Using publicly available real-world datasets, we systematically study the effectiveness of various XAI techniques, including attention visualization, feature importance mapping, and counterfactual explanations. Our findings point to the fact that such embedding serves not only to demystify the decision pathways of LLMs but also to bring their operations in line with regulatory standards and stakeholder expectations. This research makes its contribution to responsible LLM deployment in situations where mistakes have significant consequences by closing the gap between sophisticated AI capabilities and the need for transparent decision-making. The proposed XAI frameworks will, in the end, be a starting point for trust, ethics, and wider acceptance of AI-driven solutions in high-stakes domains.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoACT63339.2025.11005089 },
  booktitle={ 2025 International Conference on Advanced Computing Technologies (ICoACT) },
  chapter={0}
}

@article{rayyan-352343154,
  title={ Generative AI and Inter-rater Reliability: LLM Consistency in Coding Orders of Worth in Digital Political Debates  -  2025 25th International Conference on Control Systems and Computer Science (CSCS) },
  year={2025},
  author={Ioan, A. and Rosner, D. and Radovici, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181634 },
  abstract={This study investigates inter-rater reliability among seven large language models (LLMs) when coding justificatory regimes in political discourse using Boltanski and Thévenot's orders of worth framework. We analyze how ChatGPT-4o, Claude 3.7 Sonnet, Perplexity Sonar, Gemini 2.0 Flash, Grok 3, Mistral, and Perplexity R1 identify and score the presence of nine orders of worth in a Reddit thread about EU regulatory action against TikTok. The research employs a two-stage methodology—first measuring baseline agreement across models, then assessing convergence after exposing all models to shared interpretive references. Results reveal structured patterns of interpretive alignment and divergence: civic, green, and projective orders show perfect consensus across all models, while fame, domestic, and market orders generate significant disagreement. After exposure to interpretive scaffolding, models demonstrate convergence, with eight of nine orders achieving perfect consensus. This convergence suggests that while initial outputs vary, LLMs can achieve substantial interpretive alignment when provided with explicit normative cues. The persistent variance in coding domestic order, even after calibration, indicates that certain justificatory regimes remain computationally ambiguous. These findings contribute to methodological discussions about LLM reliability in qualitative content analysis and theoretical debates about the computational legibility of different moral grammars.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCS66924.2025.00099 },
  booktitle={ 2025 25th International Conference on Control Systems and Computer Science (CSCS) },
  chapter={0}
}

@article{rayyan-352343155,
  title={ Implementation and Evaluation of LLM on a CGLA  -  2024 Twelfth International Symposium on Computing and Networking (CANDAR) },
  year={2024},
  author={Uetani, H. and Nakashima, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818338 },
  abstract={Currently, generative AI services such as ChatGPT are attracting global attention. At the same time, the shortage of processing resources like GPUs and the increase in power demand have become significant issues, making the balance between processing performance and power efficiency a critical challenge. In this study, we evaluated the performance of Large Language Models (LLMs) using the IMAX3 prototype of our research group’s proposed Linear Array Coarse-Grained Reconfigurable Architecture (CGLA). IMAX3 is implemented on a Field Programmable Gate Array (FPGA), and we compared its processing speed and power efficiency with other computing platforms such as CPUs. IMAX aims to provide a versatile and efficient computing platform for services, including AI, with ease of use being another vital aspect. During the evaluation, we made improvements, such as adding a conversion table from 4-bit integers to single-precision floating-point numbers in the IMAX3 floating-point unit. As a result, we successfully ran GGML, a library for running LLMs on CPUs, on the IMAX3. The computation time ratio reached 80%, demonstrating the potential of CGLA as a viable computing platform for LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CANDAR64496.2024.00040 },
  booktitle={ 2024 Twelfth International Symposium on Computing and Networking (CANDAR) },
  chapter={0}
}

@article{rayyan-352343156,
  title={ AI Powered Transformative Post Generator for LinkedIn using LLM and Explicit Filter  -  2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES) },
  year={2023},
  author={Jain, V. and Goel, Y. and G, S. and Uma, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10465576 },
  abstract={This research paper presents an advanced LinkedIn post generator that utilizes cutting-edge Language Models (LLMs) to discern user intent and generate contextually relevant content. The system meticulously analyzes user input to craft professional and engaging LinkedIn posts. This tool has signifi- cant potential for individuals and businesses seeking to enhance content creation and maintain a consistent social media presence. Our paper encompasses natural language processing techniques, prompt engineering, and a user-friendly interface design. It includes an explicit content filter to ensure the production of appropriate and professional content in line with LinkedIn's standards. This paper provides a comprehensive overview of our development process, technology stack, user intent recognition methodology, and user interface design. We also discuss the practical applications, benefits, and implications of this tool for improving online presence and content creation efficiency within professional social media platforms. This research contributes to the growing field of AI-driven content generation in the context of professional networking platforms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSES60034.2023.10465576 },
  booktitle={ 2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES) },
  chapter={0}
}

@article{rayyan-352343157,
  title={ VirtualXAI: A User-Centric Framework for Explainability Assessment Leveraging GPT-Generated Personas  -  2025 21st International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT) },
  year={2025},
  author={Makridis, G. and Koukos, V. and Fatouros, G. and Kotios, D. and Separdani, M. M. and Kyriazis, D. and Soldatos, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096163 },
  abstract={In today's data-driven era, computational systems generate vast amounts of data that drive the digital transformation of industries, where Artificial Intelligence (AI) plays a key role. Currently, the demand for eXplainable AI (XAI) has increased to enhance the interpretability, transparency, and trustworthiness of AI models. However, evaluating XAI methods remains challenging: existing evaluation frameworks typically focus on quantitative properties such as fidelity, consistency, and stability without taking into account qualitative characteristics such as satisfaction and interpretability. In addition, practitioners face a lack of guidance in selecting appropriate datasets, AI models, and XAI methods - a major hurdle in human-AI collaboration. To address these gaps, we propose a framework that integrates quantitative benchmarking with qualitative user assessments through virtual personas based on the “Anthology” of backstories of the Large Language Model (LLM). Our framework also incorporates a content-based recommender system that leverages dataset-specific characteristics to match new input data with a repository of benchmarked datasets. This yields an estimated XAI score and provides tailored recommendations for both the optimal AI model and the XAI method for a given scenario.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DCOSS-IoT65416.2025.00156 },
  booktitle={ 2025 21st International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT) },
  chapter={0}
}

@article{rayyan-352343158,
  title={ CAPRI: A Context-Aware Privacy Framework for Multi-Agent Generative AI Applications  -  IEEE Access },
  author={Park, J. H. and Madisetti, V. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10916629 },
  abstract={While the swift advancement of cloud-based Large Language Models (LLMs) has significantly increased the efficiency and automation in business processes, it has also introduced considerable privacy concerns regarding Personally Identifiable Information (PII) and other protected data in multimodal forms, such as text, video, or images, being exported, potentially insecurely, outside the corporate environments. Although traditional anonymization-based techniques can alleviate these risks in offline applications, such as summarization or classification, incorporating it into online LLM workflows poses substantial challenges, particularly when these workflows encompass real-time transactions involving multiple stakeholders, as commonly observed in multi-agent generative AI applications. This study explores these challenges and proposes novel context-aware privacy frameworks and methods to address these issues. We employ a local privacy-focused gatekeeper LLM to contextually pseudonymize PII and assign unique identifiers as part of a new mapping process, thereby facilitating re-identification in real-time operations while safeguarding privacy when interacting with cloud-based LLMs. Our proposed methodologies and frameworks adeptly integrate privacy considerations into LLM and LLM Agent workflows, preserving both privacy and data utility while maintaining operational efficiency and utility comparable to non-anonymized generative AI processes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3549312 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343159,
  title={ LLM-Empowered Image Generation in the Neko Painter App: A Preliminary Application for Producing Teaching Materials  -  2024 4th International Conference on Educational Technology (ICET) },
  year={2024},
  author={Wu, K. and Ding, J. and Li, J. and Yang, Y. and Zhang, C. and Cao, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10868922 },
  abstract={This paper introduces the Neko Painter app and its key features, demonstrates the Large Language Models (LLMs)-empowered image generation with diffusion models and ContorlNet to be smarter and more automatic to control and optimise the image generation process, and shares some cases of using it to produce teaching materials. A preliminary application for producing teaching materials on General Studies using the Neko Painter app was conducted with 36 pre-service teachers from Hong Kong. The results showed that using LLM-empowered features positively impacts pre-service teachers’ motivation in producing teaching materials by using image generation. Future work will further explore the potential of LLM-empowered image generation in more educational subjects and scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICET62460.2024.10868922 },
  booktitle={ 2024 4th International Conference on Educational Technology (ICET) },
  chapter={0}
}

@article{rayyan-352343160,
  title={ Expert and LLM Evaluation of LearnShield: A Generative AI Recomnadation Application in E-Learning Environments  -  2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT) },
  year={2025},
  author={Almasre, M. A. and Al-Malki, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11082779 },
  abstract={With the increasing demand for e-learning systems in educational contexts, and the constant interactions with them in day-to-day learning activities, there is a high demand for dynamic approaches that will facilitate the provision of cybersecurity recommendations to e-learning stakeholders. Thus, the objective of this researcher is to develop and evaluate LearnShield, a GenAI recommender tool that can used by educators and students to generate context-specific user-oriented recommendations. The study evaluates this application using a mixed method approach where human and LLM-based evaluators assess the application considering multiple metrics. The results indicate the overall positive assessment of LearnShield as well as its potential in the field of cybersecurity awareness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIT63112.2025.11082779 },
  booktitle={ 2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT) },
  chapter={0}
}

@article{rayyan-352343161,
  title={ Safeguarding LLM-Applications: Specify or Train?  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Abdelkader, H. and Abdelrazek, M. and Singh, S. and Logothetis, I. and Rani, P. and Vasa, R. and Schneider, J. -G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029997 },
  abstract={Large Language Models (LLMs) are powerful tools used in several applications such as conversational AI, and code generation. However, significant robustness concerns arise with LLMs in production, such as hallucinations, prompt injection attacks, harmful content generation, and challenges in maintaining accurate domain-specific content moderation. Guardrails aim to mitigate these challenges by aligning LLM outputs with desired behaviors without modifying the underlying models. Nvidia NeMo Guardrails, for instance, rely on specifying acceptable/unacceptable behaviours. However, it is challenging to predict and address potential issues of LLMs in advance to create these guardrails. Also, manual updates from software engineers are often required to maintain and refine these guardrails. We introduce LLM-Guards, specialised machine learning (ML) models trained to function as protective guards. Additionally, we present an automation pipeline for training and continual fine-tuning of these guards using reinforcement learning from human feedback (RLHF). We evaluated several small LLMs, including Llama-3, Mistral, and Gemma, as LLM-Guards for challenges such as moderation and detecting off-topic queries, and compared their performance against NeMo Guardrails. The proposed Llama-3 LLM-Guard outperformed NeMo Guardrails in detecting offtopic queries, achieving an accuracy of 98.7% compared to 81%. Furthermore, the LLM-Guard detected 97.86% of harmful queries” surpassing NeMo Guardrails by 19.86%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00047 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343162,
  title={ Multimodal AI for Romanian University Support: An LLM, RAG and Voice Approach  -  2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI) },
  year={2025},
  author={Joldea, A. -R. and Cernăzanu-Glăvan, D. and Sârbu, V. and Bulzan, A. -Ş.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030141 },
  abstract={The era of large language models (LLMs) brings forth a new wave of automation to many fields of activity. In this work we employ the AI advancements catalyzed by these LLMs to create a smart university assistant. A chatbot that comes to assist university enrolled students and staff on administrative, legislative and public interest topics. To this end, we develop a platform that combines Large Language Models, Retrieval Augmented Generation, Speech-to-Text and Text-to-Speech technologies to automate accessibility to university-related information. We start from openly available models and resources, adapt and finetune them to our target - Romanian question answering with information retrieval - and then release our solutions publicly at https://github.com/Andrei481/RomanianChatbot.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SACI66288.2025.11030141 },
  booktitle={ 2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI) },
  chapter={0}
}

@article{rayyan-352343163,
  title={ Carbon-Aware Workload Shifting for Mitigating Environmental Impact of Generative AI Models  -  2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartD...},
  year={2024},
  author={Zhang, E. and Wu, D. and Boman, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10731798 },
  abstract={The rapid proliferation of large language models (LLMs) has raised concerns about their substantial energy consumption during both training and inference phases, contributing to environmental concerns. In particular, inference activities constitute a significant portion of carbon emissions, exacerbated by the expansive user base of LLM applications. Furthermore, the carbon intensity of data centers varies widely across different regions, suggesting an opportunity for carbon-aware workload shifting to mitigate emissions. In this study, we investigate the efficacy of such a strategy by examining three prominent large generative AI models: Mistral, Vicuna, and Stable Diffusion. We conducted comprehensive experiments to measure power consumption, runtime, and carbon emission of various prompts across five regions in the U.S. and Europe. These empirical data were then utilized to construct a simulation to assess the potential carbon savings achievable through carbon-aware workload shifting. Our results demonstrate that redirecting requests to regions with lower carbon intensities could yield substantial reductions in emissions, with a projected decrease of over 1,652 pounds on a single day per 10 million requests. This research demonstrates the great potential of reducing the environmental impact of AI and paves the way for sustainable deployment of large generative AI models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics62450.2024.00087 },
  booktitle={ 2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics },
  chapter={0}
}

@article{rayyan-352343164,
  title={ Demo Paper: A Game Agents Battle Driven by Free-Form Text Commands Using Code-Generation LLM and Behavior Branch  -  2024 IEEE Conference on Games (CoG) },
  year={2024},
  author={Ito, R. and Takahashi, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645545 },
  abstract={This paper presents a demonstration of our monster battle game, in which the game agents fight in accordance with their player’s language commands. The commands were translated into the knowledge expression called behavior branches by a code-generation large language model. This work facilitated the design of the commanding system more easily, enabling the game agent to comprehend more various and continuous commands than rule-based methods. The results of the commanding and translation process were stored in a database on an Amazon Web Services server for more comprehensive validation. This implementation would provide a sufficient evaluation of this ongoing work, and give insights to the industry that they could use this to develop their interactive game agents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG60054.2024.10645545 },
  booktitle={ 2024 IEEE Conference on Games (CoG) },
  chapter={0}
}

@article{rayyan-352343165,
  title={ Integrating Text Analysis and LLM to Explore the Development and Application of AIGC in Education  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Wang, S. -M. and Wu, Y. -I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10826827 },
  abstract={As discussions surrounding artificial intelligence (AI) and speculative design in education continue to grow, this study aims to assess how large language models (LLMs) analyze the application of AI-generated content (AIGC) and speculative design in current educational contexts, as well as their potential for future development. A sample of 30 articles on the application of AIGC and speculative design in education was collected, and a comprehensive text analysis method was employed, utilizing LLMs for summary analysis and opinion discussions. Through a cross-comparison of these methods, this research examines the similarities and differences in the impact of AI-driven tools on education. It explores their potential expanded functionalities in the educational field. In summary, this study integrates qualitative and quantitative data for comparative analysis, providing theoretical foundations and practical guidance on the future application of LLMs in education. The study also offers solutions to challenges and areas of concern for AIGC in education, as identified through LLM-generated inquiries, which can serve as a reference for future improvements. Further research can validate the effectiveness of these tools and explore their potential applications in diverse educational environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10826827 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343166,
  title={ Towards a Personalized LLM-Based Daily Edge Memory Aid  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Ha, S. and Ko, D. and Lim, J. -H. and Kang, S. and Kim, H. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827506 },
  abstract={This paper introduces a personalized memory aid system that combines a high-performance cloud-based large language model (LLM) with a low-power edge device running a small language model (sLM) to enhance user productivity by processing and summarizing daily conversations in real-time. The system optimizes efficiency and user experience while ensuring privacy through localized data handling. By combining cloud and edge resources, the system provides scalable, real-time memory support without compromising data security. The research highlights the system's architecture, its role in protecting user data, and its potential to seamlessly integrate into daily life, offering a sustainable and efficient approach to personalized artificial intelligence applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827506 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343167,
  title={ Gemini-the most powerful LLM: Myth or Truth  -  2024 5th Information Communication Technologies Conference (ICTC) },
  year={2024},
  author={Islam, R. and Ahmed, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602253 },
  abstract={Gemini models excel in various tasks including image generation and interpretation, video understanding, and solving mathematical problems, among others. The Vertex AI Gemini API and Google AI Gemini API both enable developers to integrate Gemini model functionalities into their applications. This paper offers a concise summary of the Gemini Framework, focusing on its distinctive modalities that distinguish it from current systems. In our research, we explored the details of its architecture, pointing out the innovative strategies employed to improve generative AI capabilities. Furthermore, we conduct a comparative study, assessing Gemini’s performance against other top generative AI models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC61510.2024.10602253 },
  booktitle={ 2024 5th Information Communication Technologies Conference (ICTC) },
  chapter={0}
}

@article{rayyan-352343168,
  title={ RAG-Driven Generative AI: Build custom retrieval augmented generation pipelines with LlamaIndex, Deep Lake, and Pinecone  -  RAG-Driven Generative AI: Build custom retrieval augmented generation pipelines with LlamaIndex, Deep Lake, and Pinecone },
  author={Rothman, D.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769311.pdf&bkn=10769311&pdfType=book },
  abstract={Minimize AI hallucinations and build accurate, custom generative AI pipelines with RAG using embedded vector databases and integrated human feedback Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesImplement RAG’s traceable outputs, linking each response to its source document to build reliable multimodal conversational agentsDeliver accurate generative AI models in pipelines integrating RAG, real-time human feedback improvements, and knowledge graphsBalance cost and performance between dynamic retrieval datasets and fine-tuning static dataBook DescriptionRAG-Driven Generative AI provides a roadmap for building effective LLM, computer vision, and generative AI systems that balance performance and costs. This book offers a detailed exploration of RAG and how to design, manage, and control multimodal AI pipelines. By connecting outputs to traceable source documents, RAG improves output accuracy and contextual relevance, offering a dynamic approach to managing large volumes of information. This AI book shows you how to build a RAG framework, providing practical knowledge on vector stores, chunking, indexing, and ranking. You’ll discover techniques to optimize your project’s performance and better understand your data, including using adaptive RAG and human feedback to refine retrieval accuracy, balancing RAG with fine-tuning, implementing dynamic RAG to enhance real-time decision-making, and visualizing complex data with knowledge graphs. You’ll be exposed to a hands-on blend of frameworks like LlamaIndex and Deep Lake, vector databases such as Pinecone and Chroma, and models from Hugging Face and OpenAI. By the end of this book, you will have acquired the skills to implement intelligent solutions, keeping you competitive in fields from production to customer service across any project.What you will learnScale RAG pipelines to handle large datasets efficientlyEmploy techniques that minimize hallucinations and ensure accurate responsesImplement indexing techniques to improve AI accuracy with traceable and transparent outputsCustomize and scale RAG-driven generative AI systems across domainsFind out how to use Deep Lake and Pinecone for efficient and fast data retrievalControl and build robust generative AI systems grounded in real-world dataCombine text and image data for richer, more informative AI responsesWho this book is forThis book is ideal for data scientists, AI engineers, machine learning engineers, and MLOps engineers. If you are a solutions architect, software developer, product manager, or project manager looking to enhance the decision-making process of building RAG applications, then you’ll find this book useful.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ RAG-Driven Generative AI: Build custom retrieval augmented generation pipelines with LlamaIndex, Deep Lake, and Pinecone },
  chapter={0}
}

@article{rayyan-352343169,
  title={ ChatGPT for Conversational AI and Chatbots: Learn how to automate conversations with the latest large language model technologies  -  ChatGPT for Conversational AI and Chatbots: Learn how to automate conversations with the latest large language model technologies },
  author={Thompson, A.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769209.pdf&bkn=10769209&pdfType=book },
  abstract={Explore ChatGPT technologies to create state-of-the-art chatbots and voice assistants, and prepare to lead the AI revolutionKey FeaturesLearn how to leverage ChatGPT to create innovative conversational AI solutions for your organizationHarness LangChain and delve into step-by-step LLM application development for conversational AIGain insights into security, privacy, and the future landscape of large language models and conversational AIPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionChatGPT for Conversational AI and Chatbots is a definitive resource for exploring conversational AI, ChatGPT, and large language models. This book introduces the fundamentals of ChatGPT and conversational AI automation. You’ll explore the application of ChatGPT in conversation design, the use of ChatGPT as a tool to create conversational experiences, and a range of other practical applications. As you progress, you’ll delve into LangChain, a dynamic framework for LLMs, covering topics such as prompt engineering, chatbot memory, using vector stores, and validating responses. Additionally, you’ll learn about creating and using LLM-enabling tools, monitoring and fine tuning, LangChain UI tools such as LangFlow, and the LangChain ecosystem. You’ll also cover popular use cases, such as using ChatGPT in conjunction with your own data. Later, the book focuses on creating a ChatGPT-powered chatbot that can comprehend and respond to queries directly from your unique data sources. The book then guides you through building chatbot UIs with ChatGPT API and some of the tools and best practices available. By the end of this book, you’ll be able to confidently leverage ChatGPT technologies to build conversational AI solutions.What you will learnGain a solid understanding of ChatGPT and its capabilities and limitationsUnderstand how to use ChatGPT for conversation designDiscover how to use advanced LangChain techniques, such as prompting, memory, agents, chains, vector stores, and toolsCreate a ChatGPT chatbot that can answer questions about your own dataDevelop a chatbot powered by ChatGPT APIExplore the future of conversational AI, LLMs, and ChatGPT alternativesWho this book is forThis book is for tech-savvy readers, conversational AI practitioners, engineers, product owners, business analysts, and entrepreneurs wanting to integrate ChatGPT into conversational experiences and explore the possibilities of this game-changing technology. Anyone curious about using internal data with ChatGPT and looking to stay up to date with the developments in large language models will also find this book helpful. Some expertise in coding and standard web design concepts would be useful, along with familiarity with conversational AI terminology, though not essential.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ ChatGPT for Conversational AI and Chatbots: Learn how to automate conversations with the latest large language model technologies },
  chapter={0}
}

@article{rayyan-352343170,
  title={ Leveraging AI to Ensure Authenticity in Student Assignments: A Knowledge-Based Validation and Evaluation Framework  -  2025 5th International Conference on Advanced Research in Computing (ICARC) },
  year={2025},
  author={Hondarangala, C. and Wickramaarachchi, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962918 },
  abstract={This research explores the development of an AI-driven assessment system designed to evaluate student knowledge while minimizing cheating in educational settings. The system operates in two distinct phases. In Phase 1, AI-generated, contextually relevant questions based on student-submitted assignments assess whether the student has genuinely engaged with the content or used external tools, such as generative AI, without proper understanding. In Phase 2, the system delves deeper into conceptual understanding by aligning submissions with course-specific materials, evaluating relevance, depth, and originality. A fine-tuned large language model (LLM), trained on domain-specific data, enables precise evaluation against academic standards. Results indicate that students demonstrated marked improvements in understanding and performance, validating the effectiveness of the two-phase model. This model encouraged deeper engagement and comprehension, increasing students’ knowledge of the material. By addressing the shortcomings of traditional assessment methods, this research introduces a model that reduces the likelihood of students blindly submitting assignments without truly understanding the content.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICARC64760.2025.10962918 },
  booktitle={ 2025 5th International Conference on Advanced Research in Computing (ICARC) },
  chapter={0}
}

@article{rayyan-352343171,
  title={ Generative AI, Ingenuity, and Law  -  IEEE Transactions on Technology and Society },
  author={Carvalko, J. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598190 },
  abstract={This paper discusses generative pre-trained transformer technology and its intersection with forms of creativity and law. It highlights the potential of generative AI to change considerable elements of society, including modes of creative endeavors, problem-solving, employment, education, justice, medicine, and governance. The author emphasizes the need for policymakers and experts to join in regulating against the potential risks and implications of this technology. The European Commission has taken steps to address the risks of AI through the European AI Act (EIA), which categorizes AI uses based on their potential harm. The legislation aims to ensure scrutiny and control in extreme cases like autonomous weapons or medical devices. However, the author criticizes the lack of meaningful AI oversight in the United States and argues that time has come for government to step in and offer meaningful regulation given the technology’s (1) rate of diffusion (2) virtually uncountable product permutations, the purposes, extent and depths to which it is anticipated to penetrate institutional and daily life.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TTS.2024.3413591 },
  booktitle={ IEEE Transactions on Technology and Society },
  chapter={0}
}

@article{rayyan-352343172,
  title={ Exploring the Suitability of the Cerebras Wafer Scale Engine for the Fast Prototyping of a Multilingual Hate Speech Detection System  -  2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI) },
  year={2024},
  author={Hoffmann, M. and John, J. and Hammer, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849395 },
  abstract={The era of digital communication has brought about a concerning rise of online hate speech. In response, researchers have focused on developing automated systems to detect and monitor such harmful content. While much attention has been given to monolingual detection systems, recent years have seen the emergence of new approaches for multilingual hate speech detection. However, there remains a limited understanding of how the underlying computational infrastructure impacts the training and development times of such systems. This study presents an innovative experimental design aimed at investigating the relationship between accelerator infrastructure and multilingual hate speech detection. It begins by constructing a prototype system of different classification algorithms for detecting hate speech in English, German, Italian and Spanish text-based social media content. The study then evaluates the fine-tuning times of these classifiers using both conventional GPU-based accelerators and cutting-edge AI-accelerator hardware, such as the Cerebras CS-2 system. The latter claims to speed up the development and fine-tuning of large language models significantly. Furthermore, the study compares the fine-tuning times of the same classifiers on two separate AI Accelerator machines. The study shows that the Cerebras AI Accelerator quickens training times by factor 4 compared to traditional setups, with little variation across high-performance computing infrastructures. However, the technology is in its early stages, with drawbacks including substantial upstart and compilation times, a limited number of models portable to the CS-2, and a need for refinement to improve accessibility for non-experts. Nonetheless, the Cerebras CS-2 technology heralds a new era for the rapid development of effective hate speech models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTAI62512.2024.00048 },
  booktitle={ 2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI) },
  chapter={0}
}

@article{rayyan-352343173,
  title={ GenAI Security: Outsmarting the Bots with a Proactive Testing Framework  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Bahadur, S. K. Jang and Dhar, G. and Nigam, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050591 },
  abstract={The increasing sophistication and integration of Generative AI (GenAI) models into diverse applications introduce new security challenges that traditional methods struggle to address. This research explores the critical need for proactive security measures to mitigate the risks associated with malicious exploitation of GenAI systems. We present a framework encompassing key approaches, tools, and strategies designed to outmaneuver even advanced adversarial attacks, emphasizing the importance of securing GenAI innovation against potential liabilities. We also empirically prove the effectiveness of the said framework by testing it against the SPML Chatbot Prompt Injection Dataset. This work highlights the shift from reactive to proactive security practices essential for the safe and responsible deployment of GenAI technologies,},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00112 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343174,
  title={ Detecting Transitional Provisions in EU Legislation with Hybrid AI for Better Regulation  -  2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG) },
  year={2025},
  author={Vagnoni, S. and Palmirani, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081693 },
  abstract={Maintaining an accessible and up-to-date legislative framework is crucial for ensuring transparent governance and enabling effective citizen participation in democratic processes. This paper examines methodological approaches for the automated detection and modeling of textual modifications within EU Regulations and Directives, with particular attention to transitional provisions and temporal concepts (retroactivity, postponement, relative dates), as well as legislative ones (entry into force, application, sunset clause). We present a comparative analysis of four distinct approaches: (1) a rule-based pipeline utilizing regular expressions to capture standardized legal expressions, (2) a SpaCy-based pipeline leveraging advanced NLP capabilities for entity recognition and pattern matching, (3) a Large Language Model (LLM)-based pipeline using the OpenRouter API for contextual extraction, and (4) RDF/Cellar extraction serving as the benchmark. Each methodology is designed to generate standardized Akoma Ntoso (AKN) metadata annotations, facilitating point-in-time understanding of legislative modifications and temporal validity. The rule-based and SpaCy-based approaches offer computational efficiency and procedural transparency, while the LLM-based method demonstrates potential for handling complex linguistic variations and contextual dependencies. RDF extraction provides authoritative temporal information for evaluation purposes. This comparative framework provides insights into the relative strengths and limitations of each approach, contributing to the ongoing development of advanced legal informatics tools for legislative drafting and eParticipation initiatives.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEDEG65568.2025.11081693 },
  booktitle={ 2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG) },
  chapter={0}
}

@article{rayyan-352343175,
  title={ On-Device or Remote? On the Energy Efficiency of Fetching LLM-Generated Content  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Nguyen, V. and Dhopate, V. and Huynh, H. and Bouhlal, H. and Annengala, A. and Scoccia, G. L. and Martinez, M. and Stoico, V. and Malavolta, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030023 },
  abstract={Context. While on-device LLMs offer higher privacy over their remotely-hosted counterparts and do not require Internet connectivity, their energy consumption on the client device still remains insufficiently investigated. Goal. This study empirically evaluates the energy usage of client devices when fetching LLM-generated content on-device versus from a remote server. Our goal is to help software developers make informed decisions on the most energy-efficient method for fetching content in different scenarios, so as to optimize the client device's energy consumption. Method. We conduct a controlled experiment with seven LLMs with varying parameter sizes running on a MacBook Pro M2 and on a remote server. The experiment involves fetching content of different lengths from the LLMs deployed either on-device or remotely, while measuring the client device's energy usage and performance metrics such as execution time, CPU, GPU, and memory usage. Results. Fetching LLM-generated content from a remote server uses 3.5 to 8.9 times less energy compared to the on-device method, with a large effect size. We observe a consistent strong positive correlation between energy usage and execution time across all content lengths and fetch methods. For the on-device method, GPU and memory usage are positively correlated with energy usage. Conclusions. We recommend offloading LLM-generated content to a remote server rather than generating it on-device to optimize energy efficiency on the client side. LLM maintainers should optimize on-device LLMs in terms of execution time and computational resources.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00016 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343176,
  title={ Automated Data Analyser using Generative AI  -  2025 8th International Conference on Trends in Electronics and Informatics (ICOEI) },
  year={2025},
  author={Abhinash, N. C. and N, H. and Reddy, E. Ramakrishna and Usha, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11013368 },
  abstract={In the era of digital transformation, data analysis plays a significant role in data science and machine learning, it act as a decision support system. Extracting insights from data is really difficult and effort-intensive activity. The Automated data Analyser is developed for such users who need automated data insights and machine learning model recommendations. It is built using python framework streamlit and uses google Gemini for generating the insights and suggesting machine learning algorithms for the given dataset. Initially the dataset is given as the only input nothing other input is needed as the system is automated it automatically pre-processes the data and generates the insightful data visualizations along with the descriptions. If the dataset is huge and contains more rows then the system uses dimensionality reduction techniques such as Principal Component Analysis (PCA) to reduce the size of data and preserve the insights. By reducing the size of dataset using dimensionality reduction techniques it takes less time to analyse the dataset. It is an efficient system for huge data sets. The system is also capable to show the mathematical analysis of data to analyse the spread of data. To produce the data insights by Gemini LLM a small set of data along with prompt is given to LLM to generate the insights and recommendations. The application uses SQLite database to store the visualizations and insights. Finally the report is generated which includes the data insights, data visualizations and machine learning model suggestions. The combination of Generative AI, Statistical Analysis and ML Automation is a great fit in the world of data analytics. This research work helps automate the Exploratory Data Analysis (EDA) tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICOEI65986.2025.11013368 },
  booktitle={ 2025 8th International Conference on Trends in Electronics and Informatics (ICOEI) },
  chapter={0}
}

@article{rayyan-352343177,
  title={ A GNN Model for the Prediction of snoRNA-Disease Associations Based on snoRNA Secondary Structures and LLM Disease Embedding  -  2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  year={2024},
  author={Mendolia, I. and Licciardi, A. and Fiannaca, A. and Paglia, L. L. and Rosa, M. L. and Urso, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990106 },
  abstract={Numerous studies have demonstrated the functional role of small nuclear RNAs (snoRNAs) in various biological processes associated with developing complex human disorders. Therefore, understanding the connections between different snoRNAs and diseases is essential for improving disease detection and therapy. In this work, we propose a graph neural network model to predict unknown snoRNA-disease associations. Our network consists of four layers, each constructed by a sequence of SAGEConv and GATConv layers. We take into account two class of features for both snoRNAs and disease never used by similar works. We generate the snoRNA node features according to substructures of varying sizes within their secondary structures; we obtain the disease node features from disease textual descriptions using two large language models, one trained on medical texts and the other trained on different text type, including medical text. Our results indicate that our model outperforms current state-of-the-ar model and in particular that the snoRNA features derived from smaller substructures are the most suitable for this problem, whereas the disease features that yielded the best performance were those extracted using a model specifically trained on medical texts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxDKE63520.2024.00034 },
  booktitle={ 2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  chapter={0}
}

@article{rayyan-352343178,
  title={ Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models  -  2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2024},
  author={Nouri, A. and Cabrero-Daniel, B. and Törner, F. and Sivencrona, H. and Berger, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556122 },
  abstract={DevOps is a necessity in many industries, including the development of Autonomous Vehicles. In those settings, there are iterative activities that reduce the speed of SafetyOps cycles. One of these activities is "Hazard Analysis & Risk Assessment" (HARA), which is an essential step to start the safety requirements specification. As a potential approach to increase the speed of this step in SafetyOps, we have delved into the capabilities of Large Language Models (LLMs). Our objective is to systematically assess their potential for application in the field of safety engineering. To that end, we propose a framework to support a higher degree of automation of HARA with LLMs. Despite our endeavors to automate as much of the process as possible, expert review remains crucial to ensure the validity and correctness of the analysis results, with necessary modifications made accordingly.CCS Concepts•Software and its engineering → Software verification and validation;•General and reference → Verification;•Computing methodologies → Natural language processing;•Computer systems organization → Dependable and fault-tolerant systems and networks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343179,
  title={ Infinite Reverie: Beyond the Threshold of Virtual Tales  -  2025 International Conference on Emerging Technologies in Engineering Applications (ICETEA) },
  year={2025},
  author={G, T. and Vishal, V. and T, V. and Bharanidharan, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11100117 },
  abstract={In the era of artificial intelligence, automated storytelling has gained significant traction, revolutionizing content creation. This paper presents an AI-driven story generation system that combines text generation and image synthesis to create engaging narrative experiences. The system utilizes Gen AI based LLM for text generation and a blackforest's text-to-image model deployed on AWS SageMaker to produce coherent and visually enriched stories. Users can input prompts, customize both textual and visual elements, and download the final story as a PDF. The model is integrated into a Flask-based web application with user authentication, providing an intuitive interface for seamless interaction. Our approach enhances creative writing by offering dynamic, context-aware storytelling, catering to writers, educators, and entertainment industries. Performance evaluation demonstrates the system's effectiveness in generating diverse and contextually relevant narratives. This research contributes to the advancement of AI in creative applications, opening new possibilities for interactive storytelling.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICETEA64585.2025.11100117 },
  booktitle={ 2025 International Conference on Emerging Technologies in Engineering Applications (ICETEA) },
  chapter={0}
}

@article{rayyan-352343180,
  title={ AI Agent-based Adaptive Task Offloading for Autonomous Drones in Dynamic Environments  -  2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S) },
  year={2025},
  author={Zhang, Q. and Machida, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068324 },
  abstract={This study introduces an AI agent architecture using large language models (LLMs) for deciding task offloading in autonomous drones operating in dynamic environments. To overcome the inflexibility of existing offload decision methods, we aim to leverage AI agents to dynamically delegate tasks to edge servers or defer execution, ensuring reliable decision-making. The proposed AI agent system integrates real-time analysis (e.g., CPU/GPU utilization, network bandwidth, battery status), offloading decision making by LLMs, and a feedback loop to refine decision accuracy over time to balance reliability, latency, and energy efficiency. A primary LLM generates initial offloading decisions, while a secondary LLM verifies the initial decision by predefined risk constraints and makes the final decision. Preliminary experiments of each LLM on the NVIDIA Jetson Orin Nano demonstrate promising results in performance log analysis speed and resource optimization, though challenges remain in achieving consistent outputs across repeated runs and scaling to more complex tasks. This work highlights the potential of AI agent-based approach to enhance drone adaptive task offloading under varying conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSN-S65789.2025.00019 },
  booktitle={ 2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S) },
  chapter={0}
}

@article{rayyan-352343181,
  title={ Agents are All you need: Elevating Trading Dynamics with Advanced Generative AI-Driven Conversational LLM Agents and Tools  -  2024 IEEE 9th International Conference for Convergence in Technology (I2CT) },
  year={2024},
  author={Kar, I. and Ralte, Z. and Shivakumara, M. and Roy, R. and Kumari, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10543356 },
  abstract={This paper presents the development of a groundbreaking LLM multi-agent system designed to optimize the Energy Exchange (EX)'s electricity trading. The system integrates cutting-edge, Generative AI, embedding-based deep learning models and LLM Agents to forecast electricity prices with heightened accuracy and facilitate interactive reporting. Our first agent performs advanced deep learning , tapping into IEX's rich databases for day-ahead and intraday market prices, alongside additional data streams such as weather and economic indicators. We eschew traditional predictive models in favor of sophisticated embedding-based models adept at discerning complex temporal patterns, enabling precise forecasts up to seven days ahead. Rigorous validation methods, including k-fold cross-validation, are applied, with accuracy gauged by metrics like Root Mean Squared Error (RMSE). The second agent is founded on a robust GenAI tools framework, translating intricate model predictions into intelligible reports and extract insights through another LLM based Agents. This interface adeptly handles energy market specifics, ensuring contextually relevant interactions. This tool's integration aims to enhance decision-making for market participants and to inject unprecedented predictive transparency into market dynamics. Our initiative heralds a transformative step toward realizing a data-centric, efficient, and customer-focused energy market in India, with potential expansion throughout the South Asian region powered by LLM and generative AI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/I2CT61223.2024.10543356 },
  booktitle={ 2024 IEEE 9th International Conference for Convergence in Technology (I2CT) },
  chapter={0}
}

@article{rayyan-352343182,
  title={ A Systematic Evaluation of AI-Generated Security Patches: Analyzing and Exploiting AI-Generated Fixes  -  2025 IEEE International Conference on Artificial Intelligence Testing (AITest) },
  year={2025},
  author={Mahmud, A. and Rawajfih, Y. and Wu, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11127134 },
  abstract={This paper presents a systematic analysis of security patches generated by large language models (LLMs) such as GPT-4, Claude, and DeepSeek. We compare them with human-written patches across diverse vulnerability types and programming languages, using a corpus of 2,161 patches. Our evaluation reveals that AI-generated patches show comparable effectiveness to human patches (3.72% difference, p=0.0803) but tend to fail in predictable ways, exposing them to targeted bypass attacks. Human-written patches focus on structural corrections, while AI patches often rely on minimalistic input validation. These findings highlight the risks of relying solely on LLMs for vulnerability remediation and underscore the importance of hybrid human-AI patching workflows and adversarial security testing.Our adversarial evaluation framework offers a reproducible methodology for testing the security reliability of large language models (LLMs), advancing research in safe and trustworthy AI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AITest66680.2025.00035 },
  booktitle={ 2025 IEEE International Conference on Artificial Intelligence Testing (AITest) },
  chapter={0}
}

@article{rayyan-352343183,
  title={ Coding with ChatGPT and Other LLMs: Navigate LLMs for effective coding, debugging, and AI-driven development  -  Coding with ChatGPT and Other LLMs: Navigate LLMs for effective coding, debugging, and AI-driven development },
  author={Hall, D. V. A.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10803972.pdf&bkn=10803972&pdfType=book },
  abstract={Leverage LLM (large language models) for developing unmatched coding skills, solving complex problems faster, and implementing AI responsiblyKey FeaturesUnderstand the strengths and weaknesses of LLM-powered software for enhancing performance while minimizing potential issuesGrasp the ethical considerations, biases, and legal aspects of LLM-generated code for responsible AI usageBoost your coding speed and improve quality with IDE integrationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionKeeping up with the AI revolution and its application in coding can be challenging, but with guidance from AI and ML expert Dr. Vincent Hall—who holds a PhD in machine learning and has extensive experience in licensed software development—this book helps both new and experienced coders to quickly adopt best practices and stay relevant in the field. You’ll learn how to use LLMs such as ChatGPT and Gemini to produce efficient, explainable, and shareable code and discover techniques to maximize the potential of LLMs. The book focuses on integrated development environments (IDEs) and provides tips to avoid pitfalls, such as bias and unexplainable code, to accelerate your coding speed. You’ll master advanced coding applications with LLMs, including refactoring, debugging, and optimization, while examining ethical considerations, biases, and legal implications. You’ll also use cutting-edge tools for code generation, architecting, description, and testing to avoid legal hassles while advancing your career. By the end of this book, you’ll be well-prepared for future innovations in AI-driven software development, with the ability to anticipate emerging LLM technologies and generate ideas that shape the future of development.What you will learnUtilize LLMs for advanced coding tasks, such as refactoring and optimizationUnderstand how IDEs and LLM tools help coding productivityMaster advanced debugging to resolve complex coding issuesIdentify and avoid common pitfalls in LLM-generated codeExplore advanced strategies for code generation, testing, and descriptionDevelop practical skills to advance your coding career with LLMsWho this book is forThis book is for experienced coders and new developers aiming to master LLMs, data scientists and machine learning engineers looking for advanced techniques for coding with LLMs, and AI enthusiasts exploring ethical and legal implications. Tech professionals will find practical insights for innovation and career growth in this book, while AI consultants and tech hobbyists will discover new methods for training and personal projects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Coding with ChatGPT and Other LLMs: Navigate LLMs for effective coding, debugging, and AI-driven development },
  chapter={0}
}

@article{rayyan-352343184,
  title={ AIced-Prep -AI Based Mock Interview Evaluator  -  2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI) },
  year={2025},
  author={Rajbhar, S. and Shelke, S. and Singh, A. and Singh, Y. and Shinde, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135157 },
  abstract={AIced Prep is an AI-driven system designed to provide individuals with realistic mock interviews and personalized feedback, particularly targeting freshers, job seekers, students, and recruitment agencies. The system aims to build confidence, improve performance, and enhance candidates' chances of success in interviews. To achieve this, the project integrates a Question Generation System using RetrievalAugmented Generation(RAG) and Large Language Models (LLMs) for generating relevant, unique, and non-repetitive questions. The project fo- cuses on two primary use cases: interview question generation and resume classification and mock interview. By leveraging the Mistral-7B LLM for contextually accurate question generation and FAISS for efficient vector-based retrieval, the system dynami- cally processes documents, including PDFs, to generate questions. The web-based interface, built using FastAPI and Streamlit, ensures users have an interactive and accessible experience. This hybrid approach addresses common challenges in question generation, such as repetitive questions and irrelevant content, by combining information retrieval techniques with generative AI methods. The ultimate goal of AIced Prep is to make quality interview preparation accessible to everyone, providing scalable, efficient, and personalized interview preparation solution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDICI66477.2025.11135157 },
  booktitle={ 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI) },
  chapter={0}
}

@article{rayyan-352343185,
  title={ Artificial Intelligence Revolution in Turkish Health Consultancy: Development of LLM-Based Virtual Doctor Assistants  -  2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP) },
  year={2024},
  author={Bulut, M. K. and Diri, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710973 },
  abstract={This study examines the performance of four different large language models (LLama2, LLama3, and Mistralbased) in doctor-patient written communication in Turkish health counseling. The models were trained and fine-tuned on a patient-doctor question-answer dataset [1]. The metrics used for performance evaluation include ROUGE, Elo rating, Winning percentage, and Expert evaluation. The comparative analysis results indicate that the SambaLingo-Turkish-Chat model was successful in terms of response accuracy and contextual relevance, while the Trendyol-LLM-7b-chat-v 1.8 model proved to be more successful when considering the ethical aspects of the task [14], [17]. This study demonstrates the potential of AI-powered virtual doctor assistants in Turkish healthcare services and contributes to the development of Turkish-specific medical chatbots.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDAP64064.2024.10710973 },
  booktitle={ 2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP) },
  chapter={0}
}

@article{rayyan-352343186,
  title={ A Hybrid LLM based Model for Calorie Tracker and Dietary Control  -  2024 International Conference on Intelligent Computing and Emerging Communication Technologies (ICEC) },
  year={2024},
  author={Mishra, S. and Siddiqui, I. A. and Sabale, K. and Alkhayyat, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837518 },
  abstract={The importance of attainable and efficient dietary management options is clearly visible through the increasing occurrences of obesity and associated health conditions. While traditional techniques of calorie tracking are useful, they can be labor-intensive and highly prone to errors, highlighting the requirement for novel technology alternatives. This work presents the use of advanced natural language processing to intensify user experience and accuracy in dietary control for a Large Language Model (LLM)-based calorie tracker. To get a more natural approach for measuring calorie intake, creating customized dietary goals, and receiving real-time feedback we use AI and machine learning algorithms in the program (GPT-3 and GPT-4). To control intermittent fasting habits, measure hydration, and monitor weight variations, various tools are provided by the device. Deep learning techniques such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) are implemented to give support and personalized recommendations to help users overcome hindrances and achieve their health goals, thus contributing to overall health and well-being.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEC59683.2024.10837518 },
  booktitle={ 2024 International Conference on Intelligent Computing and Emerging Communication Technologies (ICEC) },
  chapter={0}
}

@article{rayyan-352343187,
  title={ Assessing and Enhancing the Robustness of LLM-Based Multi-Agent Systems Through Chaos Engineering  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Owotogbe, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030017 },
  abstract={This study explores the application of chaos engineering to enhance the robustness of Large Language Model-Based Multi-Agent Systems (LLM-MAS) in production-like environments under real-world conditions. LLM-MAS can potentially improve a wide range of tasks, from answering questions and generating content to automating customer support and improving decision-making processes. However, LLM-MAS in production or preproduction environments can be vulnerable to emergent errors or disruptions, such as hallucinations, agent failures, and agent communication failures. This study proposes a chaos engineering framework to proactively identify such vulnerabilities in LLM-MAS, assess and build resilience against them, and ensure reliable performance in critical applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00039 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343188,
  title={ So you want your private LLM at home? A survey and benchmark of methods for efficient GPTs  -  2024 11th IEEE Swiss Conference on Data Science (SDS) },
  year={2024},
  author={Tuggener, L. and Sager, P. and Taoudi-Benchekroun, Y. and Grewe, B. F. and Stadelmann, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675845 },
  abstract={At least since the introduction of ChatGPT, the abilities of generative large language models (LLMs), sometimes called GPTs, are at the center of the attention of AI researchers, entrepreneurs, and others. However, for many applications, it is not possible to call an existing LLM service via an API due to data protection concerns or when no task-appropriate LLM exists. On the other hand, deploying or training a private LLM is often prohibitively computationally expensive. In this paper, we give an overview of the most important recent methodologies that help reduce the computational footprint of LLMs. We further present extensive benchmarks for seven methods from two of the most important areas of recent progress: model quantization and low-rank adapters, showcasing how it is possible to leverage state-of-the-art LLMs with limited resources. Our benchmarks include resource consumption metrics (e.g. GPU memory usage), a state-of-the-art quantitative performance evaluation as well as a qualitative performance study conducted by eight individual human raters. Our evaluations show that quantization has a profound effect on GPU memory requirements. However, we also show that these quantization methods, contrary to how they are advertised, cause a noticeable loss in text quality. We further show that low-rank adapters allow effective model fine-tuning with moderate compute resources. For methods that require less than 16 GB of GPU memory, we provide easy-to-use Jupyter notebooks that allow anyone to deploy and fine-tune state-of-the-art LLMs on the Google Colab free tier within minutes without any prior experience or infrastructure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SDS60720.2024.00036 },
  booktitle={ 2024 11th IEEE Swiss Conference on Data Science (SDS) },
  chapter={0}
}

@article{rayyan-352343189,
  title={ (Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs  -  2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2024},
  author={Ma, W. and Yang, C. and Kästner, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556117 },
  abstract={Large Language Models (LLMs) are increasingly integrated into software applications. Downstream application developers often access LLMs through APIs provided as a service. However, LLM APIs are often updated silently and scheduled to be deprecated, forcing users to continuously adapt to evolving models. This can cause performance regression and affect prompt design choices, as evidenced by our case study on toxicity detection. Based on our case study, we emphasize the need for and re-examine the concept of regression testing for evolving LLM APIs. We argue that regression testing LLMs requires fundamental changes to traditional testing approaches, due to different correctness notions, prompting brittleness, and non-determinism in LLM APIs.CCS CONCEPTS•Software and its engineering → Software testing and debugging.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343190,
  title={ Conversational Product Recommendation using LLM  -  2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB) },
  year={2024},
  author={Chang, T. -J. and Lin, L. H. -M. and Tsai, R. T. -H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602608 },
  abstract={It is expected to deploy chatbots as sales assistants on e-commerce platforms soon. In recent years, the capabilities demonstrated by large language models (LLMs) indicate their suitability for this role. However, a dialogue process is not fully established. Most existing works concentrate on searching for ideal products, such as Retrieval-Augmented Generation (RAG) and product search. Many proposed methods rely on product reviews. However, in the case of some e-commerce platform products, valuable reviews are often lacking, rendering these approaches impractical. Thus, we studied how to assist users and select a set of candidate products. Accordingly, we simulated sales conversations based on the product features provided by the seller, using LLM and reliable content while addressing the cold-start problem. Specifically, we used product features to generate customer persona for user simulation. LLM was used to play the role of sales assistant in giving recommendations. The experimental results showed that practical conversation was created between customers and chatbots in Traditional Chinese. The code and results are available at: https://github.com/terryobe-ncu/CPR_LLM},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIB61477.2024.10602608 },
  booktitle={ 2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB) },
  chapter={0}
}

@article{rayyan-352343191,
  title={ AI-Driven Financial Analyst  -  2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) },
  year={2025},
  author={Gooty, C. S. and Umashankar, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011880 },
  abstract={In the current study, large language models that process user queries and analyse stock market data are compared and used to construct an AI-enabled platform for real-time financial data analysis. In this regard, the proposed platform integrates many data sources that might be used for aggregate analysis, concentrating on the top 50 Indian NSE equities through front-end development using ReactJS and back-end development using Python Flask. The technology provides insights that are pertinent to time and events by gathering data at every imaginable level, from daily reports regarding filings and company actions to minute updates of stock tickers. The design, process, data classification, constraints, and suggestions for future iterations are the main topics of this study.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDSAAI65575.2025.11011880 },
  booktitle={ 2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) },
  chapter={0}
}

@article{rayyan-352343192,
  title={ Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery  -  2025 IEEE International Conference on Digital Health (ICDH) },
  year={2025},
  author={Wen, B. and Wang, C. and Han, Q. and Norel, R. and Liu, J. and Stappenbeck, T. and Rogers, J. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11120408 },
  abstract={The integration of voice-based AI agents in healthcare presents a transformative opportunity to bridge economic and accessibility gaps in digital health delivery. This paper explores the role of large language model (LLM)-powered voice assistants in enhancing preventive care and continuous patient monitoring, particularly in underserved populations. Drawing insights from the development and pilot study of Agent PULSE (Patient Understanding and Liaison Support Engine)-a collaborative initiative between IBM Research, Cleveland Clinic Foundation, and Morehouse School of Medicine-we present an economic model demonstrating how AI agents can provide cost-effective healthcare services where human intervention is economically unfeasible. Our pilot study with 33 inflammatory bowel disease patients revealed that 70% expressed acceptance of AI-driven monitoring, with 37% preferring it over traditional modalities. Technical challenges, including real-time conversational AI processing, integration with healthcare systems, and privacy compliance, are analyzed alongside policy considerations surrounding regulation, bias mitigation, and patient autonomy. Our findings suggest that AI-driven voice agents not only enhance healthcare scalability and efficiency but also improve patient engagement and accessibility. For healthcare executives, our costutility analysis demonstrates huge potential savings for routine monitoring tasks, while technologists can leverage our framework to prioritize improvements yielding the highest patient impact. By addressing current limitations and aligning AI development with ethical and regulatory frameworks, voice-based AI agents can serve as a critical entry point for equitable, sustainable digital healthcare solutions. Index Terms-Digital health, large language models, voicebased AI, healthcare economics, preventive care, remote patient monitoring, health equity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDH67620.2025.00040 },
  booktitle={ 2025 IEEE International Conference on Digital Health (ICDH) },
  chapter={0}
}

@article{rayyan-352343193,
  title={ AI Gym Trainer and Fitness Tracker using GPT- LLM and Prompting Techniques  -  2024 1st International Conference on Advances in Computing, Communication and Networking (ICAC2N) },
  year={2024},
  author={Bhattacharya, H. and Kalia, R. and Yadav, S. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895114 },
  abstract={In an era characterized by technological advancements, the realm of fitness and wellness is embracing innovation to revolutionize traditional approaches to exercise and nutrition. The GPT-Powered Fitness Trainer emerges as a groundbreaking solution, leveraging the power of generative pre- trained transformer (GPT) models to deliver personalized and adaptive fitness guidance breaking away from the constraints of conventional fitness training, the GPT-Powered Fitness Trainer goes beyond the one-size-fits-all approach to cater to the unique needs and preferences of individual users. By drawing upon the vast knowledge repository embedded within GPT models, this trainer meticulously constructs personalized workout routines, nutrition plans, and motivational support systems for each user. It helps in trainer's adaptability is its greatest strength. It continuously learns and evolves based on user feedback and progress, ensuring that workout routines and nutrition recommendations remain aligned with the user's changing goals, physical capabilities, dietary preferences, and time constraints in real-time beyond physical fitness, the GPT-Powered Fitness Trainer extends its support to encompass emotional well-being. Motivational messages, progress tracking, and goal-setting capabilities foster a supportive environment that encourages long- term adherence to healthy lifestyle changes. The trainer's effectiveness hinges on prompt engineering, a technique that guides the GPT model in generating personalized diet plans and fitness routines. By tailoring recommendations to each user's unique needs, the trainer surpasses the limitations of traditional routines designed for the general population. In essence, the GPT- Powered Fitness Trainer revolutionizes the approach to fitness and wellness, empowering individuals to embark on personalized journeys towards achieving their health and fitness aspiration},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAC2N63387.2024.10895114 },
  booktitle={ 2024 1st International Conference on Advances in Computing, Communication and Networking (ICAC2N) },
  chapter={0}
}

@article{rayyan-352343194,
  title={ GWise: A Graph-Structured Multi-Agent Framework for Service-Oriented and Generative-AI-Enabled Financial Trading Analytics  -  2025 IEEE International Conference on Web Services (ICWS) },
  year={2025},
  author={Rezaei, H. and Rabhi, F. and Beheshti, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169717 },
  abstract={Financial trading analytics increasingly demands modular, explainable, and adaptive intelligence systems capable of handling volatile market conditions and multimodal data streams. Recent advances in generative Artificial Intelligence (AI), Large Language Models (LLMs), and graph-based representations have enabled the creation of intelligent agents that can reason over complex, interconnected financial data. We introduce GWise, a graph-structured, generative AI-enabled multi-agent framework for real-time financial trading analytics delivered via secure web services. GWise models financial decision making as a directed computational graph of specialized analytical agents, including technical, fundamental, sentiment, and risk analysis crews, whose outputs are orchestrated through a memory-augmented LLM. This graph-structured design enables transparent, adaptive, and explainable trade recommendations that evolve over time. We demonstrate how the framework's agent orchestration forms a dynamic service graph, facilitating composability, fault isolation, and scalable deployment through cloud-native APIs. Extensive back-testing and simulated market conditions show that GWise outperforms traditional strategies in risk-adjusted returns while offering improved interpretability and service robustness. Our work illustrates how graph-based multiagent coordination and generative reasoning can advance real-time financial analytics as a service.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS67624.2025.00136 },
  booktitle={ 2025 IEEE International Conference on Web Services (ICWS) },
  chapter={0}
}

@article{rayyan-352343195,
  title={ DURA-CPS: A Multi-Role Orchestrator for Dependability Assurance in LLM-Enabled Cyber-Physical Systems  -  2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W) },
  year={2025},
  author={Srinivasan, T. and Patapati, S. and Musku, H. and Gode, I. and Arora, A. and Bhattacharya, S. and Nazriev, A. and Hirave, S. and Kanjiani, Z. and Ghose, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071569 },
  abstract={Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to operate in critical applications. However, traditional verification and validation methods often struggle to handle the unpredictable and dynamic nature of AI components. In this paper, we introduce DURA-CPS, a novel framework that employs multi-role orchestration to automate the iterative assurance process for AI-powered CPS. By assigning specialized roles (e.g., safety monitoring, security assessment, fault injection, and recovery planning) to dedicated agents within a simulated environment, DURA-CPS continuously evaluates and refines AI behavior against a range of dependability requirements. We demonstrate the framework through a case study involving an autonomous vehicle navigating an intersection with an AI-based planner. Our results show that DURA-CPS effectively detects vulnerabilities, manages performance impacts, and supports adaptive recovery strategies, thereby offering a structured and extensible solution for rigorous V&V in safety-and security-critical systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSN-W65791.2025.00040 },
  booktitle={ 2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W) },
  chapter={0}
}

@article{rayyan-352343196,
  title={ Generative AI for Improved Defect Detection in Semiconductor Wafers  -  IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society },
  year={2024},
  author={Huynh, T. and Truong, D. and Bandaragoda, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10905182 },
  abstract={Traditional methods for identifying defects in industrial settings are often complicated, inefficient, and rely heavily on expert knowledge for manual feature extraction and pipeline development. However, with the emergence of machine learning and deep learning, there’s been a shift towards using these technologies for defect detection. Particularly, Generative AI has garnered attention for its ability to generate accurate defect identifications across various sectors. Our contribution lies in leveraging generative AI to revolutionize wafer manufacturing defect detection. We explore the balance between discriminative inference, known for its speed but susceptibility to shortcuts, and generative modeling, which offers enhanced robustness despite slower operation. Our investigation emphasizes the need for a model distinct from conventional discriminative ones, capable of adaptive learning to distinguish between normal and abnormal patterns in wafer manufacturing, aligning with expert judgment and utilizing historical data for predictive maintenance. We propose two innovative approaches using Generative AI: first, augmenting existing discriminative models with generative models for improved practicality; second, utilizing generative modeling to convert image-to-text models into classifiers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IECON55916.2024.10905182 },
  booktitle={ IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society },
  chapter={0}
}

@article{rayyan-352343197,
  title={ Towards Interpretable Emotion Classification: Evaluating LIME, SHAP, and Generative AI for Decision Explanations  -  2024 28th International Conference Information Visualisation (IV) },
  year={2024},
  author={Siddiqui, M. H. Fahim and Inkpen, D. and Gelbukh, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714319 },
  abstract={This paper explores the classification of multi-label emotions utilizing fine-tuned RoBERTa base and zero-shot GPT4 models, with experiments conducted on the SemEval 2018 E-c dataset encompassing 11 emotions, where more than one label is allowed for a text. Employing SHAP and LIME for RoBERTa explanations and generative AI for GPT4, we assess the sufficiency of explanations using the BERT score metric. We show the explanations generated by LIME and SHAP visually using different plots. The BERT score indicates that generative AI produces better explanations than the statistical models, providing deeper insights into emotion selection, with a BERT score of 59.66% compared to SHAP-RoBERTa's 54.17% and LIME-RoBERTa's 53.22%. This shows the potential of generative AI in revealing the reasoning behind decisions within complex emotional contexts. Though the performance is superior, we also discuss the limitations of these models that hinder wide-scale adoption.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IV64223.2024.00053 },
  booktitle={ 2024 28th International Conference Information Visualisation (IV) },
  chapter={0}
}

@article{rayyan-352343198,
  title={ Chat Generative Pre-Trained Transformer (ChatGPT): Comprehending its Operational Structure, AI Techniques, Working, Features and Limitations  -  2023 IEEE International Conference on ICT in Business Industry & Government (ICTBIG) },
  year={2023},
  author={Naik, I. and Naik, D. and Naik, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10456201 },
  abstract={ChatGPT has transformed the way machines interact with humans, as it is a significant improvement in the field of generative AI and conversational AI. ChatGPT is a combination of generative AI and conversational AI, and it is built on an underlying large language model which can create new contents similar to human-generated contents and simulate human-like conversations. It has the ability to understand the context of a conversation and respond accordingly, and learn to adapt from user feedback. ChatGPT is a new AI tool and is still evolving very rapidly, its successive models are gradually becoming more advanced and are capable of generating highly complex, coherent and credible text, thus making it a valuable tool for a wide range of applications. Therefore, this paper will present a comprehensive study of ChatGPT covering its operational structure, key AI techniques, working, features and limitations. This comprehensive study will provide users a detailed insight of ChatGPT in order to understand its core concepts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTBIG59752.2023.10456201 },
  booktitle={ 2023 IEEE International Conference on ICT in Business Industry & Government (ICTBIG) },
  chapter={0}
}

@article{rayyan-352343199,
  title={ A Novel Approach to Generative AI Translation  -  TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  year={2024},
  author={Kodali, R. K. and Upreti, Y. P. and Boppana, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10902899 },
  abstract={Machine translation, increasingly adopted by companies, involves fine-tuning Large Language Models (LLMs) for tasks like text translation. The author introduces a data curation pipeline for creating a relevant parallel corpus and a new metric to assess the understandability of OpenHathi LLM translations. Studies show that prompting strategies improve the clarity of culturally specific translations. Additionally, adapter-based, parameter-efficient coarse-tuning methods match or exceed the performance of advanced LLMs in reasoning tasks with fewer parameters. As technology advances, translators can maintain quality while reducing costs. However, challenges remain, including inaccuracies and biases in translations for under-resourced languages, but AI translation offers significant potential for grasping context and cultural nuances.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TENCON61640.2024.10902899 },
  booktitle={ TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  chapter={0}
}

@article{rayyan-352343200,
  title={ Trends of Using AI Services Between Students of Educational Study Programs at the University of Maribor  -  2025 MIPRO 48th ICT and Electronics Convention },
  year={2025},
  author={Krašna, M. and Bratina, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11131867 },
  abstract={Since the widespread availability of ChatGPT, the utilization of large language models (LLMs) among students has notably changed. This study investigates LLM usage trends during 2023-2024 and 2024-2025 at the University of Maribor, covering Faculties of Arts, Education, and Natural Science and Mathematics. Initially, 20% of students subscribed to LLM services in 2023-2024; however, this figure significantly dropped to 4% in 2024-2025. Verification practices also decreased-from 70% to 45%-with 26% of students accepting LLM-generated outputs without verification. The primary uses of LLMs remained consistent: concept explanation, supplementary information access, and basic information retrieval. Translation declined notably from third to sixth most common application. Interestingly, LLM use did not significantly rise during examination periods. Subscription rates varied by year of study, with fourth-year students highest at 9%, followed by fifth-year at 7%. These shifts indicate changing perceptions of LLM reliability, emphasizing the urgency of training educators to integrate AI effectively. Furthermore, this evolving reliance underscores the need to strengthen students' critical thinking in AI-assisted learning environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIPRO65660.2025.11131867 },
  booktitle={ 2025 MIPRO 48th ICT and Electronics Convention },
  chapter={0}
}

@article{rayyan-352343201,
  title={ OSAgent: Copiloting Operating System with LLM-based Agent  -  2024 International Joint Conference on Neural Networks (IJCNN) },
  year={2024},
  author={Xu, J. and Guo, K. and Gong, W. and Shi, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650304 },
  abstract={The large language model (LLM) has indeed made significant strides in enhancing human-computer interaction. However, it still faces challenges when dealing with more intricate tasks. Some agents have endeavored to augment LLM capabilities through external memory and tool invocation. Despite these efforts, the task completion rate remains less than satisfactory. This paper introduces a memory-enhanced LLM-based OSAgent designed to assist users in copiloting their operating systems. Specifically, we employ an external memory to store historical user requests, along with corresponding semantic vectors, intent vectors, and human-annotated task planning instructions. When receiving a user request, OSAgent first retrieves similar user requests and task planning instructions as examples to generate prompt, then LLM conducts task planning to manipulate OS tools. Extensive experiments were conducted on mobile operating systems employing seven LLMs. The results are indicative of OSAgent’s remarkable proficiency in invoking AI capabilities, third-party applications, system settings, and data resources.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IJCNN60899.2024.10650304 },
  booktitle={ 2024 International Joint Conference on Neural Networks (IJCNN) },
  chapter={0}
}

@article{rayyan-352343202,
  title={ LLM-KT: A Versatile Framework for Knowledge Transfer from Large Language Models to Collaborative Filtering  -  2024 IEEE International Conference on Data Mining Workshops (ICDMW) },
  year={2024},
  author={Severin, N. and Ziablitsev, A. and Savelyeva, Y. and Tashchilin, V. and Bulychev, I. and Yushkov, M. and Kushneruk, A. and Zaryvnykh, A. and Kiselev, D. and Savchenko, A. and Makarov, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917882 },
  abstract={We present LLM-KT, a flexible framework designed to enhance collaborative filtering (CF) models by seamlessly integrating LLM (Large Language Model)-generated features. Unlike existing methods that rely on passing LLM-generated features as direct inputs, our framework injects these features into an intermediate layer of any CF model, allowing the model to reconstruct and leverage the embeddings internally. This model-agnostic approach works with a wide range of CF models without requiring architectural changes, making it adaptable to various recommendation scenariosOur framework is built for easy integration and modification, providing researchers and developers with a powerful tool for extending CF model capabilities through efficient knowledge transfer. We demonstrate its effectiveness through experiments on the MovieLens and Amazon datasets, where it consistently improves baseline CF models. Experimental studies showed that LLM-KT is competitive with the state-of-the-art methods in context-aware settings but can be applied to a broader range of CF models than current approaches.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDMW65004.2024.00125 },
  booktitle={ 2024 IEEE International Conference on Data Mining Workshops (ICDMW) },
  chapter={0}
}

@article{rayyan-352343203,
  title={ The Effect of Progressive Disclosure in the Transparency of Explainable Artificial Intelligence Systems  -  2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) },
  year={2024},
  author={Muralidhar, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714541 },
  abstract={Recent advances in artificial intelligence (AI) systems have resulted in their ability to provide precise recommendations in response to users’ questions (prompts). However, AI models are opaque, making it challenging for users to comprehend their inner workings. While the Human-Computer Interaction (HCI) community has advocated for design principles like progressive disclosure to improve transparency, we still lack empirical evidence validating its efficacy, especially in the context of LLM-based text generation. Addressing this gap, our paper delves into a user study aimed at investigating the effect of progressive disclosure and adjusting the explanations so as to adapt to users’ mental models for improving the transparency of AI text generation systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VL/HCC60511.2024.00057 },
  booktitle={ 2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) },
  chapter={0}
}

@article{rayyan-352343204,
  title={ Invited: SambaNova SN40L: Unleashing Agentic AI with Dataflow  -  2025 62nd ACM/IEEE Design Automation Conference (DAC) },
  year={2025},
  author={Prabhakar, R. and Nandkar, P. and Gandhi, D. and Farahini, N. and Zeffer, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11133108 },
  abstract={AI inference clouds are increasingly being tasked with running a diverse set of models to support interactive, agentic workloads such as LLM-powered assistants, chatbots, and autonomous agents. Efficient AI cloud inference requires producing tokens during the memory-bound decode phase at peak performance, as well as economically hosting and rapidly switching between a vast array of models. We describe the SambaNova SN40L Reconfigurable Dataflow Unit (RDU) that combines dataflow with a three-tier memory system with SRAM, HBM, and DDR. Dataflow enables peak token generation performance with aggressive fusion of large compute graphs into a single kernel. HBM and high-capacity DDR drastically lower hardware footprint to host and serve trillions of parameters at scale. The SN40L RDU produce tokens over $\mathbf{3} \times$ faster, consume $3 \times$ less energy, and lower model hosting costs by up to $19 \times$ over a DGX H100.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DAC63849.2025.11133108 },
  booktitle={ 2025 62nd ACM/IEEE Design Automation Conference (DAC) },
  chapter={0}
}

@article{rayyan-352343205,
  title={ LLM Based Biological Named Entity Recognition from Scientific Literature  -  2024 IEEE International Conference on Big Data and Smart Computing (BigComp) },
  year={2024},
  author={Jung, S. J. and Kim, H. and Jang, K. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10488292 },
  abstract={Recently, the application of Large Language Models (LLMs) in the field of natural language processing has witnessed remarkable growth, revolutionizing the field of bioinformatics by automating the extraction of biological entities from scientific literature. This study presents the development and evaluation of a Biological Named Entity Recognizer (BNER) using a pre-trained Large Language Model (LLM) refined through prompt engineering. The BNER was tailored to identify proteins, genes, and small molecules within scientific texts, specifically targeting the context of p53 protein-related research. To assess the BNER's efficacy, we curated a dataset comprising ten paragraphs extracted from the abstracts and significant sections of five high-relevance scientific papers. The system's performance was quantified through an entity recognition task, resulting in 51 true positives (TP), 10 false positives (FP), and 3 false negatives (FN). The BNER achieved an F1 score of 0.887, demonstrating a high degree of precision and recall. These results validate the utility of LLMs in bioinformatics and highlight the BNER's potential to support and accelerate scientific discovery by providing accurate, structured data outputs suitable for comprehensive analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigComp60711.2024.00095 },
  booktitle={ 2024 IEEE International Conference on Big Data and Smart Computing (BigComp) },
  chapter={0}
}

@article{rayyan-352343206,
  title={ Taxi Dispatch Automation via Dual LLM Dialogue  -  2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST) },
  year={2025},
  author={Todorov, T. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098196 },
  abstract={An architecture for automating taxi dispatch in Bulgarian is described. The system employs a low-latency LLM for real-time voice processing and a secondary LLM for verifying critical pick-up addresses using a vector store. Integration with SIP-based telephony and in-process. NET dispatch systems demonstrates scalable, robust performance under operational conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEST66328.2025.11098196 },
  booktitle={ 2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST) },
  chapter={0}
}

@article{rayyan-352343207,
  title={ Comparative Analysis of Digital Knowledge Bases and LLM Assistants for Supporting Business Processes in Industry 4.0  -  2025 XXVIII International Conference on Soft Computing and Measurements (SCM) },
  year={2025},
  author={Mavrin, D. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060195 },
  abstract={This study presents a comparative evaluation of the efficiency of Markov chain-based digital knowledge bases and LLM assistants within the framework of Industry 4.0. Leveraging data from TKS.RU, the research empirically assesses both technologies against key performance indicators, including response time, accuracy, usability, operational costs, and adaptability to updates. The findings reveal comparable accuracy scores (5/5) for both systems. However, the LLM assistant demonstrated superior performance in processing speed (0.5 min vs. 2 min) and adaptability to dynamic operational environments, while the knowledge base maintained advantages in stability and cost-free maintenance. The study justifies a hybrid approach that combines the reliability of Markov chains with the flexibility of LLMs, emphasizing their synergistic potential for optimizing business processes and advancing technological sovereignty in the Russian economy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCM66446.2025.11060195 },
  booktitle={ 2025 XXVIII International Conference on Soft Computing and Measurements (SCM) },
  chapter={0}
}

@article{rayyan-352343208,
  title={ LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics  -  2025 6th International Conference on Recent Advances in Information Technology (RAIT) },
  year={2025},
  author={Kumar, R. and Ishan, K. and Kumar, H. and Singla, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11088890 },
  abstract={Disconnected data silos within enterprises obstruct the extraction of actionable insights, diminishing efficiency in areas such as product development, client engagement, meeting preparation, and analytics-driven decision-making. This paper introduces a framework that uses large language models (LLMs) to unify various data sources into a comprehensive, activity-centric knowledge graph. The framework automates tasks such as entity extraction, relationship inference, and semantic enrichment, enabling advanced querying, reasoning, and analytics across data types like emails, calendars, chats, documents, and logs. Designed for enterprise flexibility, it supports applications such as contextual search, task prioritization, expertise discovery, personalized recommendations, and advanced analytics to identify trends and actionable insights. Experimental results demonstrate its success in the discovery of expertise, task management, and data-driven decision making. By integrating LLMs with knowledge graphs, this solution bridges disconnected systems and delivers intelligent analytics-powered enterprise tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAIT65068.2025.11088890 },
  booktitle={ 2025 6th International Conference on Recent Advances in Information Technology (RAIT) },
  chapter={0}
}

@article{rayyan-352343209,
  title={ Software Development and Education: Transitioning Towards AI Enhanced Teaching  -  2024 IEEE Global Engineering Education Conference (EDUCON) },
  year={2024},
  author={Israilidis, J. and Chen, W. -Y. and Tsakalerou, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578564 },
  abstract={This paper investigates the impact of large language model (LLM) AI tools, such as ChatGPT and Copilot, on software development education, focusing on usability, efficiency, and effectiveness in real-world scenarios. The research employs a quantitative approach, utilizing a survey of 50 software developers with varying levels of experience. Preliminary findings suggest that AI tools have a positive influence on expediting coding tasks and automating text generation, particularly in the early stages of product development. Challenges related to customization, accuracy, and transparency, as well as concerns about their potential impacts on employment, personal privacy, and ethical boundaries, have been identified. Pointers and initial recommendations for transitioning to AI-enhanced teaching and optimizing interactions between learners and generative AI practices are provided.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON60312.2024.10578564 },
  booktitle={ 2024 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343210,
  title={ Generative-AI(with Custom-Trained Meta's Llama2 LLM), Blockchain, NFT, Federated Learning and PBOM Enabled Data Security Architecture for Metaverse on 5G/6G Environment  -  2024 IEEE 21st International Conference on Mobile Ad-Hoc and Smart Systems (MASS) },
  year={2024},
  author={Bandara, E. and Foytik, P. and Shetty, S. and Hassanzadeh, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10723538 },
  abstract={The Metaverse is an integrated network of 3D virtual worlds accessible through a virtual reality headset. Its impact on data privacy and security is increasingly recognized as a major concern. There is a growing interest in developing a reference architecture that describes the four core aspects of its data: acquisition, storage, sharing, and interoperability. Establishing a secure data architecture is imperative to manage users' personal data and facilitate trusted AR/VR and AI/ML solutions within the Metaverse. This paper details a reference architecture empowered by Generative-AI, Blockchain, Federated Learning, and Non-Fungible Tokens (NFTs). Within this archi-tecture, various resource providers collaborate via the blockchain network. Handling personal user data and resource provider identities is executed through a Self-Sovereign Identity-enabled privacy-preserving framework. AR/NR devices in the Metaverse are represented as NFT tokens available for user purchase. Software updates and supply-chain verification for these devices are managed using a Software Bill of Materials (SBOM) and a Pipeline Bill of Materials (PBOM) verification system. Moreover, a custom-trained Llama2 LLM from Meta has been integrated to generate PBOMs for AR/NR devices' software updates, thereby preventing malware intrusions and data breaches. This Llama2-13B LLM has been quantized and fine-tuned using Qlora to ensure optimal performance on consumer-grade hardware. The provenance of AI/ML models used in the Metaverse is encapsu-lated as Model Card objects, allowing external parties to audit and verify them, thus mitigating adversarial learning attacks within these models. To the best of our knowledge, this is the very first research effort aimed at standardizing PBOM schemas and integrating Language Model algorithms for the generation of PBOMs. Additionally, a proposed mechanism facilitates different AI/ML providers in training their machine learning models using a privacy-preserving federated learning approach. Authorization of communications among AR/VR devices in the Metaverse is conducted through a Zero-Trust security-enabled rule engine. A system testbed has been implemented within a 5G environment, utilizing Ericsson new Radio with Open5GS 5G core.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MASS62177.2024.00026 },
  booktitle={ 2024 IEEE 21st International Conference on Mobile Ad-Hoc and Smart Systems (MASS) },
  chapter={0}
}

@article{rayyan-352343211,
  title={ LB-KBQA:Large-language-model and BERT based Knowledge-Based Question and Answering System  -  2024 IEEE 22nd International Conference on Industrial Informatics (INDIN) },
  year={2024},
  author={Zhao, Y. and Li, Z. and Pan, Y. and Wang, J. and Zhang, Z. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774538 },
  abstract={Generative Artificial Intelligence (AI), because of its emergent abilities, has empowered various fields, one typical of which is large language models (LLMs). One of the typical application fields of Generative AI is large language models (LLMs), and the natural language understanding capability of LLM is dramatically improved when compared with conventional AI-based methods. The natural language understanding capability has always been a barrier to the intent recognition performance of the Knowledge-Based-Question-and-Answer (KBQA) system, which arises from linguistic diversity and the newly appeared intent. Conventional AI-based methods for intent recognition can be divided into semantic parsing-based and model-based approaches. However, both of the methods suffer from limited resources in intent recognition. To address this issue, we propose a novel KBQA system based on a Large Language Model(LLM) and BERT (LB-KBQA). With the help of generative AI, our proposed method could detect newly appeared intent and acquire new knowledge. In experiments on financial domain question answering, our model has demonstrated superior effectiveness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDIN58382.2024.10774538 },
  booktitle={ 2024 IEEE 22nd International Conference on Industrial Informatics (INDIN) },
  chapter={0}
}

@article{rayyan-352343212,
  title={ Enhancing Human-Machine Interaction: A Study on Deployment of LLM and Gen AI Hybrid Models in Responsible Humanoids for Human Assistance  -  2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT) },
  year={2024},
  author={Murugesan, G. S. and Viswanathan, S. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724819 },
  abstract={This study explores the integration of Large Language Models (LLMs) and Generative AI (Gen AI) in humanoid robots to enhance human-machine interaction. The deployment of advanced AI capabilities in humanoids has revolutionized various fields, including healthcare, education, and industry. The study highlights the potential benefits of AI in humanoids for vulnerable populations, such as the elderly and disabled, including companionship, assistance with daily tasks, and improved quality of life. However, it also addresses the ethical considerations and challenges associated with AI deployment, such as job displacement and income inequality. The study emphasizes the importance of responsible AI deployment, advocating for transparency, accountability, and fairness in AI algorithms. Furthermore, the research discusses strategies for maximizing the positive impact of AI deployment while mitigating negative consequences, such as investing in education and training programs and implementing regulations and policies for ethical AI use.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCNT61001.2024.10724819 },
  booktitle={ 2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT) },
  chapter={0}
}

@article{rayyan-352343213,
  title={ Enhancing Machine Learning Model Interpretability in Intrusion Detection Systems through SHAP Explanations and LLM-Generated Descriptions  -  2024 6th International Conference on Pattern Analysis and Intelligent Systems (PAIS) },
  year={2024},
  author={Khediri, A. and Slimi, H. and Yahiaoui, A. and Derdour, M. and Bendjenna, H. and Ghenai, C. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10541168 },
  abstract={Intrusion Detection Systems (IDS) are critical for detecting and mitigating cyber threats, yet the opaqueness of machine learning models used within these systems poses challenges for understanding their decisions. This paper proposes a novel approach to address this issue by integrating SHAP (SHapley Additive exPlanations) values with Large Language Models (LLMs). With the aim of enhancing transparency and trust in IDS, this approach demonstrates how the combination facilitates the generation of human-understandable explanations for detected anomalies, drawing upon the CICIDS2017 dataset. The LLM effectively articulates significant features identified by SHAP values, offering coherent responses regarding influential predictors of model outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PAIS62114.2024.10541168 },
  booktitle={ 2024 6th International Conference on Pattern Analysis and Intelligent Systems (PAIS) },
  chapter={0}
}

@article{rayyan-352343214,
  title={ Adaptive Deception Architectures: Conceptual Foundations for LLM-Powered Honeypot Systems  -  2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI) },
  year={2025},
  author={Érsok, M. and Balogh, Á. and Kail, E. and Bánáti, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030110 },
  abstract={Conventional honeypot systems lack the dynamic adaptability required to counter evolving cyber threats, necessitating innovative approaches to automated deception. Building on foundational research from my diploma work in adaptive defense mechanisms, this paper proposes a conceptual architecture integrating large language models with next-generation honeypot systems. The framework establishes three pillars of intelligent deception: context-aware interaction through multi-modal dialogue processing that maintains service-specific personas, dynamic environment morphing guided by real-time attacker behavior analysis, and automated artifact generation creating credible system fingerprints. Security safeguards embedded in the design include adversarial prompt hardening and operational sandboxing to mitigate model exploitation risks. Experimental evaluations show marked improvements in attacker engagement compared to conventional rule-based systems, with generated responses demonstrating high plausibility during simulated advanced threat scenarios. This architecture advances adaptive cyber deception by enabling autonomous response calibration while addressing fingerprinting vulnerabilities inherent in traditional honeypot implementations, laying groundwork for intelligent defense systems capable of organic interaction with malicious actors.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SACI66288.2025.11030110 },
  booktitle={ 2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI) },
  chapter={0}
}

@article{rayyan-352343215,
  title={ Comparative Analysis of LLM-based Market Prediction and Human Expertise with Sentiment Analysis and Machine Learning Integration  -  2024 7th International Conference on Data Science and Information Technology (DSIT) },
  year={2024},
  author={Abdelsamie, M. and Wang, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881868 },
  abstract={This study conducts a comparative analysis of market prediction accuracy between Large Language Model (LLM)-based systems and human expertise within the financial analysis domain. Leveraging Quantum, an advanced LLM specialized for financial forecasting, we evaluate its predictive performance against human analysts and general-purpose LLMs, including GPT-3, GPT-4, FinGPT, and FinBERT. Employing a dataset of historical financial data, news headlines, and social media sentiment, we systematically assess predictive accuracy, response efficiency, and interpretability across models. The integration of sentiment analysis and machine learning further strengthens prediction reliability. Results reveal that Quantum’s specialized model demonstrates superior accuracy and speed in financial forecasting compared to human predictions and generalized LLMs, particularly in fast-moving, data-rich contexts. Nevertheless, limitations in nuanced contextual understanding and adaptability persist, highlighting the enduring value of human expertise. This research reinforces the potential of LLMs as robust tools for financial decision-making while identifying key areas for refinement to enhance synergy with human analytical insights. https://chatgpt.com/g/g-bS4Q76v0I-quantum},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSIT61374.2024.10881868 },
  booktitle={ 2024 7th International Conference on Data Science and Information Technology (DSIT) },
  chapter={0}
}

@article{rayyan-352343216,
  title={ Toward Edge General Intelligence with Multiple-Large Language Model (Multi-LLM): Architecture, Trust, and Orchestration  -  IEEE Transactions on Cognitive Communications and Networking },
  author={Luo, H. and Liu, Y. and Zhang, R. and Wang, J. and Sun, G. and Niyato, D. and Yu, H. and Xiong, Z. and Wang, X. and Shen, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11175216 },
  abstract={Edge computing enables real-time data processing closer to its source, thus improving the latency and performance of edge-enabled AI applications. However, predictive AI models often fall short when dealing with complex, dynamic tasks that require advanced reasoning and multimodal data processing. This survey explores the integration of multi-LLMs (Large Language Models) to address these challenges in edge computing, where multiple specialized LLMs collaborate to enhance task performance and adaptability in resource-constrained environments. We review the transition from conventional edge AI models to single LLM deployment and, ultimately, to multi-LLM systems. The survey discusses enabling technologies such as dynamic orchestration, resource scheduling, and cross-domain knowledge transfer that are key for multi-LLM implementation. A central focus is on trusted multi-LLM systems, ensuring robust decision-making in environments where reliability and privacy are crucial. We also present multimodal multi-LLM architectures, where multiple LLMs specialize in handling different data modalities, such as text, images, and audio, by integrating their outputs for comprehensive analysis. Finally, we highlight future directions, including improving resource efficiency, trustworthy governance multi-LLM systems, while addressing privacy, trust, and robustness concerns. This survey provides a valuable reference for researchers and practitioners aiming to leverage multi-LLM systems in edge computing applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCCN.2025.3612760 },
  booktitle={ IEEE Transactions on Cognitive Communications and Networking },
  chapter={0}
}

@article{rayyan-352343217,
  title={ Comparative Analysis of Web Scraping Methodologies Using Generative AI  -  2025 6th International Conference on Recent Advances in Information Technology (RAIT) },
  year={2025},
  author={Pushpalatha, M. and Aravindan, M. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11088928 },
  abstract={Web scraping is a method of extracting information from websites, and it plays a crucial role in data collection for various applications such as market research, academic studies, and competitive analysis. Traditional web scraping can be challenging, especially when dealing with multiple websites that may have different structures and content formats. The complexity of writing and maintaining scrap scripts for each site adds to the difficulty. To address these challenges, Generative AI (GenAI) offers a powerful solution for web scraping. This paper explores the use of Retrieval Augmented Generation (RAG) model architecture and ScrapeGraphAI, a Python library that leverages Large Language Models (LLMs), RAG and graph logic to automate the creation of scraping pipelines. ScrapeGraphAI employs LLMs to understand the desired information and build the necessary scraping logic. It supports multi-format data extraction, handles both single-page and multi-page scenarios, and generates scraping pipelines based on user instructions, significantly reducing manual coding efforts. The Gemini LLM is introduced as an alternative tool for web scraping. This study compares the performance of RAG, ScrapeGraphAI and Gemini LLM in collecting data from various websites to gather information on upcoming academic events. The comparison focuses on the efficiency, accuracy, and ease of use of both methods. Through this analysis, we aim to highlight the advantages and limitations of using AI driven web scraping technologies in streamlining data collection processes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAIT65068.2025.11088928 },
  booktitle={ 2025 6th International Conference on Recent Advances in Information Technology (RAIT) },
  chapter={0}
}

@article{rayyan-352343218,
  title={ LLM-Powered AI Agent Systems and Their Applications in Industry  -  2025 IEEE World AI IoT Congress (AIIoT) },
  year={2025},
  author={Liang, G. and Tong, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105299 },
  abstract={The emergence of Large Language Models (LLMs) has reshaped agent systems. Unlike traditional rule-based agents with limited task scope, LLM-powered agents offer greater flexibility, cross-domain reasoning, and natural language interaction. Moreover, with the integration of multi-modal LLMs, current agent systems are highly capable of processing diverse data modalities, including text, images, audio, and structured tabular data, enabling richer and more adaptive real-world behavior. This paper comprehensively examines the evolution of agent systems from the pre-LLM era to current LLM-powered architectures. We categorize agent systems into software-based, physical, and adaptive hybrid systems, highlighting applications across customer service, software development, manufacturing automation, personalized education, financial trading, and healthcare. We further discuss the primary challenges posed by LLM-powered agents, including high inference latency, output uncertainty, lack of evaluation metrics, and security vulnerabilities, and propose potential solutions to mitigate these concerns.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT65859.2025.11105299 },
  booktitle={ 2025 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343219,
  title={ RL- and LLM-Based AI Solvers for the Game of Wordle/Fibble  -  2025 IEEE Conference on Games (CoG) },
  year={2025},
  author={Chusap, K. and Murphy, C. and Hess, C. and Kadaru, S. D. and Buccapatnam, R. and Liu, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114257 },
  abstract={This paper investigates the performance of reinforcement learning (RL)-based AI agents and large language model (LLM)-based AI agents in tackling the word-guessing game Wordle and its variant, Fibble, which introduces misleading feedback. We conducted experiments to compare a range of RL-based approaches and several LLM chatbots, revealing distinct performance differences, especially when confronted with deceptive clues. Our findings show that an RL algorithm specifically designed to handle misleading information outperformed others in Fibble, while a standard RL algorithm designed for the original Wordle excelled in that game but struggled with Fibble. LLM-based solvers demonstrated reasonable performance across both games but generally fell short of the effectiveness of RL-based solvers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG64752.2025.11114257 },
  booktitle={ 2025 IEEE Conference on Games (CoG) },
  chapter={0}
}

@article{rayyan-352343220,
  title={ From Data to Story: Towards Automatic Animated Data Video Creation with LLM-Based Multi-Agent Systems  -  2024 IEEE VIS Workshop on Data Storytelling in an Era of Generative AI (GEN4DS) },
  year={2024},
  author={Shen, L. and Li, H. and Wang, Y. and Qu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766492 },
  abstract={Creating data stories from raw data is challenging due to humans' limited attention spans and the need for specialized skills. Recent advancements in large language models (LLMs) offer great oppor-tunities to develop systems with autonomous agents to streamline the data storytelling workflow. Though multi-agent systems have benefits such as fully realizing LLM potentials with decomposed tasks for individual agents, designing such systems also faces challenges in task decomposition, performance optimization for sub-tasks, and workflow design. To better understand these issues, we develop Data Director, an LLM-based multi-agent system designed to automate the creation of animated data videos, a representative genre of data stories. Data Director interprets raw data, breaks down tasks, designs agent roles to make informed decisions automatically, and seamlessly integrates diverse components of data videos. A case study demonstrates Data Director's effectiveness in generating data videos. Throughout development, we have derived lessons learned from addressing challenges, guiding further advancements in autonomous agents for data storytelling. We also shed light on future directions for global optimization, human-in-the-loop design, and the application of advanced multimodal LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GEN4DS63889.2024.00008 },
  booktitle={ 2024 IEEE VIS Workshop on Data Storytelling in an Era of Generative AI (GEN4DS) },
  chapter={0}
}

@article{rayyan-352343221,
  title={ Integration of Generative AI for Intelligent Diagnostic of Vehicles  -  2024 32nd National Conference with International Participation (TELECOM) },
  year={2024},
  author={Ranchev, V. and Jordanov, R. and Miletiev, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812315 },
  abstract={The latest update on Generative AI, especially the OpenAI platform, confirms they are no longer single-domain proficiency. It already has been adopted by a variety of applications, emphasizing speech, audio, vision, and multimodal interactions. GPT family of large language models (LLM) is evolving where GPT4o is a few times faster, way more intelligent, and at the same time much cheaper as a service compared to the previous version. Additional services such as “AI Assistant” make it possible to be utilized with fewer resources available in the embedded systems. The advancement of semiconductor technology and microelectronics in the form of Wireless connected SoC in small sizes opens many fields for various IoT (Internet of Things) applications. The proposed solution in this paper will present a system that combines those two technologies in the form of a standalone embedded connected device, that can perform autonomously diagnostic of vehicle by identifying and prompting the owner or driver for troubles in the vehicle and efficiently suggesting for corrective actions. The results show how comprehensive troubleshooting of logged errors is with a standalone embedded system by the support only of GPT AI Assistant.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TELECOM63374.2024.10812315 },
  booktitle={ 2024 32nd National Conference with International Participation (TELECOM) },
  chapter={0}
}

@article{rayyan-352343222,
  title={ Generative AI Digital Twin of Rats: Predicting Drug Efficacy Using Non-invasive Vital Signs and Skeleton Analysis  -  2025 IEEE Gaming, Entertainment, and Media Conference (GEM) },
  year={2025},
  author={Chang, S. -K. and Wang, C. -F. and Lin, Y. -T. and Wang, S. -A. and Chen, Y. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11155319 },
  abstract={Invasive procedures in preclinical studies with laboratory rats can induce stress and skew results. This research uses computer vision and AI to introduce a generative AI-driven digital twin system for non-invasive, real-time monitoring of rat physiological (heart rate, respiration) and behavioral (gait, posture) data. Custom hardware supports data acquisition, including a binocular camera and a wireless heart-rate sensor. Core AI models include U-Net for segmentation, 3D CNNs for video-based physiological signal extraction, and GANs for signal refinement. Initial results show successful non-invasive respiratory pattern prediction, while heart rate prediction encountered challenges with reference signal quality. Future work aims to enhance robustness, integrate GNNs for drug effect modeling, expand data acquisition, advance LLM integration, and develop generative video synthesis. This framework targets more ethical, efficient, and predictive preclinical drug efficacy assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GEM66882.2025.11155319 },
  booktitle={ 2025 IEEE Gaming, Entertainment, and Media Conference (GEM) },
  chapter={0}
}

@article{rayyan-352343223,
  title={ Using DeepSeek LLM AI System on Database Concepts and Design  -  2025 7th International Conference on Computer Communication and the Internet (ICCCI) },
  year={2025},
  author={Pornphol, P. and Chittayasothorn, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11158105 },
  abstract={The use of Large Language Model (LLM) artificial intelligence (AI) systems in learning environments is ubiquitous. They are used by learners for self-studying, assignments, and exam preparation. Practitioners use them as junior assistants. Major concerns include the correctness and the completeness of the answers generated by the AI systems. In this paper, we explore how well an LLM AI system DeepSeek, answers database concepts and design questions. Selected questions on database design and frequently misunderstood topics are asked. Related knowledge is explained. The answers are reviewed and marked to provide an assessment on its use in the subject area.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCI65070.2025.11158105 },
  booktitle={ 2025 7th International Conference on Computer Communication and the Internet (ICCCI) },
  chapter={0}
}

@article{rayyan-352343224,
  title={ New Opportunities for AI Innovation with Big Data: Indirect Docking between GLPS and LLM  -  2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  year={2023},
  author={Zou, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10206159 },
  abstract={The combination of MSPS and LLM aims to optimize the process of HCMA and turn the black box into a white box for the development of AI mathematics. The methods are: first, connect the HCII in parallel to the two systems; Then, observe the whole process of HMC; Finally, every step of GLPS reusing human and machine speech behavior is recorded transparently. MSPS is the foundation of GLPS with IKC and the function of AI mathematical characteristic. The result is that the two sides of HCI, not only have digital records, but also have abstract records of the relational database between language and speech used by users. Its significance lies in that the whole process between brain and computer has not only changed from a black box to a white box, but also the formal system are clearly recorded and can be reproduced at any time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIBD57115.2023.10206159 },
  booktitle={ 2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  chapter={0}
}

@article{rayyan-352343225,
  title={ Toward Democratized Generative AI in Next-Generation Mobile Edge Networks  -  IEEE Network },
  author={Zhang, R. and He, J. and Luo, X. and Niyato, D. and Kang, J. and Xiong, Z. and Li, Y. and Sikdar, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10879580 },
  abstract={The rapid development of generative artificial intelligence (AI) technologies, including large language models (LLMs), has brought transformative changes to various fields. However, deploying such advanced models on mobile and edge devices remains challenging due to their high computational, memory, communication, and energy requirements. To address these challenges, we propose a model-centric framework for democratizing generative AI deployment on mobile and edge networks. First, we comprehensively review key compact model strategies, such as quantization, model pruning, and knowledge distillation, and present key performance metrics to optimize generative AI for mobile deployment. Next, we provide a focused review of mobile and edge networks, emphasizing the specific challenges and requirements of these environments. We further conduct a case study demonstrating the effectiveness of these strategies by deploying LLMs on real mobile edge devices. Experimental results highlight the practicality of democratized LLMs, with significant improvements in generalization accuracy, hallucination rate, accessibility, and resource consumption. Finally, we discuss potential research directions to further advance the deployment of generative AI in resource-constrained environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MNET.2025.3541078 },
  booktitle={ IEEE Network },
  chapter={0}
}

@article{rayyan-352343226,
  title={ CalmSphere: An AI for Mental Health  -  2025 7th International Conference on Intelligent Sustainable Systems (ICISS) },
  year={2025},
  author={S, D. A and S, N. and S, P. D. and G, M. and Kalaivani, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076380 },
  abstract={Mental health is a global issue but access to professionals is limited due to cost, stigma and lack of skilled therapists. Existing AI powered mental health chatbots try to bridge the gap but suffer from many limitations like no empathy, rule based responses and inability to personalize conversations. Through a critical analysis of existing AI therapy tools, we identify key gaps in empathy and efficiency, motivating CalmSphere’s development Our research shows that most existing LLM based solutions rely on prompt engineering rather than fine tuning for therapeutic applications. This analysis is the foundation of our research and guides the development of CalmSphere.This paper introduces CalmSphere, an AI driven virtual therapist to enhance mental health support using a fine tuned Micro-LLM based on LLaMA 2-7B. Unlike traditional AI therapy models, CalmSphere uses memory driven personalization, active listening and emotion aware responses to have a more empathetic and human like conversation. The model is fine tuned using Quantized Low-Rank Adaptation (QLoRA) for efficient training and can be deployed on resource constrained systems with high performance.Also this paper presents a detailed evaluation of CalmSphere’s performance in generating contextually relevant, engaging and supportive conversations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICISS63372.2025.11076380 },
  booktitle={ 2025 7th International Conference on Intelligent Sustainable Systems (ICISS) },
  chapter={0}
}

@article{rayyan-352343227,
  title={ Building Metadata Normalization Using Generative AI  -  2024 IEEE 19th Conference on Industrial Electronics and Applications (ICIEA) },
  year={2024},
  author={Borrison, R. and Aleksy, M. and Dix, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10665241 },
  abstract={The escalating global emissions attributable to commercial buildings call for the integration of digital technologies to enhance energy efficiency and occupant comfort. Cyber-physical control systems (CPCS) can collect data from various sensors and actuators in the building to provide valuable insights to building owners. However, the unstructured metadata text fields in these systems pose a challenge in leveraging artificial intelligence and machine learning solutions for building management. This paper proposes a solution using pre-trained large language models for building metadata normalization that addresses inconsistencies in the point text metadata across buildings. The evaluation of this solution is performed using two publicly-available CPCS datasets, revealing its ability to structure the unstructured natural language metadata without fine tuning or training from scratch.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIEA61579.2024.10665241 },
  booktitle={ 2024 IEEE 19th Conference on Industrial Electronics and Applications (ICIEA) },
  chapter={0}
}

@article{rayyan-352343228,
  title={ Intentional Biases in LLM Responses  -  2023 IEEE 14th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) },
  year={2023},
  author={Badyal, N. and Jacoby, D. and Coady, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316060 },
  abstract={In this study we intentionally introduce biases into large language model responses in an attempt to create specific personas for interactive media purposes. We explore the differences between open source models such as Falcon-7b and the GPT-4 model from Open AI, and we quantity some differences in responses afforded by the two systems. We find that the guardrails in the GPT-4 mixture of experts models with a supervisor, while useful in assuring AI alignment in general, are detrimental in trying to construct personas with a variety of uncommon viewpoints. This study aims to set the groundwork for future exploration in intentional biases of large language models such that these practices can be applied in the creative field, and new forms of media.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UEMCON59035.2023.10316060 },
  booktitle={ 2023 IEEE 14th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) },
  chapter={0}
}

@article{rayyan-352343229,
  title={ Automatic Interpreting of Network Attacks Using Hybrid Architecture Based on CatBoost and LLM  -  2025 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM) },
  year={2025},
  author={Tokarev, Y. S. and Ivanov, Y. S. and Chukhnov, A. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028480 },
  abstract={We propose a method to improve the interpretability and accuracy of network attack classification based on a hybrid approach combining CatBoost models and large language models (LLMs). The key idea is to automatically generate explainable labels for multiclass classification through clustering KDD data using a modified K-means algorithm adapted to deal with categorical features, and then mapping centroids to attack types. To address the limitations of classical explanation methods (SHAP), a mechanism for converting structured features and importance vectors into textual templates enriched with contextual information is developed. This data is integrated with LLM (Llama 3.1) to generate detailed reports including the type of attack, its parameters and anomaly analysis. A strategy of “structure-text” data aggregation is introduced, where CatBoost outputs and textual descriptions of clusters are combined through ensembling. Experiments on the KDD dataset show an improvement in the accuracy of multiclass classification over the basic CatBoost model, as well as an increase in the interpretability of the explanations. The possibility of using the method in SIEM systems for automated threat analysis is demonstrated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIEAM65163.2025.11028480 },
  booktitle={ 2025 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM) },
  chapter={0}
}

@article{rayyan-352343230,
  title={ LLM-NER: Advancing Named Entity Recognition with LoRA+ Fine-Tuned Large Language Models  -  2025 11th International Conference on Computing and Artificial Intelligence (ICCAI) },
  year={2025},
  author={Zhu, Y. and Liu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105937 },
  abstract={Named Entity Recognition (NER) is a crucial task in natural language processing, but it faces persistent challenges in deep learning approaches, such as ambiguity, entity overlap, and domain variability. This study explores the potential of large language models (LLMs) to address these challenges by leveraging LoRA (Low-Rank Adaptation) and LoRA+ fine-tuning techniques. We present a specialized fine-tuned LLM based on Meta-Llama-3-8B-Instruct, optimized for NER tasks. Our model is evaluated against three benchmarks—BERT, RoBERTa, and DeBERTa—and demonstrates competitive performance using prompting alone. Moreover, the fine-tuned model with LoRA+ surpasses benchmark models by $10 \%$ in F1 score, showcasing its ability to distinguish nuanced entities effectively. These findings highlight the potential of LLMs in redefining the state of the art for NER tasks, enabling more robust and adaptable entity recognition solutions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCAI66501.2025.00063 },
  booktitle={ 2025 11th International Conference on Computing and Artificial Intelligence (ICCAI) },
  chapter={0}
}

@article{rayyan-352343231,
  title={ Evaluation of Generative AI Models in Python Code Generation: A Comparative Study  -  IEEE Access },
  author={Palla, D. and Slaby, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963975 },
  abstract={This study evaluates leading generative AI models for Python code generation. Evaluation criteria include syntax accuracy, response time, completeness, reliability, and cost. The models tested comprise OpenAI’s GPT series (GPT-4 Turbo, GPT-4o, GPT-4o Mini, GPT-3.5 Turbo), Google’s Gemini (1.0 Pro, 1.5 Flash, 1.5 Pro), Meta’s LLaMA (3.0 8B, 3.1 8B), and Anthropic’s Claude models (3.5 Sonnet, 3 Opus, 3 Sonnet, 3 Haiku). Ten coding tasks of varying complexity were tested across three iterations per model to measure performance and consistency. Claude models, especially Claude 3.5 Sonnet, achieved the highest accuracy and reliability. They outperformed all other models in both simple and complex tasks. Gemini models showed limitations in handling complex code. Cost-effective options like Claude 3 Haiku and Gemini 1.5 Flash were budget-friendly and maintained good accuracy on simpler problems. Unlike earlier single-metric studies, this work introduces a multi-dimensional evaluation framework that considers accuracy, reliability, cost, and exception handling. Future work will explore other programming languages and include metrics such as code optimization and security robustness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["TNES, UMM +  NSO"]}},
  doi={ 10.1109/ACCESS.2025.3560244 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343232,
  title={ DeepHateDetect: A Comparative Study of Traditional, Sequential, Transformer, and Large Language Models for Hate Speech Detection in Bengali using Explainable AI  -  2025 2nd International Conference on Next-Generation Computing, IoT and Machine Learning (NCIM) },
  year={2025},
  author={Shafi, A. A. and Shawon, M. H. and Leeon, R. H. and Rakib, M. R. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11160253 },
  abstract={The spread of hate speech on the internet has been associated with an increase in violent acts committed against minority groups all across the world. Nowadays, usage of social media is at its peak, and so is hate speech on online social media. Almost every continent has reported incidents. Most of the world’s population uses Facebook alone, and many people increasingly converse on social media. This study used a private dataset collected from different social media platforms. This study aims to discover an efficient and optimal method by using various models that can detect Bengali hate speech on a different text corpus. The overall procedure includes analyzing the collected data. Labeling, cleaning, vectorization, and further data set processing. Several traditional machine learning (ML) models implemented with advanced grid search. In addition, several sequential and transformer-based models were used. Also, a large language model was applied using quantization. Among these different types of models, LLaMA 3-8B gained the highest accuracy of 0.99. Furthermore, the predictability of LLaMA 3-8B has been demonstrated using explainable AI with the LIME framework.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NCIM65934.2025.11160253 },
  booktitle={ 2025 2nd International Conference on Next-Generation Computing, IoT and Machine Learning (NCIM) },
  chapter={0}
}

@article{rayyan-352343233,
  title={ How Large Language Models Work  -  How Large Language Models Work },
  author={Farris, D. and Raff, E. and Biderman, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11079740.pdf&bkn=11079740&pdfType=book },
  abstract={Learn how large language models like GPT and Gemini work under the hood in plain English. How Large Language Models Work translates years of expert research on Large Language Models into a readable, focused introduction to working with these amazing systems. It explains clearly how LLMs function, introduces the optimization techniques to fine-tune them, and shows how to create pipelines and processes to ensure your AI applications are efficient and error-free. In How Large Language Models Work you will learn how to:  Test and evaluate LLMs Use human feedback, supervised fine-tuning, and Retrieval Augmented Generation (RAG) Reducing the risk of bad outputs, high-stakes errors, and automation bias Human-computer interaction systems Combine LLMs with traditional ML  How Large Language Models Work is authored by top machine learning researchers at Booz Allen Hamilton, including researcher Stella Biderman, Director of AI/ML Research Drew Farris, and Director of Emerging AI Edward Raff. They lay out how LLM and GPT technology works in plain language that’s accessible and engaging for all.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ How Large Language Models Work },
  chapter={0}
}

@article{rayyan-352343234,
  title={ Generative AI with Big Data for Better Detection of Fraud in Medical Claims  -  2024 IEEE International Conference on E-health Networking, Application & Services (HealthCom) },
  year={2024},
  author={El-Enen, M. A. Abo and Tbaishat, D. and AbdulRazek, M. and Nazir, A. and Muhammad, R. and Sahlol, A. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10880817 },
  abstract={Generative AI refers to a type of algorithms that can generate new content. This can be text, images, or any other form of data. While Large Language Models (LLMs) are a specific type o f generative A I that focuses o n 1 anguage, they are basically trained on massive textual input to understand and generate human-like text. This paper addresses the critical challenge of fraud detection in medical insurance claims, a pervasive issue causing significant financiallo sses in healthcare. This work is focused on devising a robust, automated system for detecting fraudulent activities. Where an integration of Generative AI, specifically L LM i s implemented with B ig Data processing frameworks to enhancements in fraud detection in medical claims. Each LLM was used as an embedding layer that transforms textual features of a real-world insurance claim data into numerical representations. These claims data has been collected from countries belonging to the Mena region. The results show advantages towards LLMs that were trained on specialized medical contexts as they show better capability of understanding medical expressions which reflects model's performance. Applying further sampling techniques such as class weight and up-sampling did not have a significant impact on the LLMs performance, with a little better performance for class weight. Gemini showed advantages over BERT medical language models on most experiments by achieving 90.44% of classification accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HealthCom60970.2024.10880817 },
  booktitle={ 2024 IEEE International Conference on E-health Networking, Application & Services (HealthCom) },
  chapter={0}
}

@article{rayyan-352343235,
  title={ Integrating Generative AI for Enhanced Automation in System Design Processes  -  2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA) },
  year={2024},
  author={Guntupalli, J. and Watanabe, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710979 },
  abstract={This work delves into the potential of applying Generative AI techniques to the system design phase, aiming to streamline processes and augment human expertise. Gen AI is used to automate the creation of complex design elements and is emerging as a powerful tool for system engineers. Also, with LLM -generated content, evaluating and verifying the correctness of the responses is a challenge. The SE Assistant designed for system engineers intends to create detailed system design documents quickly and accurately along with its evaluation. At the core of the SE Assistant is a sophisticated system that combines the power of GPT-4 with a Multimodal Retrieval Augmented Generation (RAG) pipeline capable of understanding text, images, and tables to provide valuable context. The evaluation uses the strength of strong LLMs in analyzing content based on design-specific criteria. The SE Assistant prototype demonstrates its ability to streamline the system design process, from initial data gathering to the final design output, making it an invaluable tool for system engineers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETFA61755.2024.10710979 },
  booktitle={ 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA) },
  chapter={0}
}

@article{rayyan-352343236,
  title={ Utilizing Generative AI for Patient Behavioral Assessment  -  2025 IEEE 18th Dallas Circuits and Systems Conference (DCAS) },
  year={2025},
  author={Habibi, M. and Nourani, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11045457 },
  abstract={We propose a vision-language framework designed for clinical environments to monitor patient behavior and generate clinically informative reports using advanced computer vision and large language models (LLMs). Our framework analyzes camera images, identifies patient's postures, activities, and interactions with objects, and provides insights into a pretrained summarization LLM to produce context-aware reports. This is done by leveraging a custom-trained Convolutional Neural Network (CNN). This vision-language approach enables real-time or offline monitoring and report generation without the need for wearable devices, offering a non-intrusive, automatic, and scalable monitoring for healthcare settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DCAS65331.2025.11045457 },
  booktitle={ 2025 IEEE 18th Dallas Circuits and Systems Conference (DCAS) },
  chapter={0}
}

@article{rayyan-352343237,
  title={ Future Finance: Predictive Insights and Chatbot Consultation  -  2024 4th Asian Conference on Innovation in Technology (ASIANCON) },
  year={2024},
  author={Ruke, A. and Kulkarni, H. and Patil, R. and Pote, A. and Shedage, S. and Patil, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10838194 },
  abstract={The framework has four pillars on which the rest of it is built. Initially, the Stock Analysis sector is a data-driven approach where historical data is broken down into key components to reduce the amount of hidden information. This is as from there onwards the Stock Prediction module is run which applies predictive modeling methodologies to gain market revelations about future market trends and movements with precision which is informed to investors to help them not only to acquire profits but also maintain stability and to gain knowledge on what to expect. The Assystem, complementing smart wearables, utilizes AI Assistance, with forward facing conversational chatbot interface thus creating a natural environment for the users. This AI-enabled assistant provides customized suggestions, up-to-the-minute details, and impeccable representative behavior as it syncs to investors' expectations. Finally, the Market Guider feature offers users the news and updates from the stock market which were curated, enabling them to stay updated with the involved changes. For predictive analysis, we've opted for the LSTM model due to its superior performance compared to other models tested. It achieved an R-squared score of 0.89, indicating strong predictive power, and demonstrated robustness with a cross-validation score of 0.84 on both training and testing datasets. The model was serialized into a Hierarchical Data Format (HDF) file to save runtime operations and facilitate deployment in Streamlit. Through a Streamlit interface, users can input a stock ticker and receive predicted prices generated by the trained LSTM model.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASIANCON62057.2024.10838194 },
  booktitle={ 2024 4th Asian Conference on Innovation in Technology (ASIANCON) },
  chapter={0}
}

@article{rayyan-352343238,
  title={ LegalMind: Agentic AI-Driven Process Optimization and Cost Reduction in Legal Services Using DeepSeek  -  IEEE Access },
  author={Raju, N. V. D. S. S. V. P. and Faruqui, N. and Patel, N. and Alecsoiu, O. -R. and Thatoi, P. and Alyami, S. A. and Azad, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072348 },
  abstract={The legal industry struggles with inefficiencies, high costs, and manual-intensive workflows. Traditional AI lacks adaptability in optimizing legal operations. To address this, we propose LegalMind, an agentic AI-driven framework leveraging DeepSeek R1 for intelligent legal process automation and cost reduction. LegalMind integrates a structured legal dataset and fine-tunes DeepSeek R1 to enhance decision-making and workflow efficiency. Experimental results show a 42.6% cost reduction and a 60.8% improvement in document processing speed over baseline AI models. Scalability tests confirm the system’s ability to handle 100,000 queries efficiently. Real-world case studies validate LegalMind’s effectiveness in law firms, corporate legal departments, and government agencies, demonstrating significant reductions in case preparation time and operational costs. These findings highlight the transformative potential of agentic AI in legal automation, optimizing workflows and improving decision support.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3586781 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343239,
  title={ Comparative Analysis of Fine-Tuned LLM, BERT and DL Models for Customer Sentiment Analysis  -  2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART) },
  year={2024},
  author={Chinnalagu, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882546 },
  abstract={The fine-tuned Large Language Models such as Generative Pre-Trained Transformers (GPT), Google's and BERT models are leveraged for NLP tasks. The online businesses are relying on customers' online review posting and positive feedback to improve the products sales and services. To predict the accurate emotion and sentiment of the customers remains challenging. There are literatures and sentiment models' research studies show that the traditional models are having performance and accuracy issues. To overcome the sentiment prediction accuracy and model performance issues, author propose the fine-tuned Mistral LLM and BERT models. These models' experimental study results show that fine-tuned LLM outperforms traditional models, and it predicts more accurate sentiments of the customers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SMART63812.2024.10882546 },
  booktitle={ 2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART) },
  chapter={0}
}

@article{rayyan-352343240,
  title={ Don't Start a Career as an AI Prompt Engineer AI will Take Your Job  -  IEEE Spectrum },
  year={2022},
  author={Genkina, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10523015 },
  abstract={Since ChatGPT dropped in the fall of 2022, everyone and their donkey has tried their hand at prompt engineering—finding a clever way to phrase their query to a large language model (LLM) or AI art or video generator to get the best results (or sidestep protections). The Internet is replete with prompt-engineering guides, cheat sheets, and advice threads to help you get the most out of an LLM.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MSPEC.2024.10523015 },
  booktitle={ IEEE Spectrum },
  chapter={0}
}

@article{rayyan-352343241,
  title={ Towards a Conversational Invoice Issuance LLM-Based Agent  -  2024 7th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI) },
  year={2024},
  author={Nie, R. and Wu, H. and Ma, L. and Liu, Z. and Wang, Z. and Zhang, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10899737 },
  abstract={The traditional invoice issuance process within tax administration is labor-intensive and prone to errors, necessitating a shift towards digitalization. Despite the advent of digital invoicing systems that streamline invoice generation and automate rule-based audits, integration with existing financial accounting systems remains a challenge. Particularly in the hospitality and bookkeeping sectors, the adoption of these systems is hindered by the lack of standardized software, high costs, and the absence of technical expertise among small and micro enterprises. The integration of digital invoicing systems with diverse financial software presents significant barriers to uniform adaptation. Furthermore, the complexity of tax regulations and the dynamic nature of tax categories require advanced understanding beyond the capabilities of standard Large Language Models (LLMs). The need for a specialized system that can comprehend finance and tax contexts, securely handle sensitive information, and adapt to user interactions is paramount. This paper introduces an autonomous agent based on a finance and tax-specific Large Language Model (LLM) designed to address the aforementioned challenges. The system includes a Specialized Training Framework to enhance domain comprehension, a Hierarchical Memory Architecture for dynamic user interaction, and a Tax Domain Security Module to ensure compliance with tax regulations. The proposed agent aims to improve the efficiency and accuracy of the invoice issuance process, providing a robust solution for tax administration in the digital era.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACAI63924.2024.10899737 },
  booktitle={ 2024 7th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI) },
  chapter={0}
}

@article{rayyan-352343242,
  title={ Simple Action Model: Enabling LLM to Sequential Function Calling Tool Chain  -  2024 International Conference on Advancement in Renewable Energy and Intelligent Systems (AREIS) },
  year={2024},
  author={Sen, R. S. and Amalkrishna, M. and Prithviraj, R. and Jose, S. P. and Joseph, N. and Thomas, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893677 },
  abstract={Today, LLMs are everywhere. It is making human internet life a lot easier than ever. Every day new sophisticated models are released. But these models are not good enough to become personal assistants like the Jarvis from the Sci-fi movie IronMan. This paper proposes a way to enable any LLM to execute complex requirements in real-world applications. By leveraging state-of-the-art Large Language models, we can create a simple action model that can understand the environment around them. Eventually, these models can help or assist humans in real-time applications. The Sequential Function Calling Tool Chain System aims to bridge the gap between human language understanding and computer programming.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AREIS62559.2024.10893677 },
  booktitle={ 2024 International Conference on Advancement in Renewable Energy and Intelligent Systems (AREIS) },
  chapter={0}
}

@article{rayyan-352343243,
  title={ LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators  -  SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis },
  author={Chitty-Venkata, K. T. and Raskar, S. and Kale, B. and Ferdaus, F. and Tanikanti, A. and Raffenetti, K. and Taylor, V. and Emani, M. and Vishwanath, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10820566 },
  abstract={Large Language Models (LLMs) have propelled groundbreaking advancements across several domains and are commonly used for text generation applications. However, the computational demands of these complex models pose significant challenges, requiring efficient hardware acceleration. Benchmarking the performance of LLMs across diverse hardware platforms is crucial to understanding their scalability and throughput characteristics. We introduce LLM-Inference-Bench, a comprehensive benchmarking suite to evaluate the hardware inference performance of LLMs. We thoroughly analyze diverse hardware platforms, including GPUs from Nvidia and AMD and specialized AI accelerators, Intel Habana and SambaNova. Our evaluation includes several LLM inference frameworks and models from LLaMA, Mistral, and Qwen families with 7B and 70B parameters. Our benchmarking results reveal the strengths and limitations of various models, hardware platforms, and inference frameworks. We provide an interactive dashboard to help identify configurations for optimal performance for a given hardware platform.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCW63240.2024.00178 },
  booktitle={ SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis },
  chapter={0}
}

@article{rayyan-352343244,
  title={ ChatGPT: Unraveling User Challenges & Proposing Targeted Improvements  -  2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT) },
  year={2024},
  author={Gaikwad, A. and Sangole, A. and Madankar, M. and Thakre, D. and Tembhurne, A. and Mali, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10673027 },
  abstract={This research paper investigates the multifaceted challenges users encounter with chatbots, focusing specifically on the widely adopted Generative Pre-trained Transformer (GPT) models. Despite GPT's commendable proficiency in natural language understanding, issues arise, notably in the realm of mathematical calculations. A comprehensive literature review outlines the strengths and limitations of GPT across diverse user queries. Additionally, the paper sheds light on user-reported concerns, including GPT's neutral responses that may not address queries adequately, occasional unreliability, and security vulnerabilities. The study meticulously assesses GPT's performance in mathematical problem-solving, uncovering instances of inaccuracies and user dissatisfaction. The discussion delves into potential contributing factors, such as model architecture and training data, while proposing enhancements to mitigate these challenges. Moreover, the research acknowledges broader concerns, such as the delivery of excessively long answers and the lack of artistic touch and creativity in responses. Noteworthy is the observation that identical questions often yield remarkably similar responses, indicating a potential limitation in the model's diversity and adaptability. The paper concludes by underscoring the importance of addressing these challenges for an enhanced user experience and recommends future research directions for refining the ability of language models like GPT.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/ICCPCT61902.2024.10673027 },
  booktitle={ 2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT) },
  chapter={0}
}

@article{rayyan-352343245,
  title={ Will you Trust me More Than Chatgpt? Evaluating LLM-Generated Code Feedback for Mock Technical Interviews  -  2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE) },
  year={2025},
  author={Vaishampayan, S. and Brown, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024488 },
  abstract={Technical interviews are an opportunity for candidates to showcase their technical proficiency to employers. Despite social aspects of tech interviews, preparation for these assessments is often done in isolation. Cooperative preparation methods, such as mock interviews—or simulated interviews between peers—can provide useful feedback and reveal candidates' technical deficiencies. However, this process is rarely used by candidates in practice. Further, current technical interviews lack authentic feedback for candidates on technical evaluation criteria, such as code correctness, optimality, and complexity. To resolve this, we designed a website to facilitate mock technical interviews and provide users with LLM-generated feedback on code using ChatGPT. We devised a between-subjects study with 46 participants across two settings: human-administered (a live human sharing generated feedback) and automated (direct LLMgenerated feedback). Our results show that candidates perceive coding feedback as useful—however, we found participants regard automated feedback as less trustworthy compared to feedback provided by humans. In light of our findings, we discuss implications and guidelines for incorporating trustworthy AI in technical interview feedback systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CHASE66643.2025.00018 },
  booktitle={ 2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE) },
  chapter={0}
}

@article{rayyan-352343246,
  title={ BoilerTAI: A Platform for Enhancing Instruction Using Generative AI in Educational Forums  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Sinha, A. and Goyal, S. and Sy, Z. and Kuperus, R. and Dickey, E. and Bejarano, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893137 },
  abstract={Contribution: This Full paper in the Research Category track describes a practical, scalable platform that seamlessly integrates Generative AI (GenAI) with online educational forums, offering a novel approach to augment the instructional capabilities of staff. The platform empowers instructional staff to efficiently manage, refine, and approve responses by facilitating interaction between student posts and a Large Language Model (LLM). Background: This study is anchored in Vygotsky's socio- cultural theory, with a particular focus on the concept of the More Knowledgeable Other (MKO). It examines how GenAI can augment the instructional capabilities of course staff in educational environments, acting as an auxiliary MKO to facilitate an enriched educational dialogue between students and instructors. This theoretical backdrop is important for understanding the integration of AI within educational contexts, suggesting a balanced collaboration between human expertise and artificial intelligence to enhance the learning and teaching experience. Research Question: How effective is GenAI in reducing the workload of instructional staff when used to pre-answer student questions posted on educational discussion forums? Methodology: Employing a mixed-methods approach, our study concentrated on select first and second-year computer programming courses with significant enrollments. The investigation involved the use of an AI -assisted platform by designated (human) Teaching Assistants (AI- TAs) to pre-answer student queries on educational forums. Our analysis includes a qualitative examination of feedback and interactions, focusing on the AI-TAs' experiences and perceptions. While we primarily analyzed efficiency indicators such as the frequency of modifications required to AI generated responses, we also explored broader qualitative aspects to understand the impact and reception of AI -generated responses within the educational context. This approach allowed us to gather insights into both the quantitative engagement with AI -assisted posts and the qualitative sentiments expressed by the instructional staff, laying the groundwork for further in-depth analysis. Findings: The findings indicate no significant difference in student reception to responses generated by AI - TAs compared to those provided by human instructors. This suggests that GenAl can effectively meet educational needs when adequately managed. Moreover, AI - TAs experienced a reduction in the cognitive load required for responding to queries, pointing to GenAI's potential to enhance instructional efficiency without compromising the quality of education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893137 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343247,
  title={ Efficient Streaming LLM for Speech Recognition  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Jia, J. and Keren, G. and Zhou, W. and Lakomkin, E. and Zhang, X. and Wu, C. and Seide, F. and Mahadeokar, J. and Kalinli, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890853 },
  abstract={Recent works have shown that prompting large language models with audio encodings can unlock speech recognition capabilities. However, existing techniques do not scale efficiently, especially while handling long form streaming audio inputs — not only do they extrapolate poorly beyond the audio length seen during training, but they are also computationally inefficient due to the quadratic cost of attention.In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model for streaming speech recognition. We process audios in configurable chunks using limited attention window for reduced computation, and the text tokens for each audio chunk are generated auto-regressively until an EOS is predicted. During training, the transcript is segmented into chunks, using a CTC forced alignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk size achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no quality degradation on long form utterances 10x longer than the training utterances.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10890853 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343248,
  title={ SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers’ Driving-thinking Data  -  2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  year={2024},
  author={Jin, Y. and Yang, R. and Yi, Z. and Shen, X. and Peng, H. and Liu, X. and Qin, J. and Li, J. and Xie, J. and Gao, P. and Zhou, G. and Gong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802229 },
  abstract={Leveraging advanced reasoning capabilities and extensive world knowledge of large language models (LLMs) to construct generative agents for solving complex real-world problems is a major trend. However, LLMs inherently lack embodiment as humans, resulting in suboptimal performance in many embodied decision-making tasks. In this paper, we introduce a framework for building human-like generative driving agents using post-driving self-report driving-thinking data from human drivers as both demonstration and feedback. To capture high-quality, natural language data from drivers, we conducted urban driving experiments, recording drivers’ verbalized thoughts under various conditions to serve as chain-of-thought prompts and demonstration examples for the LLM-Agent. The framework’s effectiveness was evaluated through simulations and human assessments. Results indicate that incorporating expert demonstration data significantly reduced collision rates by 81.04% and increased human likeness by 50% compared to a baseline LLM-based agent. Our study provides insights into using natural language-based human demonstration data for embodied tasks. The driving-thinking dataset is available at https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IROS58592.2024.10802229 },
  booktitle={ 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  chapter={0}
}

@article{rayyan-352343249,
  title={ Fikr: AI Chatbot Powered with Vector Search  -  2024 10th International Conference on Computing, Engineering and Design (ICCED) },
  year={2024},
  author={Nurfikri, S. R. and Handayani, D. and Fahreza, A. M. and Almadani, D. and Suryady, Z. and Lathifah, Z. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10983626 },
  abstract={Fikr is a cutting-edge chatbot designed to enhance access to Islamic knowledge by leveraging advanced AI technologies such as vector search and Large Language Models (LLMs), including GPT-3.5. Developed using a combination of Streamlit for the frontend, Flask for the backend, and Firebase for data storage and authentication, Fikr provides users with precise and reliable responses, complete with accurate citations from verified sources such as Hadiths and Quranic verses. A key feature of Fikr is its vector-based search capability, which allows for efficient retrieval of semantically relevant information, improving the accuracy of query responses compared to traditional keyword-based methods. The development process encountered challenges, particularly in data vectorization and ingestion, addressed through iterative troubleshooting and data cleaning methods, resulting in a refined dataset of 33,535 entries. Fikr's answer generation algorithm, incorporating vector database results and LLM -generated responses, ensures that users receive contextually appropriate and well-supported answers. Comparative testing with other AI models, including GPT-4 and Gemini, demonstrated Fikr's superior accuracy and source citation performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCED64257.2024.10983626 },
  booktitle={ 2024 10th International Conference on Computing, Engineering and Design (ICCED) },
  chapter={0}
}

@article{rayyan-352343250,
  title={ The Practice of Enhancing Learning and Scientific Innovative Abilities Using LLM-Based AI Tools  -  2024 6th International Conference on Computer Science and Technologies in Education (CSTE) },
  year={2024},
  author={Wang, B. and Zhang, X. and Li, S. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589992 },
  abstract={With the explosive growth of data and the rapid development of artificial intelligence(AI) technology, scientific research requires to process a large amount of information. Recently AI tools based on large-scale language models (LLM) have emerged, providing researchers with new problem-solving ways. In this paper, we focus on the application of AI tools in the field of scientific research, and conduct a comprehensive analysis of LLM -based AI tools. Firstly, we introduce different types of LLM softwares and analyze their characteristics and advantages. N ext, we select some typical cases, explore the value and limitations of these tools in practice. Moreover, we summarize the main findings of the existing study and suggest some possible research directions in future. It is expected that this paper can provide reference and guidance for the use of AI tools in scientific and educational research.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSTE62025.2024.00038 },
  booktitle={ 2024 6th International Conference on Computer Science and Technologies in Education (CSTE) },
  chapter={0}
}

@article{rayyan-352343251,
  title={ Evaluating the Feasibility of Running AI Large Language Models Locally: Performance, Cost, and Strategic Insights  -  2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  year={2025},
  author={Besimi, A. and Besimi, N. and Caushi, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114035 },
  abstract={This article evaluates the use of three different Large Language Models (LLMs) in local deployment scenarios and during experiment phase. Experiments have been selected to include various LLMs and tasks that combine simple textbased tasks, with audio creation and audio transcription services. It measures time of execution, memory consumption and power consumption that results in cost measurements. The article starts by providing background information from the literature, moving into experimental stage and then providing the results. The article discusses the findings and provides feedback in a form of strategic decision that SMEs and or individual researchers can apply.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAD65464.2025.11114035 },
  booktitle={ 2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  chapter={0}
}

@article{rayyan-352343252,
  title={ Training Generative Models for the Task of Object Description in A Strict Format: Analysis of the Efficiency of Their Architectures  -  2024 7th International Youth Scientific and Technical Conference on Relay Protection and Automation (RPA) },
  year={2024},
  author={Rogozinnikov, E. I. and Doskalesku, K. V. and Ivanov, A. A. and Marinov, Y. A. and Morozov, S. M. and Yakunin, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932905 },
  abstract={In the modern world, digitalization is increasingly penetrating into people's daily lives and covers a wide variety of areas of human activity. Electric power industry is no exception. The introduction of SCADA systems has increased the observability of processes occurring in the network and increased the efficiency and speed of decision-making aimed at maintaining a stable operating mode of the EPS. The next step in the development of digital electric power industry is digital twins, which could be integrated into digital services for their visual display or, for example, for conducting processes of modeling the operating mode of the EPS. The introduction of artificial intelligence (AI) is also gaining popularity. More and more advanced AI models are constantly emerging, capable of solving increasingly complex problems. The introduction of generative artificial intelligence can significantly speed up the process of building digital models. This article provides a comparative review of various generative AI models that are further trained to generate descriptions of electric power substations in a strictly formalized form that can be further computer processed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RPA65165.2024.10932905 },
  booktitle={ 2024 7th International Youth Scientific and Technical Conference on Relay Protection and Automation (RPA) },
  chapter={0}
}

@article{rayyan-352343253,
  title={ AIsop: Exploring Immersive VR Storytelling Leveraging Generative AI  -  2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) },
  year={2024},
  author={Gatti, E. and Giunchi, D. and Numan, N. and Steed, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536541 },
  abstract={We introduce Alsop, a system that autonomously generates VR sto-rytelling experiences using generative artificial intelligence (AI). Alsop crafts unique stories by leveraging state-of-the-art Large Lan-guage Models (LLMs) and employs Text-To-Speech (TTS) technology for narration. Further enriching the experience, a visual representation of the narrative is produced through a pipeline that pairs LLM-generated prompts with diffusion models, rendering visuals for clusters of sentences in the story. Our evaluation encompasses two distinct use cases: the narration of pre-existing content and the generation of entirely new narratives. Alsop highlights the myriad research prospects spanning its technical architecture and user engagement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VRW62533.2024.00229 },
  booktitle={ 2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) },
  chapter={0}
}

@article{rayyan-352343254,
  title={ BALI—A Benchmark for Accelerated Language Model Inference  -  IEEE Access },
  author={Jurkschat, L. and Gattogi, P. and Vahdati, S. and Lehmann, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11026002 },
  abstract={The rise of Large Language Models (LLMs) has revolutionized natural language processing, enabling advancements across diverse applications, including chatbots, live translators, content generation, virtual assistants, and domain-specific automation tools. These applications rely on real-time or near-real-time responses to process sequential LLM requests, creating a critical demand for efficient and accelerated inference. These developments have led to numerous frameworks optimizing inference speed and resource utilization. However, they are often mutually incomparable or are inadequately described due to the lack of standardized benchmarks. Consequently, there is a notable lack of comparison frameworks due to the vast configuration space, bounded factors such as hardware specifications, inference framework parameters, and dataset variations. We propose BALI, an open-source Benchmark for Accelerated Language Model Inference, aiming to provide comprehensive analysis and standardized evaluation metrics to enhance the comparability of LLM performance across configurations. With BALI, we propose substantial measurements to evaluate and rank the efficiency of LLM frameworks across multiple aspects, including sequential decoding, parallelization, and setup efficiency. We show results for mainly small to medium-size models (1-30B parameters) in a sequential or non-batched setup, which is highly relevant for various real-time LLM applications. These observations reveal that the design decisions for such a framework constitute an application-dependent and multidimensional challenge. Thus, our objective is to provide LLM an inference benchmark with a clearly defined evaluation, incorporating multidimensional criteria to provide comparable performance assessments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3576898 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343255,
  title={ Gamifying Human-AI Interaction: Using Large Language Models for Enhanced Engagement and Learning  -  2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  year={2025},
  author={Costa, C. J. and Aparicio, M. and Aparicio, J. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11154284 },
  abstract={This study investigates the synergy between gamification and large language models (LLMs) with human-AI interaction. Motivated by the need to enhance user engagement and learning outcomes, the research addresses how gamification principles can improve the design of LLM-powered systems. This work proposes a framework integrating game mechanics such as narrative-driven interactions, adaptive challenges, personalized feedback, and collaborative problem-solving into LLM applications. Using a mixed-method approach combining conceptual analysis and software prototyping, we illustrate how gamified LLMs enhance motivation, foster trust, and improve performance in diverse contexts, including education, research, and therapy. The findings accentuate the transformative potential of gamification in human-AI collaboration, with implications for designing more intuitive and effective systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHMS65439.2025.11154284 },
  booktitle={ 2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  chapter={0}
}

@article{rayyan-352343256,
  title={ Generative Problem Solving: Bridging Classic and Modern AI  -  2025 19th International Conference on Semantic Computing (ICSC) },
  year={2025},
  author={Shih, H. -S. and Lyu, C. and Vaisi, G. and Sheu, P. C. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036304 },
  abstract={While Large Language Models (LLMs) have strong natural language understanding capabilities, they continue to face significant challenges in solving complex computational problems. In this position paper, we argue that a core limitation lies in the underdeveloped ability of LLMs to generate and explore diverse, meaningful problems while solving them with deeper reasoning. To address this gap, we introduce the concept of Generative Problem Solving (GPS) that emphasizes the capability of LLM for solving problems that require algorithmic reasoning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC64641.2025.00043 },
  booktitle={ 2025 19th International Conference on Semantic Computing (ICSC) },
  chapter={0}
}

@article{rayyan-352343257,
  title={ A Quad-Core AI Processing Unit for Generative AI in 4nm 5G Smartphone SoC  -  2024 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits) },
  year={2024},
  author={Lin, C. -H. and Hsu, J. -Y. and Yu, C. -Y. and Hsu, C. -W. and Tsai, Y. -M. and Wu, K. -S. and Huang, C. -L. and Hsieh, M. -H. and Lin, T. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10631508 },
  abstract={This work presents the quad-core AI processing unit (APU) for efficient execution of generative artificial intelligence (GenAI) applications on smartphones. GenAI applications featured with billions of computations and memory accesses are out of tune with smartphone platforms. The APU applies mixed-precision and hybrid-precision operations, inter-core direct data link, zero-overhead layer fusion, and data broadcasting to reduce 50% of DRAM footprint and 90% of DRAM BW. The 4nm 5G smartphone powered by the APU takes less than 1 second to generate an image with optimized stable diffusion (SD) and outputs more than 20 tokens per second with 7B speculative large language model (LLM).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VLSITechnologyandCir46783.2024.10631508 },
  booktitle={ 2024 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits) },
  chapter={0}
}

@article{rayyan-352343258,
  title={ Interpretable News Clustering and Topic Attribution for the U.S. Presidential Election: An AIME and LLM Approach  -  2025 IEEE/ACIS 23rd International Conference on Software Engineering Research, Management and Applications (SERA) },
  year={2025},
  author={Nakanishi, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11154540 },
  abstract={This paper presents an automated news-analysis method for the U.S. presidential election that combines approximate inverse model explanations (AIME), an explainable AI (XAI) technique, with a large language model (LLM). News articles related to the election were collected using NewsAPI and classified into thematic clusters using k-means clustering. Thereafter, AIME was applied to compute the global feature importance for each cluster, extracting key descriptive terms. Subsequently, an LLM was used to automatically generate appropriate labels for each cluster, significantly enhancing topic interpretability. Visualizing the daily distribution of these clusters enabled the identification of surges in specific topics on specific days and facilitated a detailed analysis of associated news articles. This approach addresses the challenge of interpretability in conventional news analysis clustering, enabling both automated political news classification and time-series trend analysis. This method provides a novel framework for tracking evolving news coverage during extended political events, such as presidential elections, and identifying key events. This methodology is not restricted to election analysis and can be applied to various other domains, including finance, sports, and social news.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SERA65747.2025.11154540 },
  booktitle={ 2025 IEEE/ACIS 23rd International Conference on Software Engineering Research, Management and Applications (SERA) },
  chapter={0}
}

@article{rayyan-352343259,
  title={ LLM-Based Automated Mitigation and Assurance Case Generation Against Threats to AI Systems  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Fujiwara, Y. and Tuchida, T. and Miyata, R. and Washizaki, H. and Ubayashi, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050665 },
  abstract={Artificial intelligence (AI)-integrated systems face unique threats, vulnerabilities, and risks compared to conventional systems. Consequently, implementing security measures for AI systems in organizations is paramount. However, the security database, Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS) has deficiencies in addressing and mitigating these concerns. Furthermore, while the application of large language models (LLMs) presents promising prospects in this field, thorough evaluations of their effectiveness have yet to be performed. In this study, we propose an LLM-based fully automated method for generating mitigations against AI systems threats and validating these mitigations using assurance cases. Furthermore, it presents innovative automated techniques for generating assurance cases, encompassing the dynamic collection of evidence, validation of effectiveness through these data, and solution nodes structured based on Toulmin's theory. We validated it using the method on 46 entries in ATLAS, producing mitigations and their corresponding assurance cases. To explore the potential superiority of the proposed method, we evaluated the mitigations based on information theory and assessed the assurance cases based on their completeness. The results indicate that the proposed method has the potential to generate more risk-specific mitigations, while the completeness of the produced assurance cases improved by up to 88.4% through each step of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00160 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343260,
  title={ Open-AI Driven Open-source Open-access Sustainable ICs Design Flow  -  2024 IEEE 17th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC) },
  year={2024},
  author={Teo, T. H. and Xiang, M. and Goh, E. and Hsu, H. -K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10819560 },
  abstract={The work first demonstrates a design flow that uses open-source electronic design automation (EDA) software and open-access process design kits (PDKs) to design artificial neural network (ANN) circuits. Based on this design flow, a large-language model (LLM) is trained and used to design a three-phase pulse-width modulator (PWM). The three-phase PWM was implemented in SkyWater 130 nm CMOS technology and tapeout through a low-cost multi-project wafer (MPW). This work demonstrates the possibility of using open-AI, open-source EDA design flow to design practical circuits. Sanctions, expensive software license subscriptions, and complicated NDA do not restrict it. All academic institutions and companies should have open-AI, open-source, open-access EDA and PDKs for a sustainable IC design flow.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MCSoC64144.2024.00066 },
  booktitle={ 2024 IEEE 17th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC) },
  chapter={0}
}

@article{rayyan-352343261,
  title={ Generative Content Analysis for Policy Research: Comparing LLM Reliability in Analyzing Institutional AI Discourse  -  2025 25th International Conference on Control Systems and Computer Science (CSCS) },
  year={2025},
  author={Rughiniș, C. and Matei, Ș. and Corcaci, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181680 },
  abstract={This study examines the methodological implications of using large language models (LLMs) as research assistants in coding and qualitative content analysis. We compared how ChatGPT-4o and Gemini 2.0 perform when independently coding and extracting content from university generative AI policies according to a framework of ten "vocabularies of AI competence." Our dataset comprised official AI guidelines from 33 leading global universities. Quantitative analysis of inter-coder reliability indicated significant variation across conceptual categories, with high convergence for vocabularies related to academic integrity and information accuracy, but divergence in detecting other concepts such as AI dependency. Qualitative comparisons of extraction outputs demonstrated methodological trade-offs between models, with ChatGPT-4o providing fewer but contextually richer extractions versus Gemini 2.0's more numerous but briefer quotations. These findings have important considerations for researchers employing LLMs in qualitative analysis: domain-specific reliability assessment, complementary multi-model approaches to balance analytical depth and breadth, and acknowledgment of model-dependent dataset composition.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCS66924.2025.00094 },
  booktitle={ 2025 25th International Conference on Control Systems and Computer Science (CSCS) },
  chapter={0}
}

@article{rayyan-352343262,
  title={ Algorithm Optimization of AI Agent in Customer Behavior Prediction Based on Large Model  -  2025 International Conference on Electrical Drives, Power Electronics & Engineering (EDPEE) },
  year={2025},
  author={Wei, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069220 },
  abstract={With the rapid development of AI technology, especially the application of Large Language Model (LLM), AI Agent shows great potential in the field of customer behavior prediction. Firstly, this paper reviews the traditional methods of customer behavior prediction and points out its limitations. Subsequently, this paper proposes an algorithm optimization strategy that combines multimodal data fusion, adaptive attention mechanism and self-optimization framework based on reinforcement learning (RL). The experimental results show that the prediction accuracy of this strategy on Online Retail data set is improved from 82.5% to 87.3%, and the F1 score is improved from 0.83 to 0.88. On the MovieLens data set, the mean square error (MSE) is reduced from 0.95 to 0.78, and the standard deviation is reduced by about 30%, which improves the stability of the algorithm. Although remarkable achievements have been made, algorithm optimization still has limitations in dealing with extremely unbalanced data sets and computing resource dependence. Future research will explore more efficient model compression technology and special processing methods for unbalanced data sets to further improve the performance and applicability of the algorithm.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDPEE65754.2025.00149 },
  booktitle={ 2025 International Conference on Electrical Drives, Power Electronics & Engineering (EDPEE) },
  chapter={0}
}

@article{rayyan-352343263,
  title={ CRAFTJAI: LLM-Enhanced Generative AI for Gamified Mood Journals  -  2025 22nd International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON) },
  year={2025},
  author={Phairoh, K. and Suchato, A. and Punyabukkana, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11100407 },
  abstract={Mood journals support emotional self-reflection and awareness, but sustaining user motivation remains a challenge. CRAFTJAI, a gamification-driven AI framework, enhances the journaling experience by integrating generative AI, transforming diary entries into AI-generated visual mood characters to make the process more interactive and expressive. By incorporating gamification principles from Self-Determination Theory and the Octalysis model, CRAFTJAI emphasizes motivation and personalization to encourage long-term engagement. It employs LLMs for mood analysis and character generation, while LoRA fine-tuning enhances text-to-image synthesis, improving visual coherence and emotional expressiveness. The evaluation assessed five criteria: unpredictability and curiosity, diary alignment, style consistency, meaning and calling, and ownership and possession, demonstrating an 8% overall improvement over the baseline. The most significant gains were observed in diary alignment and style consistency, validating the effectiveness of fine-tuning in enhancing emotional representation and visual coherence. A real-world study further evaluated engagement across five key metrics: anticipation, motivation to collect, sense of accomplishment, community sharing, and long-term engagement, all mapped to gamification principles. Results strongly supported the fine-tuned method, with all metrics surpassing 80%, confirming its effectiveness in sustaining user motivation. Future work will focus on refining the representation of negative mood characters and expanding customization options to improve user experience. These findings highlight the potential of generative AI and gamification in enhancing motivation in mood journaling.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECTI-CON64996.2025.11100407 },
  booktitle={ 2025 22nd International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON) },
  chapter={0}
}

@article{rayyan-352343264,
  title={ Program Scalability Analysis for LLM Endpoints: Ahmdal's Law Analysis of Parallelizability Benefits of LLM Completions Endpoints*  -  2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  year={2024},
  author={Ganesh, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796792 },
  abstract={This paper presents an analysis of program scalability when using LLM endpoints for parallel chunked completions. By applying Amdahl's Law, we benchmark the performance and scalability of different parallel execution strategies. Additionally, we show that program instrumentation helps Gustafson's scaled speedup formulation to quantify the elusive quality in Amdahl's Law. Furthermore, we report that without combining multiple completions into an ensemble, the results are not trustworthy. We demonstrate a methodology that can help achieve more stable completions by repeated execution with ensemble and identify the optimal degree of parallelism. The study aims to provide insights into optimizing the use of LLM endpoints for applications with large input limits.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECCME62383.2024.10796792 },
  booktitle={ 2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  chapter={0}
}

@article{rayyan-352343265,
  title={ Systematic Testing of Security-Related Vulnerabilities in LLM-Based Applications  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Kaplan, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030024 },
  abstract={Large Language Models (LLMs) have emerged as transformative tools in natural language understanding and generation. They possess billions of parameters, which enable them to generate coherent and contextually rich text [1]. These capabilities have made LLMs vital in domains such as customer service, content creation, and programming assistance [2], [3]. However, these advances come with significant risks. For example, a recent study showed that LLM responses contain private or sensitive information accidentally exposed during training [4], [5]. Furthermore, adversarial attacks have been shown to reduce system accuracy by as much as under controlled conditions [6]. A high-profile example is the misuse of LLMs to generate biased or harmful text when manipulated through adversarial prompts [7].},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00043 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343266,
  title={ Towards Offline GenAI Fine Tuning Model with LoRA Derivatives for IoT Edge Server  -  2024 Ninth International Conference on Informatics and Computing (ICIC) },
  year={2024},
  author={Yugopuspito, P. and Murwantara, I. M. and Alim, E. K. and Cendana, W. and Mitra, A. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10956262 },
  abstract={The Internet of Things (IoT) has become increasingly pervasive, connecting a vast network of devices to collect and analyze data. However, the reliance on continuous internet connectivity poses challenges in regions with limited or unstable access. This paper investigates the feasibility of deploying offline Generative AI (GenAI) models on IoT edge servers, enabling autonomous data generation in disconnected environments. A significant challenge arises from the resource constraints inherent to edge devices, which often lack the computational power required to run sophisticated AI models. To address this, techniques such as model compression and quantization are considered to reduce the size and computational demands of the models, while maintaining acceptable accuracy. One such technique, Low-Rank Adaptation (LoRA), is examined in this study alongside its various derivatives. The primary contribution of this paper is a comparative analysis of several LoRA derivatives, including Quantized LoRA (QLoRA), Multi-task LoRA (MT-LoRA), and Adaptive LoRA (AdaLoRA), in fine-tuning the LLaMA 3.1 large language model (LLM) for IoT applications. The evaluation focuses on memory optimization and model performance, with experiments conducted using the 4-bit quantized version of LLaMA 3.1 8B. These efforts aim to create realistic simulation environments for testing and evaluating IoT systems under different conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIC64337.2024.10956262 },
  booktitle={ 2024 Ninth International Conference on Informatics and Computing (ICIC) },
  chapter={0}
}

@article{rayyan-352343267,
  title={ Text Input Through Swipe Gestures Based Personalized AI Agent  -  2024 3rd International Conference on Automation, Robotics and Computer Engineering (ICARCE) },
  year={2024},
  author={Qi, X. and Weng, D. and Hao, J. and Li, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973482 },
  abstract={Text input based on virtual reality is a common technique in interactive systems, but it may face challenges related to input efficiency and task load when interacting with VR hardware and applications. The development of artificial intelligence interaction technologies offers new approaches to addressing text input challenges. In this paper, we propose a swipe gesture-based text input method under a personalized AI agent framework, combining portable devices (e.g. smartphones) with VR input and incorporating user profile information, input habits, and conversational intent. By integrating the GPT-3.5 model to train a personalized AI agent, we emphasize the importance of understanding and responding to human behavior or capabilities from the agent's perspective, enabling text prediction based on specific contexts. The keyboard layout design is based on a disk divided into 8 equal regions, where the outer circle is subdivided into key areas containing letters, and the inner circle serves as the input buffer area. By resolving word ambiguities based on user input and leveraging the extensive capabilities of large language models in context awareness and text prediction, the system allows complete sentences to be generated from keywords. This reduces the number of manual inputs required by the user, improving text input efficiency and enhancing the overall user experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICARCE63054.2024.00088 },
  booktitle={ 2024 3rd International Conference on Automation, Robotics and Computer Engineering (ICARCE) },
  chapter={0}
}

@article{rayyan-352343268,
  title={ Integrating Generative AI to Higher Education Systems in Africa: Reflections from Tests in Namibia  -  2025 IST-Africa Conference (IST-Africa) },
  year={2025},
  author={JAUHIAINEN, J. S. and NTINDA, M. N. and SUTINEN, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060488 },
  abstract={Generative AI, including Large Language Models (LLMs), is integrated into societal contexts in Africa, including in higher education. Many students, teachers, and educational administrators use these technologies daily for various purposes. This paper examines the opportunities and challenges of integrating generative AI into the higher education systems in Africa. The discussion is grounded in practical testing of TurkuEval at the University of Namibia. This LLMbased platform allows students to study learning materials, answer related questions, and receive AI-generated grading and feedback on their responses. Teachers can review and validate the AI's grading and feedback, thus creating a complementary approach for using LLMs in higher education. Pre-evaluation, evaluation, and postevaluation steps are essential to ensure a systematic and secure LLM use for evaluating students' written work. Leveraging the benefits of generative AI in African higher education requires broader policies, clear instructions and transparent explanations of results to reduce algorithmic aversion and prevent misuse or rejection of LLM technologies in education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/IST-Africa67297.2025.11060488 },
  booktitle={ 2025 IST-Africa Conference (IST-Africa) },
  chapter={0}
}

@article{rayyan-352343269,
  title={ Explainable Patterns of LLM Funding Behavior in Startup Funding Decisions  -  2025 IEEE International Conference on Information Reuse and Integration and Data Science (IRI) },
  year={2025},
  author={Buranasomphop, D. -K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11153197 },
  abstract={The research draws on the decision behavior of large language models (LLMs) in their roles as components of the AI-supported investment decision system. Specifically, three LLMs (GPT-4, Deepseek, and Claude) were compared in their evaluations of 20 real-world startup pitch decks. The LLMs produced predicted funding scores and predicted readiness scores based on aspects of the financial information and business context. The findings confirm that the LLMs do not consider themselves to be neutral or solely rational evaluators with their funding predictions or readiness scores. On the contrary, the LLMs adopt different behavioral patterns based on their training and architecture. GPT-4 took a conservative funding style in line with satisficing, Deepseek often overfunded, suggesting overconfidence and representativeness bias, while Claude made inconsistent decisions based on narrative framing and other aspects of context and framing. The implications for the design of artificial intelligence systems gleaned from the findings are important. Engineers and developers need to understand that LLMs perform in decision-making pipelines with behavioral tendencies that could affect the consequences of decisions in high-stakes situations, such as funding for new startups, acceptance in credit scoring, or assessing risk with insurance companies. These behaviors can help inform how best to align LLMbased systems with financial logic, user expectations, and ethics. However, further research should be focused on how to audit, interpret, and even manage LLM behavior, to improve transparency and reduce undisclosed biases in AI-supported financial tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IRI66576.2025.00056 },
  booktitle={ 2025 IEEE International Conference on Information Reuse and Integration and Data Science (IRI) },
  chapter={0}
}

@article{rayyan-352343270,
  title={ Medify-AI based LLM Based Healthcare System  -  2025 International Conference on Frontier Technologies and Solutions (ICFTS) },
  year={2025},
  author={P, K. and L, S. G and M, R. K. and S, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11031483 },
  abstract={Artificial Intelligence stands at the helm of the dramatic change in the management of illness in the health care sector. The ability of Artificial Intelligence to handle large-scale data analysis, thus aiding clinical decision-making, and automating diagnostic procedures portends new hope in facing global predictive care. According to current research on healthcare technology, LLM and artificial intelligence are instrumental components of medical services. With the aim of designing a more advanced healthcare system, using Large Language Models (LLM) to enhance medical diagnostics by individualised health management is one approach. It may help the user with supplements using the symptoms they give. An integrated system also includes offering you a medical chatbot to be your virtual health assistant. It analyses your health data using advanced AI and provides real-time answers to your questions. It will give you basic advice and can help prepare you for a further knowledgeable conversation with medical experts. It is accurate and offers personalized information based on your health profile; it is available anytime, anywhere to answer questions about symptoms or to request assistance from the medical world. It can be applied to anyone, regardless of age, from young adults to old people, due to its design. The general public will live healthier, better lives as a result of using the healthcare system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICFTS62006.2025.11031483 },
  booktitle={ 2025 International Conference on Frontier Technologies and Solutions (ICFTS) },
  chapter={0}
}

@article{rayyan-352343271,
  title={ Development of the Truku Language Text-to-Speech Model and Its Application in Digital Audiobook Conversion  -  2025 11th International Conference on Computing and Artificial Intelligence (ICCAI) },
  year={2025},
  author={Hsiao, Y. -H. and Guo, Y. -T. and Huang, M. -C. and Chang, W. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105855 },
  abstract={The Truku language is one of the minority Indigenous languages of Taiwan. This paper presents the development of Taiwan’s first-ever Truku language text-to-speech (TTS) model, utilizing over 8 hours of high-quality audio recordings collected from professional male and female Truku speakers. The recordings were processed using VITS2 (Variational Inference for Text-to-Speech) technology to train a robust Truku-TTS model, which can accurately synthesize natural sounding spoken language from written Truku text. To facilitate the model training, we leveraged the computational power of the National Center for High-performance Computing (NCHC), we were able to significantly enhance model training efficiency and performance. Furthermore, we integrated Optical Character Recognition (OCR) technology into the Truku-TTS model workflow, allowing us to convert printed Truku language books into digital audiobooks. This innovative approach not only preserves Truku language but also broadens its accessibility, allowing a wider audience to engage with Truku content. The Truku-TTS model contributes substantially to ongoing efforts to preserve and revitalize Truku languages and provides a crucial tool for cultural and linguistic education. Our methodology and results demostrate a framework that can effectively preserve Truku language materials, enhance Truku language promotion services, and further extend these efforts ro cover all 16 Indigeous tribes comprising 42 dialects in Taiwan, achieving the goal of revitalizing and sustaining Indigenous languages.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCAI66501.2025.00071 },
  booktitle={ 2025 11th International Conference on Computing and Artificial Intelligence (ICCAI) },
  chapter={0}
}

@article{rayyan-352343272,
  title={ A Comprehensive Review of AI in Healthcare: Exploring Neural Networks in Medical Imaging, LLM-Based Interactive Response Systems, NLP-Based EHR Systems, Ethics, and Beyond  -  2023 International Conference on Advanced Computing & Communication Technologies (ICACCTech) },
  year={2023},
  author={Sathe, N. and Deodhe, V. and Sharma, Y. and Shinde, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10441663 },
  abstract={The AI-based technologies used in healthcare systems have witnessed significant growth and innovation, as this growth is attributed to innovations in AI and rise in data collection in the healthcare sector. This survey paper provides a comprehensive overview of the diverse technological advancements reshaping the healthcare landscape. The reviewed topics include Medical Image Interpretation using Deep Learning, Generative AI-based Large Language Models (LLMs), Natural Language Processing for Healthcare Records to give a sense of what AI based systems look like in healthcare. For each of these topics, we've delved into their technical aspects and their applications. Through an overview of these cutting-edge technologies, this research aims to shed light on their current state, challenges, and potential implications for the future of health care. From enhancing diagnostics to improving patient care and accessibility, AI is poised to play pivotal roles in shaping the healthcare industry for years to come. Furthermore, this survey also delves into the ethical considerations surrounding these technologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICACCTech61146.2023.00108 },
  booktitle={ 2023 International Conference on Advanced Computing & Communication Technologies (ICACCTech) },
  chapter={0}
}

@article{rayyan-352343273,
  title={ Can Large Language Models Act as Symbolic Reasoners?  -  2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI) },
  year={2025},
  author={Sullivan, R. and Elsayed, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141039 },
  abstract={The performance of Large language models (LLMs) across a broad range of domains has been impressive but have been critiqued as not being able to reason about their process and conclusions derived. This is to explain the conclusions draw, and also for determining a plan or strategy for their approach. This paper explores the current research in investigating symbolic reasoning and LLMs, and whether an LLM can inherently provide some form of reasoning or whether supporting components are necessary, and, if there is evidence for a reasoning capability, is this evident in a specific domain or is this a general capability? In addition, this paper aims to identify the current research gaps and future trends of LLM explainability, presenting a review of the literature, identifying current research into this topic and suggests areas for future work.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMI65310.2025.11141039 },
  booktitle={ 2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI) },
  chapter={0}
}

@article{rayyan-352343274,
  title={ An AI-aware Orchestration Framework for Cloud-based LLM Workloads  -  2024 IEEE 10th International Conference on Edge Computing and Scalable Cloud (EdgeCom) },
  year={2024},
  author={Ye, Z. and Ying, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10629097 },
  abstract={Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized the entire industry with their extraordinary power, and gained traction in the cloud community. Deploying LLM workloads in cloud has become increasingly common nowadays, as cloud easily fulfills their requirement on extensive computing resources. There are already tools (such as Kubernetes) that help simplify the management of Artificial Intelligence (AI) workloads, yet LLMs often require the balancing of multi-dimensional demands, which can be hard to handle by basic tools. This paper introduces an AI-aware orchestration framework that optimizes LLM performance from aspects including scheduling, scaling, and advanced data management. It can improve the cost-efficiency of the LLM workloads while ensuring its performance, while ensuring the absence of common security risks, supported by Intel hardware.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EdgeCom62867.2024.00011 },
  booktitle={ 2024 IEEE 10th International Conference on Edge Computing and Scalable Cloud (EdgeCom) },
  chapter={0}
}

@article{rayyan-352343275,
  title={ AI as a Tool of Disinformation in the International Arena  -  2024 IEEE International Workshop on Technologies for Defense and Security (TechDefense) },
  year={2024},
  author={Grdzelidze, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10863311 },
  abstract={In the 21st century, information has become a strategic asset, fueling competition between governments and non-government bodies. As societies rely more on technology, manipulating information has become a weapon in international conflicts. This research will explore how Artificial Intelligence (AI), depending on its development and purpose, can be used to spread disinformation and amplify the influence of specific actors globally. The rise of hacktivist groups like Anonymous and increased utilization of the Internet and cyber resources by government agents highlight this issue. With advanced programming skills, these groups can exploit vulnerabilities in large language models (LLMs) to create and disseminate false narratives. This dual capacity for cyberattacks and disinformation campaigns magnifies their global impact. Moving beyond the debate of AI being good or evil, this article examines the real threat posed by accessible AI technologies to local and global information ecosystems. It analyzes how AI, despite its developers’ good intentions, can be misused to disrupt the flow of truthful information. The research also explores potential countermeasures and proactive approaches to mitigate AI-driven disinformation campaigns. This paper scrutinizes real-world cases and their implications to shed light on the complex interplay between AI, government, hacktivist groups, and disinformation in the international arena. This analysis will provide valuable insights for policymakers, security experts, and technologists to better prepare for and address the multifaceted challenges posed by AI as a disinformation tool.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TechDefense63521.2024.10863311 },
  booktitle={ 2024 IEEE International Workshop on Technologies for Defense and Security (TechDefense) },
  chapter={0}
}

@article{rayyan-352343276,
  title={ Voice-Controlled AI Companions for Natural Language Collaboration in a Survival Game  -  2025 IEEE Conference on Games (CoG) },
  year={2025},
  author={Liu, K. and Meng, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114108 },
  abstract={This demo paper introduces a novel interactive system where human players control AI companions using voice commands in a cooperative survival game. Players direct their AI companions through natural language, enhancing gameplay through intuitive interaction. The preliminary demo implementation includes basic behavior management, allowing AI agents to combat enemies, gather resources, and execute player commands. Future versions will further enrich interaction possibilities and AI autonomy levels, serving as a platform to explore advanced human-AI collaboration dynamics.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG64752.2025.11114108 },
  booktitle={ 2025 IEEE Conference on Games (CoG) },
  chapter={0}
}

@article{rayyan-352343277,
  title={ LLM Generative AI and Students’ Exam Code Evaluation: Qualitative and Quantitative Analysis  -  2024 47th MIPRO ICT and Electronics Convention (MIPRO) },
  year={2024},
  author={Smolić, E. and Pavelić, M. and Boras, B. and Mekterović, I. and Jagušt, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569820 },
  abstract={Since the introduction of generative artificial intelligence (GAI) technology in the context of large language models (LLMs), it has been widely used for information extraction and/or extrapolation from different sources. In computer science education, a potential application of such technology is for automatic code review, i. e. shifting the burden of debugging non-compilable code, detecting overlooked optimization concerns such as poor memory management in code that otherwise passes automated tests, and other advanced tasks from a human grader to LLMs. However, LLMs are currently not capable of evaluating code or mathematical expressions with 100% reliability, i. e. beyond token pattern recognition and subsequent probabilistic answer generation. With that in mind, in this paper, we explore the risk of incorrect LLM code evaluation, both descriptive and numerical, as well as begin research on its mitigation and propose further work directions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIPRO60963.2024.10569820 },
  booktitle={ 2024 47th MIPRO ICT and Electronics Convention (MIPRO) },
  chapter={0}
}

@article{rayyan-352343278,
  title={ Rethinking AI Safety and Ethics: A State-of-the-Art Multi-Task Model for Bias and Toxicity Detection via Task-Specific Supervision and Data-centric fine-tuning  -  2025 IEEE International Conference on Artificial Intelligence Testing (AITest) },
  year={2025},
  author={Jha, A. and Verma, A. and De, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11127244 },
  abstract={Advancements in large language models (LLMs) have massively transformed user interactions with AI by enabling the creation of systems that exhibit human-like capabilities, particularly in natural language processing and understanding, allowing for more natural and intuitive human-computer interactions. While the transformative potential of LLMs is undeniable, these powerful models also come with potential risks of generating biased, inappropriate and harmful responses, which needs to be mitigated; and in this process of risk management of LLMs, a very critical step is the detection of these risks.The existing models for toxicity and bias detection, primarily been trained on datasets sourced from social media or similar public platforms, have significant performance gaps when applied to real-world user-AI interactions [1]. To address these gaps, we have introduced a multi-task T5-based model [2] specifically designed for simultaneously detecting toxicity and bias within conversational AI. Our approach involved an iterative, three-stage methodology, which involves synthetic training dataset creation, balancing the dataset through strategic downsampling of dominant categories and upsampling of minority categories, and iterative model training mechanism to accommodate computational limitations. Our research emphasizes a data-centric fine-tuning approach, the importance of carefully curated, balanced training datasets, iterative model refinement, and comprehensive evaluation methodologies. Evaluation on benchmark datasets demonstrated our model’s superior performance, exceeding Claude V2 [3] and achieving comparable accuracy to GPT 4 [4] and superior accuracy to GPT-3.5 [5] in a typical setting of LLM-as-a-judge based evaluation in Phoenix evaluation framework [6]. Our work provides a foundational framework towards building safer, ethically aligned and explainable conversational AI systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AITest66680.2025.00011 },
  booktitle={ 2025 IEEE International Conference on Artificial Intelligence Testing (AITest) },
  chapter={0}
}

@article{rayyan-352343279,
  title={ Ocularis-Ensuring Healthy Vision Through Intelligent Detection  -  2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE) },
  year={2025},
  author={K, P. and G, T. M. S and P, N. and L, P. S. and Johnson, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042812 },
  abstract={Ocular diseases can cause vision impairment or blindness if not detected early. “Ocular Disease Intelligent Recognition (Ocularis)” is a multimodal system designed for automated ocular disease detection and classification. It utilizes a dataset of 5,000 patient records, incorporating age, diagnostic keywords, and high-resolution fundus images captured from diverse imaging devices. The model focuses on classifying eight primary disease categories. To enhance diagnostic accuracy, ensemble learning techniques are employed by integrating ResNet, EfficientNet, and VGG19, leveraging their strengths for robust classification. Additionally, SHAP-based Explainable AI (XAI) provides interpretable visualizations of model predictions, aiding clinical validation. A Google Gemini LLM-powered recommendation system further assists in generating personalized insights based on the detected condition. Ocularis is designed to be a scalable and reliable screening tool for real-world healthcare applications. Future enhancements include predictive analytics for disease progression and extending the system to broader ophthalmic applications, improving early detection and clinical decision-making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RMKMATE64874.2025.11042812 },
  booktitle={ 2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE) },
  chapter={0}
}

@article{rayyan-352343280,
  title={ Contextual Health State Inference from Lifelog Data Using LLM  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Park, J. and Kim, Y. and Song, J. and Lee, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827013 },
  abstract={This study investigates the application of Large Language Models (LLMs) for health state classification using multimodal sensor data from mobile and wearable devices. We address the limitations of existing approaches by integrating diverse sensor data with contextual information, aiming to improve classification accuracy in real-world, data-scarce scenarios. Our novel methodology involves creating conversation-like datasets that contextualize sensor data, which are then used to fine-tune an LLM (Meta-Llama-3-8B). We compare this approach with traditional machine learning methods (XGBoost and Random Forest) and deep neural networks (DNN and Conv+GRU model) across various data configurations. Results demonstrate that our LLM-based approach, augmented with conversational data, achieves a 34.18% performance increase over the benchmark features configuration, outperforming other models with a score of 5.983 out of 10. This study highlights the potential of LLMs in revolutionizing health state classification by effectively leveraging both quantitative sensor data and qualitative contextual information. Our findings open new avenues for developing more accurate and personalized health monitoring systems, with significant implications for real-world applications in healthcare and wellness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827013 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343281,
  title={ Enhancing Conversational AI with LLMs for Customer Support Automation  -  2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS) },
  year={2024},
  author={Shareef, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760403 },
  abstract={The integration of Large Language Models (LLMs) into customer support systems offers transformative potential for improving the efficiency and quality of service interactions. As businesses increasingly rely on digital communication channels, the demand for responsive and accurate customer support escalates. LLMs, with their advanced natural language processing capabilities, provide a promising solution to meet these demands by automating responses and handling a large volume of queries simultaneously without compromising the personalization expected by customers.This research introduces a novel method that leverages the capabilities of LLMs specifically tailored for customer support scenarios. The method involves a hybrid architecture that combines traditional LLM frameworks with custom-trained models, a corpus of real-world customer service interactions on Twitter. This approach is designed to enhance the model’s ability to understand context, manage conversational states, and generate responses that are not only accurate but also contextually appropriate.The implementation of this novel method was rigorously evaluated on the dataset, with a focus on metrics such as response accuracy, contextual relevance, and customer satisfaction indicators. The results demonstrated significant improvements over baseline models, showcasing enhanced response generation capabilities. Key findings include a marked increase in the model’s ability to resolve queries in fewer interaction rounds and its enhanced capability to adapt responses based on the customer’s sentiment and query complexity.By bridging the gap between theoretical LLM architectures and practical, scalable applications for customer support, this research contributes to the ongoing evolution of conversational AI. The implications of this study are profound, suggesting that LLMs can not only automate but also enrich the customer support experience, thereby supporting businesses in maintaining high standards of customer service in the digital age.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSSAS64001.2024.10760403 },
  booktitle={ 2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS) },
  chapter={0}
}

@article{rayyan-352343282,
  title={ Understanding Performance Implications of LLM Inference on CPUs  -  2024 IEEE International Symposium on Workload Characterization (IISWC) },
  year={2024},
  author={Na, S. and Jeong, G. and Ahn, B. H. and Young, J. and Krishna, T. and Kim, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10763564 },
  abstract={The remarkable performance of LLMs has led to their application in a wide range of fields, with data centers utilizing expensive accelerators such as GPUs and TPUs to support LLM inference and training. However, these costly accelerators face challenges with memory capacity due to the large size of LLMs and Key-Value (KV) cache during inference. To address memory capacity issues of accelerators such as GPUs/TPUs, offloading-based LLM inference has been proposed to store model weights, activations, and KV cache in CPU memory. This approach, however, often incurs significant performance degradation in LLM inference in terms of latency and throughput as the offloaded data must be transferred back and forth over the PCIe bus, which has a lower bandwidth compared to memory.This study explores new opportunities for leveraging CPUs in LLM inference. Recent CPUs are equipped with dedicated accelerators for efficient matrix computations and have extended ISAs to support training and inference of new AI models. They support larger memory sizes than most GPUs, allowing for the direct computation of large models and KV caches without offloading. Additionally, recent CPUs are often equipped with DDR and HBM memory, which provides options for optimizing for either memory capacity or bandwidth. This study provides a detailed analysis of LLM inference performance on the latest CPUs equipped with these advanced features. Based on our experimental results, we propose potential optimization strategies tailored to enhance the performance of LLM inference on CPUs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["le couple séquence plus batch, combiné à la taille du modèle et à la présence ou non d’offloading, détermine des ordres de grandeur très différents en latence et en débit, et que la mémoire occupée par le KV cache devient rapidement dominante"]}},
  doi={ 10.1109/IISWC63097.2024.00024 },
  booktitle={ 2024 IEEE International Symposium on Workload Characterization (IISWC) },
  chapter={0}
}

@article{rayyan-352343283,
  title={ LLM-based AI-Powered Offline Portable Transcriptor (OPT) : SURYA-TAC: A Tactical Speech-to-Speech Translation System  -  2025 IEEE International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3) },
  year={2025},
  author={Bohra, P. S. and Berwal, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167249 },
  abstract={Effective intelligence gathering along the Middle Sector of the Line of Actual Control (LAC), which encompasses Himachal Pradesh, Uttarakhand, and the Nepal border, faces persistent challenges due to language barriers, including the use of Mandarin Chinese with military-specific jargon by opposing forces, and the prevalence of low-resource regional languages such as Kinnauri, Bhoti, Kumaoni, Garhwali, and Nepali. This paper proposes the design of an AI-powered offline portable transcription (OPT) based on a large language model (LLM) capable of real-time speech-to-speech (S2S) translation during patrol operations. The system operates entirely offline, using edge-deployable models for Automatic Speech Recognition (ASR), Neural Machine Translation (NMT) and Text-to-Speech (TTS) processing. Conceptually, the system, codenamed SURYA-TAC (Surya Tactical Translator), draws inspiration from the Indian Army’s Surya Command and is designed for disconnected tactical environments. This work lays the foundation for future development by focusing on system architecture, language dataset preparation, optimization strategies and projected operational performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC2E365635.2025.11167249 },
  booktitle={ 2025 IEEE International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3) },
  chapter={0}
}

@article{rayyan-352343284,
  title={ Learning Theory and Knowledge Hierarchy for Artificial Intelligence Systems  -  2024 IEEE International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON) },
  year={2024},
  author={Nechesov, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10758505 },
  abstract={This work represents a continuation of our research in the realm of building Trustworthy AI and Explainable AI. The paper delves into the learning theory of intelligent systems, drawing upon classical mathematical approaches such as the task-based approach, the concept of semantic programming, computability theory, and model theory. This approach allows us to construct a knowledge base for AI systems, which can then be used to establish a natural hierarchy of knowledge within these systems. This enables AI systems to engage in continuous self-learning, as well as efficiently tackle the specific tasks they are designed for. Furthermore, AI systems can provide logical explanations for their decisions, accompanied by a set of guiding rules. This attribute of explainability, however, is notably absent in many large language models, leading us to explore the concept of hybrid AI systems, where neuro-symbolic AI integrates symbolic AI with neuro-statistical AI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SIBIRCON63777.2024.10758505 },
  booktitle={ 2024 IEEE International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON) },
  chapter={0}
}

@article{rayyan-352343285,
  title={ LEDRO: LLM-Enhanced Design Space Reduction and Optimization for Analog Circuits  -  2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  year={2025},
  author={Kochar, D. V. and Wang, H. and Chandrakasan, A. P. and Zhang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106097 },
  abstract={Traditional approaches for designing analog circuits are time-consuming and require significant human expertise. Existing automation efforts using methods like Bayesian Optimization (BO) and Reinforcement Learning (RL) are suboptimal and costly to generalize across different topologies and technology nodes. In our work, we introduce a novel approach, LEDRO, utilizing Large Language Models (LLMs) in conjunction with optimization techniques to iteratively refine the design space for analog circuit sizing. LEDRO is highly generalizable compared to other RL and BO baselines, eliminating the need for design annotation or model training for different topologies or technology nodes. We conduct a comprehensive evaluation of our proposed framework and baseline on 22 different OpAmp topologies across four FinFET technology nodes. Results demonstrate the superior performance of LEDRO as it outperforms our best baseline by an average of 13% FoM improvement with 2.15× speed-up on low-complexity Op-Amps and 48% FoM improvement with 1.7× speed-up on high-complexity Op-Amps. This highlights LEDRO’s effective performance, efficiency, and generalizability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLAD65226.2025.00011 },
  booktitle={ 2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  chapter={0}
}

@article{rayyan-352343286,
  title={ Malicious Code Detection Using LLM  -  NAECON 2024 - IEEE National Aerospace and Electronics Conference },
  year={2024},
  author={Hossain, A. A. and PK, M. K. and Zhang, J. and Amsaad, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670668 },
  abstract={The rapid evolution of cyber threats raises the inevitability of the advancement of innovative and effective approaches in cybersecurity. There are numerous cyber threats; among these threats, malicious code, including viruses, worms, and sophisticated malware, poses significant risks to digital systems. The existing threat detection methods often rely on signature-based techniques and need help to keep pace with the dynamic and evolving characteristics of malware. Large language models (LLMs) such as GPT-4, renowned for their ability to perform natural language processing, offer a promising alternative for enhancing malicious code detection. This research paper proposes a novel approach using large language models (LLMs) to detect unwanted malicious code in Java source code, leveraging the Mixtral architecture. The Mixtral model is trained on a diverse dataset of benign and malicious Java code, enabling it to learn complex patterns and characteristics of malicious code. Experimental results validate the efficiency of the proposed in identifying malicious code, outperforming existing static analysis tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NAECON61878.2024.10670668 },
  booktitle={ NAECON 2024 - IEEE National Aerospace and Electronics Conference },
  chapter={0}
}

@article{rayyan-352343287,
  title={ Demo: Towards a Conversational LLM-Based Voice Assistant for Transportation Applications  -  2024 IEEE Vehicular Networking Conference (VNC) },
  year={2024},
  author={Jafarnejad, S. and Berthe-Pardo, A. and Frank, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575993 },
  abstract={Conversational assistants based on large language models (LLMs) have spread widely across many domains, and the automotive industry is keen to follow suit. However, current LLMs lack sufficient understanding of geospatial data; in addition, timely information, such as weather and traffic conditions, is inaccessible to LLMs. In this demo, we present an in-car assistant capable of verbally communicating with the driver, and by utilizing external APIs, it can answer questions related to routing, finding points of interest, and is aware of the local weather and traffic conditions. The assistant, including a customizable speech synthesizer, is accessible through a graphical user interface that facilitates experimentation by simulating the change in time, origin, destination, and location of the car.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VNC61989.2024.10575993 },
  booktitle={ 2024 IEEE Vehicular Networking Conference (VNC) },
  chapter={0}
}

@article{rayyan-352343288,
  title={ Generating Human Daily Activities with LLM for Smart Home Simulator Agents  -  2024 International Conference on Intelligent Environments (IE) },
  year={2024},
  author={Yonekura, H. and Tanaka, F. and Mizumoto, T. and Yamaguchi, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599909 },
  abstract={This paper presents a novel approach to smart home simulation by integrating Large Language Models (LLMs) for generating human daily schedules and activities of smart home simulator agents. The use of LLMs aims to reduce the complexity of user settings and increase the variety and generality of generated activities. This study explores the potential of LLMs to simulate human-like activity-generating by exploiting their experiential knowledge and adaptability. In addition, this paper discusses fine-tuning techniques for LLMs to optimize their performance within a simulator. By utilizing LoRA and task-specific fine-tuning datasets, while maintaining the ability to generate proper activities, we achieve as much as 4.3% performance improvement about the number of queries. Overall, the integration of LLMs into smart home simulators offers promising opportunities for enhancing the intelligence and adaptability of virtual agents in smart home environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IE61493.2024.10599909 },
  booktitle={ 2024 International Conference on Intelligent Environments (IE) },
  chapter={0}
}

@article{rayyan-352343289,
  title={ Enhancing Local LLM Performance Through Heterogeneous Multi-Device Computing  -  2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR) },
  year={2024},
  author={Metcalfe, R. and Long, G. and Wang, C. L. and Moccagatta, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707864 },
  abstract={In the pursuit of computation efficiency., leveraging multiple compute devices presents a significant opportunity for performance enhancement of locally running Large Language Models (LLMs) on commodity consumer devices., such as laptops. This paper presents a method to improve Time To First Token (TTFT) performance of llama.cpp[l]., a popular framework used throughout the industry to execute a wide array of state-of-the-art LLMs locally., by employing a heterogeneous computing approach. We introduce a novel parallelization strategy that harnesses the combined compute of CPU., GPU., and Neural Processing Unit (NPU) to significantly reduce TTFT latency. Our methodology involves a detailed analysis of llama.cpp to identify parallelizable segments., followed by the implementation of a heterogenous execution model using OpenVINO™[2]. The results demonstrate a −6X performance improvement in TTFT latency when using our heterogenous compute approach., as compared to the native implementation of llama.cpp running on CPU. This study not only showcases the potential of multi-device computing in enhancing llama.cpp., but also serves as a blueprint for similar optimizations in other compute-intensive applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIPR62202.2024.00016 },
  booktitle={ 2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR) },
  chapter={0}
}

@article{rayyan-352343290,
  title={ Colorbot: Interactive Smartphone Assistant for Color Blindness Detection and Realtime Assistance using LLM-based Chatbots and Machine Learning  -  2025 5th International Conference on Soft Computing for Security Applications (ICSCSA) },
  year={2025},
  author={Chaudhari, I. and Wahane, A. and Rahate, U. and Bisen, A. and Gupta, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171137 },
  abstract={Color blindness, or color vision deficiency (CVD), impacts a large percentage of the population, making it difficult for them to differentiate between some colors. In addition to difficulties in everyday activities such as understanding traffic lights or recognizing colored objects, people with CVD usually experience social embarrassment, miscommunication, or even humiliation when incorrectly identifying colors in work, school, or social environments. This research puts forth an interactive smartphone app meant to grant color-blind individuals autonomy, self-esteem, and a dependable aid in facing everyday problems without needing the help of others. The application incorporates sophisticated color recognition and live help capabilities using the Ishihara test for customized CVD analysis. A tailored, interactive, real-time chatbot based on Gemini and Chat GPT-4 Vision models facilitates color recognition, while traffic light detection offers added road safety. The solution employs image processing techniques and machine learning models, developed using the Flutter framework and FastAPI backend, and is protected with Firebase Authentication. Using user testing and feedback, we assess the app's efficiency in offering accurate color detection and helpful support. The findings show that our method is a user-friendly, effective, and accessible solution for the color-blind, paving the way for future advancements in assistive technology.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSCSA66339.2025.11171137 },
  booktitle={ 2025 5th International Conference on Soft Computing for Security Applications (ICSCSA) },
  chapter={0}
}

@article{rayyan-352343291,
  title={ Can LLM Pass a CS1 Course?  -  2025 MIPRO 48th ICT and Electronics Convention },
  year={2025},
  author={Mekterović, I. and Brkić, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11131962 },
  abstract={ChatGPT and other Large Language Models (LLMs) have significantly impacted a number of fields by offering sophisticated natural language processing capabilities. LLMs produce remarkable outcomes in higher education, particularly in introductory computer science courses (CS1). This study examines the changing performance of two cutting-edge LLMs, ChatGPT and Gemini, in the setting of a university-level introductory computer science course (CS1). These LLMs were ‘enrolled’ as students for two consecutive academic years and given a wide range of assignments: lab exercises, midterm exam, and final exam. The fact that only one of the two LLMs finished the course in the first year showed the limitations of these models at that stage. But there was a noticeable change in the second year, when both LLMs received passing ratings, indicating the quick development of LLMs. This study highlights how LLMs can revolutionize computer science's higher education by creating chances for individualized learning, feedback and advanced teaching strategies. It also calls into question the authenticity of student work, academic integrity, and the necessity for teachers to modify their pedagogical approaches to successfully incorporate and utilize these powerful technologies while upholding the fundamental principles of their courses.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIPRO65660.2025.11131962 },
  booktitle={ 2025 MIPRO 48th ICT and Electronics Convention },
  chapter={0}
}

@article{rayyan-352343292,
  title={ LLM Interpretability: Tracing How LLMs Answer Factual Queries and Math Questions  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Agrawal, S. and Li, H. N. T. and Lu, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050622 },
  abstract={In this paper, we study how LLMs like GPT store and retrieve facts to answer factual queries. Using a pretrained GPT-2 model, we evaluate factual accuracy on knowledge datasets, math questions, and hand-crafted prompts, employing metrics such as weighted first token accuracy, F1 score for token overlap, perplexity, and BLEU. We leverage interpretability techniques like attention visualization, logit-lens analysis, and causal tracing to identify layers responsible for knowledge retrieval. To enhance the model's factual and mathematical capabilities, we implement prompt engineering, retrieval-augmented generation (RAG), and fine-tuning, comparing their impact on accuracy and fact retrieval mechanisms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00151 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343293,
  title={ 3 Generative AI Models and LLM: Training Techniques and Evaluation Metrics  -  Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  author={Arun, C. and Karthick, S. and Samy, S. Selvakumara and Hariharan, B. and Lee, P. -M.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11164582.pdf&bkn=11164515&pdfType=chapter },
  abstract={Generative artificial intelligence (AI) has been a prominent technique across data-driven applications, which uses deep learning architecture to learn the underlying characteristic of the sample to build the knowledge base in generating synthetic samples that mimic the real distribution. Generative AI models are ideal solutions where models suffer due to scarcity of data sample that hinders the training process be it text, video, audio, and image. Training the model plays a pivotal role, where it discovers the hidden pattern and understands the intrinsic behavior of samples that aid in generating realistic samples. The volume of data that is available for training and the computing power required pose threat on the performance of the intelligent systems, where large language models (LLM) has been an ideal solution. LLMs are generative AI systems that understand human language and provide intelligent, creative solutions to questions. Complex architecture of LLM allows them to capture the intricacies of language more precise, enabling to generate coherent and contextually relevant outputs. This chapter delves into comprehensive analysis on the well-known generative AI models such as generative adversarial networks, transformers, and LangChain. Generative AI employs different training techniques such as reinforcement learning, adversarial training, variational inference, transfer learning, and progressive training on diverse application domains. Furthermore, the study examines the crucial aspect of evaluating the effectiveness of generative models, using a variety of metrics ranging from BLUE, inception score, perplexity, Frechet inception distance, precision, ROUGE, recall, METEOR, BERT, MoverScore, and many more. A comparative analysis of these metrics offers insights into their respective advantages and disadvantages, aiding practitioners and researchers in selecting benchmarks that align with their specific use cases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  chapter={0}
}

@article{rayyan-352343294,
  title={ FlockGPT: Guiding UAV Flocking with Linguistic Orchestration  -  2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct) },
  year={2024},
  author={Lykov, A. and Karaf, S. and Martynov, M. and Serpiva, V. and Fedoseev, A. and Konenkov, M. and Tsetserukou, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765199 },
  abstract={The paper introduces the first rapid drone flocking control using natural language via generative AI. This approach enables the intuitive orchestration of a drone flock of any size to form desired geometries. The core innovation is a new interface based on Large Language Models (LLMs) that allows user interaction and target geometry description. Users can modify or comment on the flock geometry model interactively. By integrating flocking technology with target surface definition through a signed distance function, smooth and adaptive swarm movement is achieved. A user 1study on FlockGPT showed high intuitive control over drone flocking. Participants without prior experience constructed complex shapes in a few iterations and accurately recognized the figures. The study demonstrated a high recognition rate for six geometric patterns generated through the LLM-based interface, with an 80% mean and up to 93% for cube and tetrahedron patterns. Users reported low temporal demand (NASA-TLX score of 19.2), high performance (NASA-TLX score of 26), attractiveness (UEQ score of 1.94), and hedonic quality (UEQ score of 1.81). The FlockGPT demo code is available at: https://github.com/Taintedy/flock_gpt},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISMAR-Adjunct64951.2024.00141 },
  booktitle={ 2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct) },
  chapter={0}
}

@article{rayyan-352343295,
  title={ WIP: Just-in-Time AI Assisted Formative Feedback for Written, Oral, Team-Based Assessment Tasks: What Worked, What Didn't and Why  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Lim, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893330 },
  abstract={This innovative practice WIP paper describes the use of three large language model-based pre-trained AI (LLM-based AI), Inflection's Pi, Azure OpenAI GPT-3.5-Turbo and Azure OpenAI GPT-4 models to provide insightful and timely feedback across written, oral, and team-based assessment tasks in a capstone engineering design course. These LLM-based AI could analyze the content of artefacts produced in formative verbal and written tasks, ensuring that the students include relevant information in their report, and the report requirements such as structure, grammar, style, mechanics etc. are met. The models were also used to analyze the meeting transcripts of student teams, thus allowing the teamwork process and contributions from each member of the student team to be monitored closely. The integration of LLM-based pre-trained AI increased the timeliness and effectiveness of formative feedback on students' design and teamwork processes, thereby fostering a more adaptive and personalized learning experience. Any missteps or misunderstandings on the part of the students regarding the task requirements, as well as any issues arising within team interactions can be promptly communicated to the instructor for immediate resolution. While LLM-based pre-trained AI holds significant promise in transforming feedback practice, it is important to acknowledge that there are still limitations and barriers to practical implementation in the classroom. The feedback produced by LLM-based pre-trained AI lacks nuanced contextual understanding. The integration of LLM-based pre-trained AI into feedback practices holds transformative potential for education. On one hand, the models offer the promise of responsive and personalized learning, and the potential to foster critical thinking and problem-solving skills through interactive and adaptive learning platforms. Conversely, the reliability of the models as a feedback tool and students' receptions to their use remains ambiguous. We conclude the paper by proposing some strategies to overcome these limitations and support academics in applying LLM-based pre-trained AI in feedback practice.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893330 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343296,
  title={ Ask your Transcript: LLM Driven Insights for Academic Advising  -  2024 2nd International Conference on Computing and Data Analytics (ICCDA) },
  year={2024},
  author={Ali, U. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10867349 },
  abstract={Recent advances in Artificial Intelligence have witnessed an unprecedented penetration of AI tools into our day-to-day life like never before. Especially, a generative AI tool such as ChatGPT that is driven by Large Language Model (LLM), has been proven successful and effectively adapted across many domains such as business, health care, education and much more. The ability of LLM models in understating natural language text and generating human-fashioned responses is very astonishing that paved the way for wide usage of such tools among the population. The students in education domain face many hurdles in their academic advising due to the lack of adequate upfront information available to them. In this work, we explore a more viable and feasible solution to alleviate this problem in term of LLM driven tool and provide a student community with concise and informative responses by retrieving the information given in their academic transcripts. The proposed work crafts a possible list of questions that student community seeks answers based on their past academic performance and experience in navigating the transcripts for their information needs. The tool then injects these questions as prompts to the RAG models to generate relevant automated responses in natural language as if generated by human adviser. The proposed tool may compliment both the student and human advisers in term of equipping them with academic equity and comfort.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCDA64887.2024.10867349 },
  booktitle={ 2024 2nd International Conference on Computing and Data Analytics (ICCDA) },
  chapter={0}
}

@article{rayyan-352343297,
  title={ Automated IoT Fingerprinting with LLMs: Harnessing Explainable AI and Artificial Bee Colony Optimization  -  2025 IEEE Security and Privacy Workshops (SPW) },
  year={2025},
  author={Shrestha, Y. and Ansari, K. and Aksoy, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050828 },
  abstract={Identifying malicious IoT devices significantly impacts the security of hosts within a network. Many automated systems have been introduced using machine learning and deep-learning techniques. However, these approaches often lack explainability, adaptability, and the ability to incorporate contextual and domain-specific knowledge seamlessly. This study investigates an automated approach for classifying IoT devices using LLMs by analyzing network packets. Another issue with current implementations utilizing traditional or LLM-based techniques is that they usually need to process vast amounts of data to be trained. A rigorous feature selection before classification can immensely increase efficiency without sacrificing accuracy. Therefore, we integrate Explainable AI (XAI) techniques, such as SHAP, and optimization algorithms, like Artificial Bee Colony (ABC), to reduce the features obtained from network packets and utilize an LLM for classification. Our method achieves substantial feature reduction-up to 75%-while maintaining high classification accuracy, up to 98.9%. With the help of SHAP and ABC, we can automatically and successfully detect the most relevant features that help distinguish IoT devices efficiently and accurately. This helps our models adapt to changes in device behavior and generalize to diverse network environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPW67851.2025.00024 },
  booktitle={ 2025 IEEE Security and Privacy Workshops (SPW) },
  chapter={0}
}

@article{rayyan-352343298,
  title={ Application of Generative AI in the Interior Design of Autonomous Vehicles  -  2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI) },
  year={2025},
  author={Zhong, C. -R. and Chen, C. -C. and Zheng, M. -C. and Lin, J. -L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108796 },
  abstract={With the development of autonomous driving technology, the car's interior space is changing from driver-oriented to passenger experience-oriented, which makes the car's interior design face the demand for innovation and development space. Therefore, to promote the in-depth application of AI technology in car design, this study examines the interior design of autonomous vehicles as a case study to investigate the effectiveness of generative AI applications in automotive interior design and to evaluate the quality of the generated content. Using a questionnaire survey method, designers from different professions were invited to assess the design quality of generative AI. The findings reveal that RAG-LLM and ChatGPT significantly outperform LLM in terms of the quality of design research texts, with ChatGPT-generated texts being particularly well-received by designers. Furthermore, leveraging the high-quality text outputs from ChatGPT, the concept design renderings generated by Midjourney were also highly regarded by designers with different levels of experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SEAI65851.2025.11108796 },
  booktitle={ 2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI) },
  chapter={0}
}

@article{rayyan-352343299,
  title={ TM-LLM: Token-Motion Embedding Fusion for Large Language Model-Based Vessel Trajectory Prediction  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Nguyen, T. C. Anh and Tao, T. M. and Lee, C. and Youn, C. -H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827542 },
  abstract={Automatic Identification System (AIS) is a key resource in monitoring maritime traffic, providing essential data such as vessel positions, speed, and course changes over time. Despite extensive research, predicting vessel trajectories using AIS time-series data remains challenging due to the intricate movement patterns and the diverse characteristics of vessels. Recently, Large Language Model (LLM) have gained recognition for their ability to transfer knowledge across time-series analysis. However, LLMs face significant difficulties in effectively representing the motion patterns in AIS time-series data. To tackle this problem, we propose a novel model named TM-LLM, designed for vessel trajectory prediction using historical AIS data. In TM-LLM, we develop a token and motion embedding layer that effectively captures both local and global patterns within sequential AIS data. These embeddings are subsequently combined uniformly using a convolutional fusion layer, making them compatible for input into the LLM. We then fine-tune a pre-trained LLM to help it learn the patterns in historical AIS data and effectively predict future vessel trajectories. Experimental results demonstrate that TM - LLM achieves prediction performance comparable to state-of-the-art deep learning models. Furthermore, TM - LLM has a significantly shorter prediction time, making it well-suited for real-time prediction scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827542 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343300,
  title={ Compound AI System for Personalized Learning: Integrating LLM Agents with Knowledge Graphs  -  2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI) },
  year={2024},
  author={Antonov, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911764 },
  abstract={Personalized learning plays a critical role in enhancing educational outcomes by customizing experiences to meet individual learners' unique needs, preferences, and abilities. Although Large Language Models (LLMs) offer promising opportunities for personalization through natural language interactions, they face challenges related to maintaining long-term context and ensuring traceability of a learner's evolving knowledge. This paper introduces a composite AI framework that merges an LLM-powered conversational agent with Knowledge Graphs (KGs) structured according to Knowledge Space Theory (KST), enhanced by advanced retrieval tools and a robust long-term memory mechanism. This system autonomously orchestrates meaningful, context-aware dialogues while utilizing function calling to access various tools, effectively bridging the gap between dynamic interactions and structured knowledge representation. Our empirical evaluations indicate that the proposed system excels in maintaining coherent dialogues, accurately tracking learner progress, and providing reliable, personalized educational support. By addressing the limitations of standalone LLMs and traditional adaptive learning systems, this integrated approach signifies a notable advancement in intelligent educational technology.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RICAI64321.2024.10911764 },
  booktitle={ 2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI) },
  chapter={0}
}

@article{rayyan-352343301,
  title={ AI-Assisted Autoformalization of Combinatorics Problems in Proof Assistants  -  2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER) },
  year={2025},
  author={Doan, L. and Nguyen, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023945 },
  abstract={Proof assistants such as Coq and LEAN have been increasingly used by renowned mathematicians to formalize and prove mathematical theorems. Despite their growing use, writing formal proofs is challenging, and even the first step of stating the problem formally is difficult as it requires a deep understanding of these systems’ languages. Recent advancements in AI, especially large language models (LLMs), have shown promise in automating this formalization task. However, domains such as combinatorics pose significant challenges for AI-assisted proof assistant systems due to their cryptic nature and the lack of existing data to train AI models. We introduce AutoForm4Lean, a system designed to leverage LLMs to aid in formalizing combinatorics problems for LEAN. By combining LLMs with techniques from software engineering and formal methods such as validation and synthesis, AutoForm4Lean generates formalizations of combinatorics problems more effectively than the current state-of-the-art LLMs. Moreover, this project seeks to provide a comprehensive collection of formalized combinatorics problems, theorems, and lemmas, which would enrich the LEAN library and provide valuable training data for LLMs. Preliminary results demonstrate the effectiveness of AutoForm4Lean in formalizing combinatorics problems in LEAN, making a step forward in AI-based theorem proving.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE-NIER66352.2025.00006 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER) },
  chapter={0}
}

@article{rayyan-352343302,
  title={ Pandora: an Ai Model for the Automatic Extraction of Clinical Unstructured Data and Clinical Risk Score Implementation  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Jimenez, D. and Castano-Villegas, N. and Llano, I. and Martinez, J. and Ortiz, L. and Velasquez, L. and Zea, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050460 },
  abstract={Introduction: Medical records and physician notes contain valuable non-tabular information that requires significant manual effort to extract and structure. Large Language Models (LLMs) have demonstrated the ability to understand, reason, and retrieve information from such sources, transforming it into accessible information for clinical or research purposes. Objective: To present and asses the capabilities of PANDORA, our AI system, comprised of two LLMs that can extract data and use it in validated calculator and prediction models to provide recommendations. Methods: The study evaluates the model's ability to extract clinical features from discharge notes from the MIMIC database and synthetically generated outpatient charts. We use the PUMA calculator for Chronic Obstructive Pulmonary Disease (COPD) case finding, which interacts with the model to calculate a score based on seven criteria and determine which patients should undergo further spirometry testing. Results: The model's exhibited excellent extraction accuracy, achieving 100 % for MIMIC and 99 % for synthetic cases. Interaction with the PUMA scale produced accurate scores, with an accuracy of 94% for both databases. The final recommendation on COPD risk was based on the PUMA scale, classified as positive if score $\geq 5$. Sensitivity was 86 % for MIMIC and 100 % for synthetic cases. Conclusion: LLMs have been successful in extracting information and generating recommendations. However, this is the first model that successfully extracts information based on existing, validated clinical scores from plain, non-tabular data and provides a recommendation mixing all these capabilities. It leverages existing knowledge, making it available to be explored in light of the highest-quality evidence in several medical fields.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00280 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343303,
  title={ Detecting and Mitigating Bias in LLMs through Knowledge Graph-Augmented Training  -  2025 International Conference on Artificial Intelligence and Data Engineering (AIDE) },
  year={2025},
  author={Kumar, R. and Kumar, H. and Shalini, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987418 },
  abstract={Large language models have revolutionized natural language processing with their surprising capability to understand and generate human-like text. However, many of these models inherit and further amplify the biases present in their training data, raising ethical and fairness concerns. The detection and mitigation of such biases are vital to ensuring that LLMs act responsibly and equitably across diverse domains. This work investigates Knowledge Graph-Augmented Training (KGAT) as a novel method to mitigate bias in LLM. Using structured domain-specific knowledge from real-world knowledge graphs, we improve the understanding of the model and reduce biased output. Public datasets for bias assessment include Gender Shades, Bias in Bios, and FairFace, while metrics such as demographic parity and equal opportunity facilitate rigorous detection. We also performed targeted mitigation strategies to correct biased associations, leading to a significant drop in biased output and improved bias metrics. Equipped with real-world datasets and knowledge graphs, our framework is both scalable and effective, paving the way toward responsible deployment in sensitive and high-stakes applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIDE64228.2025.10987418 },
  booktitle={ 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE) },
  chapter={0}
}

@article{rayyan-352343304,
  title={ LLM-Assisted Generation of SWRL Rules from Natural Language  -  2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  year={2024},
  author={Soularidis, A. and Kotis, K. and Lamolle, M. and Mejdoul, Z. and Lortal, G. and Vouros, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990088 },
  abstract={Recently, Large Language Models (LLMs) have attracted great attention due to their remarkable performance in human-like text generation and reasoning skills (although their memory and hallucination problems still remain key issues to tackle more efficiently). LLMs have been applied to various application domains, including Knowledge Graph (KG) generation, question and answering over KGs and text-to-SPARQL translation. In this work, we investigate the capabilities of LLMs in text-to-SWRL translation, i.e., translation of Natural Language (NL) rules into Semantic Web Rule Language (SWRL) rules, put in the context of an industrial Ontology Engineering (OE) environment called GLUON, presenting our first experimental results. The aim of this work is to identify the level of automation that is adequate for the LLM to generate well-formed SWRL rules, towards the development of an LLM-based framework, as a plugin to the GLUON OE environment. In this direction we leverage and combine the reasoning capabilities of GPT-4o model, the Retrieval-Augmented Generation (RAG) technology, and prompt engineering. We employ quantitative and qualitative metrics to evaluate the generated SWRL rules, focusing on the correct syntax and the level of human intervention.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxDKE63520.2024.00008 },
  booktitle={ 2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  chapter={0}
}

@article{rayyan-352343305,
  title={ Generative AI-Powered Cognitive Agent for Holistic Human Performance Optimization  -  2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  year={2025},
  author={Minissale, K. and Pitrone, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11154323 },
  abstract={This article introduces a Cognitive Agent for human-machine interaction, empowering individuals to enhance both professional and personal performance. The Cognitive Agent operates through a mobile application that integrates Generative AI for conversational interactions, sentiment analysis, personalized recommendations, and structured data collected from wearable devices or measurement tools. It monitors and optimizes human psychological and physiological dynamics across the three core pillars of the Holistic Wellness Framework: rest, movement, and nutrition. Additionally, it leverages music as an intervention to reduce stress and enhance performance, offering a holistic tool for improving wellness and productivity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHMS65439.2025.11154323 },
  booktitle={ 2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  chapter={0}
}

@article{rayyan-352343306,
  title={ Comparing AI in Online Learning: The Transition and Trade-offs Between Intent-Based Learning Assistants and LLM-Chatbots in MOOCs  -  2024 IEEE Digital Education and MOOCS Conference (DEMOcon) },
  year={2024},
  author={Zobel, T. and Meinel, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10748211 },
  abstract={In the evolving landscape of Massive Open Online Courses (MOOCs), Artificial Intelligence (AI) technologies, notably intent-based learning assistants and Large Language Model (LLM)-Chatbots, present innovative avenues for personalizing and enhancing online education. This paper conducts a succinct comparative analysis of these AI approaches, highlighting their respective strengths and limitations in MOOC environments. Intent-based assistants offer precise, tailored support by responding to specific user intents, facilitating a more structured learning experience. Conversely, LLM-Chatbots, with their vast knowledge bases and conversational capabilities, provide flexible and wide-ranging interactions, encouraging exploratory learning.This analysis further considers the impact of these technologies on fostering social learning communities, addressing ethical and privacy concerns, and their applicability across diverse educational contexts. By comparing the trade-offs between intent-based assistants and LLM-Chatbots, the paper aims to equip educators and technologists with insights into their optimal integration for improving MOOCs. It underscores the importance of aligning AI technologies with educational goals to enhance learning accessibility and quality, especially for underrepresented groups, thereby contributing to the development of more inclusive and effective online learning environments. This research serves as a guide for future AI applications in education, emphasizing the need for a balanced approach in leveraging AI to benefit learners globally.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DEMOcon63027.2024.10748211 },
  booktitle={ 2024 IEEE Digital Education and MOOCS Conference (DEMOcon) },
  chapter={0}
}

@article{rayyan-352343307,
  title={ Adversarially Enhanced Financial Misinformation: A Comparative Analysis of LLM- vs. GAN-Generated Content Exposing AI Moderation Vulnerabilities  -  2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC) },
  year={2025},
  author={Santorelli, C. and Belmonte, V. G. and Mastropaolo, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077509 },
  abstract={As Large Language Models (LLMs) become more pervasive, their capability to generate convincing financial news poses an escalating threat to investor decision-making and market stability. However, contemporary content moderation and AIbased verification systems exhibit notable vulnerabilities when confronted with the subtle linguistic manipulations introduced by advanced prompt engineering techniques and adversarial training. This study investigated the comparative credibility, influence, and detectability of AI-generated financial headlines produced via Zero-Shot, Few-Shot (8-Shot), and Chain-of-Thought (CoT) prompting, with CoT outputs further used to train a GAN for adversarially enhanced text generation. We compiled a combined dataset of NASDAQ-listed securities and web-scraped, human authored news, generated additional AI-driven headlines under three prompting paradigms, and conducted a survey of randomly sampled headlines ($\mathbf{n} \boldsymbol{=} \mathbf{3 0 0}$) to assess the credibility, market perception impact, investment influence, and AI detectability. The analysis revealed that headlines generated through Chain-of-Thought prompting consistently scored higher in perceived authenticity, influenced investment sentiment more profoundly, and were harder for participants to classify as AI-written. The findings underscore the urgent need for adversarially robust content moderation and verification mechanisms, capable of adapting to the rapidly evolving landscape of AI-generated financial misinformation, particularly when Chain-of-Thought reasoning is leveraged to enhance GAN-generated content.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIRC64931.2025.11077509 },
  booktitle={ 2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC) },
  chapter={0}
}

@article{rayyan-352343308,
  title={ Large Language Model-Driven Immersive Agent  -  2024 IEEE World AI IoT Congress (AIIoT) },
  year={2024},
  author={Singh, A. and Kumar, S. and Ehtesham, A. and Khoei, T. T. and Bhati, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578948 },
  abstract={Recent research in the field of Large Language Models (LLMs) has given a new direction to the capabilities of AI agents for solving complex problems. This paper attempts to explore one such use case to investigate LLMs-based AI agents’ role in immersive technology, specifically focusing on GPT-4’s vision capabilities in Augmented Reality (AR). The paper utilizes Smart App Agent Framework for recommending products. This recommendation system assists users to make context-aware decisions during their online shopping experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT61789.2024.10578948 },
  booktitle={ 2024 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343309,
  title={ The Personalized Scene-Based AI Agents: Exploring Chinese Language Learning Among International Students  -  2025 5th International Conference on Artificial Intelligence and Education (ICAIE) },
  year={2025},
  author={Su, B. and Peng, J. and Xu, H. and Chen, K. and Zhou, Z. and Liu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11158030 },
  abstract={With the development of deep learning and large language model (LLM) technologies, AI agents, as a key application of generative artificial intelligence (AIGC), have demonstrated significant potential in the field of international Chinese education. Personalized scenario AI agents, leveraging open-source AI chat frameworks, large-scale Chinese language corpora, and dynamic adjustment mechanisms (RAG, PAL, ReAct), effectively address key challenges in Chinese language acquisition for international students. These challenges include a lack of communicative practice, difficulties in acquiring everyday expressions, the inability of large-class instruction to accommodate individual differences, and the absence of real-time feedback. By constructing immersive interactive scenarios, personalized learning pathways, and intelligent feedback systems, AI agents enhance learning efficiency and flexibility while providing new pathways for the intelligent development of international Chinese education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIE64856.2025.11158030 },
  booktitle={ 2025 5th International Conference on Artificial Intelligence and Education (ICAIE) },
  chapter={0}
}

@article{rayyan-352343310,
  title={ AI-Buddies in MMORPGs: Player Perceptions of Conceptual LLM-Driven NPCs in World of Warcraft  -  2025 IEEE Conference on Games (CoG) },
  year={2025},
  author={Ploug, R. and Scirea, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114149 },
  abstract={This study investigates player perceptions of conceptual Large Language Model (LLM)-driven Non-Player Characters (NPCs) in World of Warcraft (WoW), referred to as “AIBuddies.” Building on prior work on Conversational Artificial Autonomous Agents (CA-bots), it explores how such companions could enhance gameplay and player experience. A mixed-method survey of 273 WoW players was conducted, using visual mock-ups to present the AI-Buddy concept rather than a working prototype. Participants evaluated interaction features, customization options, and potential gameplay impact. Results show general support, particularly among Casual players, for using AI-Buddies to improve solo content, personalization, and immersion. However, concerns were raised about balance, multiplayer exploitation, and ethical implications. Thematic analysis also revealed worries about reduced social interaction and technical feasibility. This short study contributes to ongoing discussions on CA-bots and LLM-driven NPCs in MMORPGs and offers early insights into how such features are perceived by the WoW playerbase.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG64752.2025.11114149 },
  booktitle={ 2025 IEEE Conference on Games (CoG) },
  chapter={0}
}

@article{rayyan-352343311,
  title={ Large Language Model (LLM) & GPT, A Monolithic Study in Generative AI  -  2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE) },
  year={2023},
  author={Mohammad, A. F. and Clark, B. and Hegde, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487437 },
  abstract={Large Language Models (LLMs) are a branch of computer science and artificial intelligence which is concerned with computer and human language interaction. It is the study of mathematical and computational modeling of various aspects of language and the development of an arsenal of systems. Large Language Models are considered an area of research and application that explores how computers can be used to comprehend and manipulate natural language text or speech to perform useful tasks. It has spread its applications in various areas such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc. Large Language Models (LLMs) have a greater contribution in the area of text pre-processing as well in the time of ChatGPT as an example. Different pre-processing steps are required to perform, such as stemming, part-of-speech (POS) tagging, chunking, parsing, information extraction, etc. to perform language processing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCE60160.2023.00068 },
  booktitle={ 2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE) },
  chapter={0}
}

@article{rayyan-352343312,
  title={ A Novel LLM Architecture for Intelligent System Configuration  -  2024 28th International Conference Information Visualisation (IV) },
  year={2024},
  author={D'Urso, S. and Martini, B. and Sciarrone, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714278 },
  abstract={This paper presents a comparative analysis of novel LLM-based architectures designed specifically for system configuration purposes. Generative Artificial Intelligence (Gen AI) has rapidly evolved, offering transformative capabilities in content generation across various domains. Large Language Models (LLMs) stand at the forefront of this evolution, revolutionizing natural language understanding and enabling sophisticated conversational systems. Leveraging the potential of LLMs, our study introduces a novel system architecture centered around an intelligent chatbot tailored to assist learners in complex network configurations. By integrating Generative Pre-trained Transformer-based models with Retrieval Augmented Generation (RAG) and Function Calling features, our architecture aims to provide a co-pilot-like experience, guiding users through understanding requirements and generating configuration scripts. Through a comparative analysis of three LLM architectures, each tailored to handle system network configuration, we evaluate their effectiveness, strengths, and limitations. Our findings offer valuable insights into the potential applications of Generative AI in network operations and highlight avenues for future research and development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IV64223.2024.00063 },
  booktitle={ 2024 28th International Conference Information Visualisation (IV) },
  chapter={0}
}

@article{rayyan-352343313,
  title={ LLM4GV: An LLM-Based Flexible Performance-Aware Framework for GEMM Verilog Generation  -  2025 Design, Automation & Test in Europe Conference (DATE) },
  year={2025},
  author={Zou, D. and Zhang, G. and Sun, K. and Wen, Z. and Wang, M. and Wang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992751 },
  abstract={Advancements in AI have increased the demand for specialized AI accelerators, with design for general matrix multiplication (GEMM) module being crucial but time-consuming. While large language models (LLMs) show promise for automating GEMM design, challenges arise from GEMM's vast design space and performance requirements. Existing LLM-based frameworks for RTL code generation often lack flexibility and performance awareness. To overcome the challenges, we propose LLM4GV, a multi-agent LLM-based framework that integrates hardware optimization techniques (HOTs) and performance modeling, improving correctness and performance of the generated code over prior works.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/DATE64628.2025.10992751 },
  booktitle={ 2025 Design, Automation & Test in Europe Conference (DATE) },
  chapter={0}
}

@article{rayyan-352343314,
  title={ Diverse Stacking Ensemble for Attributing LLM Outputs via Relational Reasoning  -  2025 8th International Conference on Computer Information Science and Application Technology (CISAT) },
  year={2025},
  author={Zhou, Z. and Zhao, C. and Li, X. and Zhang, H. and Chang, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181963 },
  abstract={Attributing the origin of outputs generated by large language models (LLMs) is critical for ensuring transparency and accountability in AI systems. This paper presents LLM-OriginNet, a two-stage ensemble learning framework designed to identify the source model of a given response. In the first stage, multiple fine-tuned classifiers based on diverse LLM architectures are employed to capture model-specific generation patterns. The second stage introduces relational feature engineering, which extracts comparative signals from the outputs of these classifiers. A LightGBM-based meta-classifier then integrates these relational features to produce the final attribution decision. By leveraging architectural diversity and inter-model relational reasoning, LLM-OriginNet provides a scalable and interpretable solution for LLM attribution in multi-model environments. Furthermore, the framework can incorporate differential privacy mechanisms and support federated learning, enabling attribution on decentralized or noisy feature representations while preserving user privacy and data confidentiality.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CISAT66811.2025.11181963 },
  booktitle={ 2025 8th International Conference on Computer Information Science and Application Technology (CISAT) },
  chapter={0}
}

@article{rayyan-352343315,
  title={ Two Sides of the Same Coin: Differing Approaches to Generative AI in Two Computer Science Classrooms  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Mackay, S. and Eiselt, K. and Decker, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893388 },
  abstract={This innovative practice paper explores two differing approaches to the use of artificial intelligence tools in computer science classrooms. Artificial Intelligence (AI), while not a new technology, has seen a rise in popularity over the past two years, with companies such as OpenAI, Google, and Microsoft making readily available generative AI tools for anyone to use. This surge in AI popularity has led to a rise in its use in educational settings, in some cases allowed and in others discouraged or disallowed. A debate has risen among academics, particularly in higher education, about what AI's place in education is, with some educators actively encouraging its use while others view the use of AI as a form of academic dishonesty. Given AI is only advancing and is becoming more prevalent, it will only continue to become a more dominant force throughout education and the world at large. This paper presents two educators' distinct viewpoints and experiences on how AI should be handled in computer science courses (absolutely forbidden vs. decriminalized). The goal of this paper is to present different perspectives as well as concrete experiences we have had with AI in our own classrooms to encourage others to consider their own positions on its use and its implications for their own learning environments. While the debate on the place of AI in education is a long way from being settled, educators need to think about making choices, clearly articulating policies, and evaluating the positives and negatives of positions about AI in their classrooms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893388 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343316,
  title={ LLM Enabled Social Robots – Transforming Aged Care Through AI  -  2025 International Conference on Activity and Behavior Computing (ABC) },
  year={2025},
  author={Tahir, H. and Ansari, S. and Bushra, N. and Khan, A. and Lwin, M. and Alnajjar, F. and Mubin, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118445 },
  abstract={This research work provides personalized a model for elderly care by integrating Large Language Models (LLMs) to the Pepper, a social humanoid robot. The facial and emotional recognition is achieved using the robot’s onboard sensors, including cameras and microphones.Using these, pepper captures real-time facial expressions from elderly individuals, enabling empathetic interactions. The visual data are processed on external hardware, such as the NVIDIA Jetson Nano, where the advanced tasks like fine-tuned facial emotion analysis are performed. A proof of concept system demonstrated Pepper’s ability to infer emotional states and deliver dynamic, tailored responses through efficient processing that combines lightweight on-device tasks with external AI resources. Two curated datasets, FER-2013 (containing facial images labeled with emotions) and FFHQ (featuring high-resolution facial images), enhance the model’s accuracy by enabling it to combine fine-grained visual details, such as facial features and expressions, with a deeper understanding of emotional context and meaning. The results confirm that AI-powered Pepper can effectively deliver empathetic care, marking a significant advancement in human-robot interaction and healthcare technologies, particularly for elderly care.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ABC64332.2025.11118445 },
  booktitle={ 2025 International Conference on Activity and Behavior Computing (ABC) },
  chapter={0}
}

@article{rayyan-352343317,
  title={ Exploring the Patent Landscape of Sintered Metal Technologies: An Analysis Using LLM-Based AI Patent Search  -  2024 IEEE 40th International Electronics Manufacturing Technology (IEMT) },
  year={2024},
  author={Siow, K. S. and Wang, W. and Bahru, R. and Long, X. and Lee, H. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10875250 },
  abstract={This study leveraged a proprietary Large Language Model (LLM) via app.amplified.ai, focusing on sintered metal technology patents for die-bonding uses in electronics packaging. This AI platform analyzed patent complexities, particularly examining 11 pre-selected patents with known activities on uses of silver or copper paste formulations as die-attach materials from companies like Infineon Technologies, Siemens, Nihon Superior Tanaka Kikinzoku, Heraeus, Hitachi and Alphametals. Following similarity assessments with these 11 pre-selected patents, 243 core patents were identified from the app.amplified.ai patent databases (of more than 150 million), retrieved and analyzed, resulting in six key clusters: 1) conductive adhesive bonding 2) metal particle bonding 3) porous metal bonding 4) sintered silver bonding, 5) substrate bonding methods 6) terminal management bonding. These clusters match the dominant Cooperative Patent Cooperation codes as follows: H01L24/83, H01L24/29 and H01L2224/8384; all methods related to connecting semiconductor using layer connector, and mainly with sintering technology. Finally, these clusters helped to outline the interconnections among patents, their legal statuses, and assignees from 1994 to 2024, offering valuable insights for patent analytics regarding significant patents and the main technology players for this sintered bonding},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEMT61324.2024.10875250 },
  booktitle={ 2024 IEEE 40th International Electronics Manufacturing Technology (IEMT) },
  chapter={0}
}

@article{rayyan-352343318,
  title={ Demonstration of LLM-based AI-Agent for Optical Network Management and Automation  -  ECOC 2024; 50th European Conference on Optical Communication },
  year={2024},
  author={Sun, C. and Ayassi, R. and Yang, X. and Charlet, G. and Stavrou, P. A. and Pointurier, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10926432 },
  abstract={We deployed an LLM-based AI-agent on a commercial product testbed for optical network management and automation. This demonstration showcases how the AI-agent interacts with controller APIs to implement service establishment, QoT estimation, and power optimization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ ECOC 2024; 50th European Conference on Optical Communication },
  chapter={0}
}

@article{rayyan-352343319,
  title={ An Agentic AI-based Multi-Agent Framework for Recommender Systems  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Portugal, I. D. S. and Alencar, P. and Cowan, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825765 },
  abstract={Agentic AI describes the use of LLMs in novel AI agents that can answer questions or collaborate to achieve goals. These LLM agents can be used to build a novel generation of recommender systems. However, little is known about the LLM agents or their relationships needed to provide recommendations. Once identified, a framework can be constructed. Moreover, evaluating this framework is still not well understood. In this paper, we propose an agentic AI-based, multi-agent framework for recommender systems. We first identify LLM agents proposed in the literature, followed by the identification of their relationships and we propose a framework to represent them. Next, we evaluate this framework with respect to the LLM agents and functionalities of a recommender system based on published studies. This study is a stepping stone in a novel paradigm shift in the construction of recommender systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825765 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343320,
  title={ Identification and Optimization of Redundant Code Using Large Language Models  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Cynthia, S. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029992 },
  abstract={Redundant code is a persistent challenge in software development that makes systems harder to maintain, scale, and update. It adds unnecessary complexity, hinders bug fixes, and increases technical debt. Despite their impact, removing redundant code manually is risky and error-prone, often introducing new bugs or missing dependencies. While studies highlight the prevalence and negative impact of redundant code, little focus has been given to Artificial Intelligence (AI) system codebases and the common patterns that cause redundancy. Additionally, the reasons behind developers unintentionally introducing redundant code remain largely unexplored. This research addresses these gaps by leveraging large language models (LLMs) to automatically detect and optimize redundant code in AI projects. Our research aims to identify recurring patterns of redundancy and analyze their underlying causes, such as outdated practices or insufficient awareness of best coding principles. Additionally, we plan to propose an LLM agent that will facilitate the detection and refactoring of redundancies on a large scale while preserving original functionality. This work advances the application of AI in identifying and optimizing redundant code, ultimately helping developers maintain cleaner, more readable, and scalable codebases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00042 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343321,
  title={ Capturing the Process of Students' AI Interactions When Creating and Learning Complex Network Structures  -  IEEE Transactions on Learning Technologies },
  author={López-Pernas, S. and Misiejuk, K. and Kaliisa, R. and Saqr, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10994563 },
  abstract={Despite the growing use of large language models (LLMs) in educational contexts, there is no evidence on how these can be operationalized by students to generate custom datasets suitable for teaching and learning. Moreover, in the context of network science, little is known about whether LLMs can replicate real-life network properties. This study addresses these gaps by evaluating the use of generative artificial intelligence (AI), specifically LLMs, to create synthetic network datasets for educational use. The analyzed data include students’ AI-generated network datasets, their interactions with the LLMs, and their perceptions and evaluations of the task's value. The results indicate that the LLM-generated networks had properties closer to real-life networks, such as higher transitivity, network density, and smaller mean distances compared to randomly generated networks. Thus, our findings show that students can use LLMs to produce synthetic networks with realistic structures while tailoring to the individual preferences of each student. The analysis of students’ interactions (prompts) with the LLMs revealed a predominant use of direct instructions and output specifications, with less emphasis on providing contextual details or iterative refinement of the LLM's responses, which highlights the need for AI literacy training to optimize students’ use of generative AI. Students’ perceptions of the use of AI were overall positive; they found using LLMs time saving and beneficial, although opinions on output relevance and quality varied, especially for assignments requiring replication of specific networks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TLT.2025.3568599 },
  booktitle={ IEEE Transactions on Learning Technologies },
  chapter={0}
}

@article{rayyan-352343322,
  title={ Enhancing Software Design and Developer Experience Via LLMs  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Sun, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765018 },
  abstract={This research explores the transformative potential of generative AI in software development. Generative AI is revolutionizing the field by offering capabilities to automatically generate, refactor, and test code. Through the use of action research, new methods and tools based on generative AI models are studied and developed. The initial focus is on the models’ ability to comprehend high-level design concepts. Subsequently, the research moves into the augmented generation of software artifacts. Finally, organization-specific or task-specific methods are introduced to enhance software developers’ productivity and experience.CCS CONCEPTS• Software and its engineering → Software development process management; Software development methods;},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352343323,
  title={ Detection of AI-Generated Text Using Large Language Model  -  2024 International Conference on Emerging Systems and Intelligent Computing (ESIC) },
  year={2024},
  author={Prajapati, M. and Baliarsingh, S. K. and Dora, C. and Bhoi, A. and Hota, J. and Mohanty, J. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10481602 },
  abstract={A large language model (LLM) is a trained deep-learning model that understands and generates text in a human-like fashion. Due to the significant advancements of LLM, it becomes a challenging task to distinguish human-written content from artificial intelligence (AI) generated content. In this work, we leverage the machine learning (ML) models to reliably identify whether an essay is authored by a human being or by an LLM. Concerns about LLMs replacing human tasks, especially in education persist. However, optimism remains for their potential as tools to enhance writing skills. An academic worry is LLMs facilitating plagiarism due to their extensive training in text and code datasets. Using diverse texts and unknown generative models, we replicate typical scenarios to encourage feature learning across models. In a study involving human subjects, we demonstrate that the annotation scheme offered by generative textual likelihood ratio (GLTR) enhances the human detection rate of fake text from 74% to 99% without requiring any previous training. GLTR is open source and publicly deployed, already finding widespread use in detecting generated outputs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ESIC60604.2024.10481602 },
  booktitle={ 2024 International Conference on Emerging Systems and Intelligent Computing (ESIC) },
  chapter={0}
}

@article{rayyan-352343324,
  title={ LLM-based Methodology for Expanding 3D Metadata in Point Cloud  -  2025 27th International Conference on Advanced Communications Technology (ICACT) },
  year={2025},
  author={Kim, G. -W. and Kim, J. -C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936764 },
  abstract={This paper proposes a method for expanding the metadata of three-dimensional point cloud data using Large Language Models (LLMs). Currently, point cloud data plays a crucial role in various fields such as autonomous driving and medical image reconstruction, necessitating the expansion of metadata for efficient processing. Traditionally, metadata construction has relied on manual input, which is prone to errors. In this study, we propose a method that utilizes LLMs, particularly the Llama 3.1 model, to extract the center points of each class in the point cloud data and expand the metadata by adding these center points to the annotation files. By using center points, computational costs are reduced, and the performance of segmentation and detection models based on this data is improved.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/ICACT63878.2025.10936764 },
  booktitle={ 2025 27th International Conference on Advanced Communications Technology (ICACT) },
  chapter={0}
}

@article{rayyan-352343325,
  title={ DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Zhao, L. and Yang, Y. and Zhang, K. and Shao, W. and Zhang, Y. and Qiao, Y. and Luo, P. and Ji, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656490 },
  abstract={Text-to-image (T2I) generative models have attracted significant attention and found extensive applications within and beyond academic research. For example, the Civitai community, a platform for T2I innovation, currently hosts an impressive array of 74,492 distinct models. However, this diversity presents a formidable challenge in selecting the most appropriate model and parameters, a process that typically requires numerous trials. Drawing inspiration from the tool usage research of large language models (LLMs), we introduce DiffAgent, an LLM agent designed to screen the accurate selection in seconds via API calls. DiffAgent leverages a novel two-stage training framework, SFTA, enabling it to accurately align T2I API responses with user input in accordance with human preferences. To train and evaluate DiffAgent's capabilities, we present DABench, a comprehensive dataset encompassing an extensive range of T2I APIs from the community. Our evaluations reveal that DiffAgent not only excels in identifying the appropriate T2I API but also underscores the effectiveness of the SFTA training framework. Codes are available at https://github.com/OpenGVLab/DiffAgent.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.00611 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343327,
  title={ Evaluating the Explainability of Large Language Models for Ethical Decision Making  -  2025 IEEE International Conference on Consumer Electronics (ICCE) },
  year={2025},
  author={Miguel, G. S. San and Griffith, H. and Silva, J. and Rathore, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10929891 },
  abstract={The innate ethical decision-making capabilities of large language models (LLMs) has been previously assessed in the literature using a classification-based workflow. An analysis performed for morally unambiguous scenarios indicated strong alignment between LLM and human ethical judgement. This paper proposes an enhanced explainability-based workflow for exploring the ethical decision-making capabilities of LLMs. In addition to producing binary labels indicating moral acceptability, models are prompted to produce justifications for their decisions. We propose and verify an approach for assessing similarity in the produced justifications across prompting style using latent semantic analysis. We demonstrate that justifications produced for identical moral scenarios are considerably more similar than those produced for arbitrary scenario combinations. We also show that variability in the similarity of justifications produced across prompting styles is negligible as expected for the morally unambiguous scenarios considered.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCE63647.2025.10929891 },
  booktitle={ 2025 IEEE International Conference on Consumer Electronics (ICCE) },
  chapter={0}
}

@article{rayyan-352343328,
  title={ Evaluating LLM-Generated Topics from Survey Responses: Identifying Challenges in Recruiting Participants through Crowdsourcing  -  2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) },
  year={2024},
  author={Tamime, R. A. and Salminen, J. and Jung, S. -G. and Jansen, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714580 },
  abstract={The evolution of generative artificial intelligence (AI) technologies, particularly large language models (LLMs), has lead to consequences for the field of Human-Computer Interaction (HCI) in areas such as personalization, predictive analytics, automation, and data analysis. This research aims to evaluate LLM-generated topics derived from survey responses in comparison with topics suggested by humans, particularly participants recruited through a crowdsourcing experiment. We present an evaluation results to compare LLM-generated topics with human-generated topics in terms of Quality, Usefulness, Accuracy, Interestingness, and Completeness. This involves three stages: (1) Design and Generate Topics with an LLM (OpenAI’s GPT-4); (2) Crowdsourcing Human-Generated Topics; and (3) Evaluation of Human-Generated Topics and LLM-Generated Topics. However, a feasibility study with 33 crowdworkers indicated challenges in using participants for LLM evaluation, particularly in inviting humans participants to suggest topics based on open-ended survey answers. We highlight several challenges in recruiting crowdsourcing participants for generating topics from survey responses. We recommend using well-trained human experts rather than crowdsourcing to generate human baselines for LLM evaluation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VL/HCC60511.2024.00064 },
  booktitle={ 2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) },
  chapter={0}
}

@article{rayyan-352343329,
  title={ An Adaptive End-to-End IoT Security Framework Using Explainable AI and LLMs  -  2024 IEEE 10th World Forum on Internet of Things (WF-IoT) },
  year={2024},
  author={Baral, S. and Saha, S. and Haque, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10811456 },
  abstract={The exponential growth of the Internet of Things (IoT) has significantly increased the complexity and volume of cybersecurity threats, necessitating the development of advanced, scalable, and interpretable security frameworks. This paper presents an innovative, comprehensive framework for real-time IoT attack detection and response that leverages Machine Learning (ML), Explainable AI (XAI), and Large Language Models (LLM). By integrating XAI techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) with a model-independent architecture, we ensure our framework’s adaptability across various ML algorithms. Additionally, the incorporation of LLMs enhances the interpretability and accessibility of detection decisions, providing system administrators with actionable, human-understandable explanations of detected threats. Our end-to-end framework not only facilitates a seamless transition from model development to deployment but also represents a real-world application capability that is often lacking in existing research. Based on our experiments with the CIC-IOT-2023 dataset [1], Gemini and OPENAI LLMS demonstrate unique strengths in attack mitigation: Gemini offers precise, focused strategies, while OPENAI provides extensive, in-depth security measures. Incorporating SHAP and LIME algorithms within XAI provides comprehensive insights into attack detection, emphasizing opportunities for model improvement through detailed feature analysis, fine-tuning, and the adaptation of misclassifications to enhance accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WF-IoT62078.2024.10811456 },
  booktitle={ 2024 IEEE 10th World Forum on Internet of Things (WF-IoT) },
  chapter={0}
}

@article{rayyan-352343330,
  title={ Analysis of Student-LLM Interaction in a Software Engineering Project  -  2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code) },
  year={2025},
  author={Naman, A. and Shariffdeen, R. and Wang, G. and Rasnayaka, S. and Iyer, G. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028221 },
  abstract={Large Language Models (LLMs) are becoming increasingly competent across various domains, educators are showing a growing interest in integrating these LLMs into the learning process. Especially in software engineering, LLMs have demonstrated qualitatively better capabilities in code summarization, code generation, and debugging. Despite various research on LLMs for software engineering tasks in practice, limited research captures the benefits of LLMs for pedagogical advancements and their impact on the student learning process. To this extent, we analyze 126 undergraduate students’ interaction with an AI assistant during a 13-week semester to understand the benefits of AI for software engineering learning. We analyze the conversations, code generated, code utilized, and the human intervention levels to integrate the code into the code base.Our findings suggest that students prefer ChatGPT over CoPilot. Our analysis also finds that ChatGPT generates responses with lower computational complexity compared to CoPilot. Furthermore, conversational-based interaction helps improve the quality of the code generated compared to auto-generated code. Early adoption of LLMs in software engineering is crucial to remain competitive in the rapidly developing landscape. Hence, the next generation of software engineers must acquire the necessary skills to interact with AI to improve productivity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LLM4Code66737.2025.00019 },
  booktitle={ 2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code) },
  chapter={0}
}

@article{rayyan-352343331,
  title={ SLDB: An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design  -  2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  year={2025},
  author={Alvanaki, E. L. and Lee, K. and Carloni, L. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105967 },
  abstract={Over the last few years, Large Language Models (LLMs) have emerged as a valuable tool for Electronic Design Automation (EDA). State-of-the-art research in LLM-aided design has demonstrated the ability of LLMs to generate syntactically correct RTL code, showcasing encouraging prospects for integrating AI into the hardware design process. A key enabler of these advancements is the availability of high-quality benchmarks to evaluate new approaches. However, existing datasets and benchmarks fall short of system-level design, as they focus primarily on component-level information and low-complexity designs. To address this gap, we introduce the System-Level Design Benchmark (SLDB), a dataset tailored for evaluating LLMs in system-level integration and configuration tasks. SLDB includes a curated benchmark suite of 10 baseline SoC designs, whose components can be combined into an exponential number of distinct tile-based SoCs through a synthetic library. The dataset provides full SoC configurations, accelerator integration code, communication parameters, and accelerator-aware system configurations, along with testing-application code, compatible with the ESP platform [1].},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLAD65226.2025.00016 },
  booktitle={ 2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  chapter={0}
}

@article{rayyan-352343332,
  title={ FhGenie: A Custom, Confidentiality-Preserving Chat AI for Corporate and Scientific Use  -  2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) },
  year={2024},
  author={Weber, I. and Linka, H. and Mertens, D. and Muryshkin, T. and Opgenoorth, H. and Langer, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628294 },
  abstract={Since OpenAI's release of ChatGPT, generative AI has received significant attention across various domains. These AI-based chat systems have the potential to enhance the productivity of knowledge workers in diverse tasks. However, the use of free public services poses a risk of data leakage, as service providers may exploit user input for additional training and optimization without clear boundaries. Even subscription-based alternatives sometimes lack transparency in handling user data. To address these concerns and enable Fraunhofer staff to leverage this technology while ensuring confidentiality, we have designed and developed a customized chat AI called FhGenie (genie being a reference to a helpful spirit). Within few days of its release, thousands of Fraunhofer employees started using this service. As pioneers in implementing such a system, many other organizations have followed suit. Our solution builds upon commercial large language models (LLMs), which we have carefully integrated into our system to meet our specific requirements and compliance constraints, including confidentiality and GDPR. In this paper, we share detailed insights into the architectural considerations, design, implementation, and subsequent updates of FhGenie. Additionally, we discuss challenges, observations, and the core lessons learned from its productive usage.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C63560.2024.00011 },
  booktitle={ 2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343333,
  title={ Splitwise: Efficient Generative LLM Inference Using Phase Splitting  -  IEEE Micro },
  author={Choukse, E. and Patel, P. and Zhang, C. and Shah, A. and Goiri, Í. and Maleki, S. and Fonseca, R. and Bianchini, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024200 },
  abstract={Generative large language model (LLM) applications are rapidly growing, leading to widespread deployment of expensive, power-hungry GPUs. Growing power demands of artificial intelligence (AI) in the cloud industry has become a global problem.5 Our analysis shows that LLM inference involves two distinct phases: a compute-intensive prefill phase and a memory-intensive decode phase, each with different resource needs. Running them together introduces inefficient scheduling. Furthermore, unlike the prefill phase, the decode phase can run on lower-cost and lower-power hardware. Building on these insights, we propose Splitwise, a scheduling technique that splits prefill and decode phases across different machines to achieve better throughput. Additionally, Splitwise allows phase-specific hardware optimization. By efficiently transferring request state between machines, Splitwise achieves up to 2.35× more throughput within the same power and cost budgets, or 1.4× higher throughput at 20% lower cost and same power.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MM.2025.3575361 },
  booktitle={ IEEE Micro },
  chapter={0}
}

@article{rayyan-352343334,
  title={ Architecture Exploration and Reflection Meet LLM-based Agents  -  2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  year={2025},
  author={Diaz-Pace, J. A. and Tommasel, A. and Capilla, R. and Ramírez, Y. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014919 },
  abstract={The exploration of architecture alternatives is an essential part of the architecture design process, in which designers search and assess solutions for their requirements. Although automated tools and techniques have been proposed for this process, they still face adoption challenges. Nowadays, the emergence of generative AI techniques creates an opportunity for leveraging natural language representations in architecture design, particularly through LLM-based agents. To date, these agents have been mostly focused on coding-related tasks or requirements analysis. In this work, we investigate an approach for defining design agents, which can autonomously search for architectural patterns and tactics for a particular system and requirements using a textual format. In addition to incorporating architectural knowledge, these agents can reflect on the pros and cons of the proposed decisions, enabling a feedback loop towards improving the decisions' quality. We present a proof-of-concept called ReArch that adapts elements from the ReAct and LATS agent frameworks, and discuss initial results of applying our LLM-based agents to a case study considering different patterns.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C65153.2025.00015 },
  booktitle={ 2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343335,
  title={ Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Ghimire, A. and Pather, J. and Edwards, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892891 },
  abstract={This research full paper delves into university in-structors' experiences and attitudes toward AI language models, filling a gap in the literature by analyzing educators' perspectives on AI's role in the classroom and its potential impacts on teaching and learning. The rapid advancement of artificial intelligence (AI) and the expanding integration of large language models (LLMs) have ignited a debate about their application in education. The objective of this research is to investigate the level of awareness, overall sentiment towards adoption, and the factors influencing these attitudes for LLMs and generative AI-based tools in higher education. Data was collected through a survey using a Likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. The collected data was processed using statistical and thematic analysis techniques. Our findings reveal that educators are increasingly aware of and generally positive towards these tools. We find no correlation between teaching style and attitude toward generative AI. Finally, while CS educators show far more confidence in their technical understanding of generative AI tools and more positivity towards them than educators in other fields, they show no more confidence in their ability to detect AI-generated work.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10892891 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343336,
  title={ LLMind: Orchestrating AI and IoT with LLM for Complex Task Execution  -  IEEE Communications Magazine },
  author={Cui, H. and Du, Y. and Yang, Q. and Shao, Y. and Liew, S. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10697418 },
  abstract={Task-oriented communications are an important element in future intelligent IoT systems. Existing IoT systems, however, are limited in their capacity to handle complex tasks, particularly in their interactions with humans to accomplish these tasks. In this article, we present LLMind, a large language model-based (LLM-based), task-oriented AI agent framework that enables effective collaboration among IoT devices, with humans communicating high-level verbal instructions, to perform complex tasks. Inspired by the functional specialization theory of the brain, our framework integrates an LLM with domain-specific AI modules, enhancing its capabilities. Complex tasks, which may involve collaborations of multiple domain-specific AI modules and IoT devices, are executed through a control script generated by the LLM using a Language-Code transformation approach, which first converts language descriptions to an intermediate finite-state machine (FSM) before final precise transformation to code. Furthermore, the framework incorporates a novel experience accumulation mechanism to enhance response speed and effectiveness, allowing the framework to evolve and become progressively sophisticated through continuing user and machine interactions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MCOM.002.2400106 },
  booktitle={ IEEE Communications Magazine },
  chapter={0}
}

@article{rayyan-352343337,
  title={ Feedback Analysis and Management of International Travelers Using LLM Powered AI Text Analysis: A Case Study in Japanese  -  2025 International Conference on IOT, Data Science and Advanced Computing (IDSAC) },
  year={2025},
  author={Ma, Z. and Ren, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11170279 },
  abstract={With the globalization of tourism and the rise of multilingual feedback, extracting actionable insights from diverse, unstructured traveler reviews has become a key challenge for public governance. This study aims to address the limitations of traditional feedback systems that rely on fragmented ratings and unstructured text, which often hinder real-time, culturally aware decision-making. We introduce a domain-adapted BERT (Bidirectional Encoder Representation from Transformers)-based AI (Artificial Intelligence) system that analyzes Japanese tourist reviews—selected for their linguistic ambiguity and cultural richness—via a multi-perspective prompt engineering framework. Our system integrates sentiment analysis, stakeholder-specific keyword extraction, and misinterpretation detection into a closed-loop feedback workflow. Compared to conventional methods, our approach offers higher accuracy, improved contextual understanding, and scalable management applications. Experimental results show that with 1,000 reviews, sentiment classification reaches 89.8 percent accuracy, stakeholder routing achieves 83.2 percent, and cultural misinterpretation detection yields 77.5 percent precision. These findings suggest that LLM (Large Language Model)-powered systems can significantly enhance tourism governance and service quality, especially when sufficient data is available. This work contributes a practical, scalable solution to AI-driven multilingual feedback analysis in public administration.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDSAC65763.2025.11170279 },
  booktitle={ 2025 International Conference on IOT, Data Science and Advanced Computing (IDSAC) },
  chapter={0}
}

@article{rayyan-352343338,
  title={ JARVIS: A Next-Gen Conversational AI Platform  -  2024 8th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC) },
  year={2024},
  author={Kakarla, P. and Sruthi, S. J. and Zahid, P. and Neha, V. and Charan, S. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10714857 },
  abstract={This research presents JARVIS, an innovative desktop assistant tool designed to revolutionize user interaction within the realm of robotics. Leveraging the powerful capabilities of Python, the Mistral AI language model, and real-time data integration, JARVIS offers a streamlined and user-friendly interface. The proposed system prioritizes delivering an exceptional user experience by harnessing Mistral AI's ability to comprehend and respond to natural language queries. The language model acts as a conversational interface, facilitating seamless communication between users and the robotics system. By integrating real-time data from Mistral, JARVIS ensures adaptability and responsiveness in dynamic scenarios. This enables the system to access and utilize the most current information, fostering context-aware and informed interactions. JARVIS serves as a pivotal link between users and robotics, streamlining communication and control. This research signifies a significant advancement in user-centric interfaces and explores the potential synergy between cutting-edge language models and real-time data for enhanced robotics applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/I-SMAC61858.2024.10714857 },
  booktitle={ 2024 8th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC) },
  chapter={0}
}

@article{rayyan-352343339,
  title={ Integration of LLM and Human–AI Coordination for Power Dispatching With Connected Electric Vehicles Under SAGVNs  -  IEEE Transactions on Vehicular Technology },
  author={Chen, X. and Lu, X. and Li, Q. and Li, D. and Zhu, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720517 },
  abstract={Advanced artificial intelligence (AI) solutions deployed in the environment of space-air-ground integrated vehicular networks (SAGVNs) are instrumental in achieving efficient coordination between connected electric vehicles (EVs) and distributed networks. This study addresses this challenge by leveraging a Large Language Model (LLM) based hybrid dispatching framework for formulating dispatching strategies, where the need for commonsense understanding by EV drivers is paramount. This paper proposes a framework LLM-D3PG, LLM-guided dual Deep Deterministic Policy Gradient, which empowers EV drivers to articulate their expectations for AI-generated dispatching strategies using natural language instructions. These instructions serve as guidance for the generation of dispatching strategies within complex distributed network scenarios. According to this strategy, the proposed framework seamlessly integrates the decision-making capabilities of LLM with multiple D3PG models to generate a large number of candidate dispatching strategies and then uses the whale optimization algorithm to optimize these strategies to achieve better dispatching results. Comprehensive experimental results demonstrate the effectiveness of the proposed framework and show outperformance in comparison to some existing methods for power dispatching tasks with the random connection of EVs in SAGVNs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TVT.2024.3434969 },
  booktitle={ IEEE Transactions on Vehicular Technology },
  chapter={0}
}

@article{rayyan-352343340,
  title={ Extended Abstract: Leveraging AI to Bridge the Gap Between Aspiring Engineers and Effective Communicators  -  2024 IEEE International Professional Communication Conference (ProComm) },
  year={2024},
  author={Narendranath, A. D. and Tewari, R. and Johnson, J. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10609590 },
  abstract={This extended abstract proposes using the capabilities of open-source large language models (LLMs) to assess rhetorical moves in the executive summaries delivered by students enrolled in a Mechanical Engineering Capstone Senior Design course at a North American public STEM university. Our brief discussion surrounds the national and institutional contextualization of a capstone course, the current state of affairs and drawbacks of the executive summary assessment method, using an LLM to overcome these drawbacks, its potential benefits, and future work.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ProComm61427.2024.00019 },
  booktitle={ 2024 IEEE International Professional Communication Conference (ProComm) },
  chapter={0}
}

@article{rayyan-352343341,
  title={ A Client-Server Based Educational Chatbot for Academic Institutions  -  2024 4th International Conference on Intelligent Technologies (CONIT) },
  year={2024},
  author={Richard, R. P. and Veemaraj, E. and Thomas, J. M. and Mathew, J. and Stephen, C. and Koshy, R. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10627567 },
  abstract={The use of Generative AI applications in academia, such as ChatGPT, Bard and Perplexity among others is growing at a rapid pace. With its rise, certain ramifications are being felt in regards to the quality and correctness of knowledge and output of these apps. This is detrimental to the process of learning and understanding subject matter in relevant context. In order to stop this issue in its tracks, a solution must be identified, built, tested and deployed so that students will get reliable outputs from trusted sources. This research analyses and describes a sample architecture as well as implementation for such a solution. It incorporates the latest in AI research and development, such as the Large Language Model Mixture of Experts (MoE) architecture as well as a Retrieval Augmented Generation (RAG) with a vector store to use trusted documents such as presentation files, PDF handouts and more from instructors. This is used to add context to the request to the Large Language Model and enrich the understanding as well as response of the model. Apart from this, the application is packaged into a server that can be run on the intranet, as well as deployed for public access. A frontend client page is served to the user, and communicates with the server for all its functioning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONIT61985.2024.10627567 },
  booktitle={ 2024 4th International Conference on Intelligent Technologies (CONIT) },
  chapter={0}
}

@article{rayyan-352343342,
  title={ RAGNAR: Retrieval-Augmented Generation using Networked and Advanced Relational Data  -  2024 8th International Symposium on Innovative Approaches in Smart Technologies (ISAS) },
  year={2024},
  author={Mestre, A. and Marques, R. and Fernandes, A. and Silva, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845598 },
  abstract={The technological evolution carried out in recent years has enabled significant developments in various areas of Artificial Intelligence (AI), such as Generative AI. Large Language Models (LLMs) are becoming increasingly complex, allowing for better results and enhancing their real-world applicability. However, these models still face issues such as hallucination or outdated information. This last one occurs due to the temporal gap between the training process and the model’s use. A Retrieval-Augmented Generation (RAG) architecture can address these issues since the information source used is not involved in the training phase, which also facilitates the reuse of models for different applications. One of the challenges of RAG is its applicability when the data source is a relational database, becoming even more challenging as the database size and complexity increase. This article proposes a potential architecture and approach for solving this problem and implementing a RAG architecture using a relational database as the data source.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISAS64331.2024.10845598 },
  booktitle={ 2024 8th International Symposium on Innovative Approaches in Smart Technologies (ISAS) },
  chapter={0}
}

@article{rayyan-352343343,
  title={ Grid Search and LLM Assisted Hybrid Approach for Hyperparameter Optimization  -  2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI) },
  year={2025},
  author={Kalele, N. and Kalyani, V. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10985615 },
  abstract={AI has become one of the technological stepping stones in most industry verticals including BFSI. The use of AI for tasks like credit risk assessment, fraud detection, and customized client experiences has been become a norm in BFSI space. However, developing AI/ML based decision systems for such applications involves spectrum of tasks such as data gathering and analysis, feature selection, tuning models via hyperparameter optimization and finally testing and deployment. In this paper, we explore hyperparameter optimization with feature analysis for credit risk assessment application in the BFSI industry. Typically, GridSearchCV and Bayesian Optimization are widely acceptable and reliable methods for hyperparameter optimization. Recently, it was proposed that LLMs can be used for optimization problems. Here, we look at a hybrid approach with the structured search capabilities of GridSearchCV in tandem with the optimization strength of LLMs. In the proposed approach, we perform the coarse-grain grid search and use the collected data as input for the LLM. Based on these data, we further prompt LLM to analyze and draw and propose a finer search space. Sampling from this finer search space results in more efficient and accurate optimization. This shows the effectiveness of LLMs to refine the search. Further, we explore feature analysis methods like SHAP values, correlation, significance distribution, etc. and identify important features that are helpful in better modeling and decision explanations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IATMSI64286.2025.10985615 },
  booktitle={ 2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI) },
  chapter={0}
}

@article{rayyan-352343344,
  title={ FlashDecoding++Next: High Throughput LLM Inference With Latency and Memory Optimization  -  IEEE Transactions on Computers },
  author={Dai, G. and Hong, K. and Mao, Q. and Li, X. and Xu, J. and Huang, H. and Xia, H. and Ning, X. and Yan, S. and Liang, Y. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11062854 },
  abstract={As the Large Language Model (LLM) becomes increasingly important in various domains, the performance of LLM inference is crucial to massive LLM applications. However, centering around the computational efficiency and the memory utilization, the following challenges remain unsolved in achieving high-throughput LLM inference: (1) Synchronous partial softmax update. The softmax operation requires a synchronous update operation among each partial softmax result, leading to $\sim$∼20% overheads for the attention computation in LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices performing GEMM in LLM inference tends to be flat, leading to under-utilized computation and 50% performance loss after padding zeros in previous designs (e.g., cuBLAS, CUTLASS, etc.). (3) Memory redundancy caused by activations. Dynamic allocation of activations during inference leads to redundant storage of useless variables, bringing 22% more memory consumption. We present FlashDecoding++Next, a high-throughput inference engine supporting mainstream LLMs and hardware backends. To tackle the above challenges, FlashDecoding++Next creatively proposes: (1) Asynchronous softmax with unified maximum. FlashDecoding++Next introduces a unified maximum technique for different partial softmax computations to avoid synchronization. Based on this, a fine-grained pipelining is proposed, leading to 1.18$\boldsymbol{\times}$× and 1.14$\boldsymbol{\times}$× for the prefill and decode phases in LLM inference, respectively. (2) Flat GEMM optimization with double buffering. FlashDecoding++Next points out that flat GEMMs with different shapes face varied bottlenecks. Then, techniques like double buffering are introduced, resulting in up to 52% speedup for the flat GEMM operation. (3) Buffer reusing and unified memory management. FlashDecoding++Next reuses the pre-allocated activation buffers throughout the inference process to remove redundancy. Based on that, we unify the management of different types of storage to further exploit the reusing opportunity. The memory optimization enables up to 1.57$\boldsymbol{\times}$× longer sequence to be processed. FlashDecoding++Next demonstrates remarkable throughput improvement, delivering up to 68.88$\boldsymbol{\times}$× higher throughput compared to the HuggingFace [1] implementation. On average, FlashDecoding++Next achieves 1.25$\boldsymbol{\times}$× and 1.46$\boldsymbol{\times}$× higher throughput compared to vLLM [2] and TensorRT-LLM [3] on mainstream LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TC.2025.3585339 },
  booktitle={ IEEE Transactions on Computers },
  chapter={0}
}

@article{rayyan-352343345,
  title={ PENTEST-AI, an LLM-Powered Multi-Agents Framework for Penetration Testing Automation Leveraging Mitre Attack  -  2024 IEEE International Conference on Cyber Security and Resilience (CSR) },
  year={2024},
  author={Bianou, S. G. and Batogna, R. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679480 },
  abstract={In the digital transformation era, the surge of better development technologies and citizen developers disrupted the space of innovation by increasing the number and complexity of applications used in production. This context prompts advanced cybersecurity measures and more frequent and thorough penetration testing to protect an organization's security posture. The scarcity of skilled expertise in cybersecurity today makes it challenging to cope with the evolving challenge and the growing demand. This paper introduces PENTESTAI, a novel framework for penetration testing automation using Large Language Model (LLM)-powered agents leveraging the MITRE ATTACK knowledge base. The paper provides an overview of the current state of research on cybersecurity and LLM-powered agents, followed by a detailed description of PENTESTAI building blocks. A proof-of-concept implementation is discussed to validate the framework's core constructs. The paper concludes with suggestions for future research directions to achieve the highest level of penetration testing automation with average skilled human-agent collaboration and to create citizen penetration testers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSR61664.2024.10679480 },
  booktitle={ 2024 IEEE International Conference on Cyber Security and Resilience (CSR) },
  chapter={0}
}

@article{rayyan-352343346,
  title={ Trust, Support, and Adoption Intentions Towards Generative AI are Context Dependent  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Liew, K. and Wu, X. and Zhang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050616 },
  abstract={With the prevalence of generational artificial intelligence (AI) in everyday life, there has been a recent increase in research on individuals' perceptions and attitudes towards generational AI. However, with the breadth of use cases and applications made available with the advancements in large language models (LLMs), there are increasing signs that attitudes towards LLM-based generative AI may be context or use-case dependent. We examine the contextualised trust of individuals in AI, the support for using AI, and AI adoption intentions in a survey experiment ($\mathrm{N}=306$) across three contexts (reasons): technical, mental health, and creative assistance. Participants read ostensible news articles about AI use in one of these three contexts, and completed a survey on their resultant and previous attitudes. The results show that trust and adoption were significantly higher for technical assistance, and lower for creative assistance and mental health assistance. However, support for using AI for mental health assistance was significantly higher than creative assistance, and comparable to technical assistance. Contextualised trust and support also significantly predicted AI adoption intentions, above and beyond trust scores towards AI in general. Our study suggests that contextualised attitudes towards specific AI products appear to be sufficiently differentiated from (general) AI attitudes, and instances where AI is used for technical reasons, as opposed to creative or mental health reasons, garners more favourable attitudes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00051 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343347,
  title={ Mainstream AI Technology Analysis for Vertical Domain Digital Consultants  -  2025 37th Chinese Control and Decision Conference (CCDC) },
  year={2025},
  author={Wang, J. and Wang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11090774 },
  abstract={In the process of digital transformation, enterprises and institutions require intelligent resources that can be flexibly adjusted in accordance with business development. AI Agents are well-suited to meet the diverse needs of current and future businesses. With the assistance of AI Agents, enterprises can eliminate repetitive task execution, reduce human error, alleviate process bottlenecks, and prevent personnel overload. This paper, based on the author's ongoing research projects and a substantial body of relevant information, analyzes mainstream artificial intelligence technologies required for building digital consultants in the vertical field of the industry. The content encompasses Knowledge Graph (KG), Large Language Model (LLM), Retrieval-Augmented Generation (RAG), classification and characteristics of AI Agents, and selection principles for constructing digital consultants in the industry vertical field. It is anticipated that this paper will contribute to time and cost savings for similar vertical AI applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCDC65474.2025.11090774 },
  booktitle={ 2025 37th Chinese Control and Decision Conference (CCDC) },
  chapter={0}
}

@article{rayyan-352343348,
  title={ Generative AI Agents With Large Language Model for Satellite Networks via a Mixture of Experts Transmission  -  IEEE Journal on Selected Areas in Communications },
  author={Zhang, R. and Du, H. and Liu, Y. and Niyato, D. and Kang, J. and Xiong, Z. and Jamalipour, A. and Kim, D. In},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679152 },
  abstract={In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregate them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JSAC.2024.3459037 },
  booktitle={ IEEE Journal on Selected Areas in Communications },
  chapter={0}
}

@article{rayyan-352343349,
  title={ 2 Automatic Authorities: Power and AI  -  Collaborative Intelligence: How Humans and AI Are Transforming Our World },
  year={2008},
  author={Arellano, K. C.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10745010.pdf&bkn=10735166&pdfType=chapter },
  abstract={As rapid advances in artificial intelligence and the rise of some of history's most potent corporations meet the diminished neoliberal state, people are increasingly subject to power exercised by means of automated systems. Machine learning (ML), big data, and related computational technologies now underpin vital government services from criminal justice to tax auditing, public health to social services, immigration to defense (Citron 2008; Calo and Citron 2020; Engstrom et al. 2020). Google and Amazon connect consumers and producers in new algorithmic markets (Nadler and Cicilline 2020). Google's search algorithm—and possibly, in the near future, OpenAI's GPT-4 or another large language model (LLM)—determines, for many, how they find out about everything from how to vote to where to get vaccinated. Meta, X (formerly known as Twitter), TikTok, Google, and others algorithmically decide whose speech is amplified, reduced, or restricted (Vaidhyanathan 2011; Pasquale 2015; Gillespie 2018; Suzor 2019). And a new wave of products based on rapid advances in LLMs have the potential to transform our economic and political lives further.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Collaborative Intelligence: How Humans and AI Are Transforming Our World },
  chapter={0}
}

@article{rayyan-352343350,
  title={ Generative AI on the Edge: Architecture and Performance Evaluation  -  ICC 2025 - IEEE International Conference on Communications },
  year={2025},
  author={Nezami, Z. and Hafeez, M. and Djemame, K. and Zaidi, S. A. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11161569 },
  abstract={6G's AI native vision of embedding advance intelligence in the network while bringing it closer to the user requires a systematic evaluation of Generative AI (GenAI) models on edge devices. Rapidly emerging solutions based on Open RAN (ORAN) and Network-in-aBox strongly advocate the use of low-cost, off-the-shelf components for simpler and efficient deployment, for example, in provisioning rural connectivity. In this context, conceptual architecture, hardware testbeds, and precise performance quantification of Large Language Models (LLMs) on off-theshelf edge devices remain largely unexplored. This research investigates computationally demanding LLM inference on a single commodity Raspberry Pi serving as an edge testbed for ORAN. We investigate various LLMs, including small, medium, and large models, on a Raspberry Pi 5 Cluster using a lightweight Kubernetes distribution (K3s) with modular prompting implementation. We study its feasibility and limitations by analyzing throughput, latency, accuracy, and efficiency. Our findings indicate that CPU-only deployment of lightweight models, such as Yi, Phi, and Llama3, can effectively support edge applications, achieving a generation throughput of 5 to 12 tokens per second with less than 50% CPU and RAM usage. We conclude that GenAI on the edge offers localized inference in remote or bandwidthconstrained environments in 6 G networks without reliance on cloud infrastructure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICC52391.2025.11161569 },
  booktitle={ ICC 2025 - IEEE International Conference on Communications },
  chapter={0}
}

@article{rayyan-352343351,
  title={ GenManip: LLM-driven Simulation for Generalizable Instruction-Following Manipulation  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Gao, N. and Chen, Y. and Yang, S. and Chen, X. and Tian, Y. and Li, H. and Huang, H. and Wang, H. and Wang, T. and Pang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093105 },
  abstract={Robotic manipulation in real-world settings remains challenging, especially regarding robust generalization. Existing simulation platforms lack sufficient support for exploring how policies adapt to varied instructions and scenarios. Thus, they lag behind the growing interest in instruction-following foundation models like LLMs, whose adaptability is crucial yet remains underexplored in fair comparisons. To bridge this gap, we introduce GenManip, a realistic tabletop simulation platform tailored for policy generalization studies. It features an automatic pipeline via LLM-driven task-oriented scene graph to synthesize large-scale, diverse tasks using 10K annotated 3D object assets. To systematically assess generalization, we present GenManip-Bench, a benchmark of 200 scenarios refined via human-in-the-loop corrections. We evaluate two policy types: (1) modular manipulation systems integrating foundation models for perception, reasoning, and planning, and (2) end-to-end policies trained through scalable data collection. Results show that while data scaling benefits end-to-end methods, modular systems enhanced with foundation models generalize more effectively across diverse scenarios. We anticipate this platform to facilitate critical insights for advancing policy generalization in realistic conditions. All code will be available at project page.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.01138 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343352,
  title={ Towards Transparent Intrusion Detection: A Coherence-Based Framework in Explainable AI Integrating Large Language Models  -  2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA) },
  year={2024},
  author={Alnahdi, A. and Narain, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835438 },
  abstract={Intrusion Detection Systems (IDS) are essential for maintaining cybersecurity by identifying potential threats within networks. However, the black-box nature of the Artificial Intelligence models used in many IDS deployments hinders their effectiveness. Explainable AI (XAI) methods have emerged to provide transparency, but their evaluation metrics—such as faithfulness, completeness, and stability—are generic and fail to measure coherence with domain-specific knowledge transparently. Domain-specific knowledge is typically expressed as natural language rules, yet manually applying these rules in real-time cybersecurity is labor-intensive, costly, and error-prone due to the high volume of incidents. This paper introduces a coherence evaluation metric designed to ensure XAI explanations align with IDS domain knowledge, aiding cybersecurity analysts in understanding and responding to incidents more effectively. We propose a framework that integrates Generative AI (GAI) with XAI to automate the coherence evaluation process, leveraging Large Language Models (LLMs) for optimal performance. Using the NSL-KDD and CICIDS2017 datasets, we demonstrate the effectiveness of our framework in improving the interpretability and trustworthiness of IDS predictions. Our findings revealed that the chain-of-thought (COT) prompting method achieved an 86% correctness rate in LLM responses for automating written rules towards the coherence metric. Additionally, our framework models written rules using colors, provides coherence or incoherence recommendations, improves the integration of XAI with LLMs, and ultimately advances human-computer interaction in security decision-making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPS-ISA62245.2024.00020 },
  booktitle={ 2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA) },
  chapter={0}
}

@article{rayyan-352343353,
  title={ Emotion Translator in Conversational AI Based on Big Five Personality Profiles  -  2025 International Electronics Symposium (IES) },
  year={2025},
  author={Nurrahman, F. Z. and Takano, K. and Rante, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11160736 },
  abstract={Traditional chatbots often lack emotional awareness, resulting in interactions that feel generic, disconnected, and lacking human-like depth. This limitation reduces their effectiveness in emotionally sensitive or interactive storytelling applications. To address this issue, this study proposes an enhanced Emotional AI framework that integrates personality traits-specifically the Big Five Personality Traits- in to the emotional response mechanism. The system employs a fine-tuned Large Language Model (LLM) alongside a static personality-emotion matrix to modulate emotional updates in a way that reflects the AI character's individual personality. For instance, a character high in Openness maintains stable, optimistic emotional patterns, while one high in Neuroticism exhibits more volatile emotional responses. Implemented within the Ren'Py Visual Novel Engine, the method enables real-time emotional expression through dynamic character sprite transitions and dialogue generation. Experimental results show that the approach improves emotional stability by 60%, alignment with personality traits by 35%, and dialogue coherence by 75% compared to a baseline model. These findings demonstrate the system's effectiveness in producing emotionally consistent, personality-aligned AI companions, advancing the development of emotionally intelligent storytelling agents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IES67184.2025.11160736 },
  booktitle={ 2025 International Electronics Symposium (IES) },
  chapter={0}
}

@article{rayyan-352343354,
  title={ SolSearch: An LLM-Driven Framework for Efficient SAT-Solving Code Generation  -  2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER) },
  year={2025},
  author={Sheng, J. and Lin, Y. and Wu, J. and Huang, Y. and Shi, J. and Zhang, M. and Wang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023952 },
  abstract={The Satisfiability (SAT) problem is a core challenge with significant applications in software engineering, including automated testing, configuration management, and program verification. This paper presents SolSearch, a novel framework that harnesses large language models (LLMs) to discover and optimize SAT-solving strategies automatically. Leveraging a curriculum-based, trial-and-error process, SolSearch enables the LLM to iteratively modify and generate SAT solver code, thereby improving solving efficiency and performance. This automated SAT-solving paradigm has the advantage of being plug-and-play, allowing integration with any SAT solver and accelerating the development or design process of new SAT solvers (new methods). Our preliminary experimental results are encouraging by demonstrating that the LLM-powered paradigm improves state-of-the-art SAT solvers on general SAT benchmarks and significantly enhances the performance of the widely used Z3 solver (11% on PAR-2 score). These results highlight the potential for using LLM-driven methods to advance solver adaptability and effectiveness in real-world software engineering challenges. Future research directions are discussed to further refine and validate this approach, offering a promising avenue for integrating AI with traditional software engineering tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE-NIER66352.2025.00007 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER) },
  chapter={0}
}

@article{rayyan-352343355,
  title={ Let's Have a Chat with the EU AI Act  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Kővári, Á. and Ghafourian, Y. and Hegedus, C. and Naim, B. A. and Mezei, K. and Varga, P. and Tauber, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073655 },
  abstract={As artificial intelligence (AI) regulations evolve and the regulatory landscape develops and becomes be more complex, ensuring compliance with ethical guidelines and legal frameworks remains a challenge for AI developers. This paper introduces an AI -driven self-assessment chatbot designed to assist users in navigating the European Union AI Act and related standards. Leveraging a Retrieval-Augmented Generation (RAG) frame-work, the chatbot enables real-time, context-aware compliance verification by retrieving relevant regulatory texts and providing tailored guidance. By integrating both public and proprietary standards, it streamlines regulatory adherence, reduces complex-ity, and fosters responsible AI development. The paper explores the chatbot's architecture, comparing naive and graph-based RAG models, and discusses its potential impact on AI governance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073655 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343356,
  title={ Improving LLM Outputs Against Jailbreak Attacks With Expert Model Integration  -  IEEE Access },
  author={Tsmindashvili, T. and Kolkhidashvili, A. and Kurtskhalia, D. and Maghlakelidze, N. and Mekvabishvili, E. and Dentoshvili, G. and Shamilov, O. and Gachechiladze, Z. and Saporta, S. and Choladze, D. Dachi},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095693 },
  abstract={Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address, may be irrelevant to that field. These problems can be mitigated for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient and reliable. In response to these challenges, we introduce Archias, an expert model, adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model’s ability to understand the user’s intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be simply customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3592458 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343357,
  title={ Accelerate Learning with AI Powered Quiz Master Using Llama LLM  -  2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E) },
  year={2025},
  author={Bhatia, G. and Alhajri, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10983252 },
  abstract={Multiple-choice questions quizzes provide an interactive and engaging way to assess students' understanding and reinforce learning, but their manual creation can be time-consuming and labor-intensive for educators. The emergence of Large Language Models (LLMs) offers a transformative solution by enabling automated MCQ generation, correction, and personalized feedback. LLMs, with their advanced natural language understanding and generation capabilities, facilitate the creation of diverse and adaptive MCQ quizzes that cater to various learning objectives and difficulty levels. This paper introduces Quiz Master, an AI-powered platform for automated MCQ quiz generation, correction, and feedback, developed using open-source tools such as Meta Llama, Ollama, LangChain, and Streamlit. Quiz Master delivers an engaging and personalized learning experience, allowing students to actively participate in quizzes while receiving instant, adaptive feedback. By optimizing quiz creation and reducing educator workload, Quiz Master demonstrates the potential of LLMs to enhance educational practices, making learning more enjoyable, interactive, and effective.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AI2E64943.2025.10983252 },
  booktitle={ 2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E) },
  chapter={0}
}

@article{rayyan-352343358,
  title={ A 28nm 3.14 TFLOP/W BF16 LLM Fine-Tuning Processor with Asymmetric Quantization Computing for AI PC  -  2025 IEEE Custom Integrated Circuits Conference (CICC) },
  year={2025},
  author={Lin, X. and Huang, L. and Wei, C. and Jia, W. and Wang, H. and Wang, W. and Jia, H. and Yang, H. and Liu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10983849 },
  abstract={The powerful capabilities of large language models (LLMs) enable them to function as personal digital assistants. To ensure user privacy, personalized fine-tuning can be conducted locally on memoryconstrained AI PCs using Parameter-Efficient Fine-Tuning (PEFT) algorithms, such as QLoRA[1] and QA-LORA[2]. Figure 1 illustrates the computation flow of QLoRA: BF16 input activations undergo matrix multiplication with 4-bit quantized pre-trained weights and BF16 adapter weights. In this flow, asymmetric quantization MACs represent the primary bottleneck, consuming approximately 97% of the computational load. However, current neural processing units (NPUs) offer limited support for asymmetric computation: fine-tuning Llama2-13B on an RTX 3090 takes over 25 hours. This highlights the need for fine-tuning processors optimized for asymmetric quantization. Yet, asymmetric quantization presents hardware design challenges: 1) Existing NPUs primarily support symmetric formats, introducing conversion overhead and inefficiencies; 2) Current NPUs lack efficient support for low-precision data transposition; and 3) 4-bit quantized QLoRA encounters high external access and storage demands, while the use of 2:4 sparsity in low-bit LLM finetuning[3] incurs substantial bitmask overhead with limited benefits.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CICC63670.2025.10983849 },
  booktitle={ 2025 IEEE Custom Integrated Circuits Conference (CICC) },
  chapter={0}
}

@article{rayyan-352343359,
  title={ uTalk: Bridging the Gap Between Humans and AI  -  2024 IEEE International Conference on Consumer Electronics (ICCE) },
  year={2024},
  author={Azzuni, H. and Jamal, S. and Elsaddik, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444441 },
  abstract={Large Language Models (LLMs) have revolutionized various industries by harnessing their power to improve productivity and facilitate learning across different fields. One intriguing application involves combining LLMs with visual models to create a novel approach to Human-Computer Interaction. The core idea of this system is to create a user-friendly platform that enables people to utilize ChatGPT’s features in their everyday lives. uTalk is comprised of technologies like Whisper, ChatGPT, Microsoft Speech Services, and the state-of-the-art (SOTA) talking head system SadTalker. Users can engage in human-like conversation with a digital twin and receive answers to any questions. Also, uTalk could generate content by submitting an image and input (text or audio). This system is hosted on Streamlit, where users will be prompted to provide an image to serve as their AI assistant. Then, as the input (text or audio) is provided, a set of operations will produce a video of the avatar with the precise response. This paper outlines how SadTalker’s run-time has been optimized by 27.69% based on 25 frames per second (FPS) generated videos and 38.38% compared to our 20FPS generated videos. Furthermore, the integration and parallelization of SadTalker and Streamlit have resulted in a 9.8% improvement compared to the initial performance of the system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCE59016.2024.10444441 },
  booktitle={ 2024 IEEE International Conference on Consumer Electronics (ICCE) },
  chapter={0}
}

@article{rayyan-352343360,
  title={ The Language Model Revolution: LLM and SLM Analysis  -  2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP) },
  year={2024},
  author={Örpek, Z. and Tural, B. and Destan, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710677 },
  abstract={As technology develops day by day, significant developments have been made in the field of artificial intelligence (AI). In particular, machine learning (ML) and deep learning (DL), as the main technologies that form the basis of artificial intelligence, have offered revolutionary innovations and laid the foundation for future technologies. Traditional artificial intelligence models are based on algorithms that show high performance in certain tasks such as classification, scoring, prediction, and pattern recognition. These algorithms are developed to best perform a specific task, making it difficult for artificial intelligence to be sufficiently effective in areas that require flexibility. Generative artificial intelligence, which has become widespread in recent years, has the ability to produce certain types of content in addition to the competencies of traditional artificial intelligence models. This has revolutionized the field of productivity in artificial intelligence. Generative artificial intelligence language models have gone beyond the limitations and started a new era in artificial intelligence applications. Where traditional artificial intelligence models are limited, language models have come into play, especially with their natural language processing (NLP) capabilities. Rather than just analyzing data, language models can learn the rules of the language and provide human-like responses, produce text, and offer a wider range of applications. In this way, artificial intelligence systems have become more flexible, extensible, and dynamic. With the rise of language models in this field, concepts such as large language models (LLM) and small language models (SLM) have emerged. Large language models have come to the fore as systems that can provide deep knowledge and language production on a wide variety of topics by being trained on huge data sets. Large language models such as ChatGPT are one of the most common and impressive examples in this field. However, small language models, which are smaller and specialized language models, have begun to be used as an alternative to large language models in certain areas because they require less data and processing power. Small language models stand out with their lighter but targeted performance, offering effective solutions, especially in situations where there are resource limitations. At this point, using both large and small versions of language models in the right scenarios provides great advantages in terms of sustainability and efficiency. This study aims to reveal the transformative effect of technology on artificial intelligence and the critical role of language models in this process by evaluating language models and the issues to be considered in the selection of these models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDAP64064.2024.10710677 },
  booktitle={ 2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP) },
  chapter={0}
}

@article{rayyan-352343361,
  title={ AI in Literature Reviews: a survey of current and emerging methods  -  2024 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC) },
  year={2024},
  author={Saied, M. and Mokhtar, N. and Badr, A. and Adel, M. and Boles, P. and Khoriba, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10783597 },
  abstract={AI-assisted literature review tools have significantly enhanced researchers' productivity by streamlining the review process and reducing time consumption. Although traditional tools remain widely used, a new generation of tools leveraging state-of-the-art methods, including large language models (LLMs), is gaining popularity. However, LLMs face challenges such as hallucinations, which affect their reliability and accuracy. To address this, solutions such as knowledge augmentation are being explored. Additionally, combining knowledge-augmented LLMs with agentic frameworks has shown promise in improving their performance, making them more reliable and effective for literature review tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/MIUCC62295.2024.10783597 },
  booktitle={ 2024 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC) },
  chapter={0}
}

@article{rayyan-352343362,
  title={ The Evolution of AI and its Role in Remote Education  -  2024 15th International Conference on Distance Learning and Education (ICDLE) },
  year={2024},
  author={Sgantzos, K. and Stelios, S. and Tzavaras, P. and Theologou, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015282 },
  abstract={It will not present a hyperbole if one states that we live in the era of Artificial Intelligence. Even though nobody could forecast it to happen so fast, this particular branch of Computer Science has made tremendous progress and presents a transformative paragon within our society, with its applications dominating several sectors in almost every industry. The significant technological advancements in the past five years, resulted in the development of algorithms and models which can perform intelligent tasks and jobs that once were thought solely reserved for humans. On the other hand, and contrary to popular belief that it all happened in the last five years, it must be noted that this evolution is not a case of parthenogenesis, but rather a long and difficult preparation that lasted several decades. We hereby examine the way an offline AI model can help in remote education and at the same time preserve the personal privacy without utilizing the Internet. We note the benefits and potential such a technology brings, and the drawbacks that may act as a pushback until it presents further development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDLE63439.2024.00009 },
  booktitle={ 2024 15th International Conference on Distance Learning and Education (ICDLE) },
  chapter={0}
}

@article{rayyan-352343363,
  title={ AI-enabled Network Automation in TeraFlowSDN Orchestrated Networks  -  2025 IEEE Photonics Society Summer Topicals Meeting Series (SUM) },
  year={2025},
  author={Vilalta, R. and Gifre, L. and Alemany, P. and Adanza, D. and Martinez, R. and Casellas, R. and Muñoz, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121748 },
  abstract={This paper explores the integration of AI in enhancing network orchestration within TeraFlowSDN. It highlights current contributions, such as the introduction of traffic forecaster and autonomous agent. Moreover, this paper presents a vision for future releases to enable secure, scalable, and adaptive network automation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SUM65312.2025.11121748 },
  booktitle={ 2025 IEEE Photonics Society Summer Topicals Meeting Series (SUM) },
  chapter={0}
}

@article{rayyan-352343364,
  title={ FidoNet and Generative AI: A New Approach to Museumification of Historical Content Resources  -  2023 8th IEEE History of Electrotechnology Conference (HISTELCON) },
  year={2023},
  author={Burov, V. and Soshnikov, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365937 },
  abstract={This report considers the problem of visual representation of historical content resources based on user-generated content for museumification of the most important information resources in the history of digital networks development. The paper proposes an approach based on generative AI and shows its implementation in relation to FidoNet.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HISTELCON56357.2023.10365937 },
  booktitle={ 2023 8th IEEE History of Electrotechnology Conference (HISTELCON) },
  chapter={0}
}

@article{rayyan-352343365,
  title={ Investigating Large Language Models for Financial Causality Detection in Multilingual Setup  -  2023 IEEE International Conference on Big Data (BigData) },
  year={2023},
  author={Shukla, N. K. and Katikeri, R. and Raja, M. and Sivam, G. and Yadav, S. and Vaid, A. and Prabhakararao, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386558 },
  abstract={This paper presents our contribution to the Financial Document Causality Detection (FinCausal) task, a component of the FNP-2023 workshop. The FinCausal challenge centers on the extraction of cause-and-effect relationships from financial texts written in both English and Spanish. Recent advancements in Generative AI and Large Language Models (LLMs) have instigated investigations into their reasoning abilities, propelling our exploration of LLMs’ potential for causal reasoning within the financial domain. This study also ventures into the domain of non-English languages, aiming to uncover the capacity of LLMs on this front as well. Our investigation revealed that LLMs exhibit a remarkable ability to identify causal relationships, particularly when provided with few task-specific relevant examples. Additionally, our research demonstrates the effectiveness of LLMs in processing non-English languages when given the same English prompts along with language comprehension instructions. We conducted a comparative analysis between OpenAI GPT3.5 and 4, concluding that GPT-4 model is better-suited for this purpose. Our study unveils that LLMs yield semantically similar cause and effects. This discovery highlights LLMs don’t rely solely on content for the predictions and so the necessity of adopting an evaluation approach for this task, one that emphasizes also on semantic similarity metrics.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData59044.2023.10386558 },
  booktitle={ 2023 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343366,
  title={ Extraction of Subjective Information from Large Language Models  -  2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC) },
  year={2024},
  author={Kobayashi, A. and Yamaguchi, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633568 },
  abstract={Large Language Models (LLMs) have been advancing natural language processing technologies for several years. Especially in the last year, generative AI (Artificial Intelligence) models have improved remarkably and attracted attention. Then, there has been a great discussion about these models, such as extracting the knowledge in these models. However, these existing works were mainly for the extraction of objective information. In this paper, we study the extraction of subjective information from LLMs by focusing on GPT, Gemini Pro, and Claude2. We then show that such information extraction can be severely limited in LLMs, but that information extraction is possible from some models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPSAC61105.2024.00253 },
  booktitle={ 2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC) },
  chapter={0}
}

@article{rayyan-352343367,
  title={ Enhanced Database Interaction Using Large Language Models for Improved Data Retrieval and Analysis  -  2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI) },
  year={2024},
  author={Usha, V. and Abhinash, N. C. and Chowdary, S. N. and Sathya, V. and Reddy, E. R. and S, S. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696623 },
  abstract={One of the difficult task for many users on SQL is to write the SQL Query due to its syntax and structure. If a person needs to query a database, they should know everything about how data is distributed and what the internal dependencies are. For this reason, it is not easy for everyone to access data in database without proper knowledge. This paper presents a novel application that leverages generative AI and natural language processing (NLP) to enable users to interact with databases using natural language queries. Built on the Gemini API, the application translates user queries into SQL queries, simplifying database interactions for non-technical users. The Python-based backend, SQLite database management, and Streamlit frontend provide a comprehensive solution for database querying and analysis. This approach democratizes data retrieval and analysis, offering automated insights and visualizations to users of all skill levels. The app also features automated data analysis, which boosts insight generation for users of all skill levels. Further, the traditional ways of querying SQL generally require specialized knowledge and are only accessible to those with technical backgrounds. When the application takes charge of the query construction process and offers data as UI elements, it can invigorate users to have a higher degree of insight into what their data actually is and explore it even more efficiently. The Python software stack combines Python for backend processing, SQLite for database management and a web-based frontend for user interaction to provide an all-encompassing database querying and analysis solution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoICI62503.2024.10696623 },
  booktitle={ 2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI) },
  chapter={0}
}

@article{rayyan-352343368,
  title={ On the (In)Security of LLM App Stores  -  2025 IEEE Symposium on Security and Privacy (SP) },
  year={2025},
  author={Hou, X. and Zhao, Y. and Wang, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023302 },
  abstract={LLM app stores have seen rapid growth, leading to the proliferation of numerous custom LLM apps. However, this expansion raises security concerns. In this study, we propose a three-layer concern framework to identify the potential security risks of LLM apps, i.e., LLM apps with abusive potential, LLM apps with malicious intent, and LLM apps with backdoors. Over five months, we collected 786,036 LLM apps from six major app stores: GPT Store, FlowGPT, Poe, Coze, Cici, and Character.AI. Our research integrates static and dynamic analysis, and uses a complementary approach to detect harmful content, combining a self-refining LLM-based toxic content detector with rule-based pattern matching. Additionally, we constructed a large-scale toxic word dictionary (i.e., ToxicDict) comprising over 31,783 entries. We used these methods to uncover that 15,414 apps had misleading descriptions, 1,366 collected sensitive personal information against their privacy policies, and 15,996 generated harmful content such as hate speech, self-harm, extremism, etc. Additionally, we evaluated the potential for LLM apps to facilitate malicious activities, finding that 616 apps could be used for malware generation, phishing, etc. We reported these security risks to relevant platforms, including OpenAI and Quora, which acknowledged and appreciated our findings. The platforms are actively investigating the flagged apps; as of the submission of this paper, 1,643 apps have been removed from the GPT Store.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SP61157.2025.00117 },
  booktitle={ 2025 IEEE Symposium on Security and Privacy (SP) },
  chapter={0}
}

@article{rayyan-352343369,
  title={ Quantum Computational Intelligence with Generative AI Image for Human-Machine Interaction  -  2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) },
  year={2024},
  author={Lee, C. -S. and Wang, M. -H. and Chiang, J. -K. and Kubota, N. and Sato-Shimokawara, E. and Nojima, Y. and Acampora, G. and Wu, P. -Y. and Chiu, S. -C. and Yang, S. -C. and Siow, C. -Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10611970 },
  abstract={This paper introduces a Quantum Computational Intelligence (QCI) agent equipped with a content attention ontology model, specifically designed to enhance human-machine interaction based on a Generative Artificial Intelligence (GAI) image generation agent for Taiwanese/English learning and experience. Its diverse primary applications include social media analysis on Facebook groups and YouTube learning videos related to the 2023 IEEE CIS Education Portal (EP) Subcommittee, as well as in the areas of Taiwanese/English language learning and dialogue experience with GAI image generation. To establish the knowledge and inference models for the QCI agent, we initially developed a Taiwanese/English learning and experience ontology, including a content attention ontology, and an image attention ontology. The QCI agent utilizes metrics such as the number of views, posts, and comments to predict the fuzzy number of reactions. In addition, the GAI image agent generates Taiwanese speech-based/English text-based images and evaluates the fuzzy similarity score between Taiwanese/English and the attention ontology together with the Sentence BERT (SBERT) agent. This Taiwanese/English fuzzy similarity score is further validated through human assessments, with these evaluations subsequently serving as an additional metric for comparative analysis of Human-Machine Interaction (HMI). Furthermore, the GAI image agent is designed to create images and Chinese/English texts from text/speech translated by the Meta AI Universal Speech Translator (UST) Taiwanese/English agent. A Particle Swarm Optimization (PSO)-based machine learning mechanism is employed to train the QCI model for assessing learners' performance and predicting the performance of others. The National University of Tainan (NUTN) Taiwan-Large Language Model (NUTN.TW-LLM) agent has been further enhanced to support interactive learning experiences for HMI. An SBERT-based assessment agent is used to calculate fuzzy similarities between questions and answers in Taiwanese/English experiences and dialogues. Experimental results demonstrate the feasibility and efficacy of the proposed QCI model, equipped with QCI&AI-FML (Artificial Intelligence-Fuzzy Markup Language) and machine learning capabilities, for social media and language learning applications on HMI. In the future, we will extend the QCI model to various HMI applications for student learning around the world.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FUZZ-IEEE60900.2024.10611970 },
  booktitle={ 2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) },
  chapter={0}
}

@article{rayyan-352343370,
  title={ Beyond Intent Translation: Research Gaps in the Application of Generative AI for Intent-Based Networking  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Ficzere, D. and Hollósi, G. and Varga, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073701 },
  abstract={Intent-Based Networking (IBN) promises to redefine network management by automating operations to align with high-level user intents. The advent of powerful Generative AI (GenAI) models, including Large Language Models (LLMs), could significantly accelerate this transformation. However, cur-rent research remains narrowly focused on LLM-based intent translation, leaving substantial gaps in understanding how GenAI can be applied across the entire IBN life cycle. This paper aims to bridge these gaps by investigating the wider potential of Generative AI (GenAI) in areas like intent orchestration, moni-toring, compliance assessment, and automated actions. Through a systematic categorization of tasks based on GenAI's suitability and the presentation of a practical use case, this work highlights the critical need for more comprehensive research to fully harness the potential of GenAI in advancing IBN.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073701 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343371,
  title={ Enhanced LegalTech: AI Voice Assistant for Legal Queries with Dynamic Lawyer Recommendations  -  2025 Global Conference in Emerging Technology (GINOTECH) },
  year={2025},
  author={S, S. P. and S, M. A. and P, N. and R, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076664 },
  abstract={This Research gives an AI-pushed voice assistant that gives prison information the use of Generative AI and herbal Language Processing (NLP) technology, mainly targeted on Indian laws. The assistant is designed to offer real-time prison causes primarily based totally on consumer activates and inquiries, helping each English and Tamil. By leveraging a big Language version (LLM) skilled on Indian prison documents, the machine can offer unique regulation sections, give an explanation for their implications, and provide steerage. Additionally, it complements accessibility through supplying responses in spoken Tamil, making prison statistics greater inclusive for nearby language speakers. A key function of this undertaking is the change of the set of rules primarily based totally on epoch, which improves the version choice manner for extra accuracy. The machine additionally indicates a listing of practising attorneys in India primarily based totally at the consumer’s prison difficulty and location, with real-time updates on to be had practitioners. This voice assistant addresses the constraints posed through conventional text-primarily based totally prison statistics systems, streamlining the prison question manner and making prison steerage greater accessible, specifically in rural groups in India.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GINOTECH63460.2025.11076664 },
  booktitle={ 2025 Global Conference in Emerging Technology (GINOTECH) },
  chapter={0}
}

@article{rayyan-352343372,
  title={ MALTopic: Multi-Agent LLM Topic Modeling Framework  -  2025 IEEE World AI IoT Congress (AIIoT) },
  year={2025},
  author={Sharma, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105319 },
  abstract={Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT65859.2025.11105319 },
  booktitle={ 2025 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343373,
  title={ SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation  -  2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  year={2025},
  author={Petrukha, I. and Kurliak, Y. and Stulova, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052807 },
  abstract={In recent years, large language models (LLMs) have showcased significant advancements in code generation. However, most evaluation benchmarks are primarily oriented towards Python, making it difficult to evaluate other programming languages, such as Swift, with high quality. By examining widely established multilingual benchmarks like HumanEval-Xl and MultiPL-E, we identified critical issues specific to their Swift components, making them insufficient or even irrelevant for assessing LLM coding capabilities on Swift. Unlike these existing approaches, which prioritize rapid scaling and generalization by automatically translating Python-Centric benchmarks with LLMs, we adopt a quality-over-quantity methodology. We present SwiftEval, the first Swift-Oriented benchmark consisting of 28 carefully hand-crafted problems, and evaluate 44 popular Code LLMs on it. Our results show significant LLM scores drop for problems requiring language-specific features, most noticeable in the models of smaller sizes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Forge66646.2025.00015 },
  booktitle={ 2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  chapter={0}
}

@article{rayyan-352343374,
  title={ CTC-Assisted LLM-Based Contextual ASR  -  2024 IEEE Spoken Language Technology Workshop (SLT) },
  year={2024},
  author={Yang, G. and Ma, Z. and Gao, Z. and Zhang, S. and Chen, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832154 },
  abstract={Contextual ASR or hotword customization holds substantial practical value. Despite the impressive performance of current end-to-end (E2E) automatic speech recognition (ASR) systems, they often face challenges in accurately recognizing rare words. Typical E2E contextual ASR models commonly feature complex architectures and decoding mechanisms, limited in performance and susceptible to interference from distractor words. With large language model (LLM)-based ASR models emerging as the new mainstream, we propose a CTC-Assisted LLM-Based Contextual ASR model with an efficient filtering algorithm. By using coarse CTC decoding results to filter potential relevant hotwords and incorporating them into LLM prompt input, our model attains WER/B-WER of $1.27 \% / 3.67 \%$ and $2.72 \% / 8.02 \%$ on the Librispeech test-clean and test-other sets targeting on recognizing rare long-tail words, demonstrating significant improvements compared to the baseline LLM-based ASR model, and substantially surpassing other related work. More remarkably, with the help of the large language model and proposed filtering algorithm, our contextual ASR model still performs well with 2000 biasing words.1},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SLT61566.2024.10832154 },
  booktitle={ 2024 IEEE Spoken Language Technology Workshop (SLT) },
  chapter={0}
}

@article{rayyan-352343375,
  title={ Development of Home Manager for Smart Home 4.0 Services  -  2025 International Conference on Information Networking (ICOIN) },
  year={2025},
  author={Park, H. and Na, Y. and Ko, Y. and Kim, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993084 },
  abstract={The integration of AI and IoT technologies is opening the era of ‘Smart Home 4.0.’ This evolution makes possible not only home automation but also human care, particularly for vulnerable groups like the elderly and those living alone. Despite the growing demand, existing systems often lack comprehensive solutions that combine intelligent monitoring, personalized interaction, and seamless device control. To address these challenges, this paper presents the development of the Smart Home Manager, an innovative system designed to enhance daily living and quality of life by integrating IoT platforms, AI Human interface, and conversational LLM-based chatbots. The Smart Home Manager actively monitors and manages household environments for recognizing user needs and delivering tailored services. This paper describes the system architecture of the Smart Home manager, the integration of advanced IoT technologies including IoT platforms such as OCF and Matter for interoperability, and the application of GPT-4-based conversational AI for proactive user interaction. Usability evaluations validate the system’s effectiveness, offering significant insights into future innovations in smart home services and their practical implementation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICOIN63865.2025.10993084 },
  booktitle={ 2025 International Conference on Information Networking (ICOIN) },
  chapter={0}
}

@article{rayyan-352343376,
  title={ 13 Generative AI and LLM: Case Study in E-Commerce  -  Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  author={Iyer, R. and Maralapalle, V. C. and Mahesh, P. and Patil, D.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11164767.pdf&bkn=11164515&pdfType=chapter },
  abstract={The work presented in this chapter provides extensive knowledge concerning generative artificial intelligence (AI) and large language models. It reflects on the revolutionary nature of generative AI and large language models in e-commerce. Moreover, the document emphasizes the development, implementation, challenges, and prospects of generative AI and large language models in e-commerce. Successful integration is discussed, along with dangers to avoid, numerous advantages, and the issue of ethics. Finally, the file underlines the need for customization, improved operations, predictive analytics, and Ethernet implementation of AI in e-commerce. In addition, this chapter also discusses ethical concerns and data privacy issues related to the search and highlights the importance of ethical practices, participant safety, and data integrity. The chapter covers ethical considerations including the importance of ethical procedures and ethical decision-making and the future trends related to AI ethics and data sharing. This addresses the importance of maintaining integrity, transparency, and participant safety in research to maintain trust in the scientific community and conduct responsible research. Besides, the chapter talks about a number of AI advancements for e-commerce, listing, in particular, smart recommendations, augmented reality shopping, and blockchain solutions for dealing with suppliers and security issues. It delves into AI ethics issues, the hyper-personalization approach and also the cross-channel integration concepts, which will be the future! Consequently, the AI tools will be the basis for the development. The section on tackling shortcomings and risks provides small-scale environmental ethics implications of welfare reforms, animal agriculture, and transportation pollutants.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  chapter={0}
}

@article{rayyan-352343377,
  title={ Two-Stage Compliance Detection for Power Enterprises Based on NLI and LLM  -  2024 IEEE International Symposium on Product Compliance Engineering - Asia (ISPCE-ASIA) },
  year={2024},
  author={Hua, M. and Zhao, Q. and Song, J. and -s. Tang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10756275 },
  abstract={Enterprise compliance refers to ensuring that a company's operations adhere to relevant laws, regulations, industry standards, and internal policies. Non-compliance can result in legal liabilities, financial losses, and reputational damage, making it a critical issue in corporate governance. With the advancement of generative artificial intelligence, particularly Large Language Models (LLM), the potential for automated compliance analysis is emerging, offering new methods and tools for enterprise compliance detection. This paper proposes a two-stage compliance detection framework that combines Natural Language Inference (NLI) models and LLM to enhance the efficiency and interpretability of compliance detection between corporate policies and higher-level laws. The framework leverages NLI models for efficient reasoning in detecting semantic conflicts, while LLM are used to generate natural language explanations for deeper semantic analysis, thereby improving both the accuracy and interpretability of compliance detection. Experimental validation in the power industry demonstrates that the proposed framework significantly enhances detection efficiency and reduces compliance risks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISPCE-ASIA64773.2024.10756275 },
  booktitle={ 2024 IEEE International Symposium on Product Compliance Engineering - Asia (ISPCE-ASIA) },
  chapter={0}
}

@article{rayyan-352343378,
  title={ Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence  -  IEEE Transactions on Artificial Intelligence },
  author={McIntosh, T. R. and Susnjak, T. and Arachchilage, N. and Liu, T. and Xu, D. and Watters, P. and Halgamuge, M. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11002710 },
  abstract={The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs’ complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems’ integration into society.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TAI.2025.3569516 },
  booktitle={ IEEE Transactions on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352343379,
  title={ Uncovering Malicious Activity: Interpretable Web Log Analysis with XAI, SHAP, and LLM  -  2025 IEEE Guwahati Subsection Conference (GCON) },
  year={2025},
  author={Gogoi, B. and Suklabaidya, M. and Das, D. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11173318 },
  abstract={This research introduces an offline method for detecting malicious web traffic using XAI for interpretability. By analyzing web server access logs, malicious activities are identified through a two-tiered classification approach. The first tier, called the string based model extracts a subset of features using an embedding model. It combines these with additional features derived from individual web requests to classify them as malicious or benign. The second tier, called the integrated model aggregates features at the IP level, such as request rates and the malicious probability derived from the first tier, to detect broader temporal patterns and coordinated attack behaviors. For interpretability, SHAP (Shapley Additive exPlanations) values highlight the most significant features influencing classifications. To enhance interpretability, these SHAP values are translated into natural language explanations using an LLM offering human-readable insights into the model’s decisions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GCON65540.2025.11173318 },
  booktitle={ 2025 IEEE Guwahati Subsection Conference (GCON) },
  chapter={0}
}

@article{rayyan-352343380,
  title={ Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations  -  2024 IEEE Global Engineering Education Conference (EDUCON) },
  year={2024},
  author={Abu-Rasheed, H. and Weber, C. and Fathi, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578654 },
  abstract={In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON60312.2024.10578654 },
  booktitle={ 2024 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343381,
  title={ Generative AI for Game Theory-Based Mobile Networking  -  IEEE Wireless Communications },
  author={He, L. and Sun, G. and Niyato, D. and Du, H. and Mei, F. and Kang, J. and Debbah, M. and Han, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10872872 },
  abstract={With the continuous advancement of network technology, various emerging complex networking optimization problems have created a wide range of applications utilizing game theory. However, since game theory is a mathematical framework, game theory-based solutions often rely heavily on the experience and knowledge of human experts. Recently, the remarkable advantages exhibited by generative artificial intelligence (GAI) have gained widespread attention. In this work, we propose a novel GAI-enabled game theory solution that combines the powerful reasoning and generation capabilities of GAI with the design and optimization of mobile networking. Specifically, we first outline the game theory and key technologies of GAI and explore the advantages of combining GAI with game theory. Then, we review the contributions and limitations of existing research and demonstrate the potential application values of GAI applied to game theory in mobile networking. Subsequently, we develop a large language model (LLM)-enabled game theory framework to realize this combination and demonstrate the effectiveness of the proposed framework through a case study in secured UAV networks. Finally, we provide several directions for future extensions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MWC.007.2400133 },
  booktitle={ IEEE Wireless Communications },
  chapter={0}
}

@article{rayyan-352343382,
  title={ A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Singh, A. and Shetty, A. and Ehtesham, A. and Kumar, S. and Khoei, T. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903689 },
  abstract={Text-to-SQL systems facilitate smooth interaction with databases by translating natural language queries into Structured Query Language (SQL), bridging the gap between non-technical users and complex database management systems. This survey provides a comprehensive overview of the evolution of AI-driven text-to-SQL systems, highlighting their foundational components, advancements in large language model (LLM) architectures, and the critical role of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine the applications of text-to-SQL in domains like healthcare, education, and finance, emphasizing their transformative potential for improving data accessibility. Additionally, we analyze persistent challenges, including domain generalization, query optimization, support for multi-turn conversational interactions, and the limited availability of datasets tailored for NoSQL databases and dynamic real-world scenarios. To address these challenges, we outline future research directions, such as extending text-to-SQL capabilities to support NoSQL databases, designing datasets for dynamic multi-turn interactions, and optimizing systems for real-world scalability and robustness. By surveying current advancements and identifying key gaps, this paper aims to guide the next generation of research and applications in LLM-based text-to-SQL systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903689 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343383,
  title={ Towards Trustworthy AI Software Development Assistance  -  2024 IEEE/ACM 46th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER) },
  year={2024},
  author={Maninger, D. and Narasimhan, K. and Mezini, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10727135 },
  abstract={It is expected that in the near future, AI software development assistants will play an important role in the software industry. However, current software development assistants tend to be unreliable, often producing incorrect, unsafe, or low-quality code. We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants. In the center of the architecture, there is a foundational LLM trained on datasets representative of real-world coding scenarios and complex software architectures, and fine-tuned on code quality criteria beyond correctness. The LLM will make use of graph-based code representations for advanced semantic comprehension. We envision a knowledge graph integrated into the system to provide up-to-date background knowledge and to enable the assistant to provide appropriate explanations. Finally, a modular framework for constrained decoding will ensure that certain guarantees (e.g., for correctness and security) hold for the generated code.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3639476.3639770 },
  booktitle={ 2024 IEEE/ACM 46th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER) },
  chapter={0}
}

@article{rayyan-352343384,
  title={ AI-Assisted Personal Wardrobe Management: A Human-Centric Approach to Intelligent Clothing Organization and Style Recommendation  -  2025 IEEE 6th International Conference in Robotics and Manufacturing Automation (ROMA) },
  year={2025},
  author={Idris, S. A. Bin and Rahman, S. Binti Abdul and Farid, F. N. Atikah Bt Mohd and Rahman, S. Binti Abdul and Yazid, R. B. and Lazam, N. Azlinah Binti Md},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11155852 },
  abstract={This paper presents WearIn, a human-AI collaborative wardrobe management system integrating NFC technology with fine-tuned artificial intelligence. The system combines ESP8266-based IoT sensors for real-time clothing tracking with a customized Gemini LLM for personalized outfit recommendations. Multi-modal interaction includes NFC scanning, OLED feedback, and conversational AI interface. Fine-tuning achieved significant performance improvements: 80.1% accuracy in reasoning tasks (vs. 69.7% baseline) and 70.8% in real-time queries (vs. 39.2% without optimization). Comprehensive evaluation through nine systematic test cases validated system reliability, cloud synchronization, and human-AI interaction effectiveness. The AI provides contextual outfit suggestions exclusively from user's registered clothing inventory, promoting sustainable fashion practices. **This system has immediate applications in smart homes, retail inventory management, and sustainable fashion initiatives, demonstrating how intelligent automation enhances daily decision-making while preserving user autonomy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ROMA66616.2025.11155852 },
  booktitle={ 2025 IEEE 6th International Conference in Robotics and Manufacturing Automation (ROMA) },
  chapter={0}
}

@article{rayyan-352343385,
  title={ LLM-Driven Agentic AI Approach to Enhanced O-RAN Resilience in Next-Generation Networks  -  IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS) },
  year={2025},
  author={Wu, X. and Wang, Y. and Farooq, J. and Chen, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11152722 },
  abstract={The open radio access network (O-RAN) architecture in next generation networks has significantly transformed RAN design by enabling greater flexibility, interoperability, and facilitating automated, artificial intelligence (AI)-driven management solutions. However, efficient resource allocation remains challenging due to the dynamic and heterogeneous nature of network slices, each characterized by distinct and evolving quality-of-service (QoS) requirements. These challenges become particularly pronounced in real-time operational environments, where traditional machine learning (ML) approaches, typically dependent on offline training, exhibit limited adaptability to rapidly changing system conditions. To overcome these limitations, this paper presents a large language model (LLM)-Driven agentic AI framework for enhancing resource management and resilience in O-RAN systems. By employing strategically formulated prompts, the proposed framework guides the LLM agent to dynamically optimize resource allocation across various network slices, thus ensuring greater adaptability and significantly improved overall system performance. Experimental evaluations conducted on the Open AI Cellular (OAIC) testbed demonstrate demonstrate notable improvements in average data rates, slice reliability, and system responsiveness. These results highlight the efficacy and potential of leveraging LLMs for resilient and adaptive real-time decision-making in next-generation wireless networks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOMWKSHPS65812.2025.11152722 },
  booktitle={ IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS) },
  chapter={0}
}

@article{rayyan-352343386,
  title={ DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject Consistent Diffusion  -  IEEE Transactions on Pattern Analysis and Machine Intelligence },
  author={He, H. and Yang, H. and Tuo, Z. and Zhou, Y. and Wang, Q. and Zhang, Y. and Liu, Z. and Huang, W. and Chao, H. and Yin, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130395 },
  abstract={Story visualization aims to create visually compelling images or videos corresponding to textual narratives. Despite recent advances in diffusion models yielding promising results, existing methods still struggle to create a coherent sequence of subject-consistent frames based solely on a story. To this end, we propose DreamStory, an automatic open-domain story visualization framework by leveraging the LLMs and a novel multi-subject consistent diffusion model. DreamStory consists of (1) an LLM acting as a story director and (2) an innovative Multi-Subject consistent Diffusion model (MSD) for generating consistent multi-subject across the images. First, DreamStory employs the LLM to generate descriptive prompts for subjects and scenes aligned with the story, annotating each scene's subjects for subsequent subject-consistent generation. Second, DreamStory utilizes these detailed subject descriptions to create portraits of the subjects, with these portraits and their corresponding textual information serving as multimodal anchors (guidance). Finally, the MSD uses these multimodal anchors to generate story scenes with consistent multi-subject. Specifically, the MSD includes Masked Mutual Self-Attention (MMSA) and Masked Mutual Cross-Attention (MMCA) modules. MMSA module ensures detailed appearance consistency with reference images, while MMCA captures key attributes of subjects from their reference text to ensure semantic consistency. Both modules employ masking mechanisms to restrict each scene's subjects to referencing the multimodal information of the corresponding subject, effectively preventing blending between multiple subjects. To validate our approach and promote progress in story visualization, we established a benchmark, DS-500, which can assess the overall performance of the story visualization framework, subject-identification accuracy, and the consistency of the generation model. Extensive experiments validate the effectiveness of DreamStory in both subjective and objective evaluations. Please visit our project homepage at https://dream-xyz.github.io/dreamstory.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAMI.2025.3600149 },
  booktitle={ IEEE Transactions on Pattern Analysis and Machine Intelligence },
  chapter={0}
}

@article{rayyan-352343387,
  title={ A Taxonomy-Driven Survey of AI for Seizure Detection: Thalamic Signals, Phase Dynamics, and Translational Gaps  -  IEEE Access },
  author={Ganti, B. and Balasubramanian, K. and Pati, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11177257 },
  abstract={Seizure prediction and postictal recovery remain critical challenges in epilepsy care, particularly in real-world, resource-constrained settings. This survey presents a taxonomy-driven synthesis of 150+ peer-reviewed studies spanning seizure phase modeling, thalamic EEG biomarkers, edge inference, and clinical AI integration. We introduce an eight-axis framework covering neurophysiological foundations, machine learning advances, wearable inference pipelines, large language model (LLM) assistants, and privacy-preserving architectures. A key focus is the emerging role of thalamic stereo-EEG (SEEG) as a high-fidelity substrate for modeling seizure transitions and informing closed-loop interventions. Unlike prior reviews, this work explicitly unifies preictal and postictal phase dynamics with modern AI tools—such as federated learning, explainable deep learning, and agentic reasoning. We highlight gaps in dataset diversity, clinical interpretability, and cross-center generalization, while proposing a translational roadmap toward ethical, explainable, and deployment-ready seizure care.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3614148 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343388,
  title={ ThreatFinderAI: Automated Threat Modeling Applied to LLM System Integration  -  2024 20th International Conference on Network and Service Management (CNSM) },
  year={2024},
  author={der Assen, J. Von and Huertas, A. and Sharif, J. and Feng, C. and Bovet, G. and Stiller, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814632 },
  abstract={Artificial Intelligence (AI) is a rapidly integrated technology, significantly contributing to advancements like 6G. However, its swift adoption raises considerable security concerns. Large Language Models (LLMs) pose risks such as spear phishing, code injections, and remote code execution. Conventional threat modeling, used in secure software development, faces challenges when applied to AI systems, as existing methodologies are designed for traditional software. Furthermore, AI-specific threat modeling research is sparse and lacks approaches providing practical support or automation. Thus, this demo paper presents ThreatFinderAI, an asset-centric threat modeling and risk assessment framework. ThreatFinderAI fulfills seven steps aligned with AI system design and transforms AI threat and control knowledge bases into a queryable knowledge graph for automated asset identification and threat elicitation. It also proposes business impact analysis and expert estimates for AI threat impact quantification. In the demonstration, ThreatFinderAI is illustrated by securing a customer care application relying on LLMs. Through this, it is demonstrated how the proposed framework can be used to identify relevant threats and practical countermeasures and communicate strategic risk.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/CNSM62983.2024.10814632 },
  booktitle={ 2024 20th International Conference on Network and Service Management (CNSM) },
  chapter={0}
}

@article{rayyan-352343389,
  title={ Examining Large Language Models Within Autism-Related Contexts: A Systematic Review of Bias and (Mis) Representation  -  2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC) },
  year={2025},
  author={Pryor, K. and Coleman, T. and Hossain, S. Z. and Tootil, E. and Ahmed, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126846 },
  abstract={Artificial Intelligence (AI) is quickly becoming an integral part of everyday life. AI is no longer limited to advanced applications; it is embedded in applications and tools we use daily to streamline tasks and solve problems. Large Language Models (LLMs), such as ChatGPT and Claude, are designed to help users make decisions, produce recommendations, and provide more personalized solutions to user inquiries. The immense reach these systems have had in such a short period has significantly impacted education, work, and interpersonal interactions. AI systems are only becoming more common, and it is imperative that developers work to address bias within them to promote fair use for all, not only the neurotypical. Research investigating the bias harbored by LLM platforms is particularly limited when it comes to addressing bias against individuals with autism. We applied inductive thematic analysis, followed by deductive thematic analysis, to analyze 34 scientific research papers gathered from two major academic databases: ACM Digital Library and IEEE Xplore. This method helped us learn more about the current empirical understanding of LLM bias as it relates to the context of autism. We found that bias within LLMs has the potential to harm individuals with autism who are looking for answers to problems for which LLMs have been postulated as a solution. LLMs also have the potential to reinforce negative stereotypes, leading users with autism who already face bias in daily life to continually struggle when faced with this new technological frontier.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPSAC65507.2025.00115 },
  booktitle={ 2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC) },
  chapter={0}
}

@article{rayyan-352343390,
  title={ Supercharging Document Composition with Generative AI: A Secure, Custom Retrieval-Augmented Generation Approach  -  2024 11th IEEE Swiss Conference on Data Science (SDS) },
  year={2024},
  author={Chen, A. and Tran, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675972 },
  abstract={Recent advancements in Retrieval Augmented Generation (RAG) provide opportunities for more efficient composition of long-form, domain-specific documents. However, few user-friendly applications leverage RAG for this specific use case. Additionally, existing RAG frameworks reliant on cloud-based, closed-source solutions pose challenges such as transparency and data privacy concerns. To address this gap, we introduce a full-stack application for automated document drafting, offering either proprietary (GPT-3.5-Turbo) or open-source (Falcon-RW-1B-Chat) Large Language Models (LLMs) for document writing and a secure, self-hosted search index (Elasticsearch) for knowledge retrieval. Users interact via a simple UI in which they submit a request with a desired topic and document type and receive a well-researched document that conforms to specific formatting and structural requirements. Given a user request, our document search pipeline employs open-source encoder models from SentenceTransformers for vector search and semantic re-ranking, then passes relevant knowledge sources to the LLM as context for document composition. To orchestrate and modularize our application backend, we use Haystack, an advanced machine learning pipeline builder, and FastAPI, which enables us to deploy components of our pipeline as independent services. Our experiments demonstrate that, using highly customized, self-hosted components, we can achieve document generation quality comparable to that of fully online RAG pipelines. This enables us to provision different application versions to accommodate different cost, scale, and data security preferences.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SDS60720.2024.00025 },
  booktitle={ 2024 11th IEEE Swiss Conference on Data Science (SDS) },
  chapter={0}
}

@article{rayyan-352343391,
  title={ An Intelligent System for Healthcare Service Logging in a Medium-Sized Language  -  2025 21st International Conference on Intelligent Environments (IE) },
  year={2025},
  author={Smerkol, M. and Susič, R. and Jarc, T. and Várkonyi, G. G. and Gradišek, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130115 },
  abstract={We present an intelligent system designed for the environment of a healthcare facility, such as a hospital or a nursing home. The aim of the system is to log the services carried out by the service provider (a nurse) without the need to choose individual items from a series of menus, which is currently the standard procedure. Instead, we used a voice recording of the nurses reporting their actions in a natural language, i.e. without particular voice commands, coupled with a fine-tuned Large Language Model (LLM). We discuss legal aspects related to recording and processing of conversations in a healthcare facility. We outline the implementation and present the results of tests using different types of LLMs. We focus on the Slovenian language, which can be seen as a medium-sized language, instead of English which is widely supported by LLMs. Our approach produces up to 97% both in precision and recall.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IE64880.2025.11130115 },
  booktitle={ 2025 21st International Conference on Intelligent Environments (IE) },
  chapter={0}
}

@article{rayyan-352343392,
  title={ OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Huang, Q. and Dong, X. and Zhang, P. and Wang, B. and He, C. and Wang, J. and Lin, D. and Zhang, W. and Yu, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10655465 },
  abstract={Hallucination, posed as a pervasive challenge of multi-modal large language models (MLLMs), has significantly impeded their real-world usage that demands precise judgment. Existing methods mitigate this issue with either training with specific designed data or inferencing with external knowledge from other sources, incurring inevitable additional costs. In this paper, we present OPERA, a novel MLLM decoding method grounded in an Over-trust Penalty and a Retrospection-Allocation strategy, serving as a nearly free lunch to alleviate the hallucination issue without additional data, knowledge, or training. Our approach begins with an interesting observation that, most hallucinations are closely tied to the knowledge aggregation patterns manifested in the self-attention matrix, i.e., MLLMs tend to generate new tokens by focusing on a few summary tokens, but not all the previous tokens. Such partial overtrust inclination results in the neglecting of image tokens and describes the image content with hallucination. Based on the observation, OPERA introduces a penalty term on the model logits during the beam-search decoding to mitigate the over-trust issue, along with a rollback strategy that retrospects the presence of summary tokens in the previously generated tokens, and re-allocate the token selection if necessary. With extensive experiments, OPERA shows significant hallucination-mitigating performance on different MLLMs and metrics, proving its effectiveness and generality. Our code is at: https://github.com/shikiw/OPERA.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.01274 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343393,
  title={ Distilling Multi-Modal Large Language Models for Autonomous Driving  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Hegde, D. and Yasarla, R. and Cai, H. and Han, S. and Bhattacharyya, A. and Mahajan, S. and Liu, L. and Garrepalli, R. and Patel, V. M. and Porikli, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091863 },
  abstract={Autonomous driving demands safe motion planning, especially in critical "long-tail" scenarios. Recent end-to-end autonomous driving systems leverage large language models (LLMs) as planners to improve generalizability to rare events. However, using LLMs at test time introduces high computational costs. To address this, we propose DiMA, an end-to-end autonomous driving system that maintains the efficiency of an LLM-free (or vision-based) planner while leveraging the world knowledge of an LLM. DiMA distills the information from a multi-modal LLM to a vision-based end-to-end planner through a set of specially designed surrogate tasks. Under a joint training strategy, a scene encoder common to both networks produces structured representations that are semantically grounded as well as aligned to the final planning objective. Notably, the LLM is optional at inference, enabling robust planning without compromising on efficiency. Training with DiMA results in a 37% reduction in the L2 trajectory error and an 80% reduction in the collision rate of the vision-based planner, as well as a 44% trajectory error reduction in long-tail scenarios. DiMA also achieves state-of-the-art performance on the nuScenes planning benchmark.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.02568 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343394,
  title={ Overcoming Memory Limitations for On-Device AI and LLM in Wearable AR Systems  -  2024 IEEE International Electron Devices Meeting (IEDM) },
  year={2024},
  author={Liu, H. and Morris, D. H. and Yang, L. and Sumbul, E. and Wu, T. F. and Gandhi, J. and Tamma, C. and Arslan, U. and Yi, B. and Naous, R. and Diefenbaugh, P. and Beigne, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10873454 },
  abstract={Wearable augmented reality (AR) devices will create new AI-enabled user experiences; but realization of this opportunity is challenged by the power and size of memory technologies. We seek to overcome these limitations. Low energy 3D interconnects enable integration of either SRAM or DRAM chiplets in compact packages. A wide interface of 33K and 0.9K connections is achieved, respectively. Moreover, cooptimizing memory for workload characteristics, reduces component energy >47% for AI workloads. These memories, along with emerging compute-in-memory subsystems, are evaluated in systems to establish the opportunities and challenges of these technologies for on-device AI in wearable AR systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEDM50854.2024.10873454 },
  booktitle={ 2024 IEEE International Electron Devices Meeting (IEDM) },
  chapter={0}
}

@article{rayyan-352343395,
  title={ LLM - TG: Towards Automated Test Case Generation for Processors Using Large Language Models  -  2024 IEEE 42nd International Conference on Computer Design (ICCD) },
  year={2024},
  author={Deng, Y. and Chen, R. and Xiao, C. and Yang, Z. and Luo, Y. and Zhao, J. and Li, N. and Wan, Z. and Ai, Y. and Dai, H. and Wang, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817956 },
  abstract={Design verification (DV) has existed for decades and is crucial for identifying potential bugs before chip tape- out. Hand-crafting test cases is time-consuming and error-prone, even for experienced verification engineers. Prior work has attempted to lighten this burden by rule-guided random test case generation. However, this approach does not eliminate the manual effort required to write rules that describe detailed hardware behavior. Motivated by advances in large language models (LLMs), we explore their potential to capture register transfer level (RTL) behavior and construct prompts for test case generation based on RTL behavior. First, we introduce a prompt framework, LLM - Driven Test Generation (LLM - TG), to generate test cases, thereby enhancing LLMs' test generation capabilities. Additionally, we provide an open-source prompt library that offers a set of standardized prompts for processor verification, aiming to improve test generation efficiency. Lastly, we use an LLM to verify a 12-stage, multi-issue, out-of-order RV64GC processor, achieving at least an 8.34 % increase in block coverage and at least a 5.8 % increase in expression coverage compared to the state-of-the-art (SOTA) methods, LLM4DV and RISCV- DV. The prompt library is available at https://github.com/LLM-TGIPrompt_Library.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCD63220.2024.00066 },
  booktitle={ 2024 IEEE 42nd International Conference on Computer Design (ICCD) },
  chapter={0}
}

@article{rayyan-352343396,
  title={ 2 Early Roots of Generative AI Models and LLM: A Diverse Landscape  -  Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  author={Ashwini, A. and Kavitha, V. and Balasubramaniam, S. and Kadry, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11164762.pdf&bkn=11164515&pdfType=chapter },
  abstract={The development of large language models (LLM) in generative modeling traces important characteristics through the differed landscapes that are under the effective characteristics through the various emerging technologies. There is a rapid increase in LLM that has attracted numerous researchers, leaders along the public. From a technical perspective, these forms of algorithms always produce content that combines with humanized instructions which aids in creating the instructions and the model structure that completes the assignment patterns. This holds two main processes: the first is where there is an extraction of rules and the generation of the retrieved content. The systems that have been working with rule-based have dominated in generating the model language by facing the issues with system complexity. The models with the computational AI systems have created a greater revolution. It was first developed by creating Gaussian mixture models in the 1950s along with the hidden Markov models. With the use of these models, the sequential data using the speech with the time series approach was developed. This mode of approach develops attraction in the years to come, where the novel methods will be updated regularly, creating life-to-language models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  chapter={0}
}

@article{rayyan-352343397,
  title={ DevSec-GPT — Generative-AI (with Custom-Trained Meta's Llama2 LLM), Blockchain, NFT and PBOM Enabled Cloud Native Container Vulnerability Management and Pipeline Verification Platform  -  2024 IEEE Cloud Summit },
  year={2024},
  author={Bandara, E. and Shetty, S. and Mukkamala, R. and Rahman, A. and Foytik, P. and Liang, X. and Zoysa, K. De and Keong, N. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10631014 },
  abstract={The ever-evolving realm of cloud-native software development and container-based deployment, although offering exceptional efficiency and scalability, presents an array of complex challenges. These prominent challenges encompass supply-chain attacks, vulnerabilities within open-source tools, difficulties in tracking the development lifecycle and pipelines, and intricacies related to managing data provenance. In response to these pressing concerns, this paper introduces “DevSec-GPT,” a pioneering solution that harnesses Generative AI, blockchain, NFTs, SBOMs (Software Bill Of Materials), and PBOMs (Pipeline Bill Of Materials) to effectively manage software container vulnerabilities and streamline the intricate intricacies of pipeline and supply-chain verification. In the contemporary software development landscape, cloud-native containers, such as Docker and Kubernetes, are the linchpins of the build and deploy process, complemented by CI/CD (Continuous Integration and Continuous Delivery) services such as GitHub Actions. This process entails the creation of pull requests, container generation, test suite execution, verification, approval, merging to the master branch, and eventual deployment. In our innovative system, blockchain smart contracts play a pivotal role in generating vulnerability scans for each pull request through SBOM analysis. Moreover, a custom-trained Llama2 Large Language Model(LLM) from Meta has been integrated to generate PBOMs tailored to each pull request and master builds, thereby preventing supply-chain attacks and data breaches etc. This Llama2-13B LLM has been quantized and fine-tuned using Qlora to ensure optimal performance on consumer-grade hardware. These PBOMs are generated as JSON schemas by the LLM, encapsulating vital details, including pull request information (branch, approver, reviewer, timestamp, etc.), test results, the identified vulnerabilities in the built container, and the status of the pull request and its timestamp. Subsequently, blockchain smart contracts employ these JSON schemas to generate signed NFT tokens. a remarkable method that enables comprehensive tracking of software container states, vulnerabilities, and pipeline details from development to production. We've innovated a tailor-made NFT token schema designed to encapsulate PBOM data within the blockchain. These NFT tokens furnish a resilient mechanism, facilitating retrieval and verification at any point. The end-to-end software/pipeline verification data provenance information is handled via ModelCards. The prototype of our proposed system has been constructed atop the Rahasak blockchain, complemented by the GitHub Actions CI/CD platform and Docker containers. The generation of PBOMs functions are handled by custom-trained Llama2-13B LLM. To the best of our knowledge, this is the very first research effort aimed at standardizing PBOM schemas and integrating Language Model algorithms for the generation of PBOMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Cloud-Summit61220.2024.00012 },
  booktitle={ 2024 IEEE Cloud Summit },
  chapter={0}
}

@article{rayyan-352343398,
  title={ Abstractive Summarization of YouTube Videos Using LaMini-Flan-T5 LLM  -  2024 Second International Conference on Advances in Information Technology (ICAIT) },
  year={2024},
  author={A, S. and R.P, P. and V, H. and R, S. Kumar and S, S. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690747 },
  abstract={In today's era, YouTube is considered as one of the best places to look for quality videos. Videos about ant topics can be found in YouTube. But the large volume of content in YouTube can be overwhelming for some people. This could be due to two reasons: people find that watching length videos are inefficient and selective the right video to watch. To tackle this problem, we have devised a solution called “YouTube Summarizer” built using artificial intelligence technology. YouTube Summarizer is an AI web application built using large language models and trained on large corpus to imitate human-like language. It works by providing a detailed summary of a YouTube video using LaMini-Flan-T5 model, which is a fine-tuned version of Google's Flan T5 LLM. The aim is to get the transcript of the YouTube video by retrieving the Video's ID by the YouTube API, tokenize the text using tokenization modules, loading a LLM and integrating using Hugging Face pipeline to summarize the text. We then use Text-To-Speech API to convert the generated summarized text into audio. This entire application is wrapped by Streamlit interface.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIT61638.2024.10690747 },
  booktitle={ 2024 Second International Conference on Advances in Information Technology (ICAIT) },
  chapter={0}
}

@article{rayyan-352343399,
  title={ Towards Ordinal Data in LLM Evaluation Meta-analysis: A Non-parametric Perspective  -  2025 IEEE 6th International Conference on Pattern Recognition and Machine Learning (PRML) },
  year={2025},
  author={Anbar, F. and Mikriukov, A. and Plaksin, Y. and Sitnikov, V. and Succi, G. and Tormasov, A. and Trofimova, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159734 },
  abstract={Ordinal data—data that are ordered categories but do not assume equal spacing between values—are firmly entrenched in social and biomedical research. Ordinal data, regardless of their prevalence, are most frequently analyzed through inappropriate parametric tests, leading to false results. The present study investigates appropriate statistical analysis of ordinal data on the basis of large language model (LLM) testing. From a collection of highly sophisticated LLM-created customized supplement regimens tested on ordinal scales by three GPT models, we report results using non-parametric testing in the form of the Mann-Whitney U test. Our findings establish statistically significant differences in evaluation models for many users, which provide evidence of variability in model judgment and necessity of proper ordinal data analysis. This article highlights the need for solid methodological precaution when performing ordinal scale analyses during AI testing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PRML66062.2025.11159734 },
  booktitle={ 2025 IEEE 6th International Conference on Pattern Recognition and Machine Learning (PRML) },
  chapter={0}
}

@article{rayyan-352343400,
  title={ Cost-Effective Extension of DRAM-PIM for Group-Wise LLM Quantization  -  IEEE Computer Architecture Letters },
  author={Kim, B. and Lee, C. and Kim, G. and Park, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10886951 },
  abstract={Processing-in-Memory (PIM) is emerging as a promising next-generation hardware to address memory bottlenecks in large language model (LLM) inference by leveraging internal memory bandwidth, enabling more energy-efficient on-device AI. However, LLMs’ large footprint poses significant challenges for accelerating them on PIM due to limited available space. Recent advances in weight-only quantization, especially group-wise weight quantization (GWQ), reduce LLM model sizes, enabling parameters to be stored at 4-bit precision or lower with minimal accuracy loss. Despite this, current PIM architectures experience performance degradation when handling the additional computations required for quantized weights. While incorporating extra logic could mitigate this degradation, it is often prohibitively expensive due to the constraints of memory technology, necessitating solutions with minimal area overhead. This work introduces two key innovations: 1) scale cascading, and 2) an INT2FP converter, to support GWQ-applied LLMs on PIM with minimal dequantization latency and area overhead compared to FP16 GEMV. Experimental results show that the proposed approach adds less than 0.6% area overhead to the existing PIM unit and achieves a 7% latency overhead for dequantization and GEMV in 4-bit GWQ with a group size of 128, compared to FP16 GEMV, while offering a 1.55× performance gain over baseline dequantization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LCA.2025.3532682 },
  booktitle={ IEEE Computer Architecture Letters },
  chapter={0}
}

@article{rayyan-352343401,
  title={ How to Regulate Large Language Models for Responsible AI  -  IEEE Transactions on Technology and Society },
  author={Berengueres, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536000 },
  abstract={Large Language Models (LLMs) are predictive probabilistic models capable of passing several professional tests at a level comparable to humans. However, these capabilities come with ethical concerns. Ethical oversights in several LLM-based products include: (i) a lack of content or source attribution, and (ii) a lack of transparency in what was used to train the model. This paper identifies four touchpoints where ethical safeguards can be applied to realize a more responsible AI in LLMs. The key finding is that applying safeguards before the training occurs aligns with established engineering practices of addressing issues at the source. However, this approach is currently shunned. Finally, historical parallels are drawn with the U.S. automobile industry, which initially resisted safety regulations but later embraced them once consumer attitudes evolved.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TTS.2024.3403681 },
  booktitle={ IEEE Transactions on Technology and Society },
  chapter={0}
}

@article{rayyan-352343402,
  title={ Enhancing Systematic Literature Reviews: Evaluating the Performance of LLM-Based Tools Across Key Systematic Literature Review Stages  -  2025 5th International Conference on Advanced Research in Computing (ICARC) },
  year={2025},
  author={Silva, N. and Wickramaarachchi, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963273 },
  abstract={AI-based tools are reshaping systematic literature reviews (SLRs), offering transformative capabilities in literature retrieval, research visualization, and summarization. This research evaluates the performance of platforms such as SciSpace, Elicit, ResearchRabbit, Scite.ai, Consensus, Claude.ai, ChatGPT, Google Gemini, Perplexity, and Microsoft Co-Pilot across the key stages of SLRs—planning, conducting, and reporting. While these tools significantly enhance workflow efficiency and accuracy, challenges remain, including variability in result quality, limited access to advanced features in free-tier versions, and the necessity for human oversight to validate outputs. To address these challenges, this research introduces guidelines for effectively integrating AI tools into SLR processes, emphasizing hybrid workflows that combine AI efficiency with human expertise. The findings underscore the potential of AI to streamline SLRs while highlighting the importance of addressing tool limitations and ensuring adherence to academic and ethical standards. Future work should expand into interdisciplinary research, explore comparisons with traditional methodologies, and validate proposed best practices to further harness LLM’s potential in advancing systematic reviews across diverse research domains.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICARC64760.2025.10963273 },
  booktitle={ 2025 5th International Conference on Advanced Research in Computing (ICARC) },
  chapter={0}
}

@article{rayyan-352343403,
  title={ An Extended Review: LLM Prompt Engineering in Cyber Defense  -  2024 International Conference on Electrical, Computer and Energy Technologies (ICECET },
  year={2024},
  author={Shenoy, N. and Mbaziira, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698605 },
  abstract={The launch of ChatGPT in November 2022 marked a significant advancement in the field of artificial intelligence, particularly in the realm of generative AI (GAI). ChatGPT is based on the Large Language Model (LLM). Use of AI in Cybersecurity can prove to be beneficial as the security analysts are employing AI models for improved detection of threats and quicker response to incidents. The interaction with LLMs needs to be skillfully and tactfully created to get precise and concise response. This technique of crafting queries to interact with the LLM is called prompt engineering. Prompt engineering in vulnerability detection and management is a new trend in the industry to manage cybersecurity threats and weaknesses proactively and effectively. This paper presents an extensive review of the field of prompt engineering in cybersecurity. It is primarily based on a comprehensive analysis of existing literature, encompassing a wide range of sources to provide a thorough overview of the current state and advancements in AI. The review delves into various aspects of prompt engineering, synthesizing key findings and theories from a multitude of scholarly articles and industry reports. This approach ensures a holistic understanding of the AI models including LLMs and how generative AI, in terms of prompt engineering, can be used for cyber-defense.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECET61485.2024.10698605 },
  booktitle={ 2024 International Conference on Electrical, Computer and Energy Technologies (ICECET },
  chapter={0}
}

@article{rayyan-352343404,
  title={ The ≪Huh?≫ Button: Improving Understanding in Educational Videos with Large Language Models  -  2024 International Symposium on Multimedia (ISM) },
  year={2024},
  author={Ruf, B. and Detyniecki, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10935983 },
  abstract={We propose a simple way to use large language models (LLMs) in education. Specifically, our method aims to improve individual comprehension by adding a novel feature to online videos. We combine the low threshold for interactivity in digital experiences with the benefits of rephrased and elaborated explanations typical of face-to-face interactions, thereby supporting to close knowledge gaps at scale. To demonstrate the technical feasibility of our approach, we conducted a proof-of-concept experiment and implemented a prototype which is available for testing online. Through the use case, we also show how caching can be applied in LLM-powered applications to reduce their carbon footprint.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISM63611.2024.00064 },
  booktitle={ 2024 International Symposium on Multimedia (ISM) },
  chapter={0}
}

@article{rayyan-352343405,
  title={ LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model  -  2024 2nd International Conference on Foundation and Large Language Models (FLLM) },
  year={2024},
  author={Lykov, A. and Tsetserukou, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852491 },
  abstract={This paper introduces a pioneering methodology in autonomous robot control, denoted as LLM-BRAIn, enabling the generation of adaptive behaviors in robots in response to operator commands, while simultaneously considering a multitude of potential future events. Unlike traditional step-by-step behavior generation methods, LLM-BRAIn leverages a behavior tree (BT) format that inherently encompasses various potential outcomes, thus reducing the frequency of model queries and optimizing resource utilization and decision-making time. LLM-BRAIn is a transformer-based Large Language Model (LLM) fine-tuned from the Stanford Alpaca 7B model to generate a BT from text descriptions. The model was trained on 8.5k instruction-following demonstrations generated using GPT-3.5. LLM-BRAIn accurately builds complex robot behavior while remaining small enough to run on the robot’s onboard microcomputer. The model generates structurally and logically correct BTs and can manage instructions not presented in the training set. Experiments revealed no significant subjective differences between BTs generated by LLM-BRAIn and human-created BTs, with participants distinguishing between them correctly in only 4.53 out of 10 cases, indicating performance close to random chance.The proposed approach holds promise for applications across various domains, including mobile robotics, drone operations, robot manipulator systems, and Industry 5.0. This applicability stems from the BT framework’s inherent consideration of numerous potential outcomes, obviating the need for exhaustive deliberation at each step, thereby expediting the robot’s operations. We provide a dataset for LLM-BRAIn replication: huggingface.co/datasets/ArtemLykov/LLM BRAIn dataset.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FLLM63129.2024.10852491 },
  booktitle={ 2024 2nd International Conference on Foundation and Large Language Models (FLLM) },
  chapter={0}
}

@article{rayyan-352343406,
  title={ Prevention of Prompt Injection Attacks Over Financial Applications Integrated with LLM  -  2025 3rd International Conference on Advancement in Computation & Computer Technologies (InCACCT) },
  year={2025},
  author={Joshi, T. and Naik, V. and Mistry, I. and Mangrulkar, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011372 },
  abstract={Prompt injection is a growing concern in financial applications integrated with Large Language Models. These attacks pose a critical risk to financial applications leading to data breaches, confidential data loss and financial losses by manipulating input prompts to cause unintended or harmful outputs. Existing defense strategies include utilizing filters f or input and output, and delimiters, however, these techniques have been proven inadequate. This paper builds upon existing mechanisms and proposes an enhanced security system that incorporates role-based access, jailbreak attack detection, validating inputs and securely passing prompts to LLM. This is done by developing a pre-processing layer at both ends-the client and LLMs-through the identification of critical as well as destructive keywords. The experimental results show that blocking of that malicious prompt ensures that only authenticated and authorized commands are processed. The measures, therefore, allow financial institutions to significantly reduce the probability of prompt injection attacks besides increasing data protection and confidence i n AI-based financial applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/InCACCT65424.2025.11011372 },
  booktitle={ 2025 3rd International Conference on Advancement in Computation & Computer Technologies (InCACCT) },
  chapter={0}
}

@article{rayyan-352343407,
  title={ Exploring LLM Tools Through the Eyes of Industry Experts and Novice Programmers  -  2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT) },
  year={2024},
  author={Tona, C. and Juárez-Ramírez, R. and Jiménez, S. and Durán, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795589 },
  abstract={At present, Large Language Models (LLM) and Generative AI models have emerged and impacted industry and society. LLMs are Artificial intelligence (AI) systems designed to understand and generate human language. The rise in popu-1arity of LLM-based systems has motivated research into their use in education, including code generation tools, automated feedback systems, and support for student software projects. The release of ChatGPT™ marked a significant milestone, providing an accessible tool for IA interaction. ChatGPT™ has gained popularity among students, not only in software areas. This study analyzes the perspectives of software engineering students and software engineers on using LLM tools such as ChatGPT™ for software development projects. In this study, we use a questionnaire to analyze different viewpoints and graphics to show the experiment results between these groups. The findings of this study are expected to provide valuable contributions to the understanding of how LLM tools are perceived in the context of software development and their potential implications for educational practices and industry standards.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONISOFT63288.2024.00048 },
  booktitle={ 2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT) },
  chapter={0}
}

@article{rayyan-352343408,
  title={ AI-Analyst: An AI-Assisted SDLC Analysis Framework for Business Cost Optimization  -  IEEE Access },
  author={Faruqui, N. and Thatoi, P. and Choudhary, R. and Roncevic, I. and Alqahtani, H. and Sarker, I. H. and Khanam, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804767 },
  abstract={Managing the System Development Lifecycle (SDLC) is a complex task because of its involvement in coordinating diverse activities, stakeholders, and resources while ensuring project goals are met efficiently. The complex nature of the SDLC process leaves plenty of scope for human error, which impacts the overall business cost. This paper introduces AI-Analyst, an AI-assisted framework developed using the transformer-based model with more than 150 million parameters to assist with SDLC management. It minimizes manual effort errors, optimizes resource allocation, and improves decision-making processes, resulting in substantial cost savings. The statistical analysis shows that it saves around 53.33% of costs in an experimental project. The transformer model has been trained with a uniquely prepared dataset tailored for SDLC through transfer learning. It achieved impressive results, with an accuracy of 91.5%, precision of 91.9%, recall of 91.3%, and an F1-score of 91.5%, demonstrating its high reliability and performance. The perplexity score of 15 further indicates the model’s strong language understanding capabilities to retrieve relations from complex characteristics of Natural Language Processing (NLP). The AI-Analyst framework represents a significant advancement in integrating Large Language Models (LLMs) into SDLC, offering a scalable and cost-effective solution for optimizing business processes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3519423 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343409,
  title={ AI-Powered, But Power-Hungry? Energy Efficiency of LLM-Generated Code  -  2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  year={2025},
  author={Solovyeva, L. and Weidmann, S. and Castor, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052793 },
  abstract={Large language models (LLMs) are used in software development to assist in various tasks, e.g., code generation and code completion, but empirical evaluations of the quality of the results produced by these models focus on correctness and ignore other relevant aspects, such as their performance and energy efficiency. Studying the performance of LLM-produced programs is essential to understand how well LLMs can support the construction of performance- and energy-critical software, such as operating systems, servers, and mobile applications. This paper presents the first study analyzing the energy efficiency and performance of LLM-generated code for three programming languages Python, Java, and C++, on two platforms, a Mac and a PC, leveraging three frontier LLMs, Github Copilot, GPT-4o, and the recently-released OpenAI o1-mini, and targeting "hard" programming problems from LeetCode. Our results show that the models are much more successful in generating Python and Java than C++ code. Also, LLM-generated code sometimes surpasses an efficient human-written solution, although that is language-dependent and the language with the best results, Python, is the one where application performance and energy consumption tend to matter the least in practice. Furthermore, the performance of generated code is highly correlated across the two platforms, hinting at potential for results to be portable across platforms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Forge66646.2025.00012 },
  booktitle={ 2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  chapter={0}
}

@article{rayyan-352343410,
  title={ Sec-Llama: a Compact Fine-Tuned LLM for Network Intrusion Detection in Kubernetes Clusters  -  2025 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN) },
  year={2025},
  author={Abdennebi, A. and Nadjia, K. and Lahlou, L. and Younis, M. and Ould-Slimane, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140090 },
  abstract={In today’s interconnected world, cyber threats have grown both pervasive and sophisticated, especially in the Artificial Intelligence (AI) era, where digital systems face unprecedented risks. As companies and enterprises increasingly rely on Kubernetes to orchestrate an enormous number of microservices and deliver high-quality services to users, a serious security threat endangers the application flow. In particular, recent advances in generative AI have increased the pace, scale, and level of cyberattacks on microservice-based systems. At the network level, traditional defensive tools fail to detect these threats accurately and timely, increasing the average latencies of detection and remediation and hence, risking worse damages on the services and system levels. Due to their excessive computation and memory requirements, large language models (LLM) have not been considered viable network intrusion detection systems (NIDS) or tools within the Kubernetes clusters. We developed Sec-Llama, a compact LLM for intrusion detection. We demonstrated a case study where we applied a memory-efficient data-driven technique incorporating Byte-based transformation of the raw network flow, to optimize the model’s training and inference processes, on resource-wise, while maintaining a 96% threat detection F1-score. To facilitate the model’s training and deployment processes for users, we have developed an application to monitor, train, and launch our Sec-Llama for real-time inferences that took, on average, 21.1ms per inference while occupying only 172 MB.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLCN64995.2025.11140090 },
  booktitle={ 2025 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN) },
  chapter={0}
}

@article{rayyan-352343411,
  title={ End-to-End Deployment of the Educational AI Hub for Personalized Learning and Engagement: A Case Study on Environmental Science Education  -  IEEE Access },
  author={Sajja, R. and Sermet, Y. and Demir, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938135 },
  abstract={This study introduces an end-to-end framework for deploying conversational AI-enabled educational assistants, focusing on personalized support for students across diverse subject areas, including Business, Culture, Environmental Sciences, History, Politics, and Science, as outlined in our evaluation framework. The system leverages advanced conversational AI technologies to provide targeted, course-specific learning experiences by facilitating access to complex data and integrating seamlessly with Learning Management Systems (LMS) like Canvas. Key metrics—information retrieval accuracy, question-answering accuracy, and hallucination accuracy—were selected to rigorously evaluate the system’s ability to retrieve relevant contexts, generate accurate responses, and identify unanswerable questions. Additionally, the Educational AI Hub agents utilize innovative document parsing methods, such as the Nougat technique, to interpret content accurately, enabling adaptable academic support tailored to individual learning needs and extending to quantitative fields through code execution capabilities. This study also emphasizes the importance of accessibility, inclusivity, and user privacy. The results showcase the potential for enhanced engagement and improved understanding of environmental concepts and software tools, demonstrating the significant impact of conversational AI in educational settings, especially in disciplines involving complex data interactions. A case study, presented at the 12th International Congress on Environmental Modelling and Software, illustrates the Educational AI Hub’s effectiveness in enhancing student engagement and delivering personalized learning experiences in environmental sciences education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3554222 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343412,
  title={ Leveraging Large Language Models for Dynamic Scenario Building targeting Enhanced Cyber-threat Detection and Security Training  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Marantos, C. and Evangelatos, S. and Veroni, E. and Lalas, G. and Chasapas, K. and Christou, I. T. and Lappas, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825681 },
  abstract={As cybercrime is becoming increasingly sophisticated, effective cybersecurity is crucial to safeguard digital assets and protect critical infrastructures from emerging threats. Several security applications exploit recent advances in (Big) data analysis and Artificial Intelligence (AI) to prevent and respond to malicious activities. Towards this direction, supervised and unsupervised Machine Learning (ML) methods are used to detect anomalies or reveal patterns that may indicate potential threats. However, the successful implementation of these technologies requires security practitioners to undergo specialized training to fully understand and use AI-driven tools and data analytics. On the other hand, AI models themselves are vulnerable to a variety of cyber threats, which can compromise their training data and learning processes. To ensure the safe operation of these systems, especially when deployed in adversarial environments, it is crucial to create novel AI adversarial algorithms and models that are resilient against diverse security threats. This work presents a conceptual framework based on Large Language Models (LLMs) supported by a Multi-Agent layer for training of security practitioners in various advanced technologies and enhance ML models ability to detect and respond to emerging cyber threats effectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825681 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343413,
  title={ Exploring A LLM-Based Ubiquitous Learning Model for Elementary and Middle School Teachers  -  2024 6th International Conference on Computer Science and Technologies in Education (CSTE) },
  year={2024},
  author={Lyu, H. and Cheng, Y. and Fu, Y. and Yang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589995 },
  abstract={Generative AI presents both opportunities and challenges for primary and secondary teacher capacity development. With the advancement of large language models (LLMs), combining AI with teachers' ubiquitous learning is a topic of concern. This study discusses the necessity of building a ubiquitous learning model for teachers based on big model technology from three perspectives: the research status on ubiquitous learning and LLMs, policy, and teachers' needs, constructing a framework for LLMs to empower teachers' ubiquitous learning for three major scenarios: teaching, teaching and research, and learning. The LLMs can assist teachers to automate the generation of learning situation analysis, teaching objectives and teaching resources to improve efficiency and teaching quality. In the teaching and research scenarios, the LLMs help to develop training content, evaluate teaching and optimize suggestions to improve the teaching and research. In the learning scenario, the LLMs provide personalized resources, stage summaries and evaluation to promote teachers' professional development. In addition, this study proposes the design idea of generative AI prompts to optimize teachers' learning experience and help them better apply the LLMs for ubiquitous learning. However, here are still some potential challenges and risks in the application of LLMs in education. Therefore, we explored the challenges and risks of teacher’ s collaboration with LLMs and propose responses to them. At the same time, we also prospectively analyzed the iteration and development trends of LLMs technology and explored the potential impact of future technological advances on teachers' pervasive learning and professional development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSTE62025.2024.00039 },
  booktitle={ 2024 6th International Conference on Computer Science and Technologies in Education (CSTE) },
  chapter={0}
}

@article{rayyan-352343414,
  title={ Development of AI Agent Based on Large Language Model Platforms  -  2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  year={2025},
  author={Chen, J. and Peng, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11082094 },
  abstract={This paper explores the process and applications of AI agent development based on Large Language Model (LLM) platforms. It begins by introducing the fundamental concepts, working principles, and development history of LLM, emphasizing the advantages of pre-trained models in multitask learning. The paper then discusses the key technical steps involved in developing AI agent through development platforms. Additionally, it analyzes the technical challenges of LLM platforms in AI agent development. Finally, based on the construction and application process of the "Course Development Assistant" case study, this paper proposes future development directions for AI agent development on LLM platforms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIBD64986.2025.11082094 },
  booktitle={ 2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  chapter={0}
}

@article{rayyan-352343415,
  title={ From Manual to Automated Prompt Engineering: Evolving LLM Prompts with Genetic Algorithms  -  2025 IEEE Congress on Evolutionary Computation (CEC) },
  year={2025},
  author={Loss, L. A. and Dhuvad, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11043059 },
  abstract={Large Language Models (LLMs) have proven to be one of the most innovative and capable techniques in modern Artificial Intelligence (AI). However, the efficacy and consistency of LLMs still rely on the structure and quality of prompts (i.e., their input instructions). In real-world applications, the need for specialized prompt engineering, qualified staff, and domain knowledge often results in suboptimal performance and increased development costs. This paper explores the application of Genetic Algorithms (GAs) in generating and optimizing prompts for LLMs, with the aim of enhancing their performance across various tasks tackled by diversely skilled teams. Here, we customize a standard GA implementation to work with textual individuals, which are initialized and manipulated by LLM-defined crossover and mutation operators to evolve candidate prompts. This approach enables the automated discovery of LLM-based solutions across a broad range of problems with minimal human effort. This process allows LLMs to achieve optimized outputs that are comparable to or even superior to those obtained through expert, costly labor. We test our approach on four modern LLMs by OpenAI, Meta, and Mistral, and four domain-specific problems. Our results demonstrate quantitative improvements in both accuracy and efficiency compared to human prompt engineers. Achieving an average accuracy 24% higher than that of manual crafted prompts, our results also prove the viability and potential of autonomous optimization tools to discover high-performing prompt configurations, reducing the need for extensive human intervention and trial-and-error methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEC65147.2025.11043059 },
  booktitle={ 2025 IEEE Congress on Evolutionary Computation (CEC) },
  chapter={0}
}

@article{rayyan-352343416,
  title={ A Novel CAD Framework with Visual and Textual Interpretability: Multimodal Insights for Predicting Respiratory Diseases  -  2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP) },
  year={2024},
  author={Mukhlis, R. and Salem, S. and Kwon, H. and Hussain, J. and Aydin, A. A. and Al-Antari, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710824 },
  abstract={Generating textual interpretability using recent advancements in large language models (LLMs) is crucial for enhancing the efficiency of comprehensive computer-aided diagnosis (CAD) systems. This improves transparency between medical staff, intelligent CAD systems, and end-users by creating a trustworthy and effective intermediate medical diagnosis environment. In this paper, an innovative explainable throughout CAD system is introduced, designed to predict diseases from Chest X-rays (CXR) in a comprehensive scenario. The primary goal is to undertake multiple tasks that reduce the burden on medical staff and enrich CAD outcomes, including classification, visual explanations (heatmaps), and textual report generation. The proposed CAD system is developed through eight key steps: Data Collection and Annotation, Data Preparation, Text Vectorizations (Indexing), Visual Encoder, RAG-Fusion, Structural Prompt, XAI LLmTextual Reasoning (LLM Model), and Final Output (LLM textual report, image classification, and heatmap localization). The AI-based CAD system is trained and evaluated using the public benchmark MIMIC-CXR dataset with 14 different classes. The classification performance achieved an overall accuracy of $70 \%$, precision of $70 \%$, and F1-score of $0.60 \%$, while for text report generation, the system obtained an average BERTScore precision of 0.83, RougeL 0.16, and a Meteor score of 0.28. These promising results suggest the potential for further improvement of the CAD system and its applicability to real-world medical tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDAP64064.2024.10710824 },
  booktitle={ 2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP) },
  chapter={0}
}

@article{rayyan-352343417,
  title={ MoRE-LLM: Mixture of Rule Experts Guided by a Large Language Model  -  2024 IEEE International Conference on Data Mining (ICDM) },
  year={2024},
  author={Koebler, A. and Thon, I. and Buettner, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884197 },
  abstract={To ensure the trustworthiness and interpretability of AI systems, it is essential to align machine learning models with human domain knowledge. This can be a challenging and time-consuming endeavor that requires close communication between data scientists and domain experts. Recent leaps in the capabilities of Large Language Models (LLMs) can help alleviate this burden. In this paper, we propose a Mixture of Rule Experts guided by a Large Language Model (MoRE-LLM) which combines a data-driven black-box model with knowledge extracted from an LLM to enable domain knowledge-aligned and transparent predictions. While the introduced Mixture of Rule Experts (MoRE) steers the discovery of local rule-based surrogates during training and their utilization for the classification task, the LLM is responsible for enhancing the domain knowledge alignment of the rules by correcting and contextualizing them. Importantly, our method does not rely on access to the LLM during test time and ensures interpretability while not being prone to LLM-based confabulations. We evaluate our method on several tabular data sets and compare its performance with interpretable and non-interpretable baselines. Besides performance, we evaluate our grey-box method with respect to the utilization of interpretable rules. In addition to our quantitative evaluation, we shed light on how the LLM can provide additional context to strengthen the comprehensibility and trustworthiness of the model's reasoning process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDM59182.2024.00085 },
  booktitle={ 2024 IEEE International Conference on Data Mining (ICDM) },
  chapter={0}
}

@article{rayyan-352343418,
  title={ A Real Time Self-Generating Control for AI Platforms  -  2024 IEEE 18th International Symposium on Applied Computational Intelligence and Informatics (SACI) },
  year={2024},
  author={Trifan, M. and Ionescu, B. and Ionescu, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10619873 },
  abstract={Recent advancements in hardware and software implementations of Artificial Intelligence have sparked a multitude of revolutionary applications in the theory and implementation of AI algorithms and tools. Significant new developments have been driven by the application of the Transformer concept in the fields of Large Language Models (LLMs), Reinforcement Learning, and other areas. This in turn led to capturing long-range dependencies and contextual information based on data. More recently, strong positions in the AI research community, around the proper implementations and usage of certain Machine Learning (ML) applications, have been thoroughly debated. However, it is very much known, that ChatGPT and other like platforms, such as Llama, or large GNNs, suffer from a series of black-box drawbacks out of which the “factual accuracy”, “halucinations”, “overgeneralization” and others open loop LLMs were reported in the literature. This paper presents an Autonomic Computing (AC) closed-loop architecture that manages and gathers data from user prompts via a DOMifire module. The DOMifire acts as the sensor element of the LLM AC system, referred to as the Plant. This data is logically compared by an Expert System (ES), which serves as the core of the Autonomic Manager in the AC loop of the LLM, with the data obtained from the LLM's output―in this case, the responses generated by ChatGPT. After a reduced number of iterations, the results are evaluated using a Mean Absolute Scaled Error (MASE) metric. In the context of a time series, this process results in a stable set of sentences or rules produced by the Knowledge Base module. An example, in which the “Time Series” of AutoGluOn illustrates the AC - AI interactions for a complementary contributions to a more robust AI platform. An example of the interaction AC-AI is given in the Conclusion section of this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SACI60582.2024.10619873 },
  booktitle={ 2024 IEEE 18th International Symposium on Applied Computational Intelligence and Informatics (SACI) },
  chapter={0}
}

@article{rayyan-352343419,
  title={ WedaGPT — Generative-AI (with Custom-Trained Meta’s Llama2 LLM), Blockchain, Self Sovereign Identity, NFT and Model Card Enabled Indigenous Medicine Platform  -  2024 IEEE Symposium on Computers and Communications (ISCC) },
  year={2024},
  author={Bandara, E. and Foytik, P. and Shetty, S. and Mukkamala, R. and Rahman, A. and Liang, X. and Keong, N. W. and Zoysa, K. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10733674 },
  abstract={Traditional and indigenous medicine, deeply rooted in ancient traditions and wisdom, plays a crucial role in global healthcare and cultural identity. These practices provide treatments for illnesses such as cancer and bone injuries, which often lack effective remedies in Western medicine. However, these valuable systems face challenges like potential knowledge loss, undervaluation of practitioners’ expertise, and the risk of fraud due to the absence of credential verification mechanisms. In this research, we introduce "WedaGPT," a Generative AI-enabled platform that utilizes a custom-trained Meta’s Llama2 Large Language Model (LLM), Blockchain, self-sovereign identity (SSI), Non-Fungible Tokens (NFTs), and model cards to share traditional medical knowledge and address these issues. WedaGPT creates a collaborative ecosystem connecting doctors, medicine providers, therapists, patients, and technology experts, all committed to preserving and advancing traditional healing practices. This platform enables secure and transparent contributions from all stakeholders to patient well-being. Ancient medical recipe books are translated into English and digitized into PDF formats to enrich the platform’s knowledge base. These texts are used to fine-tune the Llama2 LLM, which has been quantized and optimized with Qlora for performance on consumer-grade hardware. Through a chat-based interface in the SSI-enabled mobile wallet, users can interact with the LLM and access detailed information on treatments, recipes, prescriptions, and healing methods. Additionally, users can consult remotely with doctors who prescribe treatments through this wallet. A key feature of WedaGPT is transforming ancient medicinal recipes into NFT tokens for sale on NFT marketplaces, giving traditional knowledge digital authenticity and economic value. Revenue from these sales is distributed among platform contributors, promoting equitable ownership and recognition. Medical recipe data, including treatment histories and physician details, are encapsulated in Model Cards and securely stored on the blockchain. This system offers mechanisms to verify doctors and treatments in a privacy-preserving way, potentially reducing fraud and medication errors.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCC61673.2024.10733674 },
  booktitle={ 2024 IEEE Symposium on Computers and Communications (ISCC) },
  chapter={0}
}

@article{rayyan-352343420,
  title={ Social Impact of AI on the Organization of Higher Education in Electrical Engineering and in Society  -  2025 34th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE) },
  year={2025},
  author={Fonseca, I. and Martins, N. Cid and Lopes, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11136314 },
  abstract={The way we access information has evolved continuously throughout human history. In 2022, the first global LLM appeared, ChatGPT. This innovation enabled direct interaction and precise answers to questions asked in natural written language. By 2025, the model evolved to support interaction through verbal natural language, with integration into systems such mobile devices, further expanding access to information. Since ChatGPT, many AI tools have emerged in different contexts. In Higher Education Institutions, there is a high level of concern about fundamental aspects of education, three of which stand out: the development of students' critical thinking, the real acquisition of essential competences, and engagement. Several studies have been carried out on the application of LLM in Higher Education. A short review will be presented. In society, changes are starting to be implemented and are expected to have a significant impact. Examples or trends on changes in the healthcare and justice systems will be introduced. The paper aims to show the current state of LLMs, their impact on education, on society, and consequently on the procedures within most present and future professions. To support this, a student survey was carried out, presenting their perception of the impact of LLM systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EAEEIE65428.2025.11136314 },
  booktitle={ 2025 34th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE) },
  chapter={0}
}

@article{rayyan-352343421,
  title={ Lessons from Building StackSpot Al: A Contextualized AI Coding Assistant  -  2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP) },
  year={2024},
  author={Pinto, G. and de Souza, C. R. B. and Neto, J. B. and de Souza, A. and Gotto, T. and Monteiro, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554711 },
  abstract={With their exceptional natural language processing capabilities, tools based on Large Language Models (LLMs) like ChatGPT and Co-Pilot have swiftly become indispensable resources in the software developer's toolkit. While recent studies suggest the potential productivity gains these tools can unlock, users still encounter drawbacks, such as generic or incorrect answers. Additionally, the pursuit of improved responses often leads to extensive prompt engineering efforts, diverting valuable time from writing code that delivers actual value. To address these challenges, a new breed of tools, built atop LLMs, is emerging. These tools aim to mitigate drawbacks by employing techniques like fine-tuning or enriching user prompts with contextualized information. In this paper, we delve into the lessons learned by a software development team venturing into the creation of such a contextualized LLM-based application, using retrieval-based techniques, called StackSpot Al. Over a four-month period, the team, despite lacking prior professional experience in LLM-based applications, built the product from scratch. Following the initial product release, we engaged with the development team responsible for the code generative components. Through interviews and analysis of the application's issue tracker, we uncover various intriguing challenges that teams working on LLM-based applications might encounter. For instance, we found three main group of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By understanding these lessons, software development teams could become better prepared to build LLM-based applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3639477.3639751 },
  booktitle={ 2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP) },
  chapter={0}
}

@article{rayyan-352343422,
  title={ Context-Aware Summarization for PDF Documents using Large Language Models  -  2024 International Conference on Expert Clouds and Applications (ICOECA) },
  year={2024},
  author={Ramprasad, A. and Sivakumar, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612472 },
  abstract={In an era characterized by the overflow of textual information, the demand for effective text summarization techniques has become increasingly evident. This research study presents a novel solution to address this demand: the development of a PDF Summarizer Generative AI Platform for context-aware text and document summarization. The developed platform empowers users to generate informative summaries from lengthy textual documents. It features an interface powered by Gradio for enabling user-friendly accessibility. Equipped with essential components such as OpenAI's language models for text comprehension, Chroma vector enables document embedding and conversational retrieval chains for contextual understanding, where the platform offers a comprehensive solution. Users can effortlessly upload documents in various formats, including PDFs, and interactively engage with the system to obtain concise summaries tailored to their specific requirements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICOECA62351.2024.00044 },
  booktitle={ 2024 International Conference on Expert Clouds and Applications (ICOECA) },
  chapter={0}
}

@article{rayyan-352343423,
  title={ Enrich Humanoids With Large Language Models (LLM)  -  2024 IEEE Global Engineering Education Conference (EDUCON) },
  year={2024},
  author={Antikatzidis, A. and Feidakis, M. and Marathaki, K. and Toumanidis, L. and Nikolaou, G. and Patrikakis, C. Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578585 },
  abstract={Human-like social robots (or humanoids) such as Softbank's NAO6, have been proven valuable assistants, able to advance State-of-the-Art of Technology in Education and Learning (TEL) as they are quite impressive “clones” of human behavior, and due to their relatable form, are often perceived as superior social companions. The rise of accessible Large Language Models and cloud computing, could transform robots like NAO6 - a rather obsolete robot with quite low computing capacity (Pentium CPU, 2–4 GB RAM)- into a capable social agent, able to adopt A.I. behavior. In the current paper, we present a solution to enrich Softbank NAO6 with A.I. capacity, in order to act as an LLM vessel. Specifically, we managed to connect an augmented AI chatbot to NAO6 by deploying corresponding Python APIs. In our showcase, a NAO6 acts as the ancient Greek Philosopher Plato that “guides the one who seeks wisdom” based on his theory. Our solution has been evaluated in real crowded settings as a proof-of-concept. Next steps involve to evaluate our solution in school classrooms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON60312.2024.10578585 },
  booktitle={ 2024 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343424,
  title={ Improving LLM-Driven Data Annotation Through Structured Instruction Engineering  -  2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  year={2025},
  author={Molchanova, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11154345 },
  abstract={This paper introduces a method for enhancing the performance of an LLM-based AI agent designed for data annotation. We present a technique for structuring the agent's instructions and evaluate its efficacy across diverse models from multiple providers. The proposed method supports the ongoing paradigm shift in data an-notation-from human-human to human-machine interaction between a manager and an annota-tor-and underscores the significance of LLMs in facilitating this transformation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHMS65439.2025.11154345 },
  booktitle={ 2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS) },
  chapter={0}
}

@article{rayyan-352343425,
  title={ Engineering Data Funnel (WIP) – An Ontology-Enhanced LLM-Based Agent and MoE System for Engineering Data Processing  -  2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA) },
  year={2024},
  author={Schoch, N. and Hoernicke, M. and Strem, N. and Stark, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10710789 },
  abstract={Automation Engineering of a process automation system is still a very manual effort due to limited support for the interpretation and processing of process design specification documents. Even though standards for digital data exchange between process and automation engineering do exist, those formats are rarely used and consequently the immense automation potential in automation engineering cannot be lifted. This contribution presents an AI -based approach and prototype - using an ontology-enhanced LLM -based agent and a mixture-of-experts system - to structure and formalize multimodal unstructured process design information as in PDF, Excel, and Word formats and make it available for state-of-the-art engineering tools for the long-known “Automation of Automation”.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETFA61755.2024.10710789 },
  booktitle={ 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA) },
  chapter={0}
}

@article{rayyan-352343426,
  title={ Comparing Fine Tuned-LMs for Detecting LLM-Generated Text  -  2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON) },
  year={2024},
  author={Shukla, S. M. and Magoo, C. and Garg, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10866497 },
  abstract={With the introduction of LLMs (Large Language Models), NLP has demonstrated strong skills in a variety of applications, including question answering, language translation, and text summarization. As a result, their use in our day-to-day activities and at work has gained general acceptability. It is nevertheless imperative to develop cutting-edge procedures or approaches since, despite their enormous capabilities, they are still unable to live up to human expectations. It is crucial to apply the cutting-edge methods that enable LLMs to specialize in specific fields and reduce any potential for abuse. In contrast, our study has concentrated on employing fine-tuned LLM as detectors to determine whether a text was produced by a machine or by a person. Comparing how well various fine-tuned LMs function as content detectors-that is, as indicators of whether or not material is generated by LLMs-is the goal of this research. Three distinct fine-tuned LLMs are used to solve this binary classification problem: Fas'I'Text, also known as Generative Pre- Trained Transformers; DistilBERT; and BERT, or Bidirectional Encoder Representations from Transformers. The models were tested using various performance metrics, including precision, recall, Fl score, MCC, NPV, and FDR. The results showed that the BERT model outperformed the FasTText and DistilBERT models, which displayed overfitting tendencies when fine-tuned under comparable settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DELCON64804.2024.10866497 },
  booktitle={ 2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON) },
  chapter={0}
}

@article{rayyan-352343427,
  title={ AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection  -  2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  year={2025},
  author={Shi, Y. and Tao, Z. and Gao, Y. and Huang, L. and Wang, H. and Yu, Z. and Lin, T. -J. and He, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105794 },
  abstract={Multimodal large language models (MLLM) struggle to understand circuit schematics due to their limited recognition capabilities. This could be attributed to the lack of high-quality schematic-netlist training data. Existing work such as AMSnet applies schematic parsing to generate netlists. However, these methods rely on hard-coded heuristics and are difficult to apply to complex or noisy schematics in this paper. We therefore propose a novel net detection mechanism based on segmentation with high robustness. The proposed method also recovers positional information, allowing digital reconstruction of schematics. We then expand the AMSnet dataset with schematic images from various sources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with schematic images, Spectre-formatted netlists, OpenAccess digital schematics, and positional information for circuit components and nets, whereas AMSnet only includes 792 circuits with SPICE netlists but no digital schematics.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLAD65226.2025.00014 },
  booktitle={ 2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  chapter={0}
}

@article{rayyan-352343428,
  title={ WIP: Beyond Code: Evaluating ChatGPT, Gemini, Claude, and Meta AI as AI Tutors in Computer Science and Engineering Education  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Nath, S. and Yoon, S. Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893528 },
  abstract={This Work-in-Progress research paper evaluates the validity of Large Language Models (LLMs) as conversational AI tutors for computer science learning. While current engineering education literature has predominantly emphasized the rapid evolution of LLMs as conversational AI tutors for programming languages, the exploration into their effectiveness within general STEM topics remains comparatively scarce. This WIP study thus centers on evaluating the potential of LLMs to facilitate understanding of core hardware design concepts critical to computer science and engineering (CSE) education. By cross-checking the responses from generative AI chatbots to an openended CSE-based question, we aimed to uncover how LLMs, such as ChatGPT-3.5, Claude, Gemini, and Meta AI, can contribute to teaching and learning of general CSE courses instead of a specifically coding-based one. Our method involved simulating a student query on the popular debate between CISC vs. RISC related to computer architecture and analyzing the chatbots' responses. This initial collection of data served as the foundation for a continual comparative analysis aimed at determining the inherent instructional value of each LLM and its validity and reliability. To systematically assess the responses, we introduced an evaluation framework focusing on metrics, such as response accuracy, persuasiveness, and depth of explanation. The current work anticipates not only enriching our understanding of how these advanced LLMs can support general CSE education but also identifying areas where further development is needed for a more holistic integration of LLM-based chatbots in assisting student comprehension in the overarching engineering education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893528 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343429,
  title={ LLM-Therapist: A RAG-Based Multimodal Behavioral Therapist as Healthcare Assistant  -  GLOBECOM 2024 - 2024 IEEE Global Communications Conference },
  year={2024},
  author={Shafi, F. R. and Hossain, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10901139 },
  abstract={Systems and services based on Large Language Models (LLM) are trending in the applied field of Artificial Intelligence (AI). The emergence of GPTs and subsequent improvements such as, unsupervised pre-training and transformer architecture have lead to its ability to generate human-quality text and understand context effectively. This has opened huge opportunity in healthcare domain to use AI-based assistant systems that can offer tailored recommendations and guidance for patients in numerous scenarios by considering multimodal data. This paper proposes LLM-Therapist as a multimodal personalized health care assistant for various types of patients. The proposed system uses Retrieval Augmented Generation (RAG) technique to improve the quality, accuracy, and relevance of generated response, which is specially important in providing healthcare assistance. We conducted experiments with LLM-therapist by extracting knowledge from domain-specific resources in mental health and patient’s health data. Our experiments showed better efficiency and performance in providing personalized assistance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GLOBECOM52923.2024.10901139 },
  booktitle={ GLOBECOM 2024 - 2024 IEEE Global Communications Conference },
  chapter={0}
}

@article{rayyan-352343430,
  title={ Vulnerability Handling of AI-Generated Code - Existing Solutions and Open Challenges  -  2024 Conference on AI, Science, Engineering, and Technology (AIxSET) },
  year={2024},
  author={Kaniewski, S. and Holstein, D. and Schmidt, F. and Heer, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771069 },
  abstract={The increasing use of generative Artificial Intelligence (AI) in modern software engineering, particularly Large Language Models (LLMs) for code generation, has transformed professional software development by boosting productivity and automating development processes. This adoption, however, has highlighted a significant issue: the introduction of security vulnerabilities into the code. These vulnerabilities result, e.g., from flaws in the training data that propagate into the generated code, creating challenges in tackling them in established ways. Traditional vulnerability handling processes often involve extensive manual review. Applying such traditional processes to AI-generated code is challenging. AI-generated code may include several similar vulnerabilities, possibly in slightly different forms as developers might not build on already implemented code, using functions or libraries, but prompt similar tasks. In this work, we explore the current state of LLM-based approaches for vulnerability handling, focusing on approaches for vulnerability detection, localization, and repair. We provide an overview of recent progress in this area and highlight open challenges that must be addressed to establish a reliable and scalable vulnerability handling process for AI-generated code.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxSET62544.2024.00026 },
  booktitle={ 2024 Conference on AI, Science, Engineering, and Technology (AIxSET) },
  chapter={0}
}

@article{rayyan-352343431,
  title={ Having Faith in the System: How Can We Trust the AI?  -  Customer 360: How Data, AI, and Trust Change Everything },
  author={Kihn, M. and Lin, A. C.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10952217.pdf&bkn=10950212&pdfType=chapter },
  abstract={Summary <p>Prior generations of AI and ML technology focused on solving discrete tasks, whereas GenAI offers a wide range of diverse use cases and outputs. The downside of this versatility is a higher rate of error and risk. This chapter explores how to measure and manage these machine‐made outputs. GenAI models have a risk of leaking the training data either unintentionally or through prompt injection attacks. Open‐source LLMs are models whose source code, training data, or architecture details are made publicly available. Proprietary LLMs are owned and controlled by an organization so they are not freely available for public use, modification, or distribution. LLM technology has been born from years of research in academia with influence from industry. The Salesforce AI platform is delivered with a collection of safety guardrails called the Einstein Trust Layer. This is how Salesforce enables customers to achieve the benefits of AI while managing risk.</p>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1002/9781394308668.ch13 },
  booktitle={ Customer 360: How Data, AI, and Trust Change Everything },
  chapter={0}
}

@article{rayyan-352343432,
  title={ Leveraging Knowledge Graphs and LLMs for Context-Aware Messaging  -  2025 IEEE International Conference on Emerging Technologies and Applications (MPSec ICETA) },
  year={2025},
  author={Kumar, R. and Kumar, H. and Shalini, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118478 },
  abstract={Personalized messaging plays an essential role in improving communication in areas such as healthcare, education, and professional engagement. This paper introduces a framework that uses the Knowledge Graph (KG) to dynamically rephrase written communications by integrating individual and contextspecific data. The knowledge graph represents individuals, locations, and events as critical nodes, linking entities mentioned in messages to their corresponding graph nodes. The extraction of relevant information, such as preferences, professional roles, and cultural norms, is then combined with the original message and processed through a large language model (LLM) to generate personalized responses. The framework demonstrates notable message acceptance rates in various domains: $\mathbf{4 2 \%}$ in healthcare, 53% in education, and 78% in professional recruitment. By integrating entity linking, event detection, and language modeling, this approach offers a structured and scalable solution for context-aware, audience-specific communication, facilitating advanced applications in diverse fields.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MPSecICETA64837.2025.11118478 },
  booktitle={ 2025 IEEE International Conference on Emerging Technologies and Applications (MPSec ICETA) },
  chapter={0}
}

@article{rayyan-352343433,
  title={ GradPromptOpt: An Enhanced Prompt Optimization Method to Improve Performance of LLMs  -  2025 8th International Symposium on Big Data and Applied Statistics (ISBDAS) },
  year={2025},
  author={Zhong, J. and Tang, D. and Gu, M. and Xie, M. and Tao, Z. and Zhang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11116965 },
  abstract={In the application of Large Language Models (LLMs), the Prompt plays a crucial role as a key component influencing model performance. A well-crafted Prompt can significantly enhance an LLM's ability to perform specific tasks effectively. LLMs process Prompts by converting them into preceding tokens, which are then used to predict subsequent tokens. This process implicitly and uniquely translates human language into the model's semantic space-where even semantically similar Prompts can lead to vastly different outputs due to subtle variations in phrasing or structure. To mitigate the uncertainty introduced by diverse human language expressions and improve the adaptability of LLMs to various Prompts, we propose a novel method called GradPromptOpt (Gradient-Driven Prompt Optimization). This approach leverages the gradient-based optimization mechanisms inherent in LLMs and employs a carefully fine-tuned Meta Prompt to automate and refine the Prompt optimization process. GradPromptOpt aims to surpass the effectiveness of traditional, manually designed Prompts while reducing the reliance on subjective human input. Experimental results show that GradPromptOpt achieves a 31.75% performance improvement over high-quality, human-engineered Prompts, demonstrating its potential to enhance the efficiency and adaptability of LLMs in practical applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISBDAS64762.2025.11116965 },
  booktitle={ 2025 8th International Symposium on Big Data and Applied Statistics (ISBDAS) },
  chapter={0}
}

@article{rayyan-352343434,
  title={ Generative AI for Low-Level NETCONF Configuration in Network Management Based on YANG Models  -  2024 20th International Conference on Network and Service Management (CNSM) },
  year={2024},
  author={Hollósi, G. and Ficzere, D. and Varga, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814410 },
  abstract={The NETCONF protocol, standardized by the IETF, is a cutting-edge solution for configuring network entities and offers an alternative to SNMP in modern network devices. Due to the complexity of configuration protocols and the challenges in creating valid configurations, generative AI solutions are promising for converting textual prompts into configuration descriptors. However, the potential of LLMs to generate NETCONF configurations has not been explored in the literature. This paper addresses this gap by evaluating the performance of five different LLMs – including Llama3, an open-source, on-premises capable model – in creating NETCONF configurations using the widespread YANG data models. In order to create valid network configurations using generative AI, this paper proposes a pipeline for integrating domain knowledge into LLMs without additional training and highlights common shortcomings and errors that prevent the generation of valid configurations. The findings indicate that the use of LLMs is promising for this task, but the current state-of-the-art is not yet mature enough for immediate industrial application in complex cases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/CNSM62983.2024.10814410 },
  booktitle={ 2024 20th International Conference on Network and Service Management (CNSM) },
  chapter={0}
}

@article{rayyan-352343435,
  title={ Generative AI for Analog Integrated Circuit Design: Methodologies and Applications  -  IEEE Access },
  author={Zadeh, D. Noori and Elamien, M. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937153 },
  abstract={Electronic Design Automation (EDA) in analog Integrated Circuits (ICs) has been the focus of extensive research; however, unlike its digital counterpart, it has not achieved widespread adoption. In this systematic review, we discuss recent contributions in the last five years, highlighting methods that address data scarcity, topology exploration, process-voltage-temperature (PVT) variations, and layout parasitics. Our goal is to support researchers new to this domain by creating a comprehensive collection of references and practical application guidelines. We provide a methodological review of state-of-the-art machine learning (ML) approaches, including graph neural networks (GNNs), large language models (LLMs), and variational autoencoders (VAEs), which have been successfully applied to analog circuit sizing tasks. To the best of authors’ knowledge, this is the first review to comprehensively explore the application of generative AI models in analog IC circuit design. We conclude that future research could focus on few-shot learning with domain-adaptation training of generative AI methods to simplify the design tasks such as human-tool interaction or guided design space exploration.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3553743 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343436,
  title={ Intent-Driven Autonomous Reconfiguration for Telecom OSS: A Generative-AI-Empowered Hierarchical Multi-Agent Architecture  -  2025 25th Asia-Pacific Network Operations and Management Symposium (APNOMS) },
  year={2025},
  author={Lee, K. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181316 },
  abstract={Telecom Operation Support Systems (OSS) still depend on domain experts and ad-hoc scripts for network and service reconfiguration, a process that is labor-intensive, errorprone, and fragile whenever cross-domain dependencies-such as allocating an IP address before tearing down a VLAN—must be respected. The heterogeneity and dynamism anticipated for 6Gclass networks only magnify the shortcomings of today’s rigid, rule-based automation pipelines. This paper introduces an intent-driven, fully autonomous reconfiguration framework that integrates Generative AI with a hierarchical Multi-Agent architecture. At its core, a ReWOOenhanced Chief Agent transforms natural-language intents into a dependency-aware execution graph, utilizing a formally defined Command Pattern to explicitly specify actions and associated data for unambiguous inter-agent coordination. Atomic tasks-annotated with domain-specific constraints and keys governed by a Primary Key Pattern-are delegated to ReAct-based Specific Agents responsible for IP management, network control, cloud orchestration, and service management. Evaluation on a four-domain OSS testbed exposing over thirty RESTful APIs confirms accurate intent parsing, robust key-value consistency enforcement, strict adherence to create-before-destroy constraints, and seamless scalability from single-domain provisioning to complex cross-domain orchestration without code changes. The proposed work delivers a reusable agent blueprint decoupling global planning from domain execution; formal interagent interfaces curbing hallucination and enabling modular growth; an execution-aware extension to ReWOO for structured action planning; domain-driven guidelines for encapsulating OSS subsystems into loosely coupled agents; and a public OSS testbed for benchmarking future Agentic-AI architectures-collectively advancing OSS reconfiguration toward scalable, maintainable, and 6G-ready network operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/APNOMS67058.2025.11181316 },
  booktitle={ 2025 25th Asia-Pacific Network Operations and Management Symposium (APNOMS) },
  chapter={0}
}

@article{rayyan-352343437,
  title={ GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models  -  2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD) },
  year={2023},
  author={Fu, Y. and Zhang, Y. and Yu, Z. and Li, S. and Ye, Z. and Li, C. and Wan, C. and Lin, Y. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323953 },
  abstract={The remarkable capabilities and intricate nature of Artificial Intelligence (AI) have dramatically escalated the imperative for specialized AI accelerators. Nonetheless, designing these accelerators for various AI workloads remains both labor- and time-intensive. While existing design exploration and automation tools can partially alleviate the need for extensive human involvement, they still demand substantial hardware expertise, posing a barrier to non-experts and stifling AI accelerator development. Motivated by the astonishing potential of large language models (LLMs) for generating high-quality content in response to human language instructions, we embark on this work to examine the possibility of harnessing LLMs to automate AI accelerator design. Through this endeavor, we develop GPT4AIGChip, a framework intended to democratize AI accelerator design by leveraging human natural languages instead of domain-specific languages. Specifically, we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design, thus aiding our understanding of our current position and garnering insights into LLM-powered automated AI accelerator design. Furthermore, drawing inspiration from the above insights, we develop a framework called GPT4AIGChip, which features an automated demo-augmented prompt-generation pipeline utilizing in-context learning to guide LLMs towards creating high-quality AI accelerator design. To our knowledge, this work is the first to demonstrate an effective pipeline for LLM-powered automated AI accelerator generation. Accordingly, we anticipate that our insights and framework can serve as a catalyst for innovations in next-generation LLM-powered design automation tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCAD57390.2023.10323953 },
  booktitle={ 2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD) },
  chapter={0}
}

@article{rayyan-352343438,
  title={ On the Intersection of Explainable and Reliable AI for Physical Fatigue Prediction  -  IEEE Access },
  author={Narteni, S. and Orani, V. and Cambiaso, E. and Rucco, M. and Mongelli, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831436 },
  abstract={In the era of Industry 4.0, the use of Artificial Intelligence (AI) is widespread in occupational settings. Since dealing with human safety, explainability and trustworthiness of AI are even more important than achieving high accuracy. eXplainable AI (XAI) is investigated in this paper to detect physical fatigue during manual material handling task simulation. Besides comparing global rule-based XAI models (LLM and DT) to black-box models (NN, SVM, XGBoost) in terms of performance, we also compare global models with local ones (LIME over XGBoost). Surprisingly, global and local approaches achieve similar conclusions, in terms of feature importance. Moreover, an expansion from local rules to global rules is designed for Anchors, by posing an appropriate optimization method (Anchors coverage is enlarged from an original low value, 11%, up to 43%). As far as trustworthiness is concerned, rule sensitivity analysis drives the identification of optimized regions in the feature space, where physical fatigue is predicted with zero statistical error. The discovery of such “non-fatigue regions” helps certifying the organizational and clinical decision making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2022.3191907 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343439,
  title={ Enhancing International Graduate Student Experience through AI-Driven Support Systems: A LLM and RAG-Based Approach  -  2024 International Conference on Data Science and Its Applications (ICoDSA) },
  year={2024},
  author={Saha, B. and Saha, U.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10651944 },
  abstract={International graduate students encounter unique challenges that impede their academic and personal success. This paper introduces an AI-powered chatbot designed specifically for these students, utilizing advanced language models and Retrieval-Augmented Generation (RAG). Unlike generic solutions, our chatbot is tailored with a dataset curated from Reddit communi-ties frequented by international students, enabling it to provide highly relevant and actionable advice. The system combines GPT-3.5's generative capabilities with precise information retrieval to effectively guide students through academic procedures, cul-tural adjustments, and personal challenges. An evaluation shows that our RAG-enhanced model outperforms standard GPT-3.5, demonstrating significant improvements in response accuracy and relevance. This research not only advances AI applications in student support but also offers practical, real-time aid to enhance international students' educational experiences.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoDSA62899.2024.10651944 },
  booktitle={ 2024 International Conference on Data Science and Its Applications (ICoDSA) },
  chapter={0}
}

@article{rayyan-352343440,
  title={ Adapting Large Language Model with Speech for Fully Formatted End-to-End Speech Recognition  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Ling, S. and Hu, Y. and Qian, S. and Ye, G. and Qian, Y. and Gong, Y. and Lin, E. and Zeng, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10448204 },
  abstract={Most end-to-end (E2E) speech recognition models are composed of encoder and decoder blocks that perform acoustic and language modeling functions. Pretrained large language models (LLMs) have the potential to improve the performance of E2E ASR. However, integrating a pretrained language model into an E2E speech recognition model has shown limited benefits due to the mismatches between text-based LLMs and those used in E2E ASR. In this paper, we explore an alternative approach by adapting a pretrained LLMs to speech. Our experiments on fully-formatted E2E ASR transcription tasks across various domains demonstrate that our approach can effectively leverage the strengths of pretrained LLMs to produce more readable ASR transcriptions. Our model, which is based on the pretrained large language models with either an encoder-decoder or decoder-only structure, surpasses strong ASR models such as Whisper1, in terms of recognition error rate, considering formats like punctuation and capitalization as well.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10448204 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343441,
  title={ OpenEQA: Embodied Question Answering in the Era of Foundation Models  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Majumdar, A. and Ajay, A. and Zhang, X. and Putta, P. and Yenamandra, S. and Henaff, M. and Silwal, S. and Mcvay, P. and Maksymets, O. and Arnaud, S. and Yadav, K. and Li, Q. and Newman, B. and Sharma, M. and Berges, V. and Zhang, S. and Agrawal, P. and Bisk, Y. and Batra, D. and Kalakrishnan, M. and Meier, F. and Paxton, C. and Sax, A. and Rajeswaran, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654928 },
  abstract={We present a modern formulation of Embodied Question Answering (EQA) as the task of understanding an environment well enough to answer questions about it in natural language. An agent can achieve such an understanding by either drawing upon episodic memory, exemplified by agents on smart glasses, or by actively exploring the environment, as in the case of mobile robots. We accompany our formulation with OpenEQA - the first open-vocabulary benchmark dataset for EQA supporting both episodic memory and active exploration use cases. OpenEQA contains over 1600 high-quality human generated questions drawn from over 180 real-world environments. In addition to the dataset, we also provide an automatic LLM-powered evaluation protocol that has excellent correlation with human judgement. Using this dataset and evaluation protocol, we evaluate several state-of-the-art foundation models including GPT-4V, and find that they significantly lag behind human-level performance. Consequently, OpenEQA stands out as a straightforward, measurable, and practically rele-vant benchmark that poses a considerable challenge to current generation offoundation models. We hope this inspires and stimulates future research at the intersection of Embod-ied AI, conversational agents, and world models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.01560 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343442,
  title={ Adelia: A 4nm LLM Accelerator with Streamlined Dataflow and Dual-Mode Parallelization for Efficient Generative AI Inference  -  2025 Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits) },
  year={2025},
  author={Kim, J. -H. and Lim, S. and Cha, J. and Moon, S. and Seo, D. and Lee, H. and Kim, J. and Lee, J. and Kim, J. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11075108 },
  abstract={This paper presents Adelia, an efficient inference chip for large language models (LLMs) featuring a streamlined data-flow and dual-mode parallelization. The streamlined dataflow directly connects the external memory to Adelia's LLM-optimized compute engine with matched bandwidth, achieving an effective memory bandwidth usage of up to 91%. The systolic path between multiple engines facilitates data reuse to enhance computational power without compromising efficiency. Adelia dynamically transitions between context mode, which distributes the long context of a single request to optimize latency, and batch mode, which processes inputs from different requests to prioritize throughput based on the runtime status. Adelia is fabricated in 4nm technology and occupies $5.28\text{mm}^{2}$ in die area. Compared to the H100 GPU, it achieves 1.59x and 2.51x greater memory bandwidth efficiency and throughput efficiency, respectively, across various models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/VLSITechnologyandCir65189.2025.11075108 },
  booktitle={ 2025 Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits) },
  chapter={0}
}

@article{rayyan-352343443,
  title={ Automated Detection of AI-Generated Text Using LLM Embedding-Driven ML Models  -  2024 International Symposium on Electronics and Telecommunications (ISETC) },
  year={2024},
  author={Vacariu, A. -N. and Bucos, M. and Otesteanu, M. and Dragulescu, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10797258 },
  abstract={Large Language Models (LLM) have proved their ability in tasks once thought to be exclusive to humans, such as text sumarization, completion, question answering, and others. Although LLMs were present for some time, OpenAI's ChatGPT introduced them to a broader audience. Despite their ability to assist humans in various tasks, some concerns arise, as there is a big probability of misuse in areas such as fake news, plagiarism, and propaganda. Previous studies have shown that humans are unable to accurately detect generated text, which motivates the need for automated detectors. In this work, we explore whether machine learning models can distinguish between text written by humans and generated text when using embeddings as input. We process a publicly available data set, Human ChatGPT Comparison Corpus (HC3). The data set contains question-answer pairs in various domains, including open-domain, financial, medical, legal, and psychological areas. We are using Llama3, an open-source large language model, to generate the embeddings. We then evaluate the performance of four machine learning (ML) models in detecting text generated by ChatGPT with the text embeddings used as input. The ML models are the Support Vector Classifier, Naive Bayes, the K-Nearest Neighbors Classifier, and a neural network. The results show that relatively simple models can identify the generated text. SVC demonstrated the best results with an F1-score of 99.95%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISETC63109.2024.10797258 },
  booktitle={ 2024 International Symposium on Electronics and Telecommunications (ISETC) },
  chapter={0}
}

@article{rayyan-352343444,
  title={ LLM40FD: Unlocking the Potential of LLM for Anonymous Zero-Shot Fraud Detection  -  IEEE Transactions on Computational Social Systems },
  author={Yang, K. and Zhong, Z. and Sun, S. and Yu, Z. and Chen, C. L. P. and Zhang, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11037749 },
  abstract={Credit card (CC) fraud detection within the realm of financial security faces challenges such as data imbalance, large-scale anonymized transaction datasets, and the need for system-specific model training. Past methods often fail to address these aforementioned issues simultaneously. Utilizing a single model results in a lack of zero-shot capability without adaptation for real-world scenarios. This article introduces LLM40FD, a novel framework that leverages a large language model (LLM) to overcome these obstacles in anonymous zero-shot fraud detection. LLM40FD addresses the aforementioned challenges in CC fraud detection by employing a distribution-based one-class function and the walking embedding, without reliance on labeled data or fine-tuning in downstream. Additionally, LLM40FD enhances the model’s ability to detect fraudulent patterns and define robust decision boundaries. This is achieved through a dual-augmentation strategy and implicit contrastive learning, which generate enriched positive and negative samples. Our experiments demonstrate that LLM40FD not only achieves state-of-the-art (SOTA) performance in the full-shot setting but also exhibits strong zero-shot capability even with limited training data. Furthermore, we conduct additional experiments to validate the effectiveness and working mechanism of LLM40FD.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCSS.2025.3563954 },
  booktitle={ IEEE Transactions on Computational Social Systems },
  chapter={0}
}

@article{rayyan-352343445,
  title={ AI-Driven Panic Detection and Alert System Using Smartwatch and LLM Model  -  2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC) },
  year={2024},
  author={Pal, B. and Gupta, A. and Paul, S. and Rahaman, M. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10984154 },
  abstract={Technologically, most existing systems cannot detect distress autonomously through pattern recognition, further compounding the challenge of providing timely help. This research paper identifies the significant gap in the market for an automated, real-time alert system that provides a solution that does not require manual engagement. In response, an LLM-based Smartwatch-Based Panic Alert System (SBPAS) is proposed to integrate into smartwatches that continuously monitor heart rate, motion, and location biometric signals. By applying advanced machine learning models, the system detects abnormal patterns consistent with panic or distress and automatically triggers alerts to emergency contacts and local authorities. This eliminates the need for manual intervention, offering a faster, more reliable response in critical situations. The significance of this solution lies in its ability to reduce response times, improve the likelihood of timely assistance, eliminate the chance of not being notified about an emergency, and close the existing technological gap in safety infrastructure, particularly in regions where crimes against individuals are prevalent.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PDGC64653.2024.10984154 },
  booktitle={ 2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC) },
  chapter={0}
}

@article{rayyan-352343446,
  title={ Personalized Meal Planning in Inpatient Clinical Dietetics Using Generative Artificial Intelligence: System Description  -  2024 IEEE 12th International Conference on Healthcare Informatics (ICHI) },
  year={2024},
  author={Kopitar, L. and Stiglic, G. and Bedrac, L. and Bian, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628741 },
  abstract={This study addresses the limitations of traditional prescribed meal plans, which lack personalization and often prove monotonous and challenging for patients to follow. We propose a novel approach employing generative artificial intelligence in the context of a learning health system, with an emphasis on inpatient clinical dietetics. The system incorporates two key models: the Meal Plan Generation Model, MeaIGM, and the Meal Plan Image Generation Model, MealImageGM, leveraging state-of-the-art large language models. Patient information from electronic health records and clinical dietetics guidelines are incorporated into prompts for MeaIGM, which is refined through nutritionist validations and users' feedback. On the other hand, MealImageGM generates visual representations of meal plans to enhance patient engagement, utilizing crowd-sourced feedback to optimize image generation prompts. The overall system process includes extracting data from electronic health records, pre-designed user meal generation prompts, and the generation of personalized meal plans and images. Nutritionists play a crucial role in monitoring patient adherence and preferences, contributing to a continuous learning health system cycle. The proposed framework ensures clinically appropriate and personalized meal plans, aligning with dynamic dietary recommendations. The study emphasizes the importance of patient-physician co-creation for constant optimization and highlights the potential positive impact on health outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHI61247.2024.00049 },
  booktitle={ 2024 IEEE 12th International Conference on Healthcare Informatics (ICHI) },
  chapter={0}
}

@article{rayyan-352343447,
  title={ 16.3 An on-Device Generative AI Focused Neural Processing Unit in 4nm Flagship Mobile SoC with Fan-Out Wafer-Level Package  -  2025 IEEE International Solid-State Circuits Conference (ISSCC) },
  year={2025},
  author={Park, J. -S. and Lee, T. and Lee, H. and Park, C. and Cho, Y. and Kang, M. and Lee, H. and Kang, J. and Jeon, T. and Lee, D. and Kang, Y. and Kum, K. and Lee, G. and Lee, H. and Kim, M. and Kwon, S. and -b. Park, S. and Kim, D. and Jo, C. and Chung, H. and Kim, I. and Lee, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10904722 },
  abstract={A notable trend observed in on-device AI is natural progression from camera application-centric CNN-based neural networks to transformer-based generative AI (Gen AI) [1]. For instance, large language models (LLM) such as LLaMA [2] can support natural language understanding and human-like text generation while large visual models (LVM) such as Stable Diffusion [3] can generate images or 3D models based on user context. However, gen AI models exhibit different operational characteristics from traditional neural network (NN) models. LLMs require reading a several GB of weight data from DRAM every time a single token is generated during decoding, resulting in memory-intensive behavior. LVMs, on the other hand, are more compute-intensive than LLMs but have distinct operational characteristics, with softmax and layernorm accounting for 40% of total computation time [4], whereas CNNs typically consist of convolutions that account for the majority (90 to 99%) of operations in these networks. We report on neural processing unit (NPU) in 4nm Samsung Exynos™ 2400 that employs heterogeneous architecture consisting of vector engines and two types of tensor engines. NPU integrates a memory hierarchy and tiling techniques to support a wide range of neural networks. AI performance is boosted by enhancing heat dissipation through fan-out wafer level packaging (FOWLP).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISSCC49661.2025.10904722 },
  booktitle={ 2025 IEEE International Solid-State Circuits Conference (ISSCC) },
  chapter={0}
}

@article{rayyan-352343448,
  title={ EmoXpt: Analyzing Emotional Variances in Human Comments and LLM-Generated Responses  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Pyreddy, S. R. and Zaman, T. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903889 },
  abstract={The widespread adoption of generative AI has generated diverse opinions, with individuals expressing both support and criticism of its applications. This study investigates the emotional dynamics surrounding generative AI by analyzing human tweets referencing terms such as ChatGPT, OpenAI, Copilot, and LLMs. To further understand the emotional intelligence of ChatGPT, we examine its responses to selected tweets, highlighting differences in sentiment between human comments and LLM-generated responses. We introduce EmoXpt, a sentiment analysis framework designed to assess both human perspectives on generative AI and the sentiment embedded in ChatGPT's responses. Unlike prior studies that focus exclusively on human sentiment, EmoXpt uniquely evaluates the emotional expression of ChatGPT. Experimental results demonstrate that LLM-generated responses are notably more efficient, cohesive, and consistently positive than human responses.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903889 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343449,
  title={ Lins: Reducing Communication Overhead of ZeRO for Efficient LLM Training  -  2024 IEEE/ACM 32nd International Symposium on Quality of Service (IWQoS) },
  year={2024},
  author={Chen, Q. and Hu, Q. and Wang, G. and Xiong, Y. and Huang, T. and Chen, X. and Gao, Y. and Yan, H. and Wen, Y. and Zhang, T. and Sun, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10682856 },
  abstract={Training large language models (LLMs) encounters challenges in GPU memory consumption due to the high memory requirements of model states. The widely used Zero Redundancy Optimizer (ZeRO) addresses this issue through strategic sharding but introduces communication challenges at scale. To tackle this problem, we propose Lins, a system designed to optimize ZeRO for scalable LLM training. Lins incorporates three flexible sharding strategies: Full-Replica, Full-Sharding, and Partial-Sharding, and allows each component within the model states (Parameters, Gradients, Optimizer States) to independently choose a sharding strategy as well as the device mesh. We conduct a thorough analysis of communication costs, formulating an optimization problem to discover the optimal sharding strategy. Evaluations demonstrate up to 52% Model FLOPs Utilization (MFU) when training the LLaMA-based model on 1024 GPUs, resulting in a 1.56 times improvement in training throughput compared to newly proposed systems like MiCS and ZeRO++.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IWQoS61813.2024.10682856 },
  booktitle={ 2024 IEEE/ACM 32nd International Symposium on Quality of Service (IWQoS) },
  chapter={0}
}

@article{rayyan-352343450,
  title={ An Agentic AI-based Radio Access Network for Efficient Video Delivery in Internet of Vehicles  -  2025 IEEE/CIC International Conference on Communications in China (ICCC Workshops) },
  year={2025},
  author={Feng, C. and Feng, Z. and Yang, J. and Quek, T. Q. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148168 },
  abstract={Vehicular networks are increasingly relied upon to support real-time, bandwidth-intensive applications such as video streaming and immersive media services. However, the high mobility of vehicles, intermittent connectivity with roadside base stations, and fluctuating user demands introduce substantial challenges for optimizing Quality of Experience (QoE). This paper presents a novel AI-driven Radio Access Network (AI-RAN) architecture that embeds intelligent agents based on Large Language Models (LLMs) into the near-real-time RAN Intelligent Controller (near-RT RIC). These agents are designed to anticipate vehicle trajectories, predict service demands, and dynamically adjust bitrate and routing strategies in a context-aware and coordinated fashion. By leveraging semantic reasoning through prompt engineering, each agent interprets mobility patterns, network conditions, and QoE indicators to jointly optimize video delivery for mobile users. We develop a realistic co-simulation testbed integrating SUMO, ns-3, and DASH streaming modules, and benchmark our framework against traditional heuristics and deep reinforcement learning approaches. Experimental results demonstrate that the proposed system significantly enhances QoE, reduces re-buffering events and bitrate fluctuations, and enables proactive, efficient content delivery at the network edge. Our findings highlight the potential of LLM-based agents to drive edge intelligence and autonomous optimization in future AI-RAN deployments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCWorkshops67136.2025.11148168 },
  booktitle={ 2025 IEEE/CIC International Conference on Communications in China (ICCC Workshops) },
  chapter={0}
}

@article{rayyan-352343451,
  title={ A Comprehensive LLM-powered Framework for Driving Intelligence Evaluation  -  2025 IEEE International Conference on Robotics and Automation (ICRA) },
  year={2025},
  author={You, S. and Luo, X. and Liang, X. and Yu, J. and Zheng, C. and Gong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11128380 },
  abstract={Evaluation methods for autonomous driving are crucial for algorithm optimization. However, due to the complexity of driving intelligence, there is currently no comprehensive evaluation method for the level of autonomous driving intelligence. In this paper, we propose an evaluation framework for driving behavior intelligence in complex traffic environments, aiming to fill this gap. We constructed a natural language evaluation dataset of human professional drivers and passengers through naturalistic driving experiments and post-driving behavior evaluation interviews. Based on this dataset, we developed an LLM-powered driving evaluation framework. The effectiveness of this framework was validated through simulated experiments in the CARLA urban traffic simulator and further corroborated by human assessment. Our research provides valuable insights for evaluating and designing more intelligent, human-like autonomous driving agents. The implementation details of the framework11https://github.com/AIR-DISCOVER/Driving-Intellenge-Evaluation-Framework and detailed information about the dataset22https://github.com/AIR-DISCOVER/Driving-Evaluation-Datasetcan be found at the provided links.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRA55743.2025.11128380 },
  booktitle={ 2025 IEEE International Conference on Robotics and Automation (ICRA) },
  chapter={0}
}

@article{rayyan-352343452,
  title={ Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients  -  2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) },
  year={2024},
  author={Abbasian, M. and Yang, Z. and Khatibi, E. and Zhang, P. and Nagesh, N. and Azimi, I. and Jain, R. and Rahmani, A. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10781547 },
  abstract={Effective diabetes management is crucial for maintaining health in diabetic patients. Large Language Models (LLMs) have opened new avenues for diabetes management, facilitating their efficacy. However, current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses. In this paper, we propose a knowledge-infused LLM-powered conversational health agent (CHA) for diabetic patients. We customize and leverage the open-source openCHA framework, enhancing our CHA with external knowledge and analytical capabilities. This integration involves two key components: 1) incorporating the American Diabetes Association dietary guidelines and the Nutritionix information and 2) deploying analytical tools that enable nutritional intake calculation and comparison with the guidelines. We compare the proposed CHA with GPT4. Our evaluation includes 100 diabetes-related questions on daily meal choices and assessing the potential risks associated with the suggested diet. Our findings show that the proposed agent demonstrates superior performance in generating responses to manage essential nutrients.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EMBC53108.2024.10781547 },
  booktitle={ 2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) },
  chapter={0}
}

@article{rayyan-352343453,
  title={ Retrieval Augmented Generation with Multi-Modal LLM Framework for Wireless Environments  -  2025 IEEE International Conference on Communications Workshops (ICC Workshops) },
  year={2025},
  author={Mohsin, M. A. and Bilal, A. and Bhattacharya, S. and Cioffi, J. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11162457 },
  abstract={Future wireless networks aims to deliver high data rates and lower power consumption while ensuring seamless connectivity, necessitating robust wireless network optimization. To achieve this, wireless network optimization is necessary. Large language models (LLMs) have been deployed for generalized optimization scenarios. To take advantage of generative AI (GAI) models, retrieval augmented generation (RAG) is proposed for multi-sensor wireless environment perception. Utilizing domain-specific prompt engineering, we apply retrieval-augmented generation (RAG) to efficiently harness multimodal data inputs from sensors in a wireless environment. Wireless environment perception is necessary for global LLM optimization tasks. Key pre-processing pipelines including image-to-text conversion, object detection, and distance calculations for multimodal RAG input from multi-sensor data from different devices are proposed in this paper to obtain a unified vector database crucial for optimizing large language models (LLMs) in global wireless tasks. Our evaluation, conducted with OpenAI's GPT and Google's Gemini models, demonstrates an 8%, 8%, 10%, 7%, and 12% improvement in relevancy, faithfulness, completeness, similarity, and accuracy, respectively, compared to conventional LLM-based designs. Furthermore, our RAG-based LLM framework with vectorized databases are computationally efficient providing real time convergence under latency constraints. 1},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCWorkshops67674.2025.11162457 },
  booktitle={ 2025 IEEE International Conference on Communications Workshops (ICC Workshops) },
  chapter={0}
}

@article{rayyan-352343454,
  title={ SK Hynix AI-Specific Computing Memory Solution: From AiM Device to Heterogeneous AiMX-xPU System for Comprehensive LLM Inference  -  2024 IEEE Hot Chips 36 Symposium (HCS) },
  year={2024},
  author={Kim, G. and Kim, J. and Kim, N. and Shin, W. and Won, J. and Joo, H. and Choi, H. and An, B. and Shin, G. and Yun, D. and Kim, J. and Kim, C. and Kim, I. and Park, J. and Song, Y. and Yang, B. and Lee, H. and Park, S. and Lee, W. and Kim, S. and Park, Y. and Jung, Y. and Park, G. -H. and Lim, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664793 },
  abstract={•Recap Accelerator-in-Memory (AiM) & AiMX •System Extensions of AiMX Card for Datacenter •AiM & AiMX for On-device AI •Design Choices for Future AiM/AiMX •Conclusion},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HCS61935.2024.10664793 },
  booktitle={ 2024 IEEE Hot Chips 36 Symposium (HCS) },
  chapter={0}
}

@article{rayyan-352343455,
  title={ Adaptive Persuasion in Conversational AI: An LLM-Driven Framework for Dynamic Strategy Switching via Personality and Sentiment Analysis  -  2025 11th International Conference on Web Research (ICWR) },
  year={2025},
  author={Nezhad, M. M. and Kisomi, M. A. and Gholinezhad, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11006192 },
  abstract={Recent advances in persuasive communication and conversational AI have driven the development of adaptive frameworks that integrate dynamic strategy adjustment within large language model architectures. In this study, we introduce a novel framework that effectively integrates real-time sentiment analysis with comprehensive personality profiling based on the Big Five model to enable adaptive strategy switching during multi-turn dialogues. Our methodology also leverages a reinforcement learning-inspired weight adaptation mechanism that continuously readjusts the relative influence of stable personality traits and transient emotional states, thereby optimizing the selection of persuasive techniques. Furthermore, by incorporating a Retrieval-Augmented Generation (RAG) paradigm alongside the LLaMA model, the proposed framework produces contextually coherent and individually tailored responses that draw upon historical interaction data and strategic knowledge repositories. Experimental evaluations reveal that our adaptive system significantly enhances persuasive efficacy and user engagement, underscoring its potential to advance the state-of-the-art in personalized conversational agents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWR65219.2025.11006192 },
  booktitle={ 2025 11th International Conference on Web Research (ICWR) },
  chapter={0}
}

@article{rayyan-352343456,
  title={ Improving Clustering Explainability and Automated Cluster Naming with Approximate Inverse Model Explanations and Large Language Models  -  2025 IEEE Symposium on Trustworthy, Explainable and Responsible Computational Intelligence (CITREx Companion) },
  year={2025},
  author={Nakanishi, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981499 },
  abstract={This study presents a method that combines an explainable AI (XAI) technology called approximate inverse model explanation (AIME) with large language models (LLMs) to improve the explainability of clustering results and automatically generate cluster names. AIME identifies the features that are most important in forming each cluster. A language model then uses these important features to automatically generate names for the clusters. Traditionally, clustering has been used to group similar data; however, determining why clusters form and name them has been left to data analysis. This study automates both tasks by explaining cluster formation and generating cluster names, making it a useful tool in fields such as data mining. For example, in marketing, customer data can be clustered to identify segments, and the characteristics and names of these segments can be automatically generated. This method enhances the explainability of unsupervised learning and offers a new application for explainable AI. Although the method has been demonstrated for data mining, it has potential applications in other fields, such as text mining.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CITRExCompanion65208.2025.10981499 },
  booktitle={ 2025 IEEE Symposium on Trustworthy, Explainable and Responsible Computational Intelligence (CITREx Companion) },
  chapter={0}
}

@article{rayyan-352343457,
  title={ Improving Clustering Explainability and Automated Cluster Naming with Approximate Inverse Model Explanations and Large Language Models  -  2025 17th International Conference on Knowledge and Smart Technology (KST) },
  year={2025},
  author={Nakanishi, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11003292 },
  abstract={This study presents a method that combines an explainable AI (XAI) technology called approximate inverse model explanation (AIME) with large language models (LLMs) to improve the explainability of clustering results and automatically generate cluster names. AIME identifies the features that are most important in forming each cluster. A language model then uses these important features to automatically generate names for the clusters. Traditionally, clustering has been used to group similar data; however, determining why clusters form and name them has been left to data analysis. This study automates both tasks by explaining cluster formation and generating cluster names, making it a useful tool in fields such as data mining. For example, in marketing, customer data can be clustered to identify segments, and the characteristics and names of these segments can be automatically generated. This method enhances the explainability of unsupervised learning and offers a new application for explainable AI. Although the method has been demonstrated for data mining, it has potential applications in other fields, such as text mining.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/KST65016.2025.11003292 },
  booktitle={ 2025 17th International Conference on Knowledge and Smart Technology (KST) },
  chapter={0}
}

@article{rayyan-352343458,
  title={ Is This You, LLM? Recognizing AI-written Programs with Multilingual Code Stylometry  -  2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER) },
  year={2025},
  author={Gurioli, A. and Gabbrielli, M. and Zacchiroli, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992332 },
  abstract={With the increasing popularity of LLM-based code completers, like GitHub Copilot, the interest in automatically detecting AI-generated code is also increasing-in particular in contexts where the use of LLMs to program is forbidden by policy due to security, intellectual property, or ethical concerns. We introduce a novel technique for AI code stylometry, i.e., the ability to distinguish code generated by LLMs from code written by humans, based on a transformer-based encoder classifier. Differently from previous work, our classifier is capable of detecting AI-written code across 10 different programming languages with a single machine learning model, maintaining high average accuracy across all languages (84.1% ± 3.8%). Together with the classifier we also release H-AIRosettaMP, a novel open dataset for AI code stylometry tasks, consisting of 121 247 code snippets in 10 popular programming languages, labeled as either human-written or AI-generated. The experimental pipeline (dataset, training code, resulting models) is the first fully reproducible one for the AI code stylometry task. Most notably our experiments rely only on open LLMs, rather than on proprietary/closed ones like ChatGPT.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SANER64311.2025.00044 },
  booktitle={ 2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER) },
  chapter={0}
}

@article{rayyan-352343459,
  title={ GBC: GameScript Generation Using BERT Classification: —Enhancing Interactive Narratives with LLM  -  2025 5th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS) },
  year={2025},
  author={Zhang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11142053 },
  abstract={Generative Artificial Intelligence (GAI) and Large Language Models (LLMs) have been applied in text-based games, but its potential in generating executable game scripts is unexplored. By establishing a mapping from text responses to game scripts, this research explored the application of LLMs in practical game production. This study utilizes a fine-tuned Bidrectional Encoder Representations from Transformers (BERT) model to transform dialogue generated by LLMs into practical game scripts. The proposed method achieves state-of-the-art performance of transformation with an F1 score of 89.71% and an accuracy of 89.74% on the validation set, while maintaining low training and computational costs. The results highlight the potential of LLMs in game development, paving the way for immersive and personalized gaming experiences. Future research could delve deeper into complex and diverse datasets, exploring the integration of multiple labels and numerical values to enhance game interaction and immersion experiences. This research may lay the groundwork for integrating generative AI into game engines in the future, simplifying the production process of adaptive game content.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCTCS66275.2025.00028 },
  booktitle={ 2025 5th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS) },
  chapter={0}
}

@article{rayyan-352343460,
  title={ Brief State of the Art on Human-AI in Software Engineering: Impact, Ethical Challenges, and Academic Evolution  -  2024 13th International Conference On Software Process Improvement (CIMPS) },
  year={2024},
  author={M., Y. V. Morales and R., B. D. Valenzuela and Salgado, R. S. and Serna, G. G. and Sánchez, N. A. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095939 },
  abstract={This article presents a brief state of the art on the integration of artificial intelligence (AI) in software engineering, focusing on its impact, emerging ethical challenges, and the academic evolution required to address these changes. Through a systematic literature review based on the PRISMA methodology and the analysis of case studies, it explores how AI, particularly large language models (LLMs), is transforming key processes such as code generation, program verification, and integration with DevOps practices, thereby improving software productivity and quality. However, these advances entail significant ethical challenges, such as the introduction of biases, lack of transparency in automated decisions, and excessive reliance on automation, raising concerns about privacy and security. This study highlights the importance of reformulating curricula, developing models for academic institutions that integrate an ethical approach to AI teaching, and fostering collaboration with the industry. This work offers a comprehensive vision that combines the technical, ethical, and educational aspects necessary for the responsible implementation of AI. Finally, directions for future research centered on developing more transparent AI technologies and creating robust ethical frameworks to ensure effective synergy between humans and AI in software engineering are identified.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIMPS65195.2024.11095939 },
  booktitle={ 2024 13th International Conference On Software Process Improvement (CIMPS) },
  chapter={0}
}

@article{rayyan-352343461,
  title={ An AI-Gym for Industry 4.0  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Naim, B. A. and Amiri, M. Z. and Tauber, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073648 },
  abstract={The rapid evolution of Industry 4.0 demands advanced solutions for developing and deploying AI models that can interact seamlessly with industrial IoT (IIoT) systems. A critical challenge lies in creating a controlled, efficient environment to develop, train, and test AI models using real-world data streams before deploying them in production. To address this, we propose an AI-gym framework that integrates Apache Zeppelin, Eclipse Arrowhead, and IIoT components to facilitate real-time model development and validation. This approach bridges the gap between theoretical model design and practical deployment, enabling iterative experimentation with live IIoT data from industrial setups. To demonstrate its effectiveness, we validated the framework with a use case in Controlled Environment Agriculture (CEA), optimizing climate control using live data streams from sensors and actuators. By enabling real-time interaction, seamless IIoT integration, and robust testing, the proposed AI-gym aligns with the principles of Industry 4.0, such as digitalization, smart manufacturing, and data-driven decision-making, offering a transformative tool for industrial AI applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073648 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343462,
  title={ Knowledge Generation Pipeline using LLM for Building 3D Object Knowledge Base  -  2023 14th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2023},
  author={Lee, S. and Lee, H. and Lee, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392933 },
  abstract={With the wide spread of XR(eXtended Reality) contents such as Metaverse and VR(Virtual Reality) / AR(Augmented Reality), the utilization and importance of 3D objects are increasing. In this paper, we describe a knowledge generation pipeline of 3D object for reuse of existing 3D objects and production of new 3D object using generative AI(Artificial Intelligence). 3D object knowledge includes not only the object itself data that are generated in object editing phase but the information for human to recognize and understand objects. The target 3D model for building knowledge is the space model of office for business Metaverse service and the model of objects composing the space. LLM(Large Language Model)-based multimodal AI was used to extract knowledge from 3D model in a systematic and automated way. We plan to expand the pipeline to utilize knowledge base for managing extracted knowledge and correcting errors occurred during the LLM process for the knowledge extraction.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC58733.2023.10392933 },
  booktitle={ 2023 14th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343463,
  title={ Generative AI for OCL Constraint Generation: Dataset Collection and LLM Fine-tuning  -  2024 IEEE International Symposium on Systems Engineering (ISSE) },
  year={2024},
  author={Pan, F. and Zolfaghari, V. and Wen, L. and Petrovic, N. and Lin, J. and Knoll, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10741141 },
  abstract={The Object Constraint Language (OCL) is a formal specification language in model-based systems and software engineering. It defines complex rules and constraints for model-based system design and verification. Constructing an OCL constraint requires expertise not only in OCL syntax but also in meta-model information, which can hinder its application in the practical industrial scenario despite its broad usage. Recently, generative artificial intelligence has demonstrated remarkable performance in code and text generation. This work discusses the generation of OCL constraints from natural language specifications using large language models (LLMs). Given that the automotive and aviation industries are major consumers of model-based engineering, the use of commercial LLMs raises concerns about data privacy. Therefore, we propose to employ open-source and locally deployed LLMs for OCL generation tasks. In this work, we collected a set of meta-models and OCL constraints, which were syntactically validated to ensure the quality of the OCL dataset. Synthetic natural language specifications were generated and used in the dataset for model fine-tuning. Additionally, we designed a retrieval-augmented approach to incorporate meta-model information during LLM fine-tuning and OCL generation. The proposed fine-tuning and OCL generation approach has been experimented with the state-of-the-art open-source LLM, Llama 3 8B. The locally fine-tuned and deployed language model achieved comparable syntactic accuracy and a higher semantic similarity score for OCL generation compared to the cutting-edge commercial models, GPT-4 Turbo and Gemini 1.5 Pro. The usability of the fine-tuned model has been demonstrated for OCL generation in the context of automotive resource allocation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISSE63315.2024.10741141 },
  booktitle={ 2024 IEEE International Symposium on Systems Engineering (ISSE) },
  chapter={0}
}

@article{rayyan-352343464,
  title={ An Efficient Finetuning Method for LLM generated text detection in Power Grid  -  2025 IEEE/CIC International Conference on Communications in China (ICCC) },
  year={2025},
  author={Jiang, Y. and Li, J. and Zhang, X. and Xu, W. and Liang, Z. and Yang, Y. and Huang, K. and Bi, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148942 },
  abstract={The increasing prevalence of Large Language Models (LLMs) in various sectors, including the power grid industry, has raised concerns regarding the detection of AI-generated content, particularly in expert technical documents. Existing detection methods, while effective in some cases, often struggle with the diverse and complex nature of power grid documents. This paper introduces a novel approach for detecting LLMgenerated text in electrical engineering documents by efficiently fine-tuning the ChatGLM-6B model using Low-Rank Adaptation (LoRA). Our method leverages the rich domain-specific knowledge embedded in the LLM, while minimizing computational overhead and memory usage. Experimental results demonstrate that our approach significantly outperforms current state-of-theart methods, achieving $91.47 \%$ accuracy on the Kaggle dataset, 97.23% on the LLM-Detector dataset, and 87.65% on the power system dataset. This work provides a robust and efficient solution for LLM-generated text detection in the power grid sector, offering high generalization ability and scalability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCC65529.2025.11148942 },
  booktitle={ 2025 IEEE/CIC International Conference on Communications in China (ICCC) },
  chapter={0}
}

@article{rayyan-352343465,
  title={ BrandCrafter AI, an AI-Based Brand Identity Generation Platform  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Gawad, S. and Kim, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903757 },
  abstract={In today's dynamic and highly competitive market, brand differentiation has become both essential and complex. The growth of social media and enhanced digital accessibility have transformed brand promotion into a multifaceted challenge, requiring a strategic and ongoing connection with target audiences to build loyalty and deter them from migrating to competitors. The constant evolution of social media trends and search engine optimization has added layers of complexity, creating an ongoing challenge for brands to remain visible and relevant. For new entrepreneurs, the cost of professional branding consultants is often beyond reach. This paper explores the potential of large language models (LLMs) as a cost-effective, automated solution for generating comprehensive, customized brand identity guidelines. We investigate the effectiveness of LLMs in creating cohesive branding strategies, encompassing brand tone, visual elements, and audience alignment, thus offering a scalable alternative to traditional consultancy services. We conducted a pilot study involving two participants, demonstrating positive outcomes, showing that LLM-generated brand identity guidelines were relevant and consistent and provided valuable support in the branding process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903757 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343466,
  title={ Generative AI Models with Their Full Reveal*  -  2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE) },
  year={2024},
  author={Chekhovich, Y. and Grabovoy, A. and Gritsai, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605662 },
  abstract={The paper deals with Large Language Models (LLM). We present a historical overview of the development of text generation algorithms. The aim of the paper is to show the main properties and limitations of services based on Large Language Models when their results are used in scientific and educational texts. We touch on concepts such as sampling from distribution, Recurrent Neural Network, Attention mechanism, Transformer architecture and provide guidelines for the ethical use of generated texts in scientific and academic papers. We have presented the material in a popular form, so that it is possible to understand the principles of generative services with general erudition and certain computer skills. At the same time, the key concepts are provided with references that will allow readers to delve into the area on their own if necessary.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TELE62556.2024.10605662 },
  booktitle={ 2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE) },
  chapter={0}
}

@article{rayyan-352343467,
  title={ A Fairness Taxonomy for the Assessment of Korean Large Language Models  -  2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  year={2024},
  author={Shin, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827134 },
  abstract={The objective of this study is to define a systematic taxonomy for assessing the fairness of Korean-based large language models (LLMs). To achieve this, various international documents, datasets, and academic papers are collected and analyzed for their presented fairness and bias classification methods. As a result, we propose a classification framework that includes superclasses for fairness assessment and subclasses reflecting the specific characteristics of Korean society. The proposed taxonomy provides a more systematic and detailed basis for assessing the fairness of Korean-based LLMs. This approach is expected to effectively address ethical issues in Korean language models and contribute to the development of AI technology suitable for Korean society.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827134 },
  booktitle={ 2024 15th International Conference on Information and Communication Technology Convergence (ICTC) },
  chapter={0}
}

@article{rayyan-352343468,
  title={ 8 Exploring the Applications on Generative AI and LLM  -  Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  author={Ashwini, A. and Prabhakar, J. M. and Kadry, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11164795.pdf&bkn=11164515&pdfType=chapter },
  abstract={The recent advancement in artificial intelligence (AI) - the generative artificial intelligence (GenAI) - is a most powerful form that serves to support the organizational computerized structure of society. This chapter delves into the recent methodologies and various applications relating to large language models in both scientific and technical research. This chapter mainly investigates the prime significance in enhancing the various research techniques in scientific fields. This model has significantly contributed to the creation of numerous tools by comprehending and providing the source code with natural language-based instructions. The chapter focuses on the data level incorporation that is termed to be adaptive using quantum-based techniques, which emphasize the advantages they deliver in modeling the scientific domain with comprehensive context creation. The technique required for preserving the confidentiality, transfer learning with neural network, and teamwork interaction with research work are kept under light, taking prior care on the data it provides and also the robustness that is required in the applications of AI. This chapter shows the successful applications of generative neural networks in scientific research advancements. GenAI proves to be a valuable resource for both the researchers and professionals},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  chapter={0}
}

@article{rayyan-352343469,
  title={ A Method for Intelligent Optimization Algorithms to Automatically Generate LLM Test Data  -  2025 5th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS) },
  year={2025},
  author={Xie, W. and Qian, J. and Li, Y. and Huang, J. and Zheng, Y. and Liu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11142029 },
  abstract={As AI products become more and more complex, traditional methods of manual test data generation are facing problems such as high cost, low efficiency, and insufficient test coverage, which affect the quality and stability of products. In order to solve the above problems, this paper proposes a method for automatic generation of AI (LLM) test data by intelligent optimization algorithm, and applies it to practical cases to carry out more detailed research. Experiments show that after a company introduces an intelligent optimization algorithm to automatically generate AI test data, based on this method, the test data generation time of its software has been reduced from 80.16 hours to 20.25 hours. And at the same time, the test coverage has increased from 60.32 % to 95.10 %, and the defect discovery rate has also increased from 65.51 % to 90.17 %. It can be seen that this method can significantly improve the test efficiency, optimize the test cost, and enhance the stability and quality of the software. It has been proved that intelligent optimization algorithms can be reasonably applied to automatically generate software test data, and then form a reliable method to provide enterprises with more accurate and efficient software testing solutions, and provide other companies with valuable optimization experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCTCS66275.2025.00047 },
  booktitle={ 2025 5th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS) },
  chapter={0}
}

@article{rayyan-352343470,
  title={ GEMMV: An LLM-Based Automated Performance-Aware Framework for GEMM Verilog Generation  -  IEEE Journal on Emerging and Selected Topics in Circuits and Systems },
  author={Zhang, G. and Zou, D. and Sun, K. and Chen, Z. and Wang, M. and Wang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10994474 },
  abstract={Recent advancements in artificial intelligence (AI) models have intensified the need for specialized AI accelerators. The design of optimized general matrix multiplication (GEMM) module tailored for these accelerators is crucial but time-consuming and expertise-demanding, creating a demand for automating design processes. Large language models (LLMs), capable of generating high-quality designs from human instructions, show great promise in automating GEMM module creation. However, the GEMM module’s vast design space and stringent performance requirements, along with the limitations of datasets and the lack of hardware performance awareness of LLMs, have made previous LLM-based register transfer level (RTL) code generation efforts unsuitable for GEMM design. To tackle these challenges, this paper proposes an automated performance-aware LLM-based framework, GEMMV, for generating high-correctness and high-performance Verilog code for GEMM. This framework utilizes in-context learning based on GPT-4 to automatically generate high-quality and well-annotated Verilog code for different variants of the GEMM. Additionally, it leverages in-context learning to obtain performance awareness by integrating a multi-level performance model (MLPM) with fine-tuned LLMs. The Verilog code generated by this framework reduces latency by 3.1x and improves syntax correctness by 65% and functionality correctness by 70% compared to earlier efforts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JETCAS.2025.3568712 },
  booktitle={ IEEE Journal on Emerging and Selected Topics in Circuits and Systems },
  chapter={0}
}

@article{rayyan-352343471,
  title={ Optimizing Legal Information Access: Federated Search and RAG for Secure AI-Powered Legal Solutions  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Amato, F. and Cirillo, E. and Fonisto, M. and Moccardi, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825815 },
  abstract={Large Language Models (LLMs) have gained increasing importance in the field of Legal Intelligence, enabling the development of applications to assist both legal professionals and ordinary citizens.However, centralized training of these legal LLM models raises concerns about data privacy, as legal data is distributed across various institutions that contain sensitive information about individuals.Using Federated Learning (FL), legal LLMs can be locally trained on devices or clients, and their parameters are aggregated and distributed to a central server, ensuring data privacy without directly sharing the raw data. The presence of private information of the parties in legal data calls for new studies based on legal Artificial Intelligence (legal AI) to investigate new decentralized learning methods that can protect the privacy of individuals.A promising technique in this field is FL, which is useful for enabling multiple participants to collaboratively train a shared model while effectively protecting private sensitive data. However, it has significant limitations, which can be effectively addressed using a technology like FS.FS is a crucial system in managing distributed information in modern environments and it can play a fundamental role in finding relevant information from diverse heterogeneous sources to generate well-informed answers without requiring specific training on data, which proves to be a less flexible solution.FS systems aggregate results from different sources, selecting the most appropriate documents to improve the quality of results and align with the user’s intent. To achieve this goal, new technologies are being utilized, such as Retrieval-Augmented Generation (RAG) in the case study presented.In summary, FL therefore allows training AI models on distributed data without centrally sharing them, ensuring protection of sensitive data and collaboration between organizations without compromising data confidentiality.However, it has important limitations, including computational and communication overhead; in fact, distributed training requires significant computational power, which may not be sustainable for all devices or clients, and it may not be fully efficient, as model optimization in decentralized contexts often doesn’t reach the levels of centralized training, especially for complex models like LLMs. FS is a good technology that addresses these limitations, in particularly specific domains, such as the legal field, by focusing on retrieving information from distributed sources rather than on model training. This approach offers several advantages over FL, first of all lower computational requirements; in fact, since it is not necessary to train models on distributed devices, the resources required are significantly lower and subsequently better results for informative tasks in scenarios where it is necessary to generate answers based on heterogeneous information, allowing to retrieve relevant documents from different sources and better integrate the results to generate coherent and informed answers.Furthermore, the major strength concerns flexibility; FS systems can easily adapt to new data or sources without the need for retraining.This study aims to analyze the limits of FL in the legal field through an excursus on the use of these technologies, supporting the development of new FS methods, especially in the context of RAG pipelines.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825815 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343472,
  title={ AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) },
  year={2025},
  author={Lo, F. P. . -W. and Qiu, J. and Wang, Z. and Yu, H. and Chen, Y. and Zhang, G. and Lo, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147794 },
  abstract={Resume screening is a critical yet time-intensive process in talent acquisition, requiring recruiters to analyze vast volume of job applications while remaining objective, accurate, and fair. With the advancements in Large Language Models (LLMs), their reasoning capabilities and extensive knowledge bases demonstrate new opportunities to streamline and automate recruitment workflows. In this work, we propose a multi-agent framework for resume screening using LLMs to systematically process and evaluate resumes. The framework consists of four core agents, including a resume extractor, an evaluator, a summarizer, and a score formatter. To enhance the contextual relevance of candidate assessments, we integrate Retrieval-Augmented Generation (RAG) within the resume evaluator, allowing incorporation of external knowledge sources, such as industry-specific expertise, professional certifications, university rankings, and company-specific hiring criteria. This dynamic adaptation enables personalized recruitment, bridging the gap between AI automation and talent acquisition. We assess the effectiveness of our approach by comparing AI-generated scores with ratings provided by HR professionals on a dataset of anonymized online resumes. The findings highlight the potential of multi-agent RAG-LLM systems in automating resume screening, enabling more efficient and scalable hiring workflows.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPRW67362.2025.00402 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) },
  chapter={0}
}

@article{rayyan-352343473,
  title={ Generative AI in Curriculum Design: Empirical Insights Into Model Performance and Educational Constraints  -  IEEE Transactions on Learning Technologies },
  author={Rutecka, P. and Cicha, K. and Rizun, M. and Strzelecki, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072910 },
  abstract={This study verifies the ability of large language models (LLMs) to generate a curriculum and develop syllabi for specific courses. We prompted four models to generate two sets of curricula for a bachelor’s degree in Economics and Management. We also generated syllabi for the courses included in the curriculum. We chose five Polish public economics universities offering those degree programs for comparison. Four LLMs were used in this experiment: ChatGPT-3.5, ChatGPT-4, Google Bard, and Gemini. Two of them are multimodal models. The study used an iterative approach, increasing the detail of the prompt in each iteration. The results show that the more specific prompt is given to the LLM, the less accurate the results are. Moreover, the experiment shows that none of the LLMs developed a complete curriculum at a level comparable to that generated by humans. However, LLMs can significantly help create a curriculum and develop syllabi by humans, provided that there is close human–artificial intelligence (AI) collaboration. The results obtained from the AI-assisted curriculum design differ depending on the model. By analyzing the differences between the tools and the real degree programs and syllabi, we determined that multimodal models are better suited for this task than older models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TLT.2025.3587081 },
  booktitle={ IEEE Transactions on Learning Technologies },
  chapter={0}
}

@article{rayyan-352343474,
  title={ LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models  -  IEEE Transactions on Visualization and Computer Graphics },
  author={Kahng, M. and Tenney, I. and Pushkarna, M. and Liu, M. X. and Wexler, J. and Reif, E. and Kallarackal, K. and Chang, M. and Terry, M. and Dixon, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670495 },
  abstract={Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google's LLM evaluation platforms and open-sourced.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TVCG.2024.3456354 },
  booktitle={ IEEE Transactions on Visualization and Computer Graphics },
  chapter={0}
}

@article{rayyan-352343475,
  title={ Driving Style Alignment for LLM-powered Driver Agent  -  2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  year={2024},
  author={Yang, R. and Zhang, X. and Fernandez-Laaksonen, A. and Ding, X. and Gong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802629 },
  abstract={Recently, LLM-powered driver agents have demonstrated considerable potential in the field of autonomous driving, showcasing human-like reasoning and decision-making abilities. However, current research on aligning driver agent behaviors with human driving styles remains limited, partly due to the scarcity of high-quality natural language data from human driving behaviors. To address this research gap, we propose a multi-alignment framework designed to align driver agents with human driving styles through demonstrations and feedback. Notably, we construct a natural language dataset of human driver behaviors through naturalistic driving experiments and post-driving interviews, offering high-quality human demonstrations for LLM alignment. The framework’s effectiveness is validated through simulation experiments in the CARLA urban traffic simulator and further corroborated by human evaluations. Our research offers valuable insights into designing driving agents with diverse driving styles. The implementation of the framework 1 and details of the dataset 2 can be found at the link.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IROS58592.2024.10802629 },
  booktitle={ 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  chapter={0}
}

@article{rayyan-352343476,
  title={ LLM-Powered UPI Transaction Monitoring and Fraud Detection  -  2024 International Conference on System, Computation, Automation and Networking (ICSCAN) },
  year={2024},
  author={K, A. and K, A. and S, H. and R, B. and Kumaran.R, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894012 },
  abstract={In this Business World, the Unified Payments Interface (UPI) has transformed digital payments by facilitating instantaneous Business-to-Person (B2P) and Person-to-Person (P2P) transactions. But the quick expansion of UPI transactions has also drawn fraudsters. Current fraud detection systems are built on Machine Learning algorithms that have been trained on historical data and Rule-Based methodologies. Even if they work, these techniques can't keep up with changing fraud trends and can overlook new attack opportunities. The inflexibility and absence of Real-Time Natural Language understanding in current systems makes it difficult to assess user behaviour and spot false narratives. This study uses Large Language Models (LLM's) to provide a unique method of fraud detection and UPI transaction monitoring. After being trained on enormous text and code datasets, LLM's are able to discern suspicious patterns and narratives that point to fraud by analyzing transaction data, user messages, and social media interactions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSCAN62807.2024.10894012 },
  booktitle={ 2024 International Conference on System, Computation, Automation and Networking (ICSCAN) },
  chapter={0}
}

@article{rayyan-352343477,
  title={ LLM-SAP: Large Language Models Situational Awareness-Based Planning  -  2024 IEEE International Conference on Multimedia and Expo Workshops (ICMEW) },
  year={2024},
  author={Wang, L. and Zhong, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645429 },
  abstract={This study explores the integration of large language models (LLMs) with situational awareness-based planning (SAP) to enhance the decision-making capabilities of AI agents in dynamic and uncertain environments. By employing a multi-agent reasoning framework, we develop a methodology that not only anticipates but actively mitigates potential risks through iterative feedback and evaluation processes. Our approach diverges from traditional automata theory by incorporating the complexity of human-centric interactions into the planning process, thereby expanding the planning scope of LLMs beyond structured and predictable scenarios. The results demonstrate significant improvements in the models' ability to provide comparative safe actions within hazard interactions, offering a perspective on proactive and reactive planning strategies. This research highlights the potential of LLMs to perform human-like action planning, thereby paving the way for more sophisticated, reliable, and safe AI systems in unpredictable real-world applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMEW63481.2024.10645429 },
  booktitle={ 2024 IEEE International Conference on Multimedia and Expo Workshops (ICMEW) },
  chapter={0}
}

@article{rayyan-352343478,
  title={ LLM-Based Safety Case Generation for Baidu Apollo: Are We there Yet?  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Odu, O. and Belle, A. B. and Wang, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030020 },
  abstract={Justifying the correct implementation of the non-functional requirements of mission-critical systems is crucial to prevent system failure. The latter could have severe consequences such as the death of people, and financial losses. Assurance cases (e.g., safety cases, security cases) can be used to prevent system failure. They are structured sets of arguments supported by evidence and aiming at demonstrating that a system's non-functional requirements have been correctly implemented. How-ever, although the availability of complete assurance cases is crucial to allow the research community to contribute to the system assurance field, it remains very challenging to access complete assurance cases due to several concerns such as confidentiality issues. Furthermore, assurance cases are usually very large documents. Still, their creation remains a manual, tedious, and error-prone process that heavily relies on domain expertise. Thus, exploring techniques to support their automatic instantiation becomes crucial. To fill these gaps, our experience paper first demonstrates the feasibility of an AMLAS-based design methodology on a case study aiming at manually creating a safety case for the ML-enabled trajectory prediction component of an open-source autonomous driving system i.e. Baidu Apollo. Our paper then reports our experience in using a Large Language Model (LLM) to automatically re-create the same safety case. The lessons we have drawn from this case study provide actionable insights that could benefit researchers and practitioners.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00033 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343479,
  title={ TAIA: Telco Generative AI-powered Multi-Agent Assistant for managing Cloud-Native Networks  -  2025 IEEE International Conference on Communications Workshops (ICC Workshops) },
  year={2025},
  author={Panek, G. and Matysiak, P. and Ziółkowski, M. and Fajjari, I. and Auboin, C. and Wojdan, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11162216 },
  abstract={The advent of Generative AI (GenAI) introduces new technological capabilities to the telco market. With its advanced reasoning abilities, GenAI makes it much easier to automate complex manual tasks with flexibility and efficiency, even in complicated environments. This is especially helpful for cloud-native mobile networks, where GenAI can simplify many challenging operations. In this paper, we analyze the concept of using Large Language Models (LLMs) acting as a Reasoning Engine to handle complex tasks related to the management of 5G networks and their hosting telco-cloud infrastructure, turning human-level instructions into actionable steps using Chain-of-Thoughts and finally delegating tasks to proper cloud management tools. This use-case is not limited to telco environment, but also applicable for generic cloud workloads. We compared TAIA’s performance using Gemini 1.5 Pro, GPT 4.0, and GPT 4 Turbo LLMs under various scenarios. Notably, Gemini 1.5 Pro excelled in efficiency for well-defined tasks, while GPT 4.0 showed superior reasoning for complex requests, highlighting TAIA’s adaptability to diverse LLM capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCWorkshops67674.2025.11162216 },
  booktitle={ 2025 IEEE International Conference on Communications Workshops (ICC Workshops) },
  chapter={0}
}

@article{rayyan-352343480,
  title={ LLM-Guided Multi-Agent System for Natural Language-Based Robot Navigation  -  2025 IEEE World AI IoT Congress (AIIoT) },
  year={2025},
  author={Samarathunga, K. and Gurusinghe, R. and Sivasothynathan, K. and Wanigasekara, C. and Mars, J. and Logeeshan, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105295 },
  abstract={Natural language-driven robot navigation has the potential to make human-robot interactions more intuitive. This paper presents an innovative approach that integrates a Large Language Model (LLM) with a Multi-Agent System (MAS) to enable autonomous robot navigation in response to verbal commands. We use GPT-4o for interpreting user commands, LangChain and LangGraph for MAS-based decision-making, and Rapidly-Exploring Random Tree (RRT) for path planning. The system is simulated in Webots, demonstrating its adaptability in various environments. Our results show that the integration of LLM and MAS enhances decision-making efficiency and enables flexible, real-time path adjustments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT65859.2025.11105295 },
  booktitle={ 2025 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343481,
  title={ GenXSS: an AI-Driven Framework for Automated Detection of XSS Attacks in WAFs  -  SoutheastCon 2025 },
  year={2025},
  author={Babaey, V. and Ravindran, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10971558 },
  abstract={The increasing reliance on web services has led to a rise in cybersecurity threats, particularly Cross-Site Scripting (XSS) attacks, which target client-side layers of web applications by injecting malicious scripts. Traditional Web Application Firewalls (WAFs) struggle to detect highly obfuscated and complex attacks, as their rules require manual updates. This paper presents a novel generative AI framework that leverages Large Language Models (LLMs) to enhance XSS mitigation. The framework achieves two primary objectives: (1) generating sophisticated and syntactically validated XSS payloads using in-context learning, and (2) automating defense mechanisms by testing these attacks against a vulnerable application secured by a WAF, classifying bypassing attacks, and generating effective WAF security rules. Experimental results using GPT-4o demonstrate the framework's effectiveness generating 264 XSS payloads, 83% of which were validated, with 80% bypassing ModSecurity WAF equipped with an industry standard security rule set developed by the Open Web Application Security Project (OWASP) to protect against web vulnerabilities. Through rule generation, 86% of previously successful attacks were blocked using only 15 new rules. In comparison, Google Gemini Pro achieved a lower bypass rate of 63%, highlighting performance differences across LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SoutheastCon56624.2025.10971558 },
  booktitle={ SoutheastCon 2025 },
  chapter={0}
}

@article{rayyan-352343482,
  title={ Active Prompt Caching in Edge Networks for Generative AI and LLMs: An RL-Based Approach  -  2025 IEEE Wireless Communications and Networking Conference (WCNC) },
  year={2025},
  author={Baccour, E. and Erbad, A. and Mohamed, A. and Hamdi, M. and Guizani, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978306 },
  abstract={Generative AI (GAI) and Large Language Models (LLMs) have revolutionized natural language processing and content creation. However, their significant computational demands during inference often require cloud servers, which are currently the only viable option for handling complex multi-modal models like GPT-4. The inherent complexity of these models increases latency, posing challenges even within cloud environments. Furthermore, cloud reliance brings other challenges, including high bandwidth consumption to transfer diverse data types. Worse, in personalized GAI applications like virtual assistants, similar prompts frequently occur, causing redundant transmission and computation of replies, which further increases overhead. Accelerating the inference of multi-modal systems is, therefore, critical in artificial intelligence. In this paper, we aim to improve the inference efficiency through prompt caching; if a current prompt is semantically similar to a previous one, the system can reuse the earlier response without invoking the model again. We leverage collaborative edge computing to cache popular replies and store their request embeddings. New prompts are locally processed to extract embeddings, with their qualities determined by the resources available on edge servers. Our problem is formulated as an optimization to manage offloading decisions for GAI tasks, aiming to avoid cloud inferences and minimize latency while maximizing reply quality. Given its non-convex nature, we propose to solve it via Block Successive Upper Bound Minimization (BSUM). Reinforcement learning is employed to actively pre-cache prompts, tackling the complexity of unknown prompt popularity. Our approach demonstrates near-optimal performance, significantly outperforming cloud-only solutions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WCNC61545.2025.10978306 },
  booktitle={ 2025 IEEE Wireless Communications and Networking Conference (WCNC) },
  chapter={0}
}

@article{rayyan-352343483,
  title={ Will Generative AI Fill the Automation Gap in Software Architecting?  -  2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  year={2025},
  author={Ivers, J. and Ozkaya, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015085 },
  abstract={Researchers are aware that software architects lack effective automation to support much of their work. Generative AI (GenAI) is sparking research interest regarding its potential role in filling this gap, inspired by promising applications of GenAI to other software engineering activities. In this paper, we aim to reflect and sharpen this conversation from the vague “how can GenAI be applied to architecture” to “which architecture activities are most amenable to application of GenAI.” We stress the importance of considering contributions in the context of workflows and reflect on the alignment (or lack thereof) of GenAI with the nature of common architecture tasks through the discussion of five common architecture activities. We offer guiding criteria to assist architecture researchers in focusing on activities that are both amenable to automation and likely to obtain significant utility from GenAI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C65153.2025.00014 },
  booktitle={ 2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343484,
  title={ Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI  -  IEEE Network },
  author={Zhu, B. and Wang, X. and Zhang, L. and Shen, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048518 },
  abstract={In collaborative systems with complex tasks relying on distributed resources, trust evaluation of potential collaborators has emerged as an effective mechanism for task completion. However, due to the network dynamics and varying information gathering latencies, it is extremely challenging to observe and collect all trust attributes of a collaborating device concurrently for a comprehensive trust assessment. In this paper, a novel progressive trust evaluation framework, namely chain-of-trust, is proposed to make better use of misaligned device attribute data. This framework, designed for effective task completion, divides the trust evaluation process into multiple chained stages based on task decomposition. At each stage, based on the task completion process, the framework only gathers the latest device attribute data relevant to that stage—leading to reduced trust evaluation complexity and overhead. By leveraging advanced incontext learning, few-shot learning, and reasoning capabilities, generative AI is then employed to analyze and interpret the collected data to produce correct evaluation results quickly. Only devices deemed trustworthy at this stage proceed to the next round of trust evaluation. The framework ultimately determines devices that remain trustworthy across all stages. Experimental results demonstrate that the proposed framework achieves high accuracy in trust evaluation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MNET.2025.3582407 },
  booktitle={ IEEE Network },
  chapter={0}
}

@article{rayyan-352343485,
  title={ Human and Machine: How Software Engineers Perceive and Engage with AI-Assisted Code Reviews Compared to Their Peers  -  2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE) },
  year={2025},
  author={Alami, A. and Ernst, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024268 },
  abstract={The integration of artificial intelligence (AI) continues to increase and evolve, including in software engineering (SE). This integration involves processes traditionally entrusted to humans, such as coding. However, the impact on sociotechnical processes like code review remains underexplored. In this interview-based study (20 interviewees), we investigate how software engineers perceive and engage with Large Language Model (LLM)-assisted code reviews compared to human peerled reviews. In this inherently human-centric process, we aim to understand how software engineers navigate the introduction of AI into collaborative workflows. We found that engagement in code review is multi-dimensional, spanning cognitive, emotional, and behavioral dimensions. The introduction of LLM-assisted review impacts some of these attributes. For example, there is less need for emotional regulation and coping mechanisms when dealing with an LLM compared to peers. However, the cognitive load sometimes is higher in dealing with LLM-generated feedback due to its excessive details. Software engineers use a similar sense-making process to evaluate and adopt feedback suggestions from their peers and the LLM. However, the LLM feedback adoption is constrained by trust and lack of context in the review. Our findings contribute to a deeper understanding of how AI tools are impacting SE socio-technical processes and provide insights into the future of AI-human collaboration in SE practices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CHASE66643.2025.00016 },
  booktitle={ 2025 IEEE/ACM 18th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE) },
  chapter={0}
}

@article{rayyan-352343486,
  title={ Large Language Models (LLM) in Industry: A Survey of Applications, Challenges, and Trends  -  2024 IEEE 21st International Conference on Smart Communities: Improving Quality of Life using AI, Robotics and IoT (HONET) },
  year={2024},
  author={Chkirbene, Z. and Hamila, R. and Gouissem, A. and Devrim, U.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10822885 },
  abstract={Large Language Models (LLMs) are transforming industries by automating tasks such as text generation, data analysis, and customer interactions. Their impact spans various sectors, including finance, healthcare, legal services, and education’ where they streamline operations and enhance decision-making. Despite these advantages, the adoption of LLMs is hindered by challenges such as high computational costs, data privacy concerns, and the lack of explainability. Existing surveys on LLMs primarily focus on their capabilities and applications, emphasizing their role in generating human-like text, processing unstructured data, and supporting decision-making. However, these studies also highlight the significant limitations of LLMs, particularly around computational expense, privacy, and the “black box” nature of their outputs, which restrict their use in critical, regulated industries. This paper builds on prior work by exploring emerging solutions to address these challenges. It examines innovations such as domain-specific LLMs, LLM-as-a-Service (LLMaaS), and advancements in explainable AI (XAI) to enhance transparency and accessibility. The paper provides practical insights into how businesses can strategically adopt LLMs while mitigating risks, making them more viable for broader industry application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/HONET63146.2024.10822885 },
  booktitle={ 2024 IEEE 21st International Conference on Smart Communities: Improving Quality of Life using AI, Robotics and IoT (HONET) },
  chapter={0}
}

@article{rayyan-352343487,
  title={ AI-Generated Text Detection and Prevention of Unethical AI Use in Student Exams  -  2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES) },
  year={2024},
  author={Nikiforova-Ilieva, K. and Georgiev, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10811427 },
  abstract={The widespread use of Artificial Intelligence (AI) technologies based on Large Language Models (LLM) is significantly transforming the educational landscape. While AI is proving its benefits for personalized learning, it also poses serious challenges, especially in terms of assessing students' knowledge during exams and independent work. Tools like ChatGPT can help students generate or refine text, which raises questions about academic honesty.This paper examines the effectiveness of AI text detectors, as well as ways to circumvent them. The focus of the research is on Bulgarian language texts, as there is currently a dearth of such data and revised English and Bulgarian texts in terms of grammar and style only.Effective examination practices should include anti-manipulation measures such as proctoring technologies and authentication. Attendance exam remains the most reliable method of ensuring both academic honesty and important social interactions critical to students' future career development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIEES62939.2024.10811427 },
  booktitle={ 2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES) },
  chapter={0}
}

@article{rayyan-352343488,
  title={ A Demonstration of Voice-Interactive AI Agents for Vehicles Utilizing Multiple LLMs  -  2024 IEEE International Conference on Smart Computing (SMARTCOMP) },
  year={2024},
  author={Furusawa, T. and Saitoh, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10595601 },
  abstract={Voice user interfaces (VUIs) based on large language models (LLMs) can significantly enhance the user experience for vehicle drivers. However, relying on a single, centrally-located LLM does not ensure high-quality and diverse functionalities across different locations. In this demonstration, we propose a voice-interactive AI agent system for connected vehicles that utilizes multiple LLMs, integrated within an end-to-end infras-tructure that spans in-vehicle devices, edge data centers, and public cloud services. This proposed system enables drivers to fulfill various needs through natural conversations by selecting the most suitable AI agent for their intended purposes. AI agents are deployed in the optimal execution environment, whether in the in-vehicle device, edge data center, or cloud, based on each AI agent's characteristics. With this system, it is possible to achieve multiple scenarios that were challenging with traditional VUIs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SMARTCOMP61445.2024.00058 },
  booktitle={ 2024 IEEE International Conference on Smart Computing (SMARTCOMP) },
  chapter={0}
}

@article{rayyan-352343489,
  title={ Sustainable AI for Zero Touch Network & Service Management with Graph Neural Networks  -  2024 IEEE 29th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD) },
  year={2024},
  author={Vlontzou, M. E. and Samaras, G. and Theodorou, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10942655 },
  abstract={In the pursuit of sustainable and efficient 6G network management, leveraging advanced AI methodologies becomes imperative. Our work introduces a comprehensive framework for resource usage prediction, focusing on data-compute 6G networks. This novel approach relies on state-of-the-art AI/ML techniques to achieve accurate resource usage and energy consumption predictions in 6G networks. By predicting various metrics obtained from Prometheus and Kepler, such as memory usage and energy consumption, we dynamically scale services across nodes using the Edge Platform of Intracom Telecom, aiming to reduce the energy footprint while preventing performance degradation and maintaining high Quality of Service (QoS). A core component of our approach are the Graph Neural Network (GNN) models, which are based on a Spatio-Temporal Graph Neural Network (STGNN), a very capable deep learning technique in predicting future values by modeling both spatial and temporal dependencies among network nodes. This enables a proactive and accurate forecasting mechanism that outperforms traditional Attention Temporal Graph Convolutional Network (A3T-GCN), but also cutting-edge Large Language Models (LLMs) in time series forecasting tasks. Our framework additionally incorporates automated AI models Life Cycle Management (LCM) using zero-touch MLOps techniques through tools like Kubeflow and Katib, ensuring efficient deployment, monitoring, and maintenance of AI models. Our extensive evaluation demonstrates the superiority of our approach in terms of prediction accuracy and operational efficiency compared to A3T-GCN and LLM based methods. The results indicate significant improvements in resource utilization and energy efficiency, positioning our framework as a sustainable and effective solution for zero-touch network and service management in 6G networks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAMAD62243.2024.10942655 },
  booktitle={ 2024 IEEE 29th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD) },
  chapter={0}
}

@article{rayyan-352343490,
  title={ Effects of Proactive Interaction and Instructor Choice in AI-Generated Virtual Instructors for Financial Education  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Prasongpongchai, T. and Pataranutaporn, P. and Lapapirojn, A. and Kanapornchai, C. and Leong, J. and Ouppaphan, P. and Winson, K. and Lertsutthiwong, M. and Maes, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893581 },
  abstract={This research full paper describes a web-based online learning platform that delivers financial literacy lessons via talking head videos of AI-generated personas with two additional core features: LLM-powered proactive chat-based question-and-answer interactivity, and personal choice of the AI instructor from a list of distinct personas. We conducted two comparative studies with a total of 233 Thai students aged 1825, which aim to 1) investigate the impact of interactivity and instructor selection on the learning experience, and 2) further explore the underlying factors at play with instructor selection by introducing AI instructors' backstories as an extra intervention. We found that enabling interactivity significantly enhanced learning motivation, perceived learning facilitation, engagement, and virtual instructors' humanness compared to the passive setting. Providing learners with a choice of AI instructors provided minimal additional benefit. However, the learner's feeling of relatedness toward the instructor is a significant positive predictor of learning motivation, positive emotion, and agent credibility, while goal alignment with the agent correlates with perceived learning facilitation, and admiration corresponds with perceived agent humanness. These findings underscore the potential of interactive virtual instructors-ones that interactively encourage learners to reflect on the teaching materials throughout the lesson through two-way interaction-in enhancing motivational and experiential aspects of remote education, even if they do not significantly impact comprehension, and the importance of promoting learner's relatedness and goal alignment with the agent in boosting other aspects of the learning experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893581 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343491,
  title={ A First Look at AI Trends in Value-Aligned Software Engineering Publications: Human-LLM Insights  -  2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS) },
  year={2025},
  author={Mougouei, D. and Azarnik, A. and Fahmideh, M. and Mougouei, E. and Dam, H. K. and Khan, A. A. and Rafi, S. and Khan, J. A. and Ahmad, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023907 },
  abstract={Recent criticism of social media platforms by the U.S. Senate Judiciary Committee for neglecting child safety exemplifies how software can undermine human values. This is further complicated by the growing integration of Artificial Intelligence (AI) in software, which introduces inherent challenges such as biases and limited transparency. However, AI also presents opportunities to embed human values into software. To explore these opportunities, we have utilized the reasoning abilities of ChatGPT, a large language model (LLM), in combination with human expertise, to study the use of AI in publications that address human values, across some of the leading software engineering (SE) venues from 2022 to 2023. Our findings confirm the use of AI concepts - mainly General Machine Learning - in around 33 % of these valuealigned publications. The value alignments largely concern pragmatic aspects of Achievement and (personal) Security, while the majority of the values receive less attention. The socially focused values of Conformity and Tradition and the personally focused value of Hedonism are rarely addressed in the SE publications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE-SEIS66351.2025.00014 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS) },
  chapter={0}
}

@article{rayyan-352343492,
  title={ Multi-Cloud Semantic Orchestration of AI-Driven Pipelines for Privacy-First LLM Inference  -  2025 International Conference on Computing Technologies & Data Communication (ICCTDC) },
  year={2025},
  author={Jakku, P. C. and Chippagiri, S. and Uppalapati, N. R. and Dasi, U.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11158733 },
  abstract={Because more people need scalable and private Large Language Model (LLM) processing in the cloud, better orchestration methods for using different cloud resources are required. This research proposes a new architecture for handling Multi-Cloud Semantic Orchestration of AI-driven data pipelines to make LLM inference workflows more efficient, secure and in line with company policies. The framework makes it possible to effectively assign tasks and control data with the help of ontology-based knowledge graphs and added metadata by semantic enrichment. Our system uses distributed coordination engines, ensures both differential privacy and secure multiparty computation and selects appropriate models for proper latency, throughput and compliance. Experimental findings from using well-known NLP datasets show that the orchestration strategy proposed here reduces latency by up to 38 % and ensures more privacy by 22 % than standard single-cloud systems. This research supports better LLM operations (LLMOps) in areas like healthcare and finance, since both need to pay close attention to data protection and privacy laws.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCTDC64446.2025.11158733 },
  booktitle={ 2025 International Conference on Computing Technologies & Data Communication (ICCTDC) },
  chapter={0}
}

@article{rayyan-352343493,
  title={ Enhancing Engineering Education Through LLM-Driven Adaptive Quiz Generation: A RAG-Based Approach  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Gopi, S. and Sreekanth, D. and Dehbozorgi, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893146 },
  abstract={This research-to-practice study aims to develop an Artificial Intelligence (AI) MCQ generation system for engineering students, with a focus on adaptive learning, educational technology, and innovative assessment tools, to enhance personalized learning. Engineering education faces significant academic performance challenges, with first-year retention rates in STEM fields ranging between 27% to 46%, largely due to poor academic achievements. Multiple Choice Questions (MCQs) identify misconceptions, reinforce knowledge retention, and offer efficient assessment methods for engineering education. This interactive method improves attention and memory retention, reinforces knowledge, and improves comprehension. In this context, the emergence of Large Language Models (LLMs) such as GPT-4 has marked a significant advancement. Our literature review method employed a systematic approach, analyzing peer-reviewed articles, conference papers, and authoritative reports to uncover the trends and challenges in AI-driven quiz generation. The notable gap identified in our literature review is the lack of LLM-based adaptive quiz generation methods specifically for engineering education. Our methodology involved sourcing relevant structured datasets, data pre-processing, embedding generation, vector database storage, hybrid-search retrieval, LLM query results feed, prompt engineering, and context-based response. In this research, we adopted Vectara as a vector database tool for its automatic data ingestion capabilities and seamless integration with generative AI applications. Prompt engineering involves a dual-prompt approach, where the Contextual Question Prompt formulates questions based on user topics and chat history, while the Answer Question Prompt manages MCQ responses with explanations, ensuring relevant and contextually accurate interactions. Evaluation includes topic relevancy, answer relevancy, and a contextual relevancy score. Preliminary results indicate promising results for the generation of accurate and contextually appropriate questions with minimal hallucinations. The quiz generation system was deployed using Streamlit cloud-based architecture to showcase the functionality. Looking forward, we aim to expand the dataset to include more diverse engineering disciplines and to refine the retrieval algorithms to better handle complex diagrams and mathematical expressions commonly found in engineering texts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893146 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343494,
  title={ Designing an LLM-Based IELTS Question Generator, Assessment, and Personalized Training System: Architecture and Research Agenda  -  2025 22nd International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON) },
  year={2025},
  author={Tiratatri, T. and Sukittivarapunt, K. and Sarasinpitak, T. and Pyae, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101665 },
  abstract={While generative AI tools like LLMs have begun to assist in IELTS preparation, most fail to provide skill-specific, exam-aligned feedback across all four sections: Listening, Reading, Writing, and Speaking. This paper introduces NOAH, a novel LLM-based preparation system designed using a structured SDLC and LLMOps framework. Unlike generic AI tutors, NOAH features custom fine-tuned GPT-4o models trained on authentic IELTS materials, prompt-chained question generation, and automated visual and audio synthesis for realistic task simulation. The system supports modular skill pipelines, adaptive mock testing, and speech-based scoring using Azure APIs, delivering a full-stack solution optimized for personalization, scalability, and accessibility. Guided by human-centered AI principles, NOAH bridges pedagogical precision with generative AI flexibility, setting a foundation for equitable and high-fidelity language assessment preparation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECTI-CON64996.2025.11101665 },
  booktitle={ 2025 22nd International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON) },
  chapter={0}
}

@article{rayyan-352343495,
  title={ Large Language Model (LLM)-Enabled Graphs in Dynamic Networking  -  IEEE Network },
  author={Sun, G. and Wang, Y. and Niyato, D. and Wang, J. and Wang, X. and Poor, H. V. and Letaief, K. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778660 },
  abstract={Recent advances in generative artificial intelligence (AI), and particularly the integration of large language models (LLMs), have had considerable impact on multiple domains. Meanwhile, enhancing dynamic network performance is a crucial element in promoting technological advancement and meeting the growing demands of users in many applications areas involving networks. In this article, we explore an integration of LLMs and graphs in dynamic networks, focusing on potential applications and a practical study. Specifically, we first review essential technologies and applications of LLM-enabled graphs, followed by an exploration of their advantages in dynamic networking. Subsequently, we introduce and analyze LLM-enabled graphs and their applications in dynamic networks from the perspective of LLMs in different roles. On this basis, we propose a novel framework of LLM-enabled graphs for networking optimization, and then present a case study on UAV networking, concentrating on optimizing UAV trajectory and communication resource allocation to validate the effectiveness of the proposed framework. Finally, we outline several potential future extensions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MNET.2024.3511662 },
  booktitle={ IEEE Network },
  chapter={0}
}

@article{rayyan-352343496,
  title={ Impact of GenAI using Auto Content Generation Tools on Cognitive Thinking Process in Academia  -  2025 IEEE Integrated STEM Education Conference (ISEC) },
  year={2025},
  author={Marimekala, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147291 },
  abstract={In today’s world, there is a drastic change in how tools are auto-generating content. These content generation tools that use generative AI make it easier to write blogs, generate content, reply to emails, create and publish content quickly, parse text, and refer to specific information very quickly and with ease. Students use these tools in colleges and educational institutions daily on social media. GenAI tools help reconstruct sentences, correct grammar, use proper words, auto-filling information, and preempt words that make the user not think but instead follow the prompts. GenAI will impact future generations because they cannot be self-reliant and rely heavily on artificial intelligence to form sentences and write the essential content. There must be a need for AI awareness and governance adoption in AI applications and tools as an integral process with a balance on how AI adoption in educational and social networks should enrich and promote individuals in the learning process and dynamically adjust to the individual requirements and help them in crafting sentences intelligently, build information and ideas that encourage thinking process, and using standard English conventions and expression of ideas. The primary focus of this paper is to introduce the challenges of GenAI adoption in applications and tools we use daily and its exposure to Gen X, Gen Y, Gen Z, and Gen Alpha. In this paper, we will bring awareness to such GenAI tools that can adversely impact the growth of individual cognitive thinking processes and the measures that citizens should take so that Human Intelligence prevails over Artificial Intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISEC64801.2025.11147291 },
  booktitle={ 2025 IEEE Integrated STEM Education Conference (ISEC) },
  chapter={0}
}

@article{rayyan-352343497,
  title={ Development of AI Accelerators at Preferred Networks  -  2025 International VLSI Symposium on Technology, Systems and Applications (VLSI TSA) },
  year={2025},
  author={Hiraki, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11046565 },
  abstract={Preferred Networks, Inc. is a technology company that develops software and hardware for deep learning and AI applications. Preferred Networks has developed its MN-CoreTM series of AI accelerators –– MN-Core and MN-Core 2 in the current lineup –– for training neural networks for deep learning. In this talk, we will introduce the architecture of MN-Core and MN-Core 2 and how we have implemented them. We will then discuss the outline of our next-generation training accelerator in the MN-Core series as well as our upcoming LLM inference accelerator MN-Core L1000. The next-generation MN-Core accelerator is based on the 2nm CMOS technology which will ensure higher speed than that of the current generation. MN-Core L1000 employs 3D integration of an accelerator die and stacked custom DRAM dies to drastically increase memory bandwidth between the accelerator and DRAMs and reduce the system's overall power consumption.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VLSITSA64674.2025.11046565 },
  booktitle={ 2025 International VLSI Symposium on Technology, Systems and Applications (VLSI TSA) },
  chapter={0}
}

@article{rayyan-352343498,
  title={ A Pilot Study of Probing Before Trusting Large Language Models in Self-Learning  -  2025 International Symposium on Educational Technology (ISET) },
  year={2025},
  author={Wei, Z. and Lee, V. C. S. and Chan, W. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113570 },
  abstract={A critical and general problem of large language models (LLMs) is that they may hallucinate, generating specious answers, especially when they interpret certain concepts expressed in the given natural language queries using incorrect (sub)domain knowledge they possess. Still, LLMs are widely used by people. To embrace LLMs in education, students can adopt them to seek quick feedback on their questions to enhance their inquisitive approaches to self-learning, while there is a guard against hallucination. This paper introduces DomainProbe, the first approach to domain-level hallucination detection that leverages metamorphic testing for addressing the test oracle problem to improve the trustworthiness of the feedback generated by LLMs. Given a question posed by a student, DomainProbe prompts the LLM to extract key topical terms from the question and provide explanations for each. The student then evaluates whether there is any inconsistent term-explanation pair. If such an inconsistency is identified, the corresponding answer for the question from the LLM is flagged as untrustworthy. We show DomainProbe to achieve promising results by evaluating it on MMLU, a widely used question-answer benchmark dataset. We further discuss our vision on the approach to promote students' learning objectives and outline future work for the metamorphic relations formulated in DomainProbe.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISET65607.2025.00046 },
  booktitle={ 2025 International Symposium on Educational Technology (ISET) },
  chapter={0}
}

@article{rayyan-352343499,
  title={ Exploring Shared Large Language Models: Early Insights into Scalability and Efficiency in AI Assistant and Agent Deployment  -  2025 International Conference on Military Communication and Information Systems (ICMCIS) },
  year={2025},
  author={Kok, A. and Carvalho, A. and Street, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048102 },
  abstract={The deployment of Large Language Models (LLMs) is rapidly expanding across diverse applications, necessitating cost-effective and resource-efficient strategies to optimize their usage. This paper investigates the scalability, efficiency, and performance trade-offs of sharing LLMs across multiple applications, addressing critical challenges such as GPU limitations, concurrency management, and latency optimization. Using three experimental setups ranging from consumer-grade GPUs to high-performance cloud infrastructure, we examine the interplay between prompt size, model size, and concurrency on metrics like latency, throughput, and GPU utilization. Our findings reveal that shared LLM architectures significantly enhance resource efficiency, with concurrency improving throughput by 2x to 4x for longer prompts and over 20x for shorter batched prompts. However, memory constraints impose limitations on scalability, particularly for large models and extended prompts, where latency increases linearly with context length. Practical recommendations include tailoring GPU configurations to balance memory and compute demands, leveraging batching for optimal utilization, and mitigating latency through caching and load balancing. This study underscores the strategic value of shared LLMs in reducing costs and enhancing scalability for multi-application scenarios, particularly in domains with constrained resources, such as defense. The results provide actionable insights into deploying shared generative AI systems efficiently while paving the way for future exploration of advanced optimization techniques. This paper was originally presented at the NATO Science and Technology Organization Symposium (ICMCIS) organized by the Information Systems Technology (IST) Panel, IST-209-RSY-the ICMCIS, held in Oeiras, Portugal, 13–14 May 2025.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMCIS64378.2025.11048102 },
  booktitle={ 2025 International Conference on Military Communication and Information Systems (ICMCIS) },
  chapter={0}
}

@article{rayyan-352343500,
  title={ Large Language Model Virtual Assistants for International Business and Product Marketing  -  2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART) },
  year={2024},
  author={Shenoy, P. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882556 },
  abstract={In order for emergent and incumbent businesses to establish themselves on the global market, each company needs to navigate the rules, regulations, and policies native to the regions outside of their current area of operation. This is an understandably time-consuming process, and it can be challenging to understand the explicit and implicit compliances of each country for targeted product marketing. The recent development of Artificial Intelligence (AI), Natural Language Processing (NLP) and Large Language Models (LLMs) presents a unique opportunity to solve these challenges and expedite the process in which a company expands their foreign influence. The proposed solution is to retrain a Pre-trained LLM model on datasets which encompass a region's social and legal characteristics, such as its culture, politics, language differences, and ethical norms. Business professionals can leverage the proposed LLM concepts to provide answers for customer behavior and expectation related questions, which can allow them to gain a comprehensive overview of various barriers that need to be considered when introducing a new product in a foreign region or to gain ideas when developing products to meet regional needs. The efficiency of an organization is improved as a result, since the initial steps to launching the successful release of a product can be automated using machine learning processes, and administrative work can be reduced across many levels. During the search for existing work, the author did not find any research paper that constructed and evaluated a specialized LLM, to publicly available models, that supported the demands related to international business and product marketing. The advantages, challenges, and process of implementation for a fine-tuned LLM solution is explored, with the intended users being international business and market analysts as well as product designers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SMART63812.2024.10882556 },
  booktitle={ 2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART) },
  chapter={0}
}

@article{rayyan-352343501,
  title={ MEDFIT-LLM: Medical Enhancements through Domain-Focused Fine Tuning of Small Language Models  -  2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE) },
  year={2025},
  author={Rao, A. K. G. and Jaggi, A. and Naidu, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042816 },
  abstract={This research explores the efficacy of fine-tuning small Large Language Models (LLMs) for AI-based healthcare chatbots. We present a novel approach to dataset creation using synthetic data generation and fine-tuning of various LLMs. The study compares the performance of base models against their fine-tuned counterparts using a carefully curated dataset of healthcare-related questions and answers. Our methodology involves the use of phi 4 for synthetic data generation, supplemented with domain-specific questions derived from existing research. We employ LORA fine-tuning on MLX for four distinct models: Gemma 2 9B 4bit, LLama 3.2 3B Instruct, Mistral 7B, and Qwen2 7B Instruct 8 bit. The results demonstrate the potential of fine-tuning in enhancing the performance of LLMs in specialized healthcare contexts, contributing to the ongoing development of more accurate and reliable AI-powered healthcare chatbots. The code is available at https://github.com/adityak74/medfit-llm.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RMKMATE64874.2025.11042816 },
  booktitle={ 2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE) },
  chapter={0}
}

@article{rayyan-352343502,
  title={ Essay Scoring with LLM Agent  -  2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT) },
  year={2025},
  author={Espino, F. P. and Dolganov, A. Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11054195 },
  abstract={This study presents an AI-based agent designed to automate the grading of student essays in the Ecology course at Ural Federal University. The agent leverages the capabilities of Large Language Models (LLMs), particularly from the Llama family, to evaluate various aspects of student writing, including grammar, structure, and content relevance. The system integrates advanced natural language processing techniques, Python libraries for data handling and analysis, and prompt engineering strategies to ensure accurate interpretation of student input. In addition to scoring, the model generates detailed feedback aimed at helping students understand their strengths and areas for improvement.Preliminary results from experiments using different versions of Llama models show a tendency to assign mid-range scores across most submissions. This indicates a challenge in clearly distinguishing between low- and high-quality responses, particularly for essays lacking strong arguments or cohesive structure. Despite occasional inconsistencies in scoring, the implementation of AI in the grading process has the potential to significantly streamline assessment workflows, reduce instructor workload, and enhance the consistency and depth of feedback. These findings suggest promising directions for improving both the accuracy and transparency of automated grading systems in educational contexts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/USBEREIT65494.2025.11054195 },
  booktitle={ 2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT) },
  chapter={0}
}

@article{rayyan-352343503,
  title={ Prediction of actions and places by the time series recognition from images with Multimodal LLM  -  2024 IEEE 18th International Conference on Semantic Computing (ICSC) },
  year={2024},
  author={Ogawa, T. and Yoshioka, K. and Fukuda, K. and Morita, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475660 },
  abstract={In recent years, the risk of accidents in the homes of older adults in an aging society has increased, and there is a need to address this problem. We took up the challenge of utilising explainable AI techniques to identify accident risks at home and suggest safer alternatives. This study combined knowledge graphs and large-scale language models to solve real-world problems. Specifically, we addressed answering questions using a multimodal dataset of videos recording daily activities and a knowledge graph. The dataset represents the living activities in the virtual space and provides environmental information. The task is divided into two main tasks. Task 1 utilises knowledge graph to answer direct questions and processes the data using SPARQL queries. Task 2 addresses more complex questions that cannot be answered by search alone. Consequently, in Task 1, the system could answer all questions using information from the SPARQL knowledge graph. In Task 2, a certain degree of success was achieved for complex questions by reasoning with images created by concatenating multimodal LLMs and time-series images. The source code used in the experiment is available at https://github.com/tomo1115tomo/kg_reasoning_challenge.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC59802.2024.00053 },
  booktitle={ 2024 IEEE 18th International Conference on Semantic Computing (ICSC) },
  chapter={0}
}

@article{rayyan-352343504,
  title={ Verification and Validation of LLM-RAG for Industrial Automation  -  2025 IEEE International Conference on Artificial Intelligence Testing (AITest) },
  year={2025},
  author={Min, Z. and Budnik, C. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11127266 },
  abstract={Large Language Models (LLMs) have emerged as transformative tools in industrial automation, supporting decision-making from device-level control to enterprise-level coordination. When combined with Retrieval-Augmented Generation (RAG), these systems promise context-aware, domain-specific reasoning. However, their integration into mission-critical pipelines introduces considerable challenges to reliability, robustness, and continuous validation, particularly within Development and Operations (DevOps) and Continuous Integration/Continuous Delivery (CI/CD) environments. This work presents a comprehensive Verification and Validation (V&V) framework designed to address these challenges holistically across the AI system lifecycle. At its core, the framework introduces a novel Continuum-Based Failure Classification (CBFC) model that redefines validation from a binary pass/fail paradigm to a graded assessment of correctness, consistency, and uncertainty. This assessment spans key dimensions such as retrieval relevance, factual accuracy, coherence, and alignment with user intent. The CBFC model integrates embedding-based similarity measures, logical entailment checks, and quality-oriented metrics (e.g., FactScore, ROUGE) to uncover failure modes often overlooked by conventional evaluation methods. The framework emphasizes reliability and adaptability through structured testing, latency optimization, proactive model retraining, and iterative feedback loops. It is demonstrated in an industrial Root-Cause Analyzer application, where it significantly improves system performance, interpretability, and trustworthiness. By advancing toward continuous, evidence-based evaluation, this approach enables the resilient deployment of retrieval-augmented large language model systems in dynamic, real-world industrial environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AITest66680.2025.00012 },
  booktitle={ 2025 IEEE International Conference on Artificial Intelligence Testing (AITest) },
  chapter={0}
}

@article{rayyan-352343506,
  title={ 6 LLM Fine-Tuning: Instruction and Parameter-Efficient Fine-Tuning (PEFT)  -  Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  author={Aathilakshmi, S. and Sivapriya, G. and Manikandan, T.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11164768.pdf&bkn=11164515&pdfType=chapter },
  abstract={In artificial intelligence (AI) generating function the large language model plays an important role in various long data communication. Even though the system has pretrained language model, this large language model (LLM) is going to help the model according to the trained data in various analyses. This system is very useful in many fields like natural language processing, question answering, and GPT to produce better performance. The collection of large data in pretrained model will give a better solution but it is not able to tune all the data which is suitable for multitask application. This LLM is used to train the data more efficiently according to different categorizations such as medical dataset prediction, language translation, and user support. To improve the accuracy level the trained fine-tuning method is used which is more suitable for any specific task. The pretrained model is used to train all the dataset which is available in specific task and analyzed using fine-tuned data transition. Even though this pretrained model produces large analyzation of data in language processing, language training and prediction with the help of LLM it produce good performance for any dataset. The fine-tuning model is used to understand data transmission, task prediction, and medical analyzation. For example, training the dataset using fine-tuning is used to produce large dataset transition with effective way of different applications like LLM and GPT. This large language model is one of the best datasets trained sequence in real-time application of generative AI. This LLM knows how to collect a dataset according to the user concern and how it will produce the outcome using fine-tuning method but this LLM required more storage area compared to the LLM fine-tuned model. For example, finetuning an LLM like GPT has some trained language according to the predefined model; by the way of this LLM the present trained dataset is going to analyze the question and answers, present situation-based, but it has some difficulties when increasing the number of dataset for high application. At this case the parameter-efficient fine-tuning method is used for good analysis, which considers as the storage capacity for any given task.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  chapter={0}
}

@article{rayyan-352343507,
  title={ Large Language Models Cover for Speech Recognition Mistakes: Evaluating Conversational AI for Second Language Learners  -  2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  year={2025},
  author={Verhelst, E. and Belpaeme, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974188 },
  abstract={Automatic Speech Recognition (ASR) technology has been reported to reach near-human performance in recent years, yet it continues to struggle with atypical speakers, particularly second language learners. This limitation has hindered progress in leveraging social robots for second language education, a field with significant promise. Recent advancements in Large Language Models (LLMs), which demonstrate capabilities in context understanding, common sense reasoning, and pragmatics, offer a potential solution by compensating for transcription errors introduced by ASR. This study examines whether ASR combined with an LLM can produce flowing conversation. Particularly, we look at its application in learning French as a second language by Dutch-speaking students. Through task-based interactions, where successful task completion depends on the accurate interpretation of user speech, the study evaluates the impact of LLMs on conversational outcomes. Results confirm that the performance of ASR degrades significantly for both speakers with limited proficiency and a non-English language. Nonetheless, LLMs demonstrate the ability to interpret context and sustain meaningful conversations despite suboptimal ASR outputs, high-lighting a promising path forward for the integration of these technologies in second-language education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HRI61500.2025.10974188 },
  booktitle={ 2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  chapter={0}
}

@article{rayyan-352343508,
  title={ Prompt Engineering Based Generative AI as a Service (GAIaaS) for Intent-Based Networking  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Kukkalli, H. and Dandekar, A. and Bauschert, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073676 },
  abstract={This paper presents a framework that integrates Generative AI as a Service (GAIaaS) into Service Management and Orchestration (SMO) systems to enable intent-based automation. By leveraging ChatGPT-4o's advanced natural language capabilities, the system interprets user intents and generates policy-driven service chain configurations. Prompt engineering techniques are employed to evaluate the model's performance across key areas, including response time for intent processing, token usage efficiency, repeatability of outputs, infrastructure cost, and multilingual support. The framework consists of various components such as orchestration engine, cloud network function controller, and SDN controller and automates service chain design and resource management. The obtained results demonstrate its reliable and scalable performance across different scenarios. However, challenges related to handling large prompts and sustaining performance under high loads have been identified. This work highlights the potential of GAIaaS to provide scalable, adaptive, and intelligent network automation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073676 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343509,
  title={ Heuristics and Biases in AI Decision-Making: Implications for Responsible AGI  -  2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC) },
  year={2025},
  author={Saeedi, P. and Goodarzi, M. and Canbaz, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11077505 },
  abstract={We investigate the presence of cognitive biases in three large language models (LLMs): GPT-4o, Gemma 2, and Llama 3.1. The study uses 1,500 experiments across nine established cognitive biases to evaluate the responses and consistency of the models. GPT-4o demonstrated the strongest overall performance. Gemma 2 showed strengths in addressing the sunk cost fallacy and prospect theory; however, its performance varied across different biases. Llama 3.1 consistently underperformed, relying on heuristics and exhibiting frequent inconsistencies and contradictions. The findings highlight the challenges of achieving robust and generalizable reasoning in LLMs, and underscore the need for further development to mitigate biases in artificial general intelligence (AGI). The study emphasizes the importance of integrating statistical reasoning and ethical considerations in future AI development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIRC64931.2025.11077505 },
  booktitle={ 2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC) },
  chapter={0}
}

@article{rayyan-352343510,
  title={ Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning  -  2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM) },
  year={2025},
  author={Moribe, S. and Ushiama, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10857528 },
  abstract={In recent years, peer learning has gained attention as a method that promotes spontaneous thinking among learners, and its effectiveness has been confirmed by numerous studies. This study aims to develop an AI Agent as a learning companion that enables peer learning anytime and anywhere. However, peer learning between humans has various limitations, and it is not always effective. Effective peer learning requires companions at the same proficiency levels. In this study, we assume that a learner's peers with the same proficiency level as the learner make the same mistakes as the learner does and focus on English composition as a specific example to validate this approach.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMCOM64595.2025.10857528 },
  booktitle={ 2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM) },
  chapter={0}
}

@article{rayyan-352343511,
  title={ Generative AI with GOAP for Fast-Paced Dynamic Decision-Making in Game Environments  -  2024 IEEE Conference on Games (CoG) },
  year={2024},
  author={Shan, T. and Michel, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645549 },
  abstract={In this paper, we explore a novel approach to AI gaming. We combine Goal-Oriented Action Planning (GOAP) with the cognitive power of LLM such as ChatGPT. Our method tackles the issue of delayed responses commonly seen with Large Language Models (LLMs). This would be a research question that allows us to use the cognitive power of LLM in the fast-paced world of gaming. In this paper, we utilize GOAP to counter this problem, which allows agents to think strategically and make decisions on the fly, enhancing users’ overall gaming experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG60054.2024.10645549 },
  booktitle={ 2024 IEEE Conference on Games (CoG) },
  chapter={0}
}

@article{rayyan-352343512,
  title={ Evaluation of LLM Powered Agentic AI for Solving Multi-Arm Bandit Problems  -  2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS) },
  year={2025},
  author={Hazime, J. and Farooq, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11125743 },
  abstract={Multi-armed bandit (MAB) problems are foundational to decision-making under uncertainty and have found renewed importance in applications such as online recommendation, adaptive experimentation, and real-time bidding. While classical statistical and reinforcement learning-based algorithms have demonstrated effectiveness, they often require pre-specified exploration strategies and fixed reward priors. With the advent of large language models (LLMs), a new paradigm referred to as agentic AI, has emerged, enabling reasoning-driven problem-solving via natural language interaction. This paper explores the capability of agentic AI to autonomously learn and act in MAB environments using only language-based prompts, without access to reward priors. We evaluate a range of agentic models, including GPT-4o, GPT-4o-mini, and DeepSeek-V3, across diverse bandit configurations that vary in reward distribution complexity. Results indicate that LLM agents can closely approximate optimal behavior in low-entropy settings and demonstrate learning behavior in more complex environments, especially when tuned with appropriate temperature parameters. This work provides an early benchmark for the feasibility and reliability of agentic AI in reinforcement learning settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COINS65080.2025.11125743 },
  booktitle={ 2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS) },
  chapter={0}
}

@article{rayyan-352343513,
  title={ Evaluation and Mitigation of the Limitations of Large Language Models in Business Decision-Making  -  2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA) },
  year={2025},
  author={Khaldy, M. A. and Gheraibia, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11013278 },
  abstract={Large Language Models (LLMs) have emerged as transformative tools in business decision-making, offering capabilities such as automation, market analysis, and customer insights. However, their integration into business processes presents significant limitations, including biases in training data, lack of domain-specific knowledge, interpretability issues, and ethical concerns. These challenges can affect the quality and reliability of business decisions, potentially leading to biased or erroneous outcomes. This paper evaluates the key limitations of LLMs in business contexts and explores strategies to mitigate these issues. Proposed solutions include diversifying training data to reduce biases, fine-tuning models with industry-specific expertise, implementing explainable AI techniques for better transparency, and establishing ethical guidelines to safeguard against misuse. By addressing these limitations, businesses can harness the full potential of LLMs, ensuring more effective, fair, and accountable decision-making processes. This research provides a comprehensive approach for mitigating the risks associated with LLMs in business environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCIAA65327.2025.11013278 },
  booktitle={ 2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA) },
  chapter={0}
}

@article{rayyan-352343514,
  title={ LLM Diagnostic Toolkit: Evaluating LLMs for Ethical Issues  -  2024 International Joint Conference on Neural Networks (IJCNN) },
  year={2024},
  author={Bahrami, M. and Sonoda, R. and Srinivasan, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650995 },
  abstract={The rapid proliferation of large language models (LLMs) has brought with it both opportunities and challenges. While LLMs and more broadly generative AI technologies are capable of providing excellent improvements for various routine and autonomous tasks thereby enabling cost and performance benefit, they are also prone to personal and societal harms such as biases, stereotypes, misinformation, and hallucinations to name a few. These ethical concerns have in turn triggered stakeholders across the world to call in for regulatory measures that ensure safe and beneficial use of generative AI technologies. In parallel, there are also research efforts to alleviate these issues through the development of generative AI bias detection and mitigating strategies. Towards advancing this goal, in this paper, we propose an accessible and end-user-friendly LLM diagnostic toolkit whereby diverse stakeholders such as software engineers, business executives, and consumers can examine a suite of LLMs for uncovering a host of ethical issues including biases and misinformation embedded in LLMs. We also demonstrate that our toolkit can be used to diagnose for issues related to commonsense reasoning capabilities of LLMs. Extensive experiments on challenging tasks and datasets demonstrates the effectiveness of our diagnostic toolkit.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IJCNN60899.2024.10650995 },
  booktitle={ 2024 International Joint Conference on Neural Networks (IJCNN) },
  chapter={0}
}

@article{rayyan-352343515,
  title={ Design and Evaluation of an LLM-Based Agent for QoT Estimation and Performance Optimization in Optical Networks  -  IEEE Open Journal of the Communications Society },
  author={Zhang, Y. and Song, Y. and Pang, Y. and Li, S. and Jiang, X. and Wang, Y. and Li, J. and Zhang, M. and Wang, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11157742 },
  abstract={The rapid expansion of optical networks has catalyzed the growth of data capacity, creating a new era of high-speed network services. However, as the scale and complexity of nodes and connections increase, coupled with increasingly stringent demands for service efficiency, quality, and resistance to interference, intelligent solutions are needed to achieve efficient and autonomous network operation and maintenance. In this study, we proposed an advanced artificial intelligence (AI) Agent empowered by large language model (LLM), aimed at providing a practical solution for autonomous optical network management. We leverage the powerful language processing and reasoning capabilities of the Generative Pre-trained Transformer (GPT-4), and integrate domain-specific knowledge and optical network tools to simplify maintenance workflows, reduce manual intervention, and improve operational efficiency. Acting as an intelligent assistant for optical network operations, the AI Agent is capable of providing real-time insights and optimization recommendations. In particular, we focus on four typical tasks: quality of transmission (QoT) estimation, performance analysis, optimization, and parameter calibration for physical-layer modeling, which are essential for ensuring service reliability and resource efficiency. Through the design, implementation, and evaluation of these tasks, we demonstrate the feasibility and effectiveness of the proposed agent in addressing key challenges of optical network maintenance. Furthermore, we provide an assessment of accuracy and reliability based on a predetermined scoring standard. The proposed solution not only enhances automation in network monitoring and optimization, but also provides a scalable and generalizable framework for LLM-based support in evolving optical transport environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OJCOMS.2025.3608290 },
  booktitle={ IEEE Open Journal of the Communications Society },
  chapter={0}
}

@article{rayyan-352343516,
  title={ An LLM-based software developer agent demonstrated through a port-logistic optimization case study  -  2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA) },
  year={2025},
  author={Dulai, T. and Kiss, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166656 },
  abstract={Advancements in artificial intelligence (AI) are having a significant impact across various domains. Among these, generative AI models – particularly large language models (LLMs) – have brought substantial changes to a wide range of activities and professions. As these models are capable of handling complex business workflows and interacting with external tools (e.g., via APIs), their agentic behaviour becomes especially valuable for supporting diverse workflows. Software development is one of the domains that can greatly benefit from the use of LLM-based agents. We have developed a software developer agent using the LangGraph platform, capable of generating and validating the software requirements specification (SRS), design document specification (DDS), project structure, function implementations, and corresponding unit tests – all based on a well-formulated input prompt. After successfully testing the agent on the relatively simple task of generating a Snake game, we applied it to a more complex problem: an optimization scenario. A simulation framework was developed to optimize port logistics processes, such as routing and scheduling trucks and vessels. This framework allows for port structure customization and, thanks to its modular design, supports the evaluation of various optimization algorithms. Using this framework, we investigated how our software developer agent performs on a significantly more complex coding task compared to the Snake game. We also compared the results with those generated by two widely used LLM-based systems: ChatGPT and Gemini Code Assist.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACDSA65407.2025.11166656 },
  booktitle={ 2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA) },
  chapter={0}
}

@article{rayyan-352343517,
  title={ RepairAgent: An Autonomous, LLM-Based Agent for Program Repair  -  2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE) },
  year={2025},
  author={Bouzenia, I. and Devanbu, P. and Pradel, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029914 },
  abstract={Automated program repair has emerged as a powerful technique to mitigate the impact of software bugs on system reliability and user experience. This paper introduces Repair Agent, the first work to address the program repair challenge through an autonomous agent based on a large language model (LLM). Unlike existing deep learning-based approaches, which prompt a model with a fixed prompt or in a fixed feedback loop, our work treats the LLM as an agent capable of autonomously planning and executing actions to fix bugs by invoking suitable tools. Repair Agent freely interleaves gathering information about the bug, gathering repair ingredients, and validating fixes, while deciding which tools to invoke based on the gathered information and feedback from previous fix attempts. Key contributions that enable Repair Agent include a set of tools that are useful for program repair, a dynamically updated prompt format that allows the LLM to interact with these tools, and a finite state machine that guides the agent in invoking the tools. Our evaluation on the popular Defects4J dataset demonstrates Repair Agent's effectiveness in autonomously repairing 164 bugs, including 39 bugs not fixed by prior techniques. Interacting with the LLM imposes an average cost of 270k tokens per bug, which, under the current pricing of OpenAI's GPT-3.5 model, translates to 14 cents per bug. To the best of our knowledge, this work is the first to present an autonomous, LLM-based agent for program repair, paving the way for future agent-based techniques in software engineering.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE55347.2025.00157 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE) },
  chapter={0}
}

@article{rayyan-352343518,
  title={ Quality Assurance for LLM-RAG Systems: Empirical Insights from Tourism Application Testing  -  2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW) },
  year={2025},
  author={Ahmed, B. S. and Baader, L. O. and Bayram, F. and Jagstedt, S. and Magnusson, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962487 },
  abstract={This paper presents a comprehensive framework for testing and evaluating quality characteristics of Large Language Model (LLM) systems enhanced with Retrieval-Augmented Generation (RAG) in tourism applications. Through systematic empirical evaluation of three different LLM variants across multiple parameter configurations, we demonstrate the effectiveness of our testing methodology in assessing both functional correctness and extra-functional properties. Our framework implements 17 distinct metrics that encompass syntactic analysis, semantic evaluation, and behavioral evaluation through LLM judges. The study reveals significant information about how different architectural choices and parameter configurations affect system performance, particularly highlighting the impact of temperature and top-p parameters on response quality. The tests were carried out on a tourism recommendation system for the Varmland region in Sweden, utilizing standard and RAG-enhanced configurations. The results indicate that the newer LLM versions show modest improvements in performance metrics, though the differences are more pronounced in response length and complexity rather than in semantic quality. The research contributes practical insights for implementing robust testing practices in LLM-RAG systems, providing valuable guidance to organizations deploying these architectures in production environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSTW64639.2025.10962487 },
  booktitle={ 2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW) },
  chapter={0}
}

@article{rayyan-352343519,
  title={ An LLM's Medical Testing Recommendations in a Nigerian Clinic: Potential and Limits of Prompt Engineering for Clinical Decision Support  -  2024 IEEE 12th International Conference on Healthcare Informatics (ICHI) },
  year={2024},
  author={McPeak, G. and Sautmann, A. and George, O. and Hallal, A. and Simal, E. A. and Schwartz, A. L. and Abaluck, J. and Ravi, N. and Pless, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628629 },
  abstract={We explore prompt designs for a lightweight integration of a large language model (LLM) into clinical decision support in primary care in Nigeria. The LLM integration is designed to give immediate, actionable “second opinions” to frontline healthworkers on their patient interaction notes. The assessment of a physician serves as a benchmark for the quality of the LLM feedback. A particular challenge was to counter the LLM's tendency to over-recommend laboratory testing, which is more in line with medical practice in high-income countries. We evaluate the ability of a range of prompt engineering approaches to better align the LLM's medical test recommendations with locally appropriate standards of clinical care.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHI61247.2024.00094 },
  booktitle={ 2024 IEEE 12th International Conference on Healthcare Informatics (ICHI) },
  chapter={0}
}

@article{rayyan-352343520,
  title={ What Does a Software Engineer Look Like? Exploring Societal Stereotypes in LLMs  -  2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS) },
  year={2025},
  author={Bano, M. and Gunatilake, H. and Hoda, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023894 },
  abstract={Large language models (LLMs) have rapidly gained popularity and are being embedded into professional applications due to their capabilities in generating human-like content. However, unquestioned reliance on their outputs and recommendations can be problematic as LLMs can reinforce societal biases and stereotypes. This study investigates how LLMs, specifically OpenAI's GPT-4 and Microsoft Copilot, can reinforce gender and racial stereotypes within the software engineering (SE) profession through both textual and graphical outputs. We used each LLM to generate 300 profiles, consisting of 100 gender-based and 50 gender-neutral profiles, for a recruitment scenario in SE roles. Recommendations were generated for each profile and evaluated against the job requirements for four distinct SE positions. Each LLM was asked to select the top 5 candidates and subsequently the best candidate for each role. Each LLM was also asked to generate images for the top 5 candidates, providing a dataset for analysing potential biases in both text-based selections and visual representations. Our analysis reveals that both models preferred male and Caucasian profiles, particularly for senior roles, and favoured images featuring traits such as lighter skin tones, slimmer body types, and younger appearances. These findings highlight underlying societal biases influence the outputs of LLMs, contributing to narrow, exclusionary stereotypes that can further limit diversity and perpetuate inequities in the SE field. As LLMs are increasingly adopted within SE research and professional practices, awareness of these biases is crucial to prevent the reinforcement of discriminatory norms and to ensure that AI tools are leveraged to promote an inclusive and equitable engineering culture rather than hinder it.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE-SEIS66351.2025.00023 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS) },
  chapter={0}
}

@article{rayyan-352343521,
  title={ Graph-Based Filtering to Prevent Prompt-Engineered LLM Training Data Leaks  -  2025 IEEE International Conference on Smart Computing (SMARTCOMP) },
  year={2025},
  author={Barnett, A. and Ahearne, S. and Barry, P. and Globin, M. and Duggan, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058635 },
  abstract={Machine-learning generative Artificial Intelligence tools, specifically large-language models, provide varied functionality, like content generation, user-facing chatbots, and code generation. The LLM typically works with a decision engine, such as a neural network. LLMs suffer issues with training data poisoning, copyright of generated content, and this paper's focus; prompt engineering attacks and training data leaks. The authors propose an architecture to co-locate a filtering mechanism with the LLM chatbot to identify and preventing disclosure of leaked LLM training data before communication to the end-user. Implementation of a resource description framework (RDF) based filtering mechanism compares LLM outputs against a bank of training data using three approaches; the first uses a bank of hash-codes generated from training data artifacts, the second uses a bank of training data stored as plaintext, and the third couples natural language processing (NLP) with the plaintext training data bank. Accuracy, overhead and acceleration results are detailed, and observed anomalies in LLM responses to testing including plausible leaks are also discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SMARTCOMP65954.2025.00089 },
  booktitle={ 2025 IEEE International Conference on Smart Computing (SMARTCOMP) },
  chapter={0}
}

@article{rayyan-352343522,
  title={ VAP-6: A Benchmarking Framework on Vulnerability Assessment and Penetration Testing for Language Models  -  2025 International Conference on Electronics, AI and Computing (EAIC) },
  year={2025},
  author={Das, B. R. and Jassi, S. and Khandelwal, V. and Tarun and Agarwal, A. and Priyadarshini, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101426 },
  abstract={The integration of Large Language Models (LLMs) into cybersecurity operations, particularly Vulnerability Assessment and Penetration Testing (VAPT), has shown significant promise. However, there remains a scarcity of comprehensive benchmarks for evaluating LLMs in the VAPT domain, especially for small, open-source models suitable for local deployment. This paper introduces VAP-6, a novel benchmark comprising six distinct datasets designed to evaluate LLM capabilities across crucial VAPT knowledge domains: Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) identification, Common Vulnerability Scoring System (CVSS) prediction, scenario-based reasoning aligned with Certified Ethical Hacker (CEH) v12 and CompTIA PenTest+ PT0-002 certification exams, VAPT tools proficiency, and CVE-to-Metasploit module mapping. We introduce the VAP-6 methodology, encompassing dataset creation from authoritative sources like CVE and CWE MITRE, Exploit DB and Github with refinement through ChatGPT and manual verification. The benchmark was applied to evaluate selected open-source LLMs with parameters ranging from 2 to 3 billion (Qwen 2.5, Gemma2, Llama 3.2), employing Q4 quantization to ensure local computational efficiency via Ollama. This research establishes a standardized framework for benchmarking and comparing such LLMs, facilitating the development of more robust, private, and computationally efficient AI tools for VAPT professionals.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EAIC66483.2025.11101426 },
  booktitle={ 2025 International Conference on Electronics, AI and Computing (EAIC) },
  chapter={0}
}

@article{rayyan-352343523,
  title={ A Vulnerability Propagation Impact Analysis Approach Based on Code Semantics with LLM  -  2024 11th International Conference on Dependable Systems and Their Applications (DSA) },
  year={2024},
  author={Long, X. and Ai, J. and Zhao, J. and Huang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818276 },
  abstract={Vulnerability propagation in software systems is always one of the most important problems in software reliability analysis. Previous methods primarily relied on the calling relationships between functions, which failed to accurately capture the vulnerability propagation process, resulting in a high false positive rate. To resolve this issue, this paper proposes a vulnerability propagation impact analysis method based on code semantics, aimed at providing a fine-grained analysis. Specifically, the research designs a prompt template for generating prompt for each function in the vulnerability propagation chain, enabling the extraction of intra-function constraint information through a Large Language Model (LLM). Additionally, the study proposes a constraint combination method based on inter-function data transfer relationships, which is used to aggregate the complete constraint information within the vulnerability propagation chain. Finally, the research incorporates a vulnerability trigger determination method based on Satisfiability Modulo Theory (SMT) and a vulnerability trigger probability estimation method based on Monte Carlo simulation. The result of case study demonstrates the effectiveness of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSA63982.2024.00036 },
  booktitle={ 2024 11th International Conference on Dependable Systems and Their Applications (DSA) },
  chapter={0}
}

@article{rayyan-352343524,
  title={ Show and Tell: Exploring Large Language Model's Potential in Formative Educational Assessment of Data Stories  -  2024 IEEE VIS Workshop on Data Storytelling in an Era of Generative AI (GEN4DS) },
  year={2024},
  author={Sivakumar, N. and Chen, L. K. and Papasani, P. and Majmundar, V. and Feng, J. H. and Yarnall, L. and Gong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766490 },
  abstract={Crafting accurate and insightful narratives from data visualization is essential in data storytelling. Like creative writing, where one reads to write a story, data professionals must effectively “read” visualizations to create compelling data stories. In education, helping students develop these skills can be achieved through exercises that ask them to create narratives from data plots, demonstrating both “show” (describing the plot) and “tell” (interpreting the plot). Providing formative feedback on these exercises is crucial but challenging in large-scale educational settings with limited resources. This study explores using GPT-4o, a multimodal LLM, to generate and evaluate narratives from data plots. The LLM was tested in zero-shot, one-shot, and two-shot scenarios, generating narratives and self-evaluating their depth. Human experts also assessed the LLM's outputs. Additionally, the study developed machine learning and LLM-based models to assess student-generated narratives using LLM-generated data. Human experts validated a subset of these machine assessments. The findings highlight the potential of LLMs to support scalable formative assessment in teaching data storytelling skills, which has important implications for AI-supported educational interventions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GEN4DS63889.2024.00007 },
  booktitle={ 2024 IEEE VIS Workshop on Data Storytelling in an Era of Generative AI (GEN4DS) },
  chapter={0}
}

@article{rayyan-352343525,
  title={ Concepts for Teaching Software Development in the Age of AI-Tools  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Böttcher, A. and Thurner, V. and Zönnchen, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016505 },
  abstract={LLM-based tools such as ChatGPT, GitHub Copilot, and the like have already arrived in software development practice, and continue to change the way of how software is created. Students use Generative AI tools for any purpose, whether we agree with the use or not. In this paper, we argue that in order to appropriately prepare our students for professional life, we educators need to incorporate the use of these tools explicitly into the teaching and learning process, so that students will learn a systematic and professional usage of these tools. Teaching basic software development concepts to students with only little or no prior knowledge has always been a challenge. Incorporating GenAI-based tools into software development education requires some careful rethinking of teaching concepts, especially with respect to constructive alignment, i. e. aligning learning objectives, teaching and learning methods, and exams to address GenAI-based support. Based upon first observations on the usage of GenAI tools in class, in this paper we suggest and compare concepts for teaching and learning basic software development that integrate GenAI tools at different levels of intensity and at different points during a semester. From these observations, we derive recommendations both for teaching and learning settings and for corresponding assessments, for teaching software development in a constructively aligned way in the age of GenAI tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016505 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343526,
  title={ LLM Based Physical Verification Runset Generator  -  2024 ACM/IEEE 6th Symposium on Machine Learning for CAD (MLCAD) },
  year={2024},
  author={Francisco, L. and Arikati, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10740218 },
  abstract={The complexity in design rule description and coding is drastically increasing as technology nodes advance. This complexity makes the process of implementing the physical verification (PV) rule checks more time-consuming and susceptible to human error, creating the need to explore alternate methods to improve the runset creation process. The work presented proposes a generative AI solution that uses Large Language Models (LLMs) to interpret rule descriptions and generate design rule check decks (runsets) in a language that a PV tool can interpret. The LLM is fine-tuned with existing design rule manuals and runsets. After post-processing the LLM output, the presented solution can generate rules implementation with up to 97% accuracy. The proposed solution can be used as a runset writer Co-Pilot to help develop the new physical verification runsets. CCS Concepts • Hardware $\rightarrow$ Software tools for EDA; Best practices for EDA; Design rules; • Computing methodologies $\rightarrow$ Natural language processing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MLCAD62225.2024.10740218 },
  booktitle={ 2024 ACM/IEEE 6th Symposium on Machine Learning for CAD (MLCAD) },
  chapter={0}
}

@article{rayyan-352343527,
  title={ FedChip: Federated LLM for Artificial Intelligence Accelerator Chip Design  -  2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  year={2025},
  author={Nazzal, M. and Nguyen, K. and Vungarala, D. and Zand, R. and Angizi, S. and Phan, H. and Khreishah, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106162 },
  abstract={AI hardware design is advancing rapidly, driven by the promise of design automation to make chip development faster, more efficient, and more accessible to a wide range of users. Amongst automation tools, Large Language Models (LLMs) offer a promising solution by automating and streamlining parts of the design process. However, their potential is hindered by data privacy concerns and the lack of domain-specific training. To address this, we introduce FedChip, a Federated fine-tuning approach that enables multiple Chip design parties to collaboratively enhance a shared LLM dedicated for automated hardware design generation while protecting proprietary data. FedChip enables parties to train the model on proprietary local data and improve the shared LLM’s performance. To exemplify FedChip’s deployment, we create and release APTPU-Gen, a dataset of 30k design variations spanning various performance metric values such as power, performance, and area (PPA). To encourage the LLM to generate designs that achieve a balance across multiple quality metrics, we propose a new design evaluation metric, Chip@k, which statistically evaluates the quality of generated designs against predefined acceptance criteria. Experimental results show that FedChip improves design quality by more than 77% over high-end LLMs while maintaining data privacy. 1},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLAD65226.2025.00019 },
  booktitle={ 2025 IEEE International Conference on LLM-Aided Design (ICLAD) },
  chapter={0}
}

@article{rayyan-352343528,
  title={ LLM-Powered Agentic AI Approach to Securing EV Charging Systems Against Cyber Threats  -  2025 IEEE 26th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM) },
  year={2025},
  author={Honnalli, R. and Farooq, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11027017 },
  abstract={Electric vehicle (EV) charging systems are increasingly vulnerable to both cyber and physical attacks, posing significant risks to grid stability and operational security. Detecting such attacks remains a major challenge due to the complex nature of charging infrastructure and the scarcity of labeled attack data. Traditional machine learning (ML) models have demonstrated promise in intrusion and anomaly detection, however, their effectiveness is often limited by the lack of diverse real-world attack datasets, making them less reliable in detecting stealthy or emerging threats. To address these limitations, we leverage pretrained large language models (LLMs) enhanced with retrieval-augmented generation (RAG) for real-time anomaly detection in EV charging networks. The proposed system integrates domain-specific knowledge with live charging session data, enabling accurate classification of malicious activities such as billing fraud, energy theft, and communication tampering. Experimental results demonstrate that LLM-based detection improves classification accuracy while reducing false positives compared to traditional ML approaches. The developed methodology is adaptable across various cybersecurity applications, making it applicable to a wide range of attack scenarios beyond EV infrastructure. By combining AI-driven anomaly detection with real-time contextual analysis, this approach enhances the resilience of EV charging networks against evolving threats, ensuring secure and reliable operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WoWMoM65615.2025.00053 },
  booktitle={ 2025 IEEE 26th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM) },
  chapter={0}
}

@article{rayyan-352343529,
  title={ Smart-Shield: A Hybrid ML-AI Framework for Advanced Phishing Detection using Gradient Boosting and LLM Analysis  -  2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN) },
  year={2025},
  author={Kumar, P. V. Sai and Yadav, M. N. and Reddy, E. C. and Sathya, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035754 },
  abstract={Quick changes in phishing attempts make sophisticated detection techniques absolutely vital. This work presents a phishing detection system aiming at increasing accuracy and adaptability by combining machine learning with artificial intelligence-driven analysis. Along with Google’s Gemini 2.0 Flash LLM for more in-depth contextual analysis, it makes use of a Gradient Boosting Classifier (GBC) taught on 30 URL characteristics. SMote for class balance and tuned hyperparameters help to improve the model by means of fine-tuning of the detection performance. Two parts characterize the development process: the first phase concentrates on establishing the ML model, which comprises URL categorization, shortlink identification, and phishing pattern analysis; the second phase employs JSP and NetBeans to build a Java-based web application. Three portals comprise the system: an administrative portal for user management, phishing trend analysis and URL classification; a user portal for secure web browsing, suggestions, and automatic phishing alerts; and an attacker simulation site to test phishing detection capability. Python is connected with NetBeans to provide real-time classification and security analysis; an automatic access control method warns or temporarily limits users who surpass limits on browsing harmful URLs. This research presents a very accurate phishing detection system with real-time alarms and enhanced protection against changing threats by combining machine learning with AI-driven analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPCSN65854.2025.11035754 },
  booktitle={ 2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN) },
  chapter={0}
}

@article{rayyan-352343530,
  title={ LLM-Based AI Agent for VNF Deployment in OpenStack Environment  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Nam, S. and Tu, N. Van and Hong, J. W. -K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073607 },
  abstract={This paper presents a novel approach to automating the deployment of Virtual Network Functions (VNFs) in an OpenStack environment using Large Language Models (LLMs). Building on the concept of Intent-Driven Networking (IDN), which allows network administrators to manage complex networks via natural language commands, we explore the feasibility of using LLMs to automate VNF deployment tasks. A dataset of Method of Procedure (MOP) documents was created and utilized to prompt LLMs to generate Python code for deploying and configuring VNFs. Our LLM-based AI agent framework tests the generated code within an OpenStack environment, comparing the performance of various LLMs. Our findings highlight both the potential and current challenges of using LLMs in network automation, suggesting pathways for future research, including advanced prompt engineering and real-time error correction.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073607 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343531,
  title={ Retrieval Augmented MedLM  -  2024 IEEE Conference on Artificial Intelligence (CAI) },
  year={2024},
  author={Devi, S. and Dhar, G. and Bharadwaj, C. and M, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605433 },
  abstract={This paper presents a novel approach to leverage large language models (LLMs) for medical question answering (QA) by integrating them with external knowledge sources. We utilize de-identified clinical discharge notes from MIMIC-IV and Apollo Hospitals as our data source. We propose a novel summarization technique that extracts and condenses the core medical information from the discharge notes, eliminating unnecessary verbosity. This results in concise "medical summaries" that effectively inform the LLM while reducing context overload. We evaluate our approach using RAGAS, a novel framework for label-free evaluation of Retrieval-Augmented Generation (RAG) pipelines. Clinician validation further confirms the effectiveness of our approach, highlighting its potential to enhance medical QA systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI59869.2024.00217 },
  booktitle={ 2024 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343532,
  title={ BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Lu, X. and Chen, Y. and Chen, C. and Tan, H. and Chen, B. and Xie, Y. and Hu, R. and Tan, G. and Wu, R. and Hu, Y. and Zeng, Y. and Wu, L. and Bian, L. and Wang, Z. and Liu, L. and Yang, Y. and Xiao, H. and Zhou, A. and Wen, Y. and Chen, X. and Ren, S. and Li, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11094782 },
  abstract={The emergence and growing popularity of multimodal large language models (MLLMs) have significant potential to enhance various aspects of daily life, from improving communication to facilitating learning and problem-solving. Mobile phones, as essential daily companions, represent the most effective and accessible deployment platform for MLLMs, enabling seamless integration into everyday tasks. However, deploying MLLMs on mobile phones presents challenges due to limitations in memory size and computational capability, making it difficult to achieve smooth and real-time processing without extensive optimization. In this paper, we present BlueLM-V-3B, an algorithm and system co-design approach specifically tailored for the efficient deployment of MLLMs on mobile platforms. To be specific, we redesign the dynamic resolution scheme adopted by mainstream MLLMs and implement system optimization for hardware-aware deployment to optimize model inference on mobile phones. BlueLM-V-3B boasts the following key highlights: (1) Small Size: BlueLM-V-3B features a language model with 2.7B parameters and a vision encoder with 400M parameters. (2) Fast Speed: BlueLM-V-3B achieves a generation speed of 24.4 token/s on the MediaTek Dimensity 9300 processor with 4-bit LLM weight quantization. (3) Strong Performance: BlueLM-V-3B has attained the highest average score of 66.1 on the OpenCompass benchmark among models with ≤ 4B parameters and surpassed a series of models with much larger parameter sizes (e.g., MiniCPM-V-2.6, InternVL2-8B).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.00392 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343533,
  title={ WIP: Active Learning Through Prompt Engineering and Agentic AI Simulation-A Pilot Project in Computer Networks Education  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Ma, X. and Wang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10892925 },
  abstract={This work-in-progress paper introduces the AIca-demic system, an innovative framework employing Agentic AI and Agile methodologies to enhance learning in complex domains such as computer networks. Positioned within the topic of AI and Machine Learning Tools to Enhance Instruction, it aims to revolutionize the learning experience and outcomes for the intricate subject matter. This system emphasizes active, adaptive learning experiences through AI generated or AI improved educational materials with multiple iterations of feedback and improvement cycles. Utilizing fine tuned large language models (LLM), the AIcademic system assembles an interactive AI team, e.g. AIcademic Professor, Student, and Instructional Designer. Each AI agent is uniquely configured with our POISE prompt engineering model to analyze and simulate real-time classroom interactions from multiple viewpoints. Active learning pedagogy is embedded into the system through prompt engineering during the creation of each agent. Agile methodology is employed to organize collaborations of the AI agents for complex task planning and implementation, feedback integration, output con-tinuous improvement, and agent self-enhancement. A suite of AI tools is explored to dynamically create tailored educational materials aligned with the educator's teaching preferences and students' needs. Preliminary results from a pilot implementation of teaching the transport layer in computer networks demon-strated improvements in student engagement and comprehension over previous materials. This AIcademic framework presents a promising and scalable paradigm for AI applications in educational environments. While still under development, this research aims to refine and expand these findings, exploring the full potential of integrating Prompt Engineering and Agentic AI for creating active learning environments across complex technical subjects. The implications extend beyond computer network education, offering a blueprint to redefine teaching and learning in a technology-enhanced era. We invite collaboration from the broader academic community to refine the Agent prompt design, automate AI to AI interactions, assess long term impacts, and explore further applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10892925 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343534,
  title={ SLIDE: Integrating Speech Language Model with LLM for Spontaneous Spoken Dialogue Generation  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Lu, H. and Cheng, G. and Luo, L. and Zhang, L. and Qian, Y. and Zhang, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888680 },
  abstract={Recently, "textless" speech language models (SLMs) based on speech units have made huge progress in generating naturalistic speech, including non-verbal vocalizations. However, the generated speech samples often lack semantic coherence. In this paper, we propose SLM and LLM Integration for spontaneous spoken Dialogue gEneration (SLIDE). Specifically, we first utilize an LLM to generate the textual content of spoken dialogue. Next, we convert the textual dialogues into phoneme sequences and use a two-tower transformer-based duration predictor to predict the duration of each phoneme. Finally, an SLM conditioned on the spoken phoneme sequences is used to vocalize the textual dialogue. Experimental results on the Fisher dataset demonstrate that our system can generate naturalistic spoken dialogue while maintaining high semantic coherence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888680 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343535,
  title={ VindSec-Llama — Fine-Tuned Meta’s Llama-3 LLM, Federated Learning, Blockchain and PBOM-enabled Data Security Architecture for Wind Energy Data Platforms  -  2025 International Wireless Communications and Mobile Computing (IWCMC) },
  year={2025},
  author={Bandara, E. and Bouk, S. H. and Shetty, S. and Gore, R. and Kompella, S. and Mukkamala, R. and Rahman, A. and Foytik, P. and Liang, X. and Keong, N. W. and Zoysa, K. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059510 },
  abstract={Current wind energy data platforms face significant challenges in securing and managing extensive data from both offshore and onshore wind farms. These challenges include vulnerabilities to cyber-attacks, data tampering, breaches, complex data-sharing issues due to privacy concerns and regulatory compliance, and a lack of scalability and flexibility in analytical tools for real-time data processing. This paper proposes a novel multilayered data security architecture, termed "VindSec-Llama," to address these challenges. It integrates Generative AI, blockchain, federated learning, and Pipeline Bill of Materials (PBOM) to enhance data analytics, model development, and security across several layers, including Infrastructure, Data Lake, Federated Learning, MLOps, Data Provenance, and LLM. Each layer is designed to meet specific functional requirements, such as handling large datasets, facilitating secure federated learning, automating risk management, and ensuring data provenance and traceability. The platform, deployable in server environments (cloud or on-premises), complies with the Risk Management Framework (RMF) guidelines and security standards. It features a blockchain-enabled, coordinator-less federated learning system to enhance data privacy and security by enabling the development of privacy-preserving machine learning models with data from different wind farms. Automation plays a pivotal role throughout VindSec-Llama, with Meta’s custom-trained Llama-3 LLM used for generating remediation scripts in the Infrastructure Layer and for producing PPBOM in the MLOps Layer. The Llama-3 LLM has been quantized and fine-tuned using Qlora to ensure optimal performance on consumer-grade hardware. The MLOps pipeline setup, a critical functionality of VindSec-Llama, ensures seamless integration and deployment of machine learning models, embodying best practices in continuous integration and delivery. This setup is geared towards maximizing security, compliance, and operational efficiency. A prototype of the platform has been implemented within a wind-energy testbed with the collaboration of Department of Energy US, illustrating its practical applications and benefits.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IWCMC65282.2025.11059510 },
  booktitle={ 2025 International Wireless Communications and Mobile Computing (IWCMC) },
  chapter={0}
}

@article{rayyan-352343536,
  title={ Llama-Recipe — Fine-Tuned Meta's Llama LLM, PBOM and NFT Enabled 5G Network-Slice Orchestration and End-to-End Supply-Chain Verification Platform  -  2025 IEEE 22nd Consumer Communications & Networking Conference (CCNC) },
  year={2025},
  author={Bandara, E. and Bouk, S. H. and Shetty, S. and Roy, S. and Mukkamala, R. and Rahman, A. and Foytik, P. and Liang, X. and Keong, N. W. and Zoysa, K. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976116 },
  abstract={Modern 5G networks offer a network-sliced infrastructure where each network slice contains a dedicated 5G core software service layer. The 5G core software services in each slice shares common core network resources to meet specific customer needs. A primary challenge in 5G network slicing involves resource sharing and efficient network slice orchestration. Container-based methodologies, including tools like Docker and Kubernetes, have become popular for orchestrating 5G network slice services and managing configurations in microservices-based cloud-native service deployment. However, despite their utility, these tools present significant challenges. Their complexity often necessitates dedicated DevOps teams for effective management, while configuration management can prove arduous, and end-to-end supply chain oversight is lacking. To address these challenges, this paper introduces “Llama-Recipe,” a cloud-native 5G-core service deployment and orchestration platform integrating Generative AI, SBOM, PBOM and NFT. 5G-core service configurations across different network slices are represented as “HOCON (Human-Optimized Config Object Notation)” config objects adhering to the GitOps paradigm. Leveraging custom-trained Meta's Llama2 LLM, Llama-Recipe generates the Kubernetes manifests for network-sliced 5G-core services based on the defined HOCON configurations. The generated Kubernetes manifests of the 5G-core services are deployed in designated Kubernetes clusters utilizing GitOps tools (e.g., ArgoCD), ensuring seamless and automated deployment processes. Additionally, Llama-Recipe introduced a novel mechanism to handle end-to-end supply chain verification of 5G-core software services using Software-Bill of Materials (SBOM) and Pipeline-Bill of Materials (PBOM). SBOMs track all the dependencies and PBOMs facilitate the comprehensive tracking of end-to-end supply chain data for 5G-core software services, enhancing transparency and security. These PBOMs are also generated using the fine-tuned Meta's Llama-2 LLM and are encoded as NFT tokens with a novel NFT token schema. This schema enables easy verification and validation of supply-chain data during deployments, thus helping to prevent various supply-chain attacks. To fine-tune the Meta's Llama2 LLM, we've undertaken a meticulous training process, collaborating with Qlora to transform a 4-bit quantized pre-trained language model into Low-Rank Adapters(LoRA). The effectiveness of the Llama-Recipe is demonstrated through a real-world test-bed deployment in a sliced network scenario, utilizing multiple 5G cores (i.e., Open5GS) across Ericsson's new Radio Access Network (RAN).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCNC54725.2025.10976116 },
  booktitle={ 2025 IEEE 22nd Consumer Communications & Networking Conference (CCNC) },
  chapter={0}
}

@article{rayyan-352343537,
  title={ Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Wei, Y. and Wang, Z. and Lu, Y. and Xu, C. and Liu, C. and Zhao, H. and Chen, S. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656629 },
  abstract={Scene simulation in autonomous driving has gained significant attention because of its huge potential for generating customized data. However, existing editable scene simulation approaches face limitations in terms of user interaction efficiency, multi-camera photo-realistic rendering and external digital assets integration. To address these challenges, this paper introduces ChatSim, the first system that enables editable photo-realistic 3D driving scene simulations via natural language commands with external digital assets. To enable editing with high command flexibility, ChatSim leverages a large language model (LLM) agent collaboration framework. To generate photo-realistic outcomes, ChatSim employs a novel multi-camera neural radiance field method. Furthermore, to unleash the potential of extensive high-quality digital assets, ChatSim employs a novel multi-camera lighting estimation method to achieve scene-consistent assets' rendering. Our experiments on Waymo Open Dataset demonstrate that ChatSim can handle complex language commands and generate corresponding photo-realistic scene videos. Code can be accessed at: https://github.com/yifanlu0227/chatSim.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.01428 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343538,
  title={ Develop an On - Device LLM Android Application  -  2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS) },
  year={2024},
  author={Bagawan, S. and S, N. G},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816785 },
  abstract={This paper presents the development and implementation of an Android application utilizing a Large Language Model (LLM) that operates directly on the user's device. This approach aims to address the privacy and latency concerns often associated with cloud-based LLM solutions. The application leverages a smaller, optimized LLM, GEMMA 2B, which is capable of running efficiently on mobile hardware. It incorporates a hybrid approach, utilizing on-device processing for specific queries and resorting to cloud-based LLMs for more complex tasks that require extensive knowledge bases. This paper details the system architecture, implementation details, and discusses the performance and challenges encountered during the development process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSITSS64042.2024.10816785 },
  booktitle={ 2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS) },
  chapter={0}
}

@article{rayyan-352343539,
  title={ Evaluating Efficiency and Engagement in Scripted and LLM-Enhanced Human-Robot Interactions  -  2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  year={2025},
  author={Schreiter, T. and Rüppel, J. V. and Hazra, R. and Rudenko, A. and Magnusson, M. and Lilienthal, A. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974124 },
  abstract={To achieve natural and intuitive interaction with people, HRI frameworks combine a wide array of methods for human perception, intention communication, human-aware navigation and collaborative action. In practice, when encountering unpredictable behavior of people or unexpected states of the environment, these frameworks may lack the ability to dynamically recognize such states, adapt and recover to resume the interaction. Large Language Models (LLMs), owing to their advanced reasoning capabilities and context retention, present a promising solution for enhancing robot adaptability. This potential, however, may not directly translate to improved interaction metrics. This paper considers a representative interaction with an industrial robot involving approach, instruction, and object manipulation, implemented in two conditions: (1) fully scripted and (2) including LLM-enhanced responses. We use gaze tracking and questionnaires to measure the participants' task efficiency, engagement, and robot perception. The results indicate higher SUbjective ratings for the LLM condition, but objective metrics show that the scripted condition performs comparably, particularly in efficiency and focus during simple tasks. We also note that the scripted condition may have an edge over LLM-enhanced responses in terms of response latency and energy consumption, especially for trivial and repetitive interactions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HRI61500.2025.10974124 },
  booktitle={ 2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  chapter={0}
}

@article{rayyan-352343540,
  title={ Weaponizing Social Intelligence  -  The Language of Deception: Weaponizing Next Generation AI: Weaponizing Next Generation AI },
  author={Hutchens, J. and McClure, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10666472.pdf&bkn=10666290&pdfType=chapter },
  abstract={Summary <p>With increasingly powerful large language models (LLMs), threat actors have the ability to automate interactions with their targets to effectively achieve their objective by exploiting the social intelligence of these systems. In legacy models, the context of the LLM could be manipulated by using a preamble of text, which was prepended to any subsequent interactions with the system. This chapter examines how emerging LLM technologies can and inevitably will be integrated into online social platforms—there by introducing a new scourge of highly sophisticated bots that are indistinguishable from human users. Possibly even more fascinating than the use of LLMs for social engineering is the fact that these systems can also be used in a sort of Monte Carlo simulation to further improve the success of those social engineering campaigns. The chapter also examines how the complexity of LLM systems lends itself to plausible deniability of motive.</p>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1002/9781394277148.ch7 },
  booktitle={ The Language of Deception: Weaponizing Next Generation AI: Weaponizing Next Generation AI },
  chapter={0}
}

@article{rayyan-352343541,
  title={ Mapping the Landscape of Generative AI in Network Monitoring and Management  -  IEEE Transactions on Network and Service Management },
  author={Bovenzi, G. and Cerasuolo, F. and Ciuonzo, D. and Monda, D. Di and Guarino, I. and Montieri, A. and Persico, V. and Pescapé, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10891637 },
  abstract={Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and Diffusion Models have recently gained widespread attention from both the research and the industrial communities. This survey explores their application in network monitoring and management, focusing on prominent use cases, as well as challenges and opportunities. We discuss how network traffic generation and classification, network intrusion detection, networked system log analysis, and network digital assistance can benefit from the use of GenAI models. Additionally, we provide an overview of the available GenAI models, datasets for large-scale training phases, and platforms for the development of such models. Finally, we discuss research directions that potentially mitigate the roadblocks to the adoption of GenAI for network monitoring and management. Our investigation aims to map the current landscape and pave the way for future research in leveraging GenAI for network monitoring and management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TNSM.2025.3543022 },
  booktitle={ IEEE Transactions on Network and Service Management },
  chapter={0}
}

@article{rayyan-352343542,
  title={ Generative AI Based Mobile Application for Vehicle Breakdown and Maintenance Assistance  -  2025 5th International Conference on Advanced Research in Computing (ICARC) },
  year={2025},
  author={Weerawardhana, W. A. A. and Pallegama, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963154 },
  abstract={Vehicle maintenance presents significant challenges, particularly for those lacking mechanical expertise or access to professional services. While Google and ChatGPT offer basic assistance, they lack specialized automotive knowledge and real-time accuracy due to training data limitations. Existing applications like YourMechanic Mobile Car Repair primarily focus on service scheduling rather than repair guidance, with limited availability in regions like Sri Lanka. This research introduces MechAssist, a mobile application powered by fine-tuned Large Language Models (LLMs) for real-time vehicle diagnostics and maintenance guidance to address this gap. To identify the optimal machine learning model, five pre-trained models - FLAN-T5, NVIDIA-mistral, Facebook OPT-125M, GEMMA-2B, and BART - were evaluated using performance metrics after training with the dataset. The selected model was uploaded to the Hugging Face repository, cloned to a hosted server for ChatBot development, and subsequently integrated into the mobile application. User acceptance testing and customer feedback were then collected.The model selection was based on three primary criteria, which are the model size post-training, output response time, and output quality. BART demonstrated superior performance with an average response time under 2 seconds and a model size of 1.5GB compared to alternatives. Customer satisfaction with the application was notably high. The research concludes that BART is most suitable for this use case, and applications like MechAssist are valuable for vehicle owners with limited maintenance knowledge. Future development plans include expanding the dataset to 50,000 records, incorporating computer vision capabilities, implementing multi-language support, and enabling offline functionality through advanced TensorFlow Lite optimization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICARC64760.2025.10963154 },
  booktitle={ 2025 5th International Conference on Advanced Research in Computing (ICARC) },
  chapter={0}
}

@article{rayyan-352343543,
  title={ Conversational LLM-Based Decision Support for Defect Classification in AFM Images  -  IEEE Open Journal of Instrumentation and Measurement },
  author={Biswas, A. and Rade, J. and Masud, N. and Hasib, M. Hasibul Hasan and Balu, A. and Zhang, J. and Sarkar, S. and Krishnamurthy, A. and Ren, J. and Sarkar, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096088 },
  abstract={Atomic force microscopy (AFM) has emerged as a powerful tool for nanoscale imaging and quantitative characterization of organic (e.g., live cells, proteins, DNA, and lipid bilayers) and inorganic (e.g., silicon wafers and polymers) specimens. However, image artifacts in AFM height and peak force error images directly affect the precision of nanomechanical measurements. Experimentalists face considerable challenges in obtaining high-quality AFM images due to the requirement of specialized expertise and constant manual monitoring. Another challenge is the lack of high-quality AFM datasets to train machine learning models for automated defect detection. In this work, we propose a two-step AI framework that combines a vision-based deep learning (DL) model for classifying AFM image defects with a large language model (LLM)-based conversational assistant that provides real-time corrective guidance in natural language, making it particularly valuable for non-AFM experts aiming to obtain high-quality images. We curated an annotated AFM defect dataset spanning organic and inorganic samples to train the defect detection model. Our defect classification model achieves 91.43% overall accuracy, with a recall of 93% for tip contamination and 60% not-tracking defects. We further develop an intuitive user interface that enables seamless interaction with the DL model and integrates an LLM-based guidance feature to support users in understanding defects and improving future experiments. We then evaluate the performance of multiple state-of-the-art LLMs on AFM-related queries, offering users flexibility in LLM selection based on their specific needs. LLM evaluations and the benchmark questions are available at: https://github.com/idealab-isu/AFM-LLM-Defect-Guidance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OJIM.2025.3592284 },
  booktitle={ IEEE Open Journal of Instrumentation and Measurement },
  chapter={0}
}

@article{rayyan-352343544,
  title={ Fine-Tuning Large Language Model (LLM) to Answer Basic Questions for Prospective New Students at Syiah Kuala University Using the Retrieval-Augmented Generation (RAG) Method  -  2024 Ninth International Conference on Informatics and Computing (ICIC) },
  year={2024},
  author={Rachmat, H. and Riza, H. and Abidin, T. F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10956296 },
  abstract={USK Mistral 7B is a large language model designed to answer basic admission questions at Universitas Syiah Kuala (USK). The model was fine-tuned using the open-source model of Mistral 7B using collected data from admissions and lectures at the university. The QLoRA and RAG techniques were used to train the model and retrieve relevant information from external data sources. The results were evaluated using the ROUGE score. Responses were generated with a score of >0.5 on ten out of 46 questions with the RAG method, and testing with the fine-tuning method was carried out on 20 questions and resulted in responses with a score of 1.0 from all questions asked. The performance of USK Mistral 7B shows its potential as an effective tool in helping students querying information about admission and lectures at USK.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIC64337.2024.10956296 },
  booktitle={ 2024 Ninth International Conference on Informatics and Computing (ICIC) },
  chapter={0}
}

@article{rayyan-352343545,
  title={ Swiss Cheese Model for AI Safety: A Taxonomy and Reference Architecture for Multi-Layered Guardrails of Foundation Model Based Agents  -  2025 IEEE 22nd International Conference on Software Architecture (ICSA) },
  year={2025},
  author={Shamsujjoha, M. and Lu, Q. and Zhao, D. and Zhu, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978931 },
  abstract={Foundation Model (FM)-based agents are revolutionizing application development across various domains. However, their rapidly growing capabilities and autonomy have raised significant concerns about AI safety. Researchers are exploring better ways to design guardrails to ensure that the runtime behavior of FM-based agents remains within specific boundaries. Nevertheless, designing effective runtime guardrails is challenging due to the agents’ autonomous and non-deterministic behavior. The involvement of multiple pipeline stages and agent artifacts, such as goals, plans, tools, at runtime further complicates these issues. Addressing these challenges at runtime requires multilayered guardrails that operate effectively at various levels of the agent architecture. Therefore, in this paper, based on the results of a systematic literature review, we present a comprehensive taxonomy of runtime guardrails for FM-based agents to identify the key quality attributes for guardrails and design dimensions. Inspired by the Swiss Cheese Model, we also propose a reference architecture for designing multi-layered runtime guardrails for FM-based agents, which includes three dimensions: quality attributes, pipelines, and artifacts. The proposed taxonomy and reference architecture provide concrete and robust guidance for researchers and practitioners to build AI-safety-by-design from a software architecture perspective.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA65012.2025.00014 },
  booktitle={ 2025 IEEE 22nd International Conference on Software Architecture (ICSA) },
  chapter={0}
}

@article{rayyan-352343546,
  title={ Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Yoshida, K. and Mizukami, M. and Kawano, S. and Kruengkrai, C. and Sugiyama, H. and Yoshino, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888775 },
  abstract={To improve user engagement during conversations with dialogue systems, we must improve individual dialogue responses and dialogue impressions such as consistency, personality, and empathy throughout the entire dialogue. While such dialogue systems have been developing rapidly with the help of large language models (LLMs), reinforcement learning from AI feedback (RLAIF) has attracted attention to align LLM-based dialogue models for such dialogue impressions. In RLAIF, a reward model based on another LLM is used to create a training signal for an LLM-based dialogue model using zero-shot/few-shot prompting techniques. However, evaluating an entire dialogue only by prompting LLMs is challenging. In this study, the supervised fine-tuning (SFT) of LLMs prepared reward models corresponding to 12 metrics related to the impression of the entire dialogue for evaluating dialogue responses. We tuned our dialogue models using the reward model signals as feedback to improve the impression of the system. The results of automatic and human evaluations showed that tuning the dialogue model using our reward model corresponding to dialogue impression improved the evaluation of individual metrics and the naturalness of the dialogue response.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888775 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343547,
  title={ Generating Troubleshooting Trees for Industrial Equipment using Large Language Models (LLM)  -  2024 IEEE International Conference on Prognostics and Health Management (ICPHM) },
  year={2024},
  author={Vidyaratne, L. and Lee, X. Y. and Kumar, A. and Watanabe, T. and Farahat, A. and Gupta, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10626823 },
  abstract={Troubleshooting trees play a pivotal role in industrial diagnostics and fault analysis of complex systems and equipment by serving as a systematic guide in identifying and resolving issues. Constructing a troubleshooting tree involves a rigorous process that integrates multidisciplinary expertise and begins with an in-depth analysis of system architecture, operations, and known failure modes. Information from diverse sources are typically used to draft the initial tree structure, which is then iteratively refined through real-world data and field feedback. To expedite this process, this paper explores the use of generative large language models (LLMs) to automatically extract and structure information from unstructured text sources like service manuals, maintenance records, and design documents. In this work, we investigate three different product manuals and propose a method for generating an initial troubleshooting tree. Our results shows that the proposed method has data extraction coverage ranging from 36% to 64% and an extraction precision from 88% to 100%. We also performed a detailed analysis on the potential hallucination of the method and discuss the bottlenecks of the current process. We envision this work to establish a robust and reliable generative LLM-based pipeline for automated generation of an initial troubleshooting tree for diverse industrial processes and operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPHM61352.2024.10626823 },
  booktitle={ 2024 IEEE International Conference on Prognostics and Health Management (ICPHM) },
  chapter={0}
}

@article{rayyan-352343548,
  title={ Generative Chatbot Adaptation for Odia Language: A Critical Evaluation  -  2023 1st International Conference on Circuits, Power and Intelligent Systems (CCPIS) },
  year={2023},
  author={Agarwal, P. and Asif, A. and Parida, S. and Sekhar, S. and Dash, S. R. and Panda, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291329 },
  abstract={Large Language Models (LLMs) have gained significant attention in the field of Natural Language Processing (NLP) and Artificial Intelligence (AI) due to their ability to generate human-like text and facilitate conversational interactions. However, the majority of LLMs are majorly developed for English, limiting their accessibility and effectiveness for non-English speaking populations. In India, where only 10% of the population is proficient in English, the need for LLM models adapted to regional languages becomes crucial. This research paper focuses on the adaptability of LLMs to the Odia language, spoken by approximately 50 million people in India. With a primary objective to cater to the Odia-speaking community, we aim to evaluate existing LLM models such as ChatGPT, and Olive, an instruction following Odia LLM, specifically in the context of generating conversational outputs in Odia. We employ a critical evaluation approach to assess the performance, language understanding, and response generation capabilities of the LLM models for the Odia language. By conducting experiments and comparative analysis, we seek to determine the strengths, weaknesses, and potential areas of improvement for the existing LLM models. Our findings will contribute to the development of more effective and contextually accurate generative chatbots for the Odia language, enabling better communication and accessibility for the Odia-speaking population.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCPIS59145.2023.10291329 },
  booktitle={ 2023 1st International Conference on Circuits, Power and Intelligent Systems (CCPIS) },
  chapter={0}
}

@article{rayyan-352343549,
  title={ Comparative Study on Test Case generation using Generative AI  -  2025 Intelligent Methods, Systems, and Applications​ (IMSA) },
  year={2025},
  author={Azzam, A. and Hany, O. and Mansour, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166964 },
  abstract={Testing is an important part of Development life cycle, resource intensive and prone to human error. Over the years, various tools have been developed, with a recent surge in those based on Large Language Models (LLMs). Examples include prompting LLMs in chat applications to generate test cases or using AI agents with project context to generate tests. This paper comparatively studies the most prominent open and closed-source models available at the time of writing. This paper covers the most famous open and closed source models as of the date of writing this paper in a comparative study. This study analyzes each model’s characteristics and performance against well known metrics like average code coverage and mutation score. While closed source models Like GPT-4o are demonstrating better performance than all other models at 35.2% coverage, some open source models such as Llama 3.1 70B is demonstrating significantly p romising p erformance with 30.6% coverage, or models like DeepSeekCoderV2 16B that have a better chance of running locally in a normal home setting with 28.2% coverage. This study highlights LLM capabilities in automated test generation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMSA65733.2025.11166964 },
  booktitle={ 2025 Intelligent Methods, Systems, and Applications​ (IMSA) },
  chapter={0}
}

@article{rayyan-352343550,
  title={ DS Generative AI for Supporting Teaching Activities  -  2025 IEEE Engineering Education World Conference (EDUNINE) },
  year={2025},
  author={Montoya, J. F. Montoya and Lopez-Vargas, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981398 },
  abstract={Generative Artificial Intelligence (GAI) has become significant in education, particularly for creating content, resources, and automating repetitive and timeconsuming tasks. This project explores GAI’s potential to support teachers in analyzing low-to-medium complexity programs of student’s tasks, supporting the activities of teachers. The proposed solution includes an API and web application built based on the GPT-4o Large Language Model (LLM), specifically designed for teachers. The methodology begins with a review of relevant literature review to identify scenarios where GAI have shown their potential in the educational field. Subsequently, the performance of the GPT-4o model is evaluated in the context of review and analysis of student’s source code, using the Teaching Plans which the task proposals are extracted along with their respective evaluation rubrics, determining the quality and effectiveness of generative AI within this real application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUNINE62377.2025.10981398 },
  booktitle={ 2025 IEEE Engineering Education World Conference (EDUNINE) },
  chapter={0}
}

@article{rayyan-352343551,
  title={ Analog AI Accelerators for Transformer-based Language Models: Hardware, Workload, and Power Performance  -  2025 IEEE International Memory Workshop (IMW) },
  year={2025},
  author={Tsai, H. and Benmeziane, H. and Boybat, I. and Büchel, J. and Narayanan, P. and Gallo, M. L. and Jain, S. and Vasilopoulos, A. and Simon, W. and Hosokawa, K. and Ishii, M. and Kohda, Y. and Chen, A. and Mackin, C. and Maghraoui, K. E. and Okazaki, A. and Friz, A. M. and Luquin, J. and Sebastian, A. and Narayanan, V. and Burr, G. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11026974 },
  abstract={Transformer-based Large Language Models (LLMs) demand large weight capacity, efficient computing, and high throughput access to large amount of dynamic memory. These challenges present great opportunities for algorithmic and hardware innovations, including Analog AI accelerators. In this paper, we describe recent progress on Phase Change Memory-based hardware and architectural designs to address the challenges for LLM inference.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMW61990.2025.11026974 },
  booktitle={ 2025 IEEE International Memory Workshop (IMW) },
  chapter={0}
}

@article{rayyan-352343552,
  title={ Automated, Intent-Based, Scalable Software OLT Deployment by Container Orchestration and Generative AI  -  2025 30th OptoElectronics and Communications Conference (OECC) and 2025 International Conference on Photonics in Switching and Computing (PSC) },
  year={2025},
  author={Suzuki, T. and Matsumoto, Y. and Kim, S. -Y. and -i. Kani, J. and Yoshida, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11111548 },
  abstract={This paper proposes architecture that automatically deploys softwarized 10G-EPON by container orchestration and generative AI and evaluates its ability to scale up to 15 OLT pods while coexisting with LLM on a single node server},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/OECC/PSC62146.2025.11111548 },
  booktitle={ 2025 30th OptoElectronics and Communications Conference (OECC) and 2025 International Conference on Photonics in Switching and Computing (PSC) },
  chapter={0}
}

@article{rayyan-352343553,
  title={ From Hazard Identification to Controller Design: Proactive and LLM-Supported Safety Engineering for ML-Powered Systems  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Hong, Y. and Timperley, C. S. and Kästner, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030006 },
  abstract={Machine learning (ML) components are increasingly integrated into software products, yet their complexity and inherent uncertainty often lead to unintended and hazardous consequences, both for individuals and society at large. Despite these risks, practitioners seldom adopt proactive approaches to anticipate and mitigate hazards before they occur. Traditional safety engineering approaches, such as Failure Mode and Effects Analysis (FMEA) and System Theoretic Process Analysis (STPA), offer systematic frameworks for early risk identification but are rarely adopted. This position paper advocates for integrating hazard analysis into the development of any ML-powered software product and calls for greater support to make this process accessible to developers. By using large language models (LLMs) to partially automate a modified STPA process with human oversight at critical steps, we expect to address two key challenges: the heavy dependency on highly experienced safety engineering experts, and the time-consuming, labor-intensive nature of traditional hazard analysis, which often impedes its integration into real-world development workflows. We illustrate our approach with a running example, demonstrating that many seemingly unanticipated issues can, in fact, be anticipated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00021 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343554,
  title={ CANAL - Cyber Activity News Alerting Language Model : Empirical Approach vs. Expensive LLMs  -  2024 IEEE 3rd International Conference on AI in Cybersecurity (ICAIC) },
  year={2024},
  author={Patel, U. and Yeh, F. -C. and Gondhalekar, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433839 },
  abstract={In today’s digital landscape, where cyber attacks have become the norm, the detection of cyber attacks and threats is critically imperative across diverse domains. Our research presents a new empirical framework for cyber threat modeling, adept at parsing and categorizing cyber-related information from news articles, enhancing real-time vigilance for market stakeholders. At the core of this framework is a fine-tuned BERT model, which we call CANAL - Cyber Activity News Alerting Language Model, tailored for cyber categorization using a novel silver labeling approach powered by Random Forest. We benchmark CANAL against larger, costlier LLMs, including GPT-4, LLaMA, and Zephyr, highlighting their zero to few-shot learning in cyber news classification. CANAL demonstrates superior performance by outperforming all other LLM counterparts in both accuracy and cost-effectiveness. Furthermore, we introduce the Cyber Signal Discovery module, a strategic component designed to efficiently detect emerging cyber signals from news articles. Collectively, CANAL and Cyber Signal Discovery module equip our framework to provide a robust and cost-effective solution for businesses that require agile responses to cyber intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIC60265.2024.10433839 },
  booktitle={ 2024 IEEE 3rd International Conference on AI in Cybersecurity (ICAIC) },
  chapter={0}
}

@article{rayyan-352343555,
  title={ IntentGuide: Neuro-Symbolic Integration for Clarifying Human Intents by Rewriting Free-Form Sentences  -  2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  year={2024},
  author={Yeole, N. K. and Hsiao, M. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990074 },
  abstract={This paper presents “IntentGuide,” a neuro-symbolic integration framework to enhance the clarity and executability of human intentions expressed in free-form sentences. IntentGuide effectively integrates the rule-based error detection capabilities of symbolic AI with the powerful adaptive learning abilities of Large Language Model (LLM) to convert ambiguous and/or complex sentences into clear, machine-understandable English instructions. The empirical evaluation of IntentGuide, performed on natural language sentences written by middle school students for designing video games, reveals a significant improvement in error correction and code generation abilities compared to previous approaches, attaining an accuracy rate of 90%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxDKE63520.2024.00010 },
  booktitle={ 2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  chapter={0}
}

@article{rayyan-352343556,
  title={ Generating Descriptive Explanations of Machine Learning Models Using LLM  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Pang, A. and Jang, H. and Fang, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825667 },
  abstract={Machine learning algorithms play a pivotal role in a wide range of Artificial Intelligence (AI) applications. Explaining the results and behavior of a machine learning model, however, remains a challenge. In this paper, we present a new approach to the explanation of machine learning models using a large language model (LLM). In this work, we seek natural language descriptions of the behavioral patterns of a machine learning model by a combination of prompting and model sampling. A subspace sampling technique is developed to generate ML model outputs using partial features in a user defined space. A projective visualization method is employed to guide the sampling process, including user-directed interactive sampling and feature-based sampling, so that an optimal amount of information can be provided to the LLM to ensure accurate and concise natural language explanations. Two public datasets, a student performance dataset and a weather dataset, were used to test our approach under various conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825667 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343557,
  title={ LLM-Driven APT Detection for 6G Wireless Networks: A Systematic Review and Taxonomy  -  IEEE Access },
  year={2018},
  author={Golec, M. and Khamayseh, Y. and Melhem, S. B. and Alwarafy, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112774 },
  abstract={Sixth Generation (6G) wireless networks, which are expected to be deployed in the 2030s, have already created great excitement in academia and the private sector with their extremely high communication speed and low latency rates. However, despite the ultra-low latency, high throughput, and AI-assisted orchestration capabilities they promise, they are vulnerable to stealthy and long-term Advanced Persistent Threats (APTs). Large Language Models (LLMs) stand out as an ideal candidate to fill this gap with their high success in semantic reasoning and threat intelligence. This paper presents the first systematic review and taxonomy for LLM-assisted APT detection in 6G networks. It also provides insights by reviewing recent research on the intersection of LLMs, APTs, and 6G. Key challenges such as limitations in edge deployment, data scarcities, and explainability gaps are identified and a multidimensional taxonomy is provided in line with the APT lifecycle and 6G contexts. The paper is based on 142 studies from 2018 to 2025, searching leading databases such as IEEE Xplore, ACM Digital Library, SpringerLink, and Elsevier ScienceDirect.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3595665 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343558,
  title={ LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations  -  IEEE Access },
  author={Cho, S. and Kim, J. and Kim, J. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10758652 },
  abstract={This study explores whether large language models (LLMs) can learn a person’s opinions from their speech and act based on that knowledge. It also proposes the potential for utilizing such trained models in survey research. Traditional survey research collects information through standardized questions. However, surveys require repeated administration with new participants each time, which involves significant costs and time. With the recent advancements in LLMs, artificial intelligence (AI) has shown remarkable capabilities, often surpassing humans in tasks that require natural language understanding (NLU) and natural language generation (NLG). Despite this, research on whether AI can replicate human thought processes in tasks such as text interpretation or question-answering remains insufficient. This study proposes a Surveyed LLM, specialized for survey tasks, and a Doppelganger LLM that mimics human thought processes. It tests to what extent the Doppelganger model can replicate human judgment. Furthermore, it suggests the possibility of mimicking not only group distributions but also individual opinions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3502219 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343559,
  title={ Enhancing Student Engagement and Lecturer Roles in Electrical Educational Programs using LLM Models  -  2025 34th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE) },
  year={2025},
  author={Fonseca, I. and Martins, N. C. and Lopes, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11136202 },
  abstract={Today, LLM models have become an essential technology element, with applications in education constantly evolving. Its economic viability is underpinned by investments from large multinationals, with the needed vast amounts of data provided free of charge by users in their daily interactions with these systems, and the paid subscriptions that have recently emerged, with a tendency to become more expensive in the future. This scenario raises several critical issues in terms of governance, both at country level and within education and educational institutions.Europe is reacting to these changes. In France, for example, the development of Mistral AI stands out; in Spain, the ‘Alia’ project has emerged; and in Portugal, the ‘Amália’ model is starting to be available. This paper addresses this issue in an educational context, analysing the risks and opportunities associated with using different AI platforms, such as ChatGPT and Gemini, in teaching in electrical engineering. The changes implemented, the students' general feedback and their engagement throughout the process were carefully documented, as well as their perceptions of the use of AI in learning. During the semester, student-centred teaching methodologies were adopted, such as the use of explanatory videos and the flipped learning approach, providing extra support or pre-class preparation. In face-to-face sessions, students took part in tutorials guided by the main learning objectives, using artificial intelligence to reinforce their understanding of the content.The assessment, structured into various components spread over three curricular units, included quizzes, theoretical work, practical activities, sessions supervised by the educators in which the students clarified their doubts with each other, and a final exam. At the end of the semester, the students answered a specific survey on the use of artificial intelligence in the teaching-learning process. All these points and results are presented in the paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EAEEIE65428.2025.11136202 },
  booktitle={ 2025 34th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE) },
  chapter={0}
}

@article{rayyan-352343560,
  title={ A Step Towards Modern Disinformation Detection: Novel Methods for Detecting LLM-Generated Text  -  MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM) },
  year={2024},
  author={Nathanson, S. and Yoo, Y. and Na, D. and Cao, Y. and Watkins, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773838 },
  abstract={New generative artificial intelligence (GenAI) technology could have devastating consequences on our democracy because it can be easily used to spread disinformation at scale while simultaneously personalizing propaganda to demographics or individuals. The threat is significant – Large-scale GenAI-based disinformation campaigns can sway public opinion, shape political events, or even compromise the integrity of elections. One method for defending against large-scale GenAI disinformation is to build tools for autonomously detecting AI-generated content. In this article, we evaluate state-of-the-art AI detection tools. Additionally, we propose a novel AI content detection method which demonstrates up to a 48% improvement in accuracy (over existing tools) for autonomously detecting AI-generated content.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MILCOM61039.2024.10773838 },
  booktitle={ MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM) },
  chapter={0}
}

@article{rayyan-352343561,
  title={ Unmasking the AI Hand: A Machine Learning Approach to Deciphering Authorship  -  2024 3rd International Conference for Innovation in Technology (INOCON) },
  year={2024},
  author={Bhandarkar, A. and D.M, M. A. and D, V. and Mushtaq, A. and Kadam, D. and Saxena, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10512010 },
  abstract={In an era of explosive data growth, accurate text analysis tools are paramount. The surge of AI-generated texts presents a pressing challenge: discerning human-written content from AI-generated content. This affects text analysis accuracy, necessitating innovative solutions. We introduce an AI-driven model within the Model-View-Controller (MVC) architecture, categorising text as AI-generated or human-authored. Leveraging supervised learning, the model uses Count Vectorizers and Multinomial Naive Bayes algorithm for training and classification. The proposed model shows a good accuracy of 86.2%. This, with enhanced precision and F1 scores, underscores efficacy in classifying text origins. Beyond its immediate contributions, our model promises to reshape content authenticity verification, from AI-generated social media posts to verifying news sources. The model offers future directions, advancing AI-generated content detection. As AI-generated content evolves, our approach ensures credibility and reliability in text analysis within the MVC framework, addressing the critical need to navigate the AI-generated content landscape.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INOCON60754.2024.10512010 },
  booktitle={ 2024 3rd International Conference for Innovation in Technology (INOCON) },
  chapter={0}
}

@article{rayyan-352343562,
  title={ Towards Explainability in Retrieval-Augmented LLMs  -  2024 IEEE 40th International Conference on Data Engineering (ICDE) },
  year={2024},
  author={Rorseth, J. and Godfrey, P. and Golab, L. and Srivastava, D. and Szlichta, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598100 },
  abstract={In an era where artificial intelligence (AI) is re-shaping countless aspects of society, we present a forward-looking perspective for enhancing the explainability of large language models (LLMs), with a particular focus on the retrieval-augmented generation (RAG) prompting technique. We motivate the urgency for developing techniques to explain LLM decision-making behaviour, especially as these models are deployed in critical sectors. Central to this effort is RAGE, our novel explain-ability tool that can trace the provenance of an LLM's answer back to external knowledge sources provided via RAG. RAGE builds upon established explainability techniques to recover citations for LLM answers, identify context biases, and mine answer rules. Through our novel explainability formulations and practical use cases, we chart a course toward more transparent and trustworthy AI technologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDE60146.2024.00466 },
  booktitle={ 2024 IEEE 40th International Conference on Data Engineering (ICDE) },
  chapter={0}
}

@article{rayyan-352343563,
  title={ Federated Learning-Based Data Collaboration Method for Enhancing Edge Cloud AI System Security Using Large Language Models  -  2025 5th International Symposium on Computer Technology and Information Science (ISCTIS) },
  year={2025},
  author={Luo, H. and Ji, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11065696 },
  abstract={With the widespread application of edge computing and cloud systems in AI-driven applications, how to maintain efficient performance while ensuring data privacy has become an urgent security issue. This paper proposes a federated learningbased data collaboration method to improve the security of edge cloud AI systems, and use large-scale language models (LLMs) to enhance data privacy protection and system robustness. Based on the existing federated learning framework, this method introduces a secure multi-party computation protocol, which optimizes the data aggregation and encryption process between distributed nodes by using LLM to ensure data privacy and improve system efficiency. By combining advanced adversarial training techniques, the model enhances the resistance of edge cloud AI systems to security threats such as data leakage and model poisoning. Experimental results show that the proposed method is 15% better than the traditional federated learning method in terms of data protection and model robustness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCTIS65944.2025.11065696 },
  booktitle={ 2025 5th International Symposium on Computer Technology and Information Science (ISCTIS) },
  chapter={0}
}

@article{rayyan-352343564,
  title={ Poster: AI-Driven Security: Investigating LLMs for Automated Vulnerability Detection in Code Changes  -  2025 Silicon Valley Cybersecurity Conference (SVCC) },
  year={2025},
  author={Motupalli, S. R. and Choi, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11133632 },
  abstract={Security vulnerabilities in software systems give rise to serious threats nowadays because of data breaches, illegal access, and system breakdowns. Traditional vulnerability detection techniques, such as manual code inspections and Static Application Security Testing (SAST) technologies, have been extensively used to find security holes. These methods are good at finding known vulnerabilities, but they frequently follow preset guidelines, which limits their ability to recognize complex or situation-specific security threats.As artificial intelligence has progressed, Large Language Models (LLMs) have become a viable substitute for automated security analysis. In this work, we assess how well LLMs identify vulnerabilities in pull requests (PRs) by contrasting their results with those of Bandit, a popular SAST tool. We focus on free and pre-trained open-source LLM model - ‘Llama 3.2’ using the ‘Ollama’ tool to query the output.The findings show that Llama3.2 with the Rubric generates security assessments that closely match Bandit’s conclusions more when using the rubric compared to without it. By looking at how these models work in different situations, this study tries to find out if LLMs can be used along with or instead of traditional security methods to find vulnerabilities. The results offer a thorough assessment of LLM-based security analysis, including its advantages, disadvantages, and possible real-world uses. They also shed light on the developing role of AI in software security.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SVCC65277.2025.11133632 },
  booktitle={ 2025 Silicon Valley Cybersecurity Conference (SVCC) },
  chapter={0}
}

@article{rayyan-352343565,
  title={ A Framework for Security Testing of Large Language Models  -  2024 IEEE 12th International Conference on Intelligent Systems (IS) },
  year={2024},
  author={Traykov, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10705238 },
  abstract={The purpose of this paper is to present a framework for testing of large language models (LLMs) for security vulnerabilities before their implementation to production environment. The paper discusses the latest developments in the Artificial Intelligence (AI) and Generative Artificial Intelligence (Generative AI) adoption in the industry, the expectations for further accelerated adoption and evolving regulatory landscape. An overview of the most significant risks and vulnerabilities of the LLMs such as prompt injection and denial of service have been presented with their mitigation strategies. A testing approach and testing framework have been developed and implemented with simple chatbot app. The test scenarios have been executed and results have been obtained for three open-source LLMs from which two pass the test and one failed and demonstrated the application of the proposed testing framework. Source code of the application and test script are published open source for reproducibility and reuse. In conclusion the with the confirmation of the results the limitation of the reliance on semantic similarity for the responses of the models was discussed together with three areas for further development: expanding the test scenarios to significant risks, integration with popular cloud continuous development platforms and integrating blockchain for transparent publication of the final test results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IS61756.2024.10705238 },
  booktitle={ 2024 IEEE 12th International Conference on Intelligent Systems (IS) },
  chapter={0}
}

@article{rayyan-352343566,
  title={ MMInfluencer: A Multimodal AI Framework for Influencer Marketing Tasks Using Large Language Models  -  IEEE Transactions on Computational Social Systems },
  author={Yang, J. and Wang, D. and Zhu, L. and Yan, H. and Zhang, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11151670 },
  abstract={Influencer marketing involves brands partnering with influencers to promote products, often through combined text and image posts on social media platforms. This multimodal data is critical for identifying suitable products for effective marketing practice. In this study, we presented MMInfluencer, a novel framework that addressed the critical upstream challenge of knowledge extraction from unstructured multimodal social media data. Our framework operationalized communication theories, the heuristic-systematic model (HSM) and dual coding theory (DCT), to guide large language models (LLMs) in constructing a high-quality knowledge graph (KG) from the multimodal posts and biographies of 1000 Instagram influencers. Human assessment of the KG confirmed its relevance and completeness with accuracy scores of 0.89 and 0.75, respectively. We then examined the KG’s efficacy in various influencer marketing tasks using graph-based learning methods and retrieval-augmented generation (RAG) technology. The KG derived from multimodal data significantly improved product category prediction and recommendation tasks, with the Node2Vec model showing improvements of 20.47% (AUROC, p $<$ 0.0001) and 1142.15% (NDCG@20, p $<$ 0.0001), respectively. In contrast, the RAG method was ineffective, yielding an accuracy of just 0.1195 ($\pm$ 0.0162). Furthermore, the LLM-extracted KG significantly improved performance in challenging scenarios, where the best model achieved improvements of 155.51% (NDCG@20, p $=$ 0.0170) for emerging influencers (zero-shot) and 1144.51% (NDCG@20, p $<$ 0.0001) for influencers with scarce data (cold-start). Our research underscores the potential of leveraging multimodal data, LLMs, and graph-based learning methods for effective influencer marketing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCSS.2025.3597544 },
  booktitle={ IEEE Transactions on Computational Social Systems },
  chapter={0}
}

@article{rayyan-352343567,
  title={ Generative AI Efficiency and Effectiveness in Software Project Documentation Review Process  -  2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA) },
  year={2025},
  author={Demir, K. A. and Muppalla, T. N. V. and Liu, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11165833 },
  abstract={In this research, we report the capabilities of Large Language Model (LLM)-based Generative Artificial Intelligence (GenAI) tools, such as ChatGPT and Gemini, in the software project documentation review process. In software projects, the document artifact review process is an essential part of the quality assurance process. This review process is a human effort-intensive process. Introducing automation in this process will help reduce human effort, speed up the development, and reduce the potential of errors in the documents. With its enhanced natural language processing capabilities, LLM-based GenAI tools provide significant potential in the above process. In this research, we investigate the efficiency and effectiveness of LLM-based GenAI tools (such as ChatGPT and Gemini) for software documentation review process. Our experimental design includes comparing the manual document review process with the automated document review process conducted by LLM-based GenAI tools. The research results indicate that utilizing LLM-based GenAI tools provides significant efficiency in the document review process. However, LLM-based GenAI tools can only reach half the effectiveness and review quality that can be achieved by a human. To the best of our knowledge, this study is one of the first studies investigating the effectiveness and efficiency of utilizing GenAI for the software documentation review process. This research provides significant insights into improving the software document artifact review process utilizing LLM-based GenAI techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACDSA65407.2025.11165833 },
  booktitle={ 2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA) },
  chapter={0}
}

@article{rayyan-352343568,
  title={ APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration  -  IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems },
  author={Ma, S. and Fang, C. and Shao, H. and Wang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11145154 },
  abstract={Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99× speedup compared to FP16 baselines and a 2.16× speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44× speedup over FP16 and 1.65× speedup over CUTLASS integer baselines.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCAD.2025.3604321 },
  booktitle={ IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems },
  chapter={0}
}

@article{rayyan-352343569,
  title={ The Impact of Security Mindset on the Use of AI Assistants in Computing Education  -  IEEE Transactions on Education },
  author={Yuan, J. and Li, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11182622 },
  abstract={The recent advances in large-language models (LLMs) have started shifting the way computing-related students write codes. LLM-based AI assistants, such as ChatGPT and Copilot, are now increasingly adopted to produce functional code by computing-related students. Although studies have shown that these AI assistants can improve coding efficiency, they also raise security challenges, especially when users lack a security mindset. Given the fact that AI assistants are increasingly integrated into computing education, this article performed an empirical study to explore the impact of a security mindset on the use of AI assistants for computing-related students in their coding and development. Our three-stage study showed that a significant portion of computing-related students currently lack security awareness toward the use of AI assistants. In addition, their usage of AI assistants has a high chance of producing insecure programs in programming tasks that frequently appear in computing curricula. Meanwhile, the results of our study indicate that a security mindset can greatly contribute to students’ usage of AI assistants in terms of code security. Our study further discussed and evaluated strategies to improve students’ secure usage of AI assistants in computing education by integrating a security mindset.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TE.2025.3610340 },
  booktitle={ IEEE Transactions on Education },
  chapter={0}
}

@article{rayyan-352343570,
  title={ Improving Bangla Regional Dialect Detection Using BERT, LLMs, and XAI  -  2024 IEEE International Conference on Computing, Applications and Systems (COMPAS) },
  year={2024},
  author={Paul, B. and Preotee, F. F. and Sarker, S. and Muhammad, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796843 },
  abstract={This research addresses the challenge of identifying and categorizing Bangla regional dialects through the application of sophisticated natural language processing techniques. Automated translation, digital content personalization, and speech recognition systems are all improved by precise dialect detection, which is a result of the linguistic diversity in Bangladesh. Few-shot learning techniques were used to compare the performance of transformer-based models, specifically Bangla BERT, with state-of-the-art large language models such as GPT-3.5 Turbo and Gemini 1.5 Pro, and to fine-tune them. The methodology entailed the utilization of a diverse regional Bangla speech samples from the Vasantor dataset, which encompassed regions including Mymensingh, Chittagong, Barishal, Noakhali, and Sylhet. In order to enhance the interpretability of the model, implementation of Local Interpretable Model-agnostic Explanations (LIME) was done. The Bangla BERT model achieved the highest accuracy of 88.74%. GPT-3.5 Turbo’s few-shot learning exhibited substantial potential, with an accuracy rate of 64%. These results underscore the significance of hyperparameter optimization and fine-tuning in the enhancement of regional dialect detection models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPAS60761.2024.10796843 },
  booktitle={ 2024 IEEE International Conference on Computing, Applications and Systems (COMPAS) },
  chapter={0}
}

@article{rayyan-352343571,
  title={ Data-Prep-Kit: getting your data ready for LLM application development  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Wood, D. and Lublinsky, B. and Roytman, A. and Singh, S. and Adam, C. and Adebayo, A. and An, S. and Chang, Y. C. and Dang, X. -H. and Desai, N. and Dolfi, M. and Emami-Gohari, H. and Eres, R. and Goto, T. and Joshi, D. and Koyfman, Y. and Nassar, M. and Patel, H. and Selvam, P. and Shah, Y. and Surendran, S. and Tsuzuku, D. and Zerfos, P. and Daijavad, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825085 },
  abstract={Data preparation is the first and a very important step towards any Large Language Model (LLM) development. This paper introduces an easy-to-use, extensible, and scale-flexible open-source data preparation toolkit called Data Prep Kit (DPK). DPK is architected and designed to enable users to scale their data preparation to their needs. With DPK they can prepare data on a local machine or effortlessly scale to run on a cluster with thousands of CPU Cores. DPK comes with a highly scalable, yet extensible set of modules that transform natural language and code data. If the user needs additional transforms, they can be easily developed using extensive DPK support for transform creation. These modules can be used independently or pipelined to perform a series of operations. In this paper, we describe DPK architecture and show its performance from a small scale to a very large number of CPUs. The modules from DPK have been used for the preparation of Granite Models [1] [2]. We believe DPK is a valuable contribution to the AI community to easily prepare data to enhance the performance of their LLM models or to fine-tune models with Retrieval-Augmented Generation (RAG).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825085 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343572,
  title={ Robust Evaluation of LLM-Generated GraphQL Queries for Web Services  -  2025 IEEE International Conference on Web Services (ICWS) },
  year={2025},
  author={Sonthalia, V. and Kesarwani, M. and Mehta, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169687 },
  abstract={GraphQL offers a flexible alternative to REST APIs, enabling precise data retrieval across multiple services—a critical requirement in today's service-oriented architectures. However, constructing complex GraphQL queries remains challenging, and even Large Language Models (LLMs) often generate suboptimal queries due to limited schema awareness. Recent advancements, such as specialized prompt engineering, schema-aware in-context learning, and dedicated datasets, have aimed to improve query generation. However, evaluating the quality of generated queries remains challenging: GraphQL's inherent flexibility allows semantically equivalent queries to differ syntactically, complicating both automatic and manual evaluation. In this work, we introduce Robust GraphQL Evaluation (RGEval), the first benchmarking pipeline designed to systematically assess the quality of LLM-generated GraphQL queries. RGEval effectively handles schema complexities and structural variations, ensuring accurate evaluations while significantly improving efficiency—reducing evaluation time from hours to minutes. With Gartner projecting that over 60 % of enterprises will adopt GraphQL in production by 2027, RGEval provides a critical solution for benchmarking LLM-generated queries, fostering trust in AI-driven web service consumption.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS67624.2025.00042 },
  booktitle={ 2025 IEEE International Conference on Web Services (ICWS) },
  chapter={0}
}

@article{rayyan-352343573,
  title={ LLM for Question Generation and Validation to Enhance School Level Student Assessment  -  2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN) },
  year={2025},
  author={Varma, A. D. and Anand, S. and Thekkedath, A. K. and P, K. and Prasanth, N. and Rao, S. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035415 },
  abstract={Recent advancements in large language models (LLMs) have accelerated the growth of several AI-based solutions in the daily lives of people, including in the field of education. Using LLM in education can potentially automate various aspects of the teaching-learning process. This work explores how LLMs can assist educators in generating questions for student assessment. Using sophisticated prompt engineering, a system has been developed to generate multiple levels of questions from a single topic, enabling teachers to evaluate and curate a variety of questions attuned to the diverse needs of learners. This innovative approach diverges from conventional ICT-based techniques that primarily rely on keyword matching and superficial metrics. The system generates questions, taking into account the semantic meaning and contextual relevance. Furthermore, LLM evaluation metrics have been applied to assess the methods used for the generation of questions, and the results are presented accordingly.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPCSN65854.2025.11035415 },
  booktitle={ 2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN) },
  chapter={0}
}

@article{rayyan-352343574,
  title={ AES Cryptography Enabled Responsible Federated Foundation Model Using Transformer LLM and LSTM for Smart Grid IIoT Networks  -  IEEE Internet of Things Journal },
  author={Hasan, M. K. and Kabir, S. Rayhan and Islam, S. and Abdullah, S. and Abbas, H. S. and Pandey, B. and Gadekallu, T. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159217 },
  abstract={The use of SCADA and AMI systems in smart grid-based Industrial Internet-of-Things (SG-IIoT) networks for proper energy supply are noteworthy. Inaccurate energy load forecasts, cyber-threats, and energy load-based sustainability issues in smart grids hinder SG-IIoT operations. To mitigate these challenges, a federated-learning approach is developed by integrating LSTM (Long-Short-Term-Memory), Transformer-LLM (Larger Language Model) based Foundation-Model, and AES (Advanced-Encryption-Standard) cryptography. The proposed approach is named Responsible-Federated-Foundation-Model (ResFedFM). To ensure secure federated learning computation as well as data security at the edge (smart meter), fog (SCADA-based substation grid) and cloud (grid cloud server) layers of the SG-IIoT, a self-parent keys-based cryptography method has been developed by combining AES with HMAC (Hash-based-Message-Authentication-Code). A load forecasting algorithm called LSTM-LLM-GenResAI-Forecasting has been developed for computation at each end node of the federated learning process. The edge node forecast outputs are encrypted and aggregated at the fog node. At the fog node, the data are decrypted, and aggregation algorithm of federated-learning process are used to generate overall load forecasting of each sub-station grid. Again, the forecast data from these fog nodes are aggregated in an encrypted state at the cloud level and overall load forecasts are generated for multiple fog nodes. The result of proposed approach provides responsible forecasting (High accuracy, green computing-based energy demand, optimization of AI-hallucination, and grid data security), demonstrating enhanced performance over seven significant models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JIOT.2025.3608807 },
  booktitle={ IEEE Internet of Things Journal },
  chapter={0}
}

@article{rayyan-352343575,
  title={ Evaluating Large Language Model Robustness using Combinatorial Testing  -  2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW) },
  year={2025},
  author={Chandrasekaran, J. and Patel, A. R. and Lanus, E. and Freeman, L. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962520 },
  abstract={Recent advancements in large language models (LLMs) have demonstrated remarkable proficiency in understanding and generating human-like text, leading to widespread adoption across domains. Given LLM’s versatile capabilities, current evaluation practices assess LLMs across a wide variety of tasks, including answer generation, sentiment analysis, text completion, and question and answers, to name a few. Multiple choice questions (MCQ) have emerged as a widely used evaluation task to assess LLM’s understanding and reasoning across various subject areas. However, studies from the literature have revealed that LLMs exhibit sensitivity to the ordering of options in MCQ tasks, with performance variations based on option sequence, thus underscoring the robustness concerns in LLM performance.This work presents a combinatorial testing-based framework for systematic and comprehensive robustness assessment of pre-trained LLMs. By leveraging the sequence covering array, the framework constructs test sets by systematically swapping the order of options, which are then used in ascertaining the robustness of LLMs. We performed an experimental evaluation using the Measuring Massive Multitask Language Understanding (MMLU) dataset, a widely used MCQ dataset and evaluated the robustness of GPT 3.5 Turbo, a pre-trained LLM. Results suggest the framework can effectively identify numerous robustness issues with a relatively minimal number of tests.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSTW64639.2025.10962520 },
  booktitle={ 2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW) },
  chapter={0}
}

@article{rayyan-352343576,
  title={ Occ-LLM: Enhancing Autonomous Driving with Occupancy-Based Large Language Models  -  2025 IEEE International Conference on Robotics and Automation (ICRA) },
  year={2025},
  author={Xu, T. and Lu, H. and Yan, X. and Cai, Y. and Liu, B. and Chen, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11127665 },
  abstract={Large Language Models (LLMs) have made substantial advancements in the field of robotic and autonomous driving. This study presents the first Occupancy-based Large Language Model (Occ-LLM), which represents a pioneering effort to integrate LLMs with an important representation. To effectively encode occupancy as input for the LLM and address the category imbalances associated with occupancy, we propose Motion Separation Variational Autoencoder (MS-VAE). This innovative approach utilizes prior knowledge to distinguish dynamic objects from static scenes before inputting them into a tailored Variational Autoencoder (VAE). This separation enhances the model's capacity to concentrate on dynamic trajectories while effectively reconstructing static scenes. The efficacy of Occ-LLM has been validated across key tasks, including 4D occupancy forecasting, self-ego planning, and occupancybased scene question answering. Comprehensive evaluations demonstrate that Occ-LLM significantly surpasses existing state-of-the-art methodologies, achieving gains of about 6% in Intersection over Union (IoU) and 4% in mean Intersection over Union (mIoU) for the task of 4D occupancy forecasting. These findings highlight the transformative potential of Occ-LLM in reshaping current paradigms within robotic and autonomous driving.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRA55743.2025.11127665 },
  booktitle={ 2025 IEEE International Conference on Robotics and Automation (ICRA) },
  chapter={0}
}

@article{rayyan-352343577,
  title={ Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Mushtaq, A. and Naeem, R. and Ghaznavi, I. and Taj, I. and Hashmi, I. and Qadir, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016653 },
  abstract={Multi-Agent Large Language Models (LLMs) are gaining attention for their ability to harness collective intelligence in complex problem-solving, decision-making, and planning tasks. This aligns with the wisdom of crowds concept, where diverse agents collectively generate effective solutions, making them well-suited for educational settings. Senior design projects, pivotal in engineering education, integrate theoretical knowledge with practical application, fostering critical thinking, teamwork, and real-world problem-solving skills. These projects often involve multidisciplinary considerations and conflicting objectives, such as optimizing technical performance while addressing ethical, social, and environmental concerns. In this paper, we explore a framework where distinct LLM agents embody expert perspectives, including problem formulation, system complexity, societal and ethical considerations, and project management. These agents engage in rich, collaborative dialogues, leveraging multi-agent system principles like coordination, cooperation, and negotiation. Prompt engineering is employed to create diverse personas, simulating human engineering teams and incorporating swarm AI principles to balance contributions efficiently. To evaluate the framework, we analyzed six senior capstone project proposals from engineering and computer science, comparing Multi-Agent and single-agent LLMs using metrics developed with engineering faculty and widely used NLP-based measures. These metrics assess technical quality, ethical considerations, social impact, and feasibility, aligning with the educational objectives of engineering design. Our findings suggest that Multi-Agent LLMs can provide a richer, more inclusive problem-solving environment compared to single-agent systems with 89% alignment with engineering-faculty scores, offering a promising tool for enhancing the educational experience of engineering and computer science students by simulating the complexity and collaboration of real-world engineering and computer science practice. By supporting senior design projects, this tool not only aids in achieving academic excellence but also prepares students for the multifaceted challenges they will face in their professional engineering careers. We have open-sourced our framework for further development and adaptation on GitHub11Copilot is available at GitHub Repository: https://github.com/AbdullahMushtaq78/Multi-Agent-SDP-Copliot.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016653 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343578,
  title={ Explore Public's Perspectives on Generative AI in Computer Science (CS) Education: A Social Media Data Analysis  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Oh, S. and Cao, Y. and Katz, A. and Zhao, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893102 },
  abstract={This research-to-practice full paper aims to analyze the public's comments on generative artificial intelligence (GAI) in computer science (CS) education, by the BERT-based model and Large Language Model (LLM) approaches to sentiment analysis and contextualize the results within broader educational and technological landscapes. Artificial intelligence (AI) has played a crucial role in advancing technical development throughout many areas. Evidence points toward the likelihood of major developmental breakthroughs unfolding soon in those sectors. Education is one such area. While there is certainly a possibility for hype and unfulfilled promises, the advent of available GAI platforms, such as ChatGPT, has caused a surge of scholarly interest in the impact of these technologies on CS education. Amid the growing debate, both the potential benefits and concerns of GAI in this sector are increasingly coming to the fore as people grapple with the tradeoffs associated with these technologies when applied in education settings. One can imagine the range of conversations around the topic, but that is difficult to use as input for policymakers and administrators without a more concrete understanding. To wit, there remain open questions about which benefits and concerns people tend to focus on when discussing GAI in education. This large-scale qualitative study addresses that gap by exploring the public's perspectives on GAI in CS education. We engage in this work by collecting and analyzing data from social media platforms, specifically Reddit comments. The social media dataset was analyzed using machine learning (ML) techniques to identify topics based on sentiment analysis. The study's objective was to document and characterize the public's perspectives concerning the general characteristics of GAI, its features related to learning, and its usability in educational settings. Through sentiment analysis using Large Language Models (LLM), the study revealed an overall positive public perception toward using generative AI in CS education, with over 57% of comments being favorable, while also identifying prominent topics of interest and concerns, such as the potential benefits of personalized learning support and automated grading, as well as issues like academic dishonesty, perpetuation of biases, over-reliance on AI hindering critical thinking, displacement of human instructors, and the need for updated curricula. The insights gleaned from the analysis will be instrumental in computing educators gaining a more profound comprehension of GAI 'srole in education and the subsequent development of GAI -enriched curricula.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893102 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343579,
  title={ UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Lyu, Y. and Zheng, X. and Zhou, J. and Wang, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10657425 },
  abstract={We present UniBind, a flexible and efficient approach that learns a unified representation space for seven diverse modalities - image, text, audio, point cloud, thermal, video, and event data. Existing works, e.g., ImageBind [13], treat the image as the central modality and build an image-centered representation space; however, the space may be sub-optimal as it leads to an unbalanced representation space among all modalities. Moreover, the category names are directly used to extract text embeddings for the down-stream tasks, making it hardly possible to represent the se-mantics of multi-modal data. The ‘out-of-the-box’ insight of our UniBind is to make the alignment centers modality-agnostic and further learn a unified and balanced repre-sentation space, empowered by the large language mod-els (LLMs). UniBind is superior in its flexible application to all CLIP-style models and delivers remarkable performance boosts. To make this possible, we 1) construct a knowledge base of text with the help of LLMs and multi-modal LLMs; 2) adaptively build LLM-augmented class-wise embedding centers on top of the knowledge base and encoded visual embeddings; 3) align all the embeddings to the LLM-augmented embedding centers via contrastive learning to achieve a unified and balanced representation space. UniBind shows strong zero-shot recognition performance gains over prior arts by an average of 6.36%. Fi-nally, we achieve new state-of-the-art performance, e.g., a 6.75% gain on ImageNet, on the multi-modal fine-tuning setting while reducing 90% of the learnable parameters.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.02526 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343580,
  title={ On-Device Input Analysis to Proactively Enhance Data Security in Large Language Models  -  2024 4th International Conference on Artificial Intelligence and Signal Processing (AISP) },
  year={2024},
  author={S, A. and R, A. and Sekar, R. and R, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10870695 },
  abstract={Large Language Models (LLMs) have become essential in many industries, helping with productivity gains and automation. However its utilisation creates concerns regarding the unintentional disclosure of sensitive information, which puts security and privacy in jeopardy. In order to reduce these risks, this qualitative study suggests a technique called “Input Refining” that involves methodically identifying and removing personal data from LLM inputs. The process entails a careful examination of the input data, which is then paraphrased to exclude sensitive material while maintaining the input's semantic integrity. Through the incorporation of Input Refining into AI workflows, entities can enhance data security and privacy procedures, cultivating conscientious implementation of LLMs. By providing a workable solution to the problem of unintentional information security breaches in the age of large language models, our study adds to the ongoing discourse on AI ethics and data privacy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AISP61711.2024.10870695 },
  booktitle={ 2024 4th International Conference on Artificial Intelligence and Signal Processing (AISP) },
  chapter={0}
}

@article{rayyan-352343582,
  title={ Understanding Structure Of LLM using Neural Cluster Knockout  -  2024 5th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV) },
  year={2024},
  author={Bhile, P. A. and Maes, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10511242 },
  abstract={This research work presents a groundbreaking approach at the intersection of neuroscience and generative Artificial Intelligence (AI), focusing on the application of neuroscience techniques to neural networks, specifically Large Language Models (LLMs). Central to this study is the concept of ‘neural cluster knockout’ in LLMs, a method inspired by lesion studies in neuroscience involving the systematic removal of neuron clusters to decipher their role within the model. The research underscores the opaque nature of neural networks, particularly LLMs, which are often critiqued for their ‘black box’ operation. By adopting neuroscience principles, particularly lesion studies, this paper aims to illuminate the inner workings of neural networks, enhancing our understanding of their functionalities. This is crucial in an era increasingly reliant on AI in various sectors, where insights from this study could lead to the development of more efficient, transparent, and accountable AI systems. Methodologically, this study involved Principal Component Analysis (PCA) and neural cluster knockout through iterative zeroing, applied to the Large Language Model named LLaMA. This approach enabled the identification of significant neuron clusters and their functional impacts when deactivated. The results reveal both critical and redundant neurons within LLMs, demonstrating that some clusters are vital for accuracy, while others may impede efficiency or contribute to errors. This research contributes significantly to the AI field, offering a novel perspective on the intricate architecture of LLMs. It lays a foundation for future advancements in AI, envisioning refined and efficient LLMs capable of more accurate and reliable performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICICV62344.2024.00045 },
  booktitle={ 2024 5th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV) },
  chapter={0}
}

@article{rayyan-352343583,
  title={ Multi-agentic AI for Automatic Course Syllabus Generation using LangGraph  -  2025 10th International STEM Education Conference (iSTEM-Ed) },
  year={2025},
  author={Chomphooyod, P. and Jeerapradit, L. and Suchato, A. and Punyabukkana, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11129303 },
  abstract={Preparing course syllabus is a time-intensive process that requires careful alignment with educational goals, learner backgrounds, and current technological trends. This paper presents a multi-agent AI framework for automatic course syllabus generation, leveraging the LangGraph framework to orchestrate collaborative workflows among large language model (LLM) agents. To address the persistent challenge of hallucination in LLM-based content generation, our system employs an iterative agentic workflow, augmented by expert evaluation from an LLM. We implement GPT-40 as the core LLM, selected for its strong performance and efficiency. The proposed system generates a syllabus through stages including persona analysis, receive human feedback, retrieve standard curriculum, syllabus creation, expert review, and syllabus refinement. Each stage is modeled as modular nodes within LangGraph. We demonstrate the effectiveness of this approach with a case study on a Database Systems course. Evaluation by LLM-simulated domain experts, including database systems educator, data engineering specialist, and data security analyst, highlights the quality and relevance of the generated syllabus. Our findings suggest that multi-agentic systems have the potential to structure courses in a way that aligns with user requirements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iSTEM-Ed65612.2025.11129303 },
  booktitle={ 2025 10th International STEM Education Conference (iSTEM-Ed) },
  chapter={0}
}

@article{rayyan-352343584,
  title={ Serving LLMs as Detectors in Workflows with Guardrails  -  2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  year={2025},
  author={Kumbhat, G. and Ju, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015002 },
  abstract={With the growing popularity of Large Language Model (LLM) usage in generative AI applications comes a growing need to be able to verify, moderate, or “guardrail” LLM inputs and outputs. “Guardrailing” can be done with anything from simple regex detections, to more complicated techniques like using LLMs themselves to detect undesired content. Additionally, considerable effort has been going into creating and optimizing various LLM serving solutions. This paper describes our experience of using an adapter pattern with an LLM serving architecture to provide LLMs as guardrail models. The details on design trade-offs, such as performance or model accessibility, can aid in creating other LLM-based software architectures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C65153.2025.00075 },
  booktitle={ 2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343585,
  title={ Bridging HCI and AI Research for the Evaluation of Conversational SE Assistants  -  2025 IEEE/ACM International Workshop on Bots in Software Engineering (BotSE) },
  year={2025},
  author={Richards, J. and Wessel, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050035 },
  abstract={As Large Language Models (LLMs) are increasingly adopted in software engineering, recently in the form of conversational assistants, ensuring these technologies align with developers’ needs is essential. The limitations of traditional human-centered methods for evaluating LLM-based tools at scale raise the need for automatic evaluation. In this paper, we advocate combining insights from human-computer interaction (HCI) and artificial intelligence (AI) research to enable human-centered automatic evaluation of LLM-based conversational SE assistants. We identify requirements for such evaluation and challenges down the road, working towards a framework that ensures these assistants are designed and deployed in line with user needs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BotSE67031.2025.00009 },
  booktitle={ 2025 IEEE/ACM International Workshop on Bots in Software Engineering (BotSE) },
  chapter={0}
}

@article{rayyan-352343586,
  title={ RealCV - An AI-Powered Resume Generator  -  2025 IEEE International Conference on Electro Information Technology (eIT) },
  year={2025},
  author={Kulkarni, M. V. and Khan, M. H. Aslam and Raje, R. R. and Wheeler, R. and Ganci, A. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11103614 },
  abstract={The current job market is rapidly evolving and the recent advances in AI are making the marketplace extremely competitive. Such dynamic job market and associated complexities often obscure the matching process between qualified job seekers and suitable opportunities, particularly during the resume building and job application phases. This RealCV research and the system developed describe the use of a Large Language Model (LLM) to address these disconnects by automating and refining the customization of resumes. Unlike traditional systems that rely on keyword matching, this approach aims to effectively translate academic achievements and other nonconventional experiences into industry-relevant competencies. Using an LLM, our system automatically converts academic CVs into industrial resumes. RealCV will facilitate a deeper understanding of candidates' capabilities, potentially transforming recruitment paradigms and career transitions. The system builds upon our past work, COVID CV [1], in assisting individuals to highlight their “invisible” skills and their mappings to the “soft skills” that are significantly valued in the industry, thereby, providing appropriate matches between the job requirements and seekers' credentials.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/eIT64391.2025.11103614 },
  booktitle={ 2025 IEEE International Conference on Electro Information Technology (eIT) },
  chapter={0}
}

@article{rayyan-352343587,
  title={ Generative AI-assisted Standalone Wearable Reading Glasses for the Visually Impaired  -  2024 IEEE 3rd International Conference on Robotics, Automation, Artificial-Intelligence and Internet-of-Things (RAAICON) },
  year={2024},
  author={Islam, M. R. and Sadi, M. Sheikh},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10928631 },
  abstract={This paper presents a novel, low-cost, wearable Optical Character Recognition (OCR) reading assistant glasses designed for the low-vision and visually impaired community. This standalone system uses a Radxa Zero 3W single board computer and a 5MP RGB camera. PaddleOCR engine, optimized through a series of preprocessing and postprocessing algorithms, used for effective text recognition. A finetuned lightweight 0.5B Large Language Model deployed on-device as a Generative AI chat assistant (Ask-LLM) to respond to the user query with full privacy. To convert the generated response into speech, the Festival Text-to-Speech (TTS) engine has been used. Also, Whisper CT2 Automatic Speech Recognition (ASR) has been utilized for effective and real-time voice transcription. The system recognizes English text with character recognition accuracy of 95.25% and Ask-LLM generates responses at 2~4 tokens/second. The hardware cost of the whole system is only $50 while works completely offline utilizing cutting-edge technologies. This paper contributes to the field of assistive technology by showcasing how carefully selected off-the-shelf components and open-source software can be engineered into a powerful, affordable, and practical solution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAAICON64172.2024.10928631 },
  booktitle={ 2024 IEEE 3rd International Conference on Robotics, Automation, Artificial-Intelligence and Internet-of-Things (RAAICON) },
  chapter={0}
}

@article{rayyan-352343588,
  title={ Enhancing ESCO with Generative AI: A Dynamic Approach to Supporting 21st Century Education  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Pruski, C. and Gallais, M. and Silveira, M. Da},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016516 },
  abstract={In the rapidly evolving landscape of engineering education, upskilling and lifelong learning have become critical to maintaining competitiveness and fostering innovation. The use of ontologies, such as the European Skills, Competences, Qualifications, and Occupations (ESCO), plays a crucial role in organizing and managing the skills required for modern engineering roles. However, the slow pace of ontology updates and the lack of contextual adaptability present significant challenges, leading to outdated and irrelevant information for educators, learners, and industry professionals. This paper explores the potential of integrating Large Language Models (LLMs) with knowledge engineering to accelerate the process of updating ontologies like ESCO. By dynamically analyzing data and incor-porating contextual information, LLMs offer promising avenues for enhancing the evolution and precision of these ontologies. We discuss the potential impact of this approach in engineering education, particularly in aligning ups killing and reskilling efforts with the demands of emerging technologies such as AI -driven automation and digital engineering. This paper aims to highlight how LLMs can support the creation of more responsive, context-aware learning frameworks, ultimately sustaining educational ex-cellence and fostering critical thinking in engineering education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016516 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343589,
  title={ Research on AI-assisted design method of substation based on LLM+RAG  -  6th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2024) },
  year={2024},
  author={Zhou, L. and Lv, Z. and Zhang, X. and Hu, J. and Pan, L. and Pang, X. and Shi, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10854098 },
  abstract={In the digital age, in order to solve the problems of illusion, timeliness, data security, etc. of large language model technology (LLM), retrieval-augmented generation (RAG) has emerged as a feasible solution. Therefore, the architecture concept of LLM+RAG was proposed, in order to assist the design work as an efficient AI tool. Therefore, this paper adopts a layered design, and realizes the end-to-end process from professional knowledge acquisition to intelligent suggestion generation through six core functional layers: knowledge base construction layer, retrieval enhancement layer, context construction layer, LLM interaction layer, response optimization layer and interaction integration layer. In the design process, various language processing, retrieval, context model generation and other technologies are combined to complete a feasible RAG+LLM AI- assisted design architecture. Finally, through the real-time updated professional knowledge base, multi-way recall mechanism and chain reasoning method, the tool can provide reliable design suggestions for design work and improve the efficiency and quality of substation design. This study provides a design idea of a reliable RAG+LLM architecture, and finally completes the construction of an AI-assisted design tool using this architecture.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2024.4307 },
  booktitle={ 6th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2024) },
  chapter={0}
}

@article{rayyan-352343590,
  title={ College Exam Grader using LLM AI models  -  2024 IEEE/ACIS 27th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) },
  year={2024},
  author={Lee, J. X. and Song, Y. -T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10673924 },
  abstract={By far, the most effective knowledge assessment in college education is to give students exam and grade their answers then assess their level of understanding. However, exam grading can be time-consuming, tedious, cumbersome, and sometimes the grading results are not consistent with the rubric. Here, we propose an AI based exam grader that can not only ease educators’ burden but also produce accurate, consistent, and precise grading results. We have used GPT-3.5, GPT-4.0, and Gemini-pro, respectively, as our grading engine. To verify the correctness, precision, and accuracy of our proposed grader, the results were compared with the instructor’s grading result and also with human grader such as teaching assistants. In our experiment, GPT-4.0 showed the most reliable and consistent results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SNPD61259.2024.10673924 },
  booktitle={ 2024 IEEE/ACIS 27th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) },
  chapter={0}
}

@article{rayyan-352343591,
  title={ AI Applications in Medical Reporting and Diagnosis  -  2024 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC) },
  year={2024},
  author={Makram, M. and Mohammcd, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10783552 },
  abstract={The integration of artificial intelligence (AI) in healthcare is revolutionizing diagnosis and patient care by improving clinical documentation and the management of electronic health records that depend on medical image interpretation, increasing accuracy, and reducing time. Egypt ranks first in liver disease and second in liver cancer mortality worldwide in 2020. Large language models, a subset of AI techniques, can assist in disease diagnosis. LLM models with multimodal capabilities can classify and describe patient scan images and extract information from clinical notes. These models can extract vital diagnoses with the support of prompt engineering, as one of these models can answer questions, summarize information, and translate complex medical terminology into plain language, enabling patients to understand their medical reports and diagnoses. There are two primary approaches to achieving this. First, fine-tuning can adapt the model to medical data, which can be resource-intensive. The second approach, pre-trained LLM models can be utilized to leverage pre-trained models to perform the necessary tasks, focusing on effectively using prompts to guide the model for precise and relevant outputs. This study highlights the role of generative AI models by focusing on prompt engineering, and how carefully crafting prompts can enhance the effectiveness of LLM models in medical applications with high accuracy. It demonstrates this through experiments using pre-trained models based on semantic similarity with GPT-4o and BioGPT. Implementing a zero-shot model for liver tumor classification is one of the prompt engineering techniques. The performance metrics achieved were impressive, accuracy, precision, recall, and F1-scores are 88, 81, 88, and 83 percent, respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIUCC62295.2024.10783552 },
  booktitle={ 2024 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC) },
  chapter={0}
}

@article{rayyan-352343592,
  title={ Graph Retrieval-Augmented Generation for Large Language Models: A Survey  -  2024 Conference on AI, Science, Engineering, and Technology (AIxSET) },
  year={2024},
  author={Procko, T. T. and Ochoa, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771030 },
  abstract={Large Language Models (LLMs) demonstrate general knowledge, but they suffer when specifically needed knowledge is not present in their training set. Two approaches to ameliorating this, without retraining, are 1) prompt engineering and 2) Retrieval-Augmented Generation (RAG). RAG is a form of prompt engineering, insofar as relevant lexical snippets retrieved from RAG corpora are vectorized and aggregated with prompts. However, RAG documents are often noisy, i.e., while relevant to a given prompt, they can contain much other information that obfuscates the desired snippet. If the purpose of pretraining a LLM on massive and general corpora is to engender a generally applicable model, RAG is not: it is a means of LLM optimization, and as such, RAG document selection must be precise, not general. For expert tasks, it is imperative that a RAG corpus be as noise-free as possible, in much the same way a good prompt should be free of irrelevant text. Knowledge Graphs (KGs) provide a concise means of representing domain knowledge free of noisy information. This paper surveys work incorporating KGs with LLM RAG, intending to equip scientists with a better understanding of this novel research area for future work.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxSET62544.2024.00030 },
  booktitle={ 2024 Conference on AI, Science, Engineering, and Technology (AIxSET) },
  chapter={0}
}

@article{rayyan-352343593,
  title={ Dynamic Framework for Collaborative Learning: Leveraging Advanced LLM with Adaptive Feedback Mechanisms  -  2025 International Conference on Activity and Behavior Computing (ABC) },
  year={2025},
  author={Tahir, H. and Faisal, F. and Alnajjar, F. and Taj, M. I. and Gordon, L. and Khan, A. and Lwin, M. and Mubin, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118419 },
  abstract={This paper presents a framework for integrating LLM into collaborative learning platforms to enhance student engagement, critical thinking, and inclusivity. The framework employs advanced LLMs as dynamic moderators to facilitate real-time discussions and adapt to learners’ evolving needs, ensuring diverse and inclusive educational experiences. Key innovations include robust feedback mechanisms that refine AI moderation, promote reflective learning, and balance participation among users. The system’s modular architecture featuring ReactJS for the frontend, Flask for backend operations, and efficient question retrieval supports personalized and engaging interactions through dynamic adjustments to prompts and discussion flows. Testing demonstrates that the framework significantly improves student collaboration, fosters deeper comprehension, and scales effectively across various subjects and user groups. By addressing limitations in static moderation and personalization in existing systems, this work establishes a strong foundation for next-generation AI-driven educational tools, advancing equitable and impactful learning outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ABC64332.2025.11118419 },
  booktitle={ 2025 International Conference on Activity and Behavior Computing (ABC) },
  chapter={0}
}

@article{rayyan-352343594,
  title={ Evaluating Smart Building Features for Fire, Electrical, and Life Safety: A Rapid Human–LLM Framework for Literature Review and Research Mapping  -  IEEE Access },
  author={Leiva-Araos, A. and Kalasapudi, V. S. and Jiang, A. and Kaushal, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11175370 },
  abstract={The rapid integration of smart technologies into modern buildings is fundamentally transforming fire, electrical, and life safety (FELS) systems. This paper introduces a hybrid Human–Large Language Model (LLM) framework designed to efficiently conduct large-scale literature reviews, systematically map existing research, and identify critical knowledge gaps in smart building safety. Leveraging advanced LLMs for high-throughput summarization, topic modeling, and gap analysis, combined with expert validation, this method ensures both scalability and domain-specific rigor. The study analyzes 1,409 publications retrieved from Scopus, culminating in a refined corpus of 83 high-quality articles categorized into nine thematic clusters, including advanced sensing technologies, automation, enhanced connectivity, digital twins, cybersecurity, standard compliance, sustainability, specialized applications, and decision-making in disaster response. Detailed gap analyses reveal significant challenges related to real-world validation of AI-based systems, interoperability among IoT devices, cybersecurity vulnerabilities, and the need for dynamic evacuation and hazard modeling. The resulting knowledge map and research roadmap provide actionable insights for researchers, practitioners, and policymakers aiming to advance safer, smarter, and more resilient built environments. The proposed framework demonstrates how AI-assisted methodologies can accelerate knowledge synthesis while preserving analytical depth, offering a scalable solution for rapidly evolving interdisciplinary research domains.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3613246 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343595,
  title={ AutoHMA-LLM: Efficient Task Coordination and Execution in Heterogeneous Multi-Agent Systems Using Hybrid Large Language Models  -  IEEE Transactions on Cognitive Communications and Networking },
  author={Yang, T. and Feng, P. and Guo, Q. and Zhang, J. and Zhang, X. and Ning, J. and Wang, X. and Mao, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10839354 },
  abstract={Heterogeneous multi-agent systems (HMAS) comprise various intelligent agents with specialized functions, such as drones, ground robots, and automated devices, working in coordinated settings. This paper presents AutoHMA-LLM, a novel framework that combines Large Language Models (LLMs) with classical control algorithms to address the challenges of task coordination and scheduling in complex, dynamic environments. The framework is designed with a multi-tier architecture, utilizing a cloud-based LLM as the central planner alongside device-specific LLMs and Generative Agents to improve task execution efficiency and accuracy. Specifically targeting dynamic scenarios, the system enhances resource utilization and stabilizes task execution through refined task scheduling and real-time feedback mechanisms. In experiments conducted across logistics, inspection, and search & rescue scenarios, AutoHMA-LLM demonstrated a 5.7% improvement in task completion accuracy, a 46% reduction in communication steps, and a 31% decrease in token usage and API calls compared to baseline methods. These results highlight our framework’s scalability and efficiency, offering substantial support for effective multi-agent collaboration in complex, resource-constrained environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCCN.2025.3528892 },
  booktitle={ IEEE Transactions on Cognitive Communications and Networking },
  chapter={0}
}

@article{rayyan-352343596,
  title={ Bassa-Llama — Fine-Tuned Meta’s Llama LLM, Blockchain and NFT Enabled Real-Time Network Attack Detection Platform for Wind Energy Power Plants  -  2025 International Wireless Communications and Mobile Computing (IWCMC) },
  year={2025},
  author={Bandara, E. and Bouk, S. H. and Shetty, S. and Gore, R. and Kompella, S. and Mukkamala, R. and Rahman, A. and Foytik, P. and Liang, X. and Keong, N. W. and Zoysa, K. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059647 },
  abstract={Large Language Models (LLMs) are widely recognized for their applications in natural language processing tasks, but their potential extends far beyond traditional use cases. This paper introduces "Bassa-Llama," a novel platform that harnesses LLMs for predictive tasks in the realm of network security. Specifically, we propose a platform for real-time network attack detection in Wind Power Plants, leveraging a fine-tuned version of Meta’s Llama-3 LLM alongside blockchain and NFT-based data storage. Using a network PCAP dataset containing both malicious and benign packets, we fine-tune the Llama-3 LLM, with Quantized Low-Rank Adapter (QLoRA), to detect anomalies in network traffic. This approach ensures optimal performance on consumer-grade hardware while significantly enhancing the model’s ability to accurately analyze PCAP data and identify attack patterns. The end-to-end orchestration of the real-time network attack detection flow for Wind Power Plants is fully automated through blockchain smart contracts, and NFTs for storing identified attack data from the PCAP. To the best of our knowledge, this research represents the first effort to utilize a fine-tuned LLM for real-time network attack detection tasks. The results highlight the transformative potential of combining fine-tuned LLMs with blockchain and NFTs to build robust and secure network defense systems for Wind Power Plants. A prototype of the proposed platform was developed in collaboration with the U.S. Department of Energy, utilizing a simulated Wind Power Plant as a testbed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IWCMC65282.2025.11059647 },
  booktitle={ 2025 International Wireless Communications and Mobile Computing (IWCMC) },
  chapter={0}
}

@article{rayyan-352343597,
  title={ An Analysis on Integrating Advanced Conversational AI in Legal Summarization and Information Retrieval  -  2024 Second International Conference on Inventive Computing and Informatics (ICICI) },
  year={2024},
  author={Garlyal, J. S. and Hariharan, B. and Singh, A. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675619 },
  abstract={This research study explores the impact of advanced conversational AI, particularly LawGPT, on legal practice. Specializing in the Indian Penal Code (IPC) and integrated with the Legal Language Model (LLM), LawGPT offers precise interpretation of legal queries. By utilizing advanced pre-processing techniques, Dense Passage Retriever (DPR) for retrieval, and BART architecture for generation, LawGPT ensures contextually relevant responses. Through validation against human-generated responses, its efficacy and accuracy are affirmed, democratizing access to legal knowledge for professionals and laypersons. LawGPT's adoption promises to revolutionize legal research, enhancing efficiency and inclusivity in legal interactions. This study analyzes its widespread integration, recognizing its potential to shape a more accessible and efficient legal system, contributing to the ongoing research on exploring AI's role in legal practice.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICICI62254.2024.00016 },
  booktitle={ 2024 Second International Conference on Inventive Computing and Informatics (ICICI) },
  chapter={0}
}

@article{rayyan-352343598,
  title={ Prompting Large Language Models with Speech Recognition Abilities  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Fathullah, Y. and Wu, C. and Lakomkin, E. and Jia, J. and Shangguan, Y. and Li, K. and Guo, J. and Xiong, W. and Mahadeokar, J. and Kalinli, O. and Fuegen, C. and Seltzer, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447605 },
  abstract={Large language models (LLMs) have proven themselves highly flexible, able to solve a wide range of generative tasks, such as abstractive summarization and open-ended question answering. In this paper we extend the capabilities of LLM by directly attaching a small audio encoder allowing it to perform speech recognition. By directly prepending a sequence of audio embeddings to the text token embeddings, the LLM can be converted to an automatic speech recognition (ASR) system, and be used in the exact same manner as its textual counterpart. Experiments on Multilingual LibriSpeech (MLS) show that incorporating a conformer encoder into the open sourced LLaMA-7B allows it to outperform monolingual baselines by 18% relatively in WER and perform multilingual speech recognition, despite LLaMA being trained overwhelmingly on English text. Furthermore, we perform ablation studies to investigate whether the LLM can be completely frozen during training to maintain its original capabilities, scaling up the audio encoder, and increasing the audio encoder striding to generate fewer embeddings. The results from these studies show that multilingual ASR is possible even when the LLM is frozen, or when strides of almost 1 second are used in the audio encoder opening up the possibility for LLMs to operate on long-form audio.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10447605 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343599,
  title={ Zero-resource Speech Translation and Recognition with LLMs  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Mundnich, K. and Niu, X. and Mathur, P. and Ronanki, S. and Houston, B. and Elluru, V. R. and Das, N. and Hou, Z. and Huybrechts, G. and Bhatia, A. and Garcia-Romero, D. and Han, K. J. and Kirchhoff, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890008 },
  abstract={Despite recent advancements in speech processing, zero-resource speech translation (ST) and automatic speech recognition (ASR) remain challenging problems. In this work, we propose to leverage a multilingual Large Language Model (LLM) to perform ST and ASR in languages for which the model has never seen paired audio-text data. We achieve this by using a pre-trained multilingual speech encoder, a multilingual LLM, and a lightweight adaptation module that maps the audio representations to the token embedding space of the LLM. We perform several experiments both in ST and ASR to understand how to best train the model and what data has the most impact on performance in previously unseen languages. In ST, our best model is capable to achieve BLEU scores over 23 in CoVoST2 for two previously unseen languages, while in ASR, we achieve WERs of up to 28.2%. We finally show that the performance of our system is bounded by the ability of the LLM to output text in the desired language.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10890008 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343600,
  title={ Evaluating Psychometric Properties in Generated Thai Reading Ability Diagnostic Tests between the Large Language Model (LLM-Claude) and Human: Rasch Analysis  -  2025 International Technical Conference on Circuits/Systems, Computers, and Communications (ITC-CSCC) },
  year={2025},
  author={Chanaman, T. and Junpeng, P. and Intharah, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11137624 },
  abstract={This study aims to compare the quality assessment of Thai reading comprehension diagnostic tests created by Claude AI versus those developed by humans. The sample consisted of 735 seventh-grade students from Secondary educational service areas in the central northeastern region of Thailand. The methodology applied Rasch Model Analysis integrated with Turing Test procedures. The findings revealed that diagnostic tests created by both Claude AI and humans demonstrated comparable measurement quality in terms of validity, reliability, and item-model fit. Both tests exhibited low measurement error, allowing for accurate estimation of students' Thai reading abilities close to their true proficiency levels. Furthermore, both test versions showed good distribution of difficulty levels, covering nearly the full spectrum of student ability levels. These characteristics make the tests particularly suitable for students with slightly above-average proficiency. Nevertheless, certain test items require refinement to enhance their assessment efficiency according to established criteria. While some educators may remain hesitant about implementing AI-generated tests for formal student evaluation, Claude AI-created tests can effectively serve as practice exercises for student development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITC-CSCC66376.2025.11137624 },
  booktitle={ 2025 International Technical Conference on Circuits/Systems, Computers, and Communications (ITC-CSCC) },
  chapter={0}
}

@article{rayyan-352343601,
  title={ Introducing cosmosGPT: Monolingual Training for Turkish Language Models  -  2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA) },
  year={2024},
  author={Kesgin, H. T. and Yuce, M. K. and Dogan, E. and Uzun, M. E. and Uz, A. and Seyrek, H. E. and Zeer, A. and Amasyali, M. F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10683863 },
  abstract={The number of open source language models that can produce Turkish is increasing day by day, as in other languages. In order to create the basic versions of such models, the training of multilingual models is usually continued with Turkish corpora. The alternative is to train the model with only Turkish corpora. In this study, we first introduce the cosmosGPT models that we created with this alternative method. Then, we introduce new finetune datasets for basic language models to fulfill user requests and new evaluation datasets for measuring the capabilities of Turkish language models. Finally, a comprehensive comparison of the adapted Turkish language models on different capabilities is presented. The results show that the language models we built with the monolingual corpus have promising performance despite being about 10 times smaller than the others.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INISTA62901.2024.10683863 },
  booktitle={ 2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA) },
  chapter={0}
}

@article{rayyan-352343602,
  title={ Intelligent Meal Planning: A Generative LLM-Based Autonomous Agent Application  -  2025 Intermountain Engineering, Technology and Computing (IETC) },
  year={2025},
  author={Howlett, E. and Catlett, J. and Memari, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039478 },
  abstract={In this paper, we present What’s for Dinner, an intelligent mobile application that transforms meal planning by integrating advanced Large Language Models (LLMs) with state-of-the-art image analysis and Natural Language Processing (NLP) techniques. Our innovative system accurately identifies food items, maintains a dynamic virtual pantry, and retrieves or generates personalized recipe recommendations complete with detailed instructions. By leveraging an API-driven architecture, the system eliminates the need for local model storage and enables efficient real-time processing. The application couples a precise photo analysis module with a sophisticated recommendation engine, codenamed "Sous-Chef", ensuring scalability and high performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IETC64455.2025.11039478 },
  booktitle={ 2025 Intermountain Engineering, Technology and Computing (IETC) },
  chapter={0}
}

@article{rayyan-352343603,
  title={ Stimulating Brainstorming Activities with Generative AI in Higher Education  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Scala, J. La and Sahli, S. and Gillet, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016340 },
  abstract={Developing teamwork skills and creativity is becoming increasingly important in higher education. Brainstorming activities can support the acquisition of such transversal skills by encouraging open dialogue in collaborative design processes. In a successful brainstorming, participants propose diverse ideas, combine them, and elaborate new propositions by taking inspiration in the propositions of their teammates. However, the cognitive effect of idea fixation may hinder this process. Idea fixations happens when participants focus on a limited set of ideas and are unable to think about unrelated alternatives. This effect lowers the creativity of the group and prevents the participants to consider diverse aspects of the problem at hand, which is an important mechanism in design-based learning. Leveraging the recent development in Large Language Models (LLM), we propose to integrate a Generative-AI agent to introduce new ideas into a brainstorming process supported by a digital application. Such agent can be designed to bring new topics to be considered that the students may not have brought up themselves. Our study aims to examine how such AI-generated ideas may influence the ideas proposed anonymously by the participants, and ultimately, the outcome of the activity. We use a quasi-experimental design with two conditions: one in which only the students generate ideas (control), another where they receive AI-generated ideas along with their own. We conduct this experiment as a part of a design thinking project carried out by computer science students. Using a qualitative coding combined with Epistemic Network Analysis, we investigate the dissemination of the topics brought by the Generative-AI agent within the ideas of the participants. We also present and discuss practical aspects of the intervention and its implementation by educators in their teaching. Our findings are contributing to the understanding of humanAI interactions in the context of collaborative ideation in educational settings. They can inform the design of new interaction mechanisms with AI agents to support creativity. Furthermore, by introducing previously unconsidered topics to these activities, these AI-based agents can support groups of students in considering a wider range of aspects of the matter at hand, supporting the development of critical thinking. These mechanisms may be useful to educators and facilitators looking for solutions to overcome idea fixation and increase creativity in brainstorming.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016340 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343604,
  title={ Generative ΑΙ-based Cognitive Robot for exam candidates’ knowledge self-assessment  -  2024 IEEE Conference on Artificial Intelligence (CAI) },
  year={2024},
  author={Haddiya, I. and Pitrone, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605451 },
  abstract={Medical curricula are based on both theorical knowledge and competence achievement for either postgraduate or undergraduate medical education. It is important that medical students can self-assess their knowledge and competence so that they can take responsibility for their learning quality. Self-assessment is an important parameter in medical education to develop clinical competence.In this article we present a Generative ΑΙ-based Cognitive Robot developed for enabling the automatic self-assessment of hypertension exam candidates’ knowledge.The candidates are provided with ten direct open-questions automatically generated by the Artificial Intelligence solution (i.e., the Cognitive Robot): the performance of the Cognitive Robot is evaluated by comparing the outcomes calculated by the AI solution and the results achieved by the students while answering to the same list of questions, asked by a human Investigator.The Cognitive Robot has proven to present a very high level of accuracy. Moreover, the candidates involved in this study have confirmed the usefulness and trust of the Cognitive Robot. The Artificial Intelligence solution proposed for self-assessing the exam candidates’ knowledge is effective, innovative, accurate and can be extended to other field of study in the medicine realm.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI59869.2024.00124 },
  booktitle={ 2024 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343605,
  title={ A Comparative Analysis of Ai-Based Solutions for Clinical Documentation  -  2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS) },
  year={2025},
  author={Afonso, L. C. and Almeida, J. R. and Oliveira, J. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058845 },
  abstract={Healthcare systems handle thousands of documents daily across various departments, requiring some effort during the digitalization processes. One strategy employed by medical staff is recording appointments for later transcription. However, this process is time-consuming and not practical for all scenarios. In this paper, we present a comprehensive methodology for converting medical audio recordings into structured documentation through multiple AI-based solutions. We propose and evaluate three distinct methods: a baseline two-stage pipeline using Mixtral 7B and Llama 70B models, a cyclic LLM approach leveraging self-improvement loops, and an embedding-based retrieval system utilizing BGE M3. Our experimental results show that the RBF kernel consistently outperformed linear kernels and logistic regression approaches across all metrics, maintaining high precision (0.87-0.94) and perfect recall.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CBMS65348.2025.00026 },
  booktitle={ 2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS) },
  chapter={0}
}

@article{rayyan-352343606,
  title={ ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Xue, X. and Lu, Z. and Huang, D. and Wang, Z. and Ouyang, W. and Bai, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093418 },
  abstract={Much previous AI research has focused on developing monolithic models to maximize their intelligence, with the primary goal of enhancing performance on specific tasks. In contrast, this work attempts to study using LLM-based agents to design collaborative AI systems autonomously. To explore this problem, we first introduce ComfyBench to evaluate agents’s ability to design collaborative AI systems in ComfyUI. ComfyBench is a comprehensive benchmark comprising 200 diverse tasks covering various instruction-following generation challenges, along with detailed annotations for 3,205 nodes and 20 workflows. Based on ComfyBench, we further develop ComfyAgent, a novel framework that empowers LLM-based agents to autonomously design collaborative AI systems by generating workflows. ComfyAgent is based on two core concepts. First, it represents workflows with code, which can be reversibly converted into workflows and executed as collaborative systems by the interpreter. Second, it constructs a multi-agent system that cooperates to learn from existing workflows and generate new workflows for a given task. While experimental results demonstrate that ComfyAgent achieves a comparable resolve rate to o1-preview and significantly surpasses other agents on ComfyBench, ComfyAgent has resolved only 15% of creative tasks. LLM-based agents still have a long way to go in autonomously designing collaborative AI systems. Progress with ComfyBench is paving the way for more intelligent and autonomous collaborative AI systems. Our code is available at: https://github.com/xxyQwQ/ComfyBench.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.02292 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343607,
  title={ VelLMes: A High-Interaction AI-Based Deception Framework  -  2025 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW) },
  year={2025},
  author={Sladić, M. and Valeros, V. and Catania, C. and Garcia, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11129519 },
  abstract={There are very few SotA deception systems based on Large Language Models. The existing ones are limited only to simulating one type of service, mainly SSH shells. These systems - but also the deception technologies not based on LLMs - lack an extensive evaluation that includes human attackers. Generative AI has recently become a valuable asset for cybersecurity researchers and practitioners, and the field of cyber-deception is no exception. Researchers have demonstrated how LLMs can be leveraged to create realistic-looking honeytokens, fake users, and even simulated systems that can be used as honeypots. This paper presents an AI-based deception framework called VelLMes, which can simulate multiple protocols and services such as SSH Linux shell, MySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus VelLMes offers a variety of choices for deception design based on the users' needs. VelLMes is designed to be attacked by humans, so interactivity and realism are key for its performance. We evaluate the generative capabilities and the deception capabilities. Generative capabilities were evaluated using unit tests for LLMs. The results of the unit tests show that, with careful prompting, LLMs can produce realistic-looking responses, with some LLMs having a $100\%$ passing rate. In the case of the SSH Linux shell, we evaluated deception capabilities with 89 human attackers. The attackers interacted with a randomly assigned shell (either honeypot or real) and had to decide if it was a real Ubuntu system or a honeypot. The results showed that about $30\%$ of the attackers thought that they were interacting with a real system when they were assigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH Linux shell honeypot on the Internet to capture real-life attacks. Analysis of these attacks showed us that LLM honeypots simulating Linux shells can perform well against unstructured and unexpected attacks on the Internet, responding correctly to most of the issued commands.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EuroSPW67616.2025.00082 },
  booktitle={ 2025 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW) },
  chapter={0}
}

@article{rayyan-352343608,
  title={ Consistency of Code: A Prompt Based Approach to Comprehend Functionality  -  2023 30th Asia-Pacific Software Engineering Conference (APSEC) },
  year={2023},
  author={Choi, H. and Park, H. and Choi, Y. -J. and Han, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479382 },
  abstract={Large language model (LLM)-based AI for code model (e.g., Copilot) demonstrates the potential of using AI in specialized domains such as software engineering. While previous research has focused on fine-tuning models with additional data and computational cost to construct models optimized for specific domains, our research focuses on prompt engineering methods that maximize the performance of existing models. We conducted a quantitative and qualitative user study using the AI for code model and identified two limitations that hinder the recommendation performance of the model. We propose two methods to address these limitations through effective prompt engineering. Finally, we identified the potential for the use of our proposed methods to be utilized and discussed the direction of future research for the effective use of the LLM.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APSEC60848.2023.00095 },
  booktitle={ 2023 30th Asia-Pacific Software Engineering Conference (APSEC) },
  chapter={0}
}

@article{rayyan-352343609,
  title={ Online Course Improvement Through GPT-4: Monitoring Student Engagement and Dynamic FAQ Generation  -  2024 IEEE Global Engineering Education Conference (EDUCON) },
  year={2024},
  author={Lundström, O. and Maleki, N. and Ahlgren, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578788 },
  abstract={Artificial Intelligence (AI), specifically in language processing, is increasingly recognized as an invaluable educational tool. The Large Language Model (LLM) GPT, developed by OpenAI, is an advanced machine learning tool that utilizes deep learning for human-like text comprehension and generation. This study uses OpenAI's GPT-4 to enhance an online Internet of Things (loT) course at Linnaeus University. We analyzed 12,000+ messages on an online communication platform spanning four years. We compare traditional Natural Language Processing (NLP) techniques to Generative AI for understanding student feedback and issues, inspiring project ideas, and promoting student engagement. We provide a combined approach to monitor the sentiment or mood of the students' communications over the timeline of the course. Moreover, we show how to use LLM to refine the FAQ generation and decipher student feedback for course refinement. We demonstrate how to generate optimal prompts and prepare the data to apply LLMs effectively. Our research reinforces that strategic use of LLMs, like GPT-4, can revolutionize remote learning by lessening lecturer workload and boosting student satisfaction and engagement. Our future work aims to further leverage AI models across remote engineering education. One potential direction is developing an AI-powered bot for online platforms to facilitate real-time interaction, manage queries, encourage engagement, maintain FAQs, and enhance course outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON60312.2024.10578788 },
  booktitle={ 2024 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343610,
  title={ Harnessing Crowdsourced Mobile Data and LLM for Dynamic and Accessible Pedestrian Routing  -  2025 26th IEEE International Conference on Mobile Data Management (MDM) },
  year={2025},
  author={Yussif, G. I. and Abdelatti, M. and Hendawi, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058413 },
  abstract={Walking is a fundamental mode of human movement and an essential component of urban mobility. However, traditional pedestrian navigation systems lack real-time sidewalk accessibility data, relying primarily on static maps that fail to reflect dynamic hazards, such as construction zones, obstructions, or uneven pavement. To address this gap, we present a sidewalk navigation system that integrates crowdsourced reports, adaptive routing, and AI-powered assistance. The system leverages OpenStreetMap (OSM) maps and real-time user contributions to dynamically adjust pedestrian routes based on reported obstacles, ensuring a safer and more efficient walking experience. In addition, a user-driven rating system validates sidewalk conditions, while an AI assistant powered by Large Language Models (LLMs) provides context-aware guidance, interactive navigation, and additional insights. The application also features turn-by-turn navigation with audio support, enhancing accessibility for many users. By combining real-time crowdsourced data, personalized routing, and AIenhanced navigation, our system addresses critical limitations in existing pedestrian navigation applications and provides a more interactive, adaptive, and user-driven approach to sidewalk accessibility.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MDM65600.2025.00057 },
  booktitle={ 2025 26th IEEE International Conference on Mobile Data Management (MDM) },
  chapter={0}
}

@article{rayyan-352343611,
  title={ Scene-LLM: Extending Language Model for 3D Visual Reasoning  -  2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) },
  year={2025},
  author={Fu, R. and Liu, J. and Chen, X. and Nie, Y. and Xiong, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943341 },
  abstract={This paper introduces Scene-LLM, a 3D-visual-language model that enhances embodied agents' abilities in interactive 3D indoor environments by integrating the reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a unified 3D visual feature representation, that incorporates dense spatial information and supports scene state updates. The model employs a projection layer to efficiently project these features in the pretrained textual embedding space, enabling effective interpretation of 3D visual information. Unique to our approach is the integration of both scene-level and egocentric 3D information with a compact hybrid representation. This combination is pivotal for interactive planning, where scene-level data supports global planning and egocentric data is important for localization. Notably, we use egocentric 3D frame features for feature alignment, an efficient technique that incorporates the model with fine-grained concepts. Our experiments with Scene-LLM demonstrate its strong capabilities in scene captioning, question answering, and interactive planning. We believe Scene-LLM advances the field of 3D visual understanding and reasoning, offering new possibilities for sophisticated agent interactions in indoor settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WACV61041.2025.00220 },
  booktitle={ 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) },
  chapter={0}
}

@article{rayyan-352343612,
  title={ HDMoLE: Mixture of LoRA Experts with Hierarchical Routing and Dynamic Thresholds for Fine-Tuning LLM-based ASR Models  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Mu, B. and Wei, K. and Shao, Q. and Xu, Y. and Xie, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888133 },
  abstract={Recent advancements in integrating Large Language Models (LLM) with automatic speech recognition (ASR) have performed remarkably in general domains. While supervised fine-tuning (SFT) of all model parameters is often employed to adapt pre-trained LLM-based ASR models to specific domains, it imposes high computational costs and notably reduces their performance in general domains. In this paper, we propose a novel parameter-efficient multi-domain fine-tuning method for adapting pre-trained LLM-based ASR models to multi-accent domains without catastrophic forgetting named HDMoLE, which leverages hierarchical routing and dynamic thresholds based on combining low-rank adaptation (LoRA) with the mixture of experts (MoE) and can be generalized to any linear layer. Hierarchical routing establishes a clear correspondence between LoRA experts and accent domains, improving cross-domain collaboration among the LoRA experts. Unlike the static Top-K strategy for activating LoRA experts, dynamic thresholds can adaptively activate varying numbers of LoRA experts at each MoE layer. Experiments on the multi-accent and standard Mandarin datasets demonstrate the efficacy of HDMoLE. Applying HDMoLE to an LLM-based ASR model projector module achieves similar performance to full fine-tuning in the target multi-accent domains while using only 9.6% of the trainable parameters required for full fine-tuning and minimal degradation in the source general domain.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888133 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343613,
  title={ RAGE Against the Machine: Retrieval-Augmented LLM Explanations  -  2024 IEEE 40th International Conference on Data Engineering (ICDE) },
  year={2024},
  author={Rorseth, J. and Godfrey, P. and Golab, L. and Srivastava, D. and Szlichta, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598017 },
  abstract={This paper demonstrates RAGE, an interactive tool for explaining Large Language Models (LLMs) augmented with retrieval capabilities; i.e., able to query external sources and pull relevant information into their input context. Our explanations are counterfactual in the sense that they identify parts of the input context that, when removed, change the answer to the question posed to the LLM. RAGE includes pruning methods to navigate the vast space of possible explanations, allowing users to view the provenance of the produced answers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDE60146.2024.00430 },
  booktitle={ 2024 IEEE 40th International Conference on Data Engineering (ICDE) },
  chapter={0}
}

@article{rayyan-352343614,
  title={ CO-STEP: A Prompt Engineering Framework Improving LLM's Response  -  2025 10th International Conference on Applying New Technology in Green Buildings (ATiGB) },
  year={2025},
  author={Pham, T. and Cao, C. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11142099 },
  abstract={Prompt engineering has become increasingly vital in enhancing the performance of Large Language Models (LLMs), as the quality of prompts significantly affects the accuracy and relevance of generated outputs. In this study, we propose “CO-STEP,” a novel prompt engineering framework designed to address the limitations of the existing “CO-STAR” framework, particularly in handling complex tasks requiring advanced reasoning. “CO-STEP” integrates clear goal setting, detailed context with examples, task breakdown, advanced techniques like chain-of-thought prompting, and iterative refinement to improve precision and adaptability. Evaluations conducted using the OpenAI 4o-mini model on benchmark datasets, including structured tasks like invoice data extraction and mathematical derivative computation, demonstrate the superior performance of “CO-STEP.” Specifically, “CO-STEP” achieves an accuracy of 0.98 and an F1-score of 0.97, reflecting its capability to produce coherent and task-aligned outputs. These results highlight the effectiveness of “CO-STEP” in optimizing LLM interactions, with ongoing empirical validation to further explore its applicability across diverse tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ATiGB66719.2025.11142099 },
  booktitle={ 2025 10th International Conference on Applying New Technology in Green Buildings (ATiGB) },
  chapter={0}
}

@article{rayyan-352343615,
  title={ Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain  -  2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2023},
  author={Huang, Q. and Wan, Z. and Xing, Z. and Wang, C. and Chen, J. and Xu, X. and Lu, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298399 },
  abstract={API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASE56229.2023.00075 },
  booktitle={ 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352343616,
  title={ A Framework for Enhancing Accuracy in AI Generated Text Detection Using Ensemble Modelling  -  2024 IEEE Region 10 Symposium (TENSYMP) },
  year={2024},
  author={Aggarwal, K. and Singh, S. and Parul and Pal, V. and Yadav, S. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752173 },
  abstract={With the proliferation of AI-driven technologies, the generation of synthetic text has become increasingly prevalent, posing significant challenges in distinguishing between human-generated and AI-generated content (LLM). To mitigate this challenge, novel approach is proposed in this paper for AI-generated text detection through ensemble modelling based framework, leveraging the strengths of multiple state-of-the-art language models. Proposed Ensemble model integrates BERT, DeBERTa, and a custom ensemble method, each contributing to the collective decision-making process with weighted predictions. A diverse dataset sourced from various online platforms is used and this dataset comprises both human-written and AI-generated text samples. A fine-tuning strategy is used that dynamically adjusts the weights of the ensemble model based on the validation accuracy of each constituent model, while applying a cosine learning rate scheduler during training to optimize performance. The effectiveness of the ensemble model is evaluated using standard performance metrics such as accuracy, recall and F1 score. Proposed model achieved an accuracy over 94% and high recall of 98% through the ensemble framework, demonstrating accuracy improvement by 4.1% over BERT and and robustness in detecting AI-generated text across different domains and languages. The research contributes to advancing the field of AI-generated text detection and addresses critical challenges in content moderation and verification in online environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TENSYMP61132.2024.10752173 },
  booktitle={ 2024 IEEE Region 10 Symposium (TENSYMP) },
  chapter={0}
}

@article{rayyan-352343617,
  title={ Large Language Model based Personalized Learning Assistant for Career-Oriented Skills  -  2024 2nd International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES) },
  year={2024},
  author={Hemalatha, K. and Deepika, V. and Mallika, R. M and Babu, K. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990788 },
  abstract={Large Language Models (LLMs) are recently emerged as a variant of Artificial Intelligence algorithms in Natural Language Processing task such as analyzing extensive datasets, generating, summarizing content and predicting new information. LLMs fall under Generative AI, designed specifically for text generation. Their exceptional training and numerous model parameters significantly enhance the LLMs capacity to mimic human-like performances in natural language understanding. The advent of LLMs has revolutionized the interaction between humans and machines. In contrast to conventional recommendation systems and search engines, LLMs are the adoptive active user engagement. This interactive capability opens up new possibilities for the users towards personalization, enabling the provision of personalized services based on individualized information. Despite their potential, the applications of LLMs in personalization remain largely unexplored. Consequently, this study explores into the domain of personalization within education, aiming to uncover the potential contributions of Large Language Models (LLMs). In the context of this research, an innovative personalized LLM-based Human Machine Interface is crafted to individualize learning experiences for each learner. This system is adept at crafting personalized learning plans and adjusting learning materials accordingly. Additionally, it formulates assessments to analyze user strengths and weaknesses. These assessments undergo automatic evaluation, offering learners instant feedback. This feedback mechanism allows learners to promptly identify and understand their mistakes, fostering a more efficient learning process and aiding them in successfully completing their courses. The proposed personalized LLM based Assistant enhances the learner's unique journey by creating adaptive leaning plans, real time assessments with instant feedback.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCOPES64467.2024.10990788 },
  booktitle={ 2024 2nd International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES) },
  chapter={0}
}

@article{rayyan-352343618,
  title={ LLMs in Mobile Apps: Practices, Challenges, and Opportunities  -  2025 IEEE/ACM 12th International Conference on Mobile Software Engineering and Systems (MOBILESoft) },
  year={2025},
  author={Hau, K. and Hassan, S. and Zhou, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024525 },
  abstract={The integration of AI techniques has become increasingly popular in software development, enhancing performance, usability, and the availability of intelligent features. With the rise of large language models (LLMs) and generative AI, developers now have access to a wealth of high-quality open-source models and APIs from closed-source providers, enabling easier experimentation and integration of LLMs into various systems. This has also opened new possibilities in mobile application (app) development, allowing for more personalized and intelligent apps. However, integrating LLM into mobile apps might present unique challenges for developers, particularly regarding mobile device constraints, API management, and code infrastructure. In this project, we constructed a comprehensive dataset of 149 LLM-enabled Android apps and conducted an exploratory analysis to understand how LLMs are deployed and used within mobile apps. This analysis highlights key characteristics of the dataset, prevalent integration strategies, and common challenges developers face. Our findings provide valuable insights for future research and tooling development aimed at enhancing LLM-enabled mobile apps.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MOBILESoft66462.2025.00008 },
  booktitle={ 2025 IEEE/ACM 12th International Conference on Mobile Software Engineering and Systems (MOBILESoft) },
  chapter={0}
}

@article{rayyan-352343619,
  title={ Latency-Driven Execution of LLM-Generated Application Code on the Computing Continuum  -  2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW) },
  year={2025},
  author={Rao, K. and Coviello, G. and Vita, C. G. De and Mellone, G. and Khojastepour, M. A. and Chakradhar, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044757 },
  abstract={Latency-critical applications demand quick responses. Ideally, detailed insights are preferable for the best decision making and response actions. However, in situations when detailed insights cannot be provided quickly, even basic information goes a long way in tackling the situation effectively. For example, in marine security application, it is critical to immediately notify as soon as an unauthorized vessel is seen. Hence, timely response may be prioritized over the response based on entire details. To address such latency-critical situations, in this paper, we propose a novel system called DiCE-EC, which leverages LLM to generate distributed code with speculative execution on Edge (fast and simple response using resource-constrained hardware) and Cloud (detailed response using powerful hardware, but may be fast or slow depending on network conditions). DiCE-EC breaks down application into smaller components and executes them asynchronously across the edge and cloud computing continuum. As network conditions vary, we show through real-world marine security application, that DiCE-EC is effective in dynamically choosing detailed insights from cloud when received within latency-constraint, or falling back to simple response from edge to guarantee timely alert delivery. Without such dynamic selection of response from edge or cloud, existing systems either always provide simple responses or drop alerts. We perform real network measurements in the Gulf of Pozzuoli in Naples, Italy along accessible areas (inland and in a Ferry) and generate 1 million realistic measurements across four inaccessible regions, and demonstrate that DiCE-EC never misses an alert, while baseline misses up to ~4 % alerts with real data and up to ~1% (10,000 alerts) with generated data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCGridW65158.2025.00013 },
  booktitle={ 2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW) },
  chapter={0}
}

@article{rayyan-352343620,
  title={ Activation Sparsity Opportunities for Compressing General Large Language Models  -  2024 IEEE International Performance, Computing, and Communications Conference (IPCCC) },
  year={2024},
  author={Dhar, N. and Deng, B. and Islam, M. R. and Nasif, K. F. Ahmad and Zhao, L. and Suo, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850382 },
  abstract={Deploying local AI models, such as Large Language Models (LLMs), to edge devices can substantially enhance devices’ independent capabilities, alleviate the server’s burden, and lower the response time. Owing to these tremendous potentials, many big tech companies have been actively promoting edge LLM evolution and released several lightweight Small Language Models (SLMs) to bridge this gap. However, SLMs currently only work well on limited real-world applications. We still have huge motivations to deploy more powerful (larger-scale) AI models on edge devices and enhance their smartness level. Unlike the conventional approaches for AI model compression, we investigate from activation sparsity. The activation sparsity method is orthogonal and combinable with existing techniques to maximize compression rate while maintaining great accuracy. According to statistics of open-source LLMs, their Feed-Forward Network (FFN) components typically comprise a large proportion of parameters (around $\tfrac{2}{3}$). This internal feature ensures that our FFN optimizations would have a better chance of achieving effective compression. Moreover, our findings are beneficial to general LLMs and are not restricted to ReLU-based models.This work systematically investigates the tradeoff between enforcing activation sparsity and perplexity (accuracy) on state-of-the-art LLMs. Our empirical analysis demonstrates that we can obtain around 50% of main memory and computing reductions for critical FFN components with negligible accuracy degradation. This extra 50% sparsity does not naturally exist in the current LLMs, which require tuning LLMs’ activation outputs by injecting zero-enforcing thresholds. To obtain the benefits of activation sparsity, we provide a guideline for the system architect for LLM prediction and prefetching. Moreover, we further verified the predictability of activation patterns in recent LLMs. The success prediction allows the system to prefetch the necessary weights while omitting the inactive ones and their successors (compress models from the memory’s perspective), therefore lowering cache/memory pollution and reducing LLM execution time on resource-constraint edge devices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPCCC59868.2024.10850382 },
  booktitle={ 2024 IEEE International Performance, Computing, and Communications Conference (IPCCC) },
  chapter={0}
}

@article{rayyan-352343621,
  title={ Healpal Chatmate: AI Driven Disease Diagnosis and Recommendation System  -  2024 2nd International Conference on Disruptive Technologies (ICDT) },
  year={2024},
  author={Dwivedi, S. and Srivastava, N. and Rawal, V. and Dev, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10489509 },
  abstract={Using the LLM model Lamma 2 in the LangChain framework, this research study presents a novel approach to healthcare by creating a HealthBot that can analyse symptoms entered in text and provide tailored medicine recommendations. Thanks to the HealthBot's use of cutting-edge natural language processing, users may communicate with it easily and express their symptoms in natural language. Effective communication is ensured by the synergy between LangChain and Lamma 2, allowing for dynamic and responsive user experiences. The study explores the HealthBot's technical details, ethical issues, and practical assessments. It offers insightful information to the rapidly developing field of AI-driven healthcare, especially with regard to medication recommendation systems and disease detection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDT61202.2024.10489509 },
  booktitle={ 2024 2nd International Conference on Disruptive Technologies (ICDT) },
  chapter={0}
}

@article{rayyan-352343622,
  title={ AI-Assisted Twin-Sensor GPR for IED Detection  -  IEEE Transactions on Geoscience and Remote Sensing },
  author={Mohamadi, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124842 },
  abstract={This article introduces an ultra-wideband (UWB) ground-penetrating radar (GPR) system operating at 3–6 GHz, equipped with dual sensors to improve the detection of improvised explosive devices (IEDs). The system integrates advanced beamforming, clutter suppression, and deep learning (DL) models—including W-Net, SqueezeNet, and a late-fusion Twin-sensor Modified SqueezeNet—for optimized subsurface imaging and classification. A retrieval-augmented generation (RAG) pipeline, powered by a large language model (LLM), provides real-time contextual guidance for IED defusing. The twin-sensor design reduces multipath interference and enhances feature discrimination, achieving 92.12% precision and 92.18% recall—outperforming single-sensor systems. This fusion of high-resolution GPR with AI-guided interpretation boosts situational awareness and operator safety in high-threat missions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TGRS.2025.3599127 },
  booktitle={ IEEE Transactions on Geoscience and Remote Sensing },
  chapter={0}
}

@article{rayyan-352343623,
  title={ WebTrek Learner : AI Integrated Cloud Based Learning Platform  -  2024 International Conference on Computing, Semiconductor, Mechatronics, Intelligent Systems and Communications (COSMIC) },
  year={2024},
  author={Bhandari, A. and A, H. and Rishav, K. and Shifana, M. and Sameer, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871536 },
  abstract={In an era defined by the rapid proliferation of digital technology and connectivity, the need for virtual education has never been more critical. This article, referred to hereon as “WebTrek Learner,” is a forward-thinking initiative aimed at catering quality virtual education through a dynamic and engaging approach of gaming. To further enhance the learning experience, WebTrek Learner incorporates cutting-edge LLM based AI technology to curate internal insights and content based on glossary documents. Cloud based a gaming platform enables lightweight experience to all potential learners.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COSMIC63293.2024.10871536 },
  booktitle={ 2024 International Conference on Computing, Semiconductor, Mechatronics, Intelligent Systems and Communications (COSMIC) },
  chapter={0}
}

@article{rayyan-352343624,
  title={ Enhancing LLM QoS Through Cloud-Edge Collaboration: A Diffusion-Based Multi-Agent Reinforcement Learning Approach  -  IEEE Transactions on Services Computing },
  author={Yao, Z. and Tang, Z. and Yang, W. and Jia, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10970093 },
  abstract={Large Language Models (LLMs) are widely used across various domains, but deploying them in cloud data centers often leads to significant response delays and high costs, undermining Quality of Service (QoS) at the network edge. Although caching LLM request results at the edge using vector databases can greatly reduce response times and costs for similar requests, this approach has been overlooked in prior research. To address this, we propose a novel Vector database-assisted cloud-Edge collaborative LLM QoS Optimization (VELO) framework that caches LLM request results at the edge using vector databases, thereby reducing response times for subsequent similar requests. Unlike methods that modify LLMs directly, VELO leaves the LLM's internal structure intact and is applicable to various LLMs. Building on VELO, we formulate the QoS optimization problem as a Markov Decision Process (MDP) and design an algorithm based on Multi-Agent Reinforcement Learning (MARL). Our algorithm employs a diffusion-based policy network to extract the LLM request features, determining whether to request the LLM in the cloud or retrieve results from the edge's vector database. Implemented in a real edge system, our experimental results demonstrate that VELO significantly enhances user satisfaction by simultaneously reducing delays and resource consumption for edge users of LLMs. Our DLRS algorithm improves performance by 15.0% on average for similar requests and by 14.6% for new requests compared to the baselines.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TSC.2025.3562362 },
  booktitle={ IEEE Transactions on Services Computing },
  chapter={0}
}

@article{rayyan-352343625,
  title={ Structured Retrieval-Augmented Generation for Multi-Entity Question Answering over Heterogeneous Sources  -  2025 IEEE 41st International Conference on Data Engineering Workshops (ICDEW) },
  year={2025},
  author={Lin, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11107459 },
  abstract={Conventional RAG approaches, though effective for general tasks, often fail to retrieve precise information for complex questions involving multiple entities, which is called Multi-Entity question answering (QA), such as “How are all IEEE Fellows distributed across distinct research domains by 2024?”. To bridge this gap, we propose an innovative structured retrieval-augmented generation framework that includes semantic KG retrieval driven by large language model (LLM) and a table generation module, which transforms unstructured data into relational table structures. This structured format enables efficient querying via advanced table-based methods, ensuring high precision for intricate, entity-dense questions. Complementing our approach, we develop a tailored benchmark to rigorously assess performance of RAG systems for Multi-Entity QA. Experimental evaluations reveal that our system outperforms state-of-the-art baselines by 11.6% in accuracy, demonstrating the critical role of structured database technology in improving RAG systems for knowledge-intensive applications. This work paves the way for integrating database principles with generative AI to tackle real-world QA challenges requiring precise, multifaceted reasoning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDEW67478.2025.00036 },
  booktitle={ 2025 IEEE 41st International Conference on Data Engineering Workshops (ICDEW) },
  chapter={0}
}

@article{rayyan-352343626,
  title={ R2C: Mapping Room to Chessboard to Unlock LLM As Low-Level Action Planner  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Bai, Z. and Li, H. and Fu, B. and Xiong, C. and Wang, R. and Chen, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093713 },
  abstract={This paper explores using large language models (LLMs) as low-level action planners for embodied tasks. While LLMs excel as the robot’s “brain” for high-level planning, they face challenges in directly controlling the “body” by generating precise low-level actions. This limitation arises from LLMs’ strength in high-level conceptual understanding but their inability to handle spatial perception effectively, restricting their potential in embodied tasks. To address this, we bridge the gap by enabling LLMs to not only comprehend complex instructions but also produce actionable, low-level plans. We introduce Room to Chessboard (R2C), a novel semantic representation that maps environmental states onto a grid-based chessboard, empowering LLMs to generate specific low-level coordinates and guide the robot in a manner akin to playing a game of chess. To further enhance decision-making, we propose the Chain-of-Thought Decision (CoT-D) paradigm, which improves LLMs’ interpretability and context-awareness in spatial reasoning. By jointly training LLMs for high-level task decomposition and low-level action generation, we create a unified "brain-body" system capable of handling complex, free-form instructions while producing precise low-level actions, allowing the robot to flexibly control its movements and adapt to varying tasks. We validate R2C using both fine-tuned open-source LLMs and GPT-4, demonstrating effectiveness on the challenging ALFRED benchmark. Results show that with our R2C framework, LLMs can effectively act as low-level planners, generalizing across diverse settings and open-vocabulary robotic tasks. The code and demonstrations are available at: https://vipl-vsu.github.io/Room2Chessboard.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.01812 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343627,
  title={ ScamDetector: Leveraging Fine-Tuned Language Models for Improved Fraudulent Call Detection  -  TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  year={2024},
  author={Nicholas, P. Y. J. and Ng, P. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10902894 },
  abstract={This paper introduces a fine-tuned Large Language Models (LLMs) for detecting scam calls, a response to the growing severity of telecommunication fraud in Singapore, which has seen a consistent increase in scam incidents over recent years. Our approach significantly enhances scam detection capabilities through the strategic augmentation of existing datasets with generative AI. This process involves consolidating multiple datasets and employing generative models to synthesize culturally relevant scam scenarios specific to the Singapore context. We use the augmented dataset to fine tune pretrained LLMs, including GPT-2 and Llama. We conducted extensive experiments to compare the effectiveness of traditional machine learning (ML) models, deep learning (DL) techniques, transformers, and our fine-tuned LLMs. The results clearly show that our fine-tuned LLM outperforms other models in terms of inference accuracy while maintaining acceptable inference times, thereby establishing itself as a practical tool for real-time scam detection. The source code of this work is made publicly accessible at https://github.com/ict-at-sit/ScamDetector.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TENCON61640.2024.10902894 },
  booktitle={ TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  chapter={0}
}

@article{rayyan-352343628,
  title={ Retrieval Augmented Generation (RAG) Based Restaurant Chatbot with AI Testability  -  2024 IEEE 10th International Conference on Big Data Computing Service and Machine Learning Applications (BigDataService) },
  year={2024},
  author={Bhat, V. and Cheerla, S. D. and Mathew, J. R. and Pathak, N. and Liu, G. and Gao, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10730393 },
  abstract={Post-COVID the restaurant industry is experiencing a surge in demand, presenting a unique challenge of efficiently managing increased customer flow while ensuring seamless interactions. Chatbots have emerged as an innovative solution to meet the demand increase. The paper addresses the enhancement of AI chatbots through the integration of Retrieval-Augmented Generation (RAG) with the Large Language Model (LLM). This paper focuses on the development of a restaurant chatbot that not only engages in natural-language conversations but also addresses context optimization and LLM optimization for restaurant context learning. The approach uses a Neo4j Knowledge graph built using the restaurant data as an external source of knowledge. The graph is traversed to match the user question with appropriate answer tokens using Term Frequency - Inverse Document Frequency (TF-IDF) embeddings. The relevant tokens along with user questions are used to provide additional context to the T5 language model to provide nuanced responses to the users. This improvement is quantitatively evidenced by a Bilingual Evaluation Understudy (BLEU) score of 0.60, indicating a high level of precision in language understanding and generation. An extensive evaluation of the chatbot includes assessing AI testability on the level of words, sentences, and information. These evaluations include simulated dialogue assessments and performance analyses, with a focus on the chatbot's ability to retrieve and integrate information. Based on the AI testability evaluation, the models consistently produce more knowledgeable, diverse, and relevant answers as compared with state-of-the-art models with an average information score in the range of 0.6-0.8.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigDataService62917.2024.00008 },
  booktitle={ 2024 IEEE 10th International Conference on Big Data Computing Service and Machine Learning Applications (BigDataService) },
  chapter={0}
}

@article{rayyan-352343629,
  title={ The Quality of Diagnostic Tests for Misconceptions Scientific Generated AI: Rasch Psychometric Model  -  2025 International Technical Conference on Circuits/Systems, Computers, and Communications (ITC-CSCC) },
  year={2025},
  author={Buathong, S. and Junpeng, P. and Intharah, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11137623 },
  abstract={This research study aimed to develop a diagnostic testing instrument to identify scientific misconceptions in the topic "Cells as the Basic Units of Living Organisms" among 7th-grade students. The research employed a research and development (R&D) methodology, combining instruments created by our LLM model and those created by humans. The study utilized a 10-item test measuring scientific misconceptions (5 items created by ChatGPT and 5 items created by humans), administered to 150 students in schools under the Secondary Educational Service Area Office in Chaiyaphum Province. The quality of the test was analyzed using the Rasch model and psychometric analysis with ACER ConQuest version 5.0 software. Results indicated that both AI-generated and human-created tests demonstrated acceptable reliability and validity; however, the human-created tests showed higher reliability (0.92 compared to 0.54) and higher EAP/PV and Cronbach's alpha values (0.84, 0.83 compared to 0.77, 0.77). Additionally, Wright Map analysis revealed that human-created items had a better distribution of difficulty levels covering the range of student abilities compared to ChatGPT-generated items. In the Turing test, experts were unable to accurately distinguish between AI-generated and human-created test items, with incorrect identification rates ranging from 40-80%. This suggests that AI-generated items closely resemble human-created items. The findings demonstrate the potential of artificial intelligence in developing educational assessment tools, particularly in creating diagnostic tests for scientific misconceptions. However, AI should not replace human experts and still requires expert supervision.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITC-CSCC66376.2025.11137623 },
  booktitle={ 2025 International Technical Conference on Circuits/Systems, Computers, and Communications (ITC-CSCC) },
  chapter={0}
}

@article{rayyan-352343630,
  title={ SWATI AI : Advancing AI Models from Rule-Based Frameworks to NLP-Driven Prescriptive Analytics to Assist Victims of Domestic Abuse  -  2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET) },
  year={2025},
  author={Awasekar, D. D. and Lobo, L. M. R. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932279 },
  abstract={SWATI AI (Support and Welfare Assistance through Technology Interface) is an AI-driven chatbot designed to assist victims of domestic abuse by providing accessible, non-judgmental, and actionable legal guidance. This paper introduces the LAMP2 (Legal Analytics Model for Prediction and Prescription), the core framework that powers SWATI, progressing through four distinct research phases aimed at enhancing decision-making capabilities for victims of domestic violence under the Protection of Women from Domestic Violence Act, 2005. Phase 0 focuses on the creation of a curated dataset, PROTECT-JC, which compiles judgments from district courts, high courts, and the Supreme Court of India between 2008 and 2024. This dataset, developed in collaboration with legal experts and judicial professionals, serves as the foundation for training models to predict legal outcomes. Phase 1 introduces a rule-based decision framework in LAMP2 1.0, designed to extract and map predefined intents and entities from user inputs. This phase enables the structured documentation of complaints, providing victims with initial guidance based on the legal provisions of the Domestic Violence Act, 2005. The rule-based approach achieved accuracy of 80%, but with limited customization for individual cases. In Phase 2, LAMP2 2.0 leverages supervised machine learning models to predict legal outcomes, such as protection orders, custody orders, and monetary relief. These models, including Random Forest, XGBoost, and Decision Trees, achieved impressive results, with the Random Forest model showing 96.5% accuracy in predicting protection orders. Phase 3 evolves the model further with NLP-driven predictive analytics to process unstructured legal narratives, such as case judgments, transforming them into structured data for improved predictions. Models like Llama and Mixtral demonstrated strong summarization capabilities and show promise in predicting legal results. The integration of NLP and machine learning techniques allows for the prediction of case durations and other legal outcomes, addressing the complexities of the legal system. Overall, this research presents a comprehensive framework for assisting victims of domestic violence, combining rule-based models, machine learning, and natural language processing to offer predictive and prescriptive legal insights. The LAMP2-powered SWATI AI has the potential to significantly enhance access to legal assistance, empowering victims to make informed decisions regarding their legal options. This paper demonstrates the transformative potential of AI in providing personalized, data-driven legal guidance and advancing the accessibility of justice for underserved communities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAET63349.2025.10932279 },
  booktitle={ 2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET) },
  chapter={0}
}

@article{rayyan-352343631,
  title={ Efficient Generative AI-Assisted Academic Research: Considerations for a Research Model Proposal  -  2024 IEEE 11th International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC) },
  year={2024},
  author={Frank, D. and Bernik, A. and Milković, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10583155 },
  abstract={Generative artificial intelligence (GAl) has improved significantly since the emergence of ChatGPT 3.5 and is becoming an indispensable tool for many scholars, teachers, and students. This article addresses the main pitfalls of using GAl in research and academic writing, such as AI bias, AI hallucination, and ethical issues with literature review. It also provides an overview of how publishers view the use of GAl in academic writing. Finally, it offers some recommendations to address AI bias and AI hallucination problems, while maintaining the productivity benefits of using GAl. It also outlines a model that would enable efficient use of GAl in research and academic writing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCC62278.2024.10583155 },
  booktitle={ 2024 IEEE 11th International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC) },
  chapter={0}
}

@article{rayyan-352343632,
  title={ LLM-Based Edge Intelligence: A Comprehensive Survey on Architectures, Applications, Security and Trustworthiness  -  IEEE Open Journal of the Communications Society },
  author={Friha, O. and Ferrag, M. Amine and Kantarci, B. and Cakmak, B. and Ozgun, A. and Ghoualmi-Zine, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669603 },
  abstract={The integration of Large Language Models (LLMs) and Edge Intelligence (EI) introduces a groundbreaking paradigm for intelligent edge devices. With their capacity for human-like language processing and generation, LLMs empower edge computing with a powerful set of tools, paving the way for a new era of decentralized intelligence. Yet, a notable research gap exists in obtaining a thorough comprehension of LLM-based EI architectures, which should incorporate crucial elements such as security, optimization, and responsible development. This survey aims to bridge this gap by providing a comprehensive resource for both researchers and practitioners. We explore LLM-based EI architectures in-depth, carefully analyzing state-of-the-art paradigms and design decisions. To facilitate efficient and scalable edge deployments, we perform a comparative analysis of recent optimization and autonomy techniques specifically designed for resource-constrained edge environments. Additionally, we shed light on the extensive potential of LLM-based EI by demonstrating its varied practical applications across a wide range of domains. Acknowledging the utmost importance of security, our survey thoroughly investigates potential vulnerabilities inherent in LLM-based EI deployments. We explore corresponding defense mechanisms to protect the integrity and confidentiality of data processed at the edge. In conclusion, highlighting the essential aspect of trustworthiness, we outline best practices and guiding principles for the responsible development and deployment of these systems. By conducting a comprehensive review of these key components, our survey aims to support the ethical development and strategic implementation of LLM-driven EI, paving the way for its transformative impact on diverse applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OJCOMS.2024.3456549 },
  booktitle={ IEEE Open Journal of the Communications Society },
  chapter={0}
}

@article{rayyan-352343633,
  title={ Asset-Centric Threat Modeling for AI-Based Systems  -  2024 IEEE International Conference on Cyber Security and Resilience (CSR) },
  year={2024},
  author={von der Assen, J. and Sharif, J. and Feng, C. and Killer, C. and Bovet, G. and Stiller, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679445 },
  abstract={Threat modeling for systems relying on Artificial In-telligence is not well explored. While conventional threat modeling methods and tools do not address AI-related threats, research on this amalgamation still lacks solutions capable of guiding and automating the process, as well as providing evidence that the methods hold up in practice. Consequently, this paper presents ThreatFinderAI, an approach and tool providing guidance and automation to model AI-related assets, threats, countermeasures, and quantify residual risks. To do so, ThreatFinderAI presents a novel AI-based stencil library for automated asset extraction, a threat knowledge graph spanning several community initiatives, and a novel method to identify business impacts of AI threats and an approach to quantify them. To evaluate the practicality of the approach, participants were tasked to recreate a threat model developed by cybersecurity experts of an AI-based healthcare platform. Secondly, the approach was used to identify and discuss strategic risks in an LLM-based application through a case study. Overall, the solution's usability was well-perceived and effectively supports threat identification and risk discussion.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSR61664.2024.10679445 },
  booktitle={ 2024 IEEE International Conference on Cyber Security and Resilience (CSR) },
  chapter={0}
}

@article{rayyan-352343634,
  title={ Domain Agnostic Agentic AI: Enabling Autonomous Automation with SmartGenie CoPilot  -  2025 Emerging Technologies for Intelligent Systems (ETIS) },
  year={2025},
  author={Paulose, R. and Neelanath, V. and George, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10961403 },
  abstract={Generative AI and Agentic AI systems are revolutionizing the way organizations approach automation by enabling machines to autonomously perform complex tasks that traditionally required human intervention. These systems leverage large language models (LLMs) to process vast amounts of information, interpret complex workflows, and make decisions in real-time. Agentic AI frameworks, in particular, offer a new level of intelligence, allowing for dynamic, context-aware task execution across various industries. By integrating such advanced AI capabilities, businesses can automate decision-making processes and achieve unprecedented levels of efficiency and accuracy in handling routine and sophisticated tasks alike. This paper introduces SmartGenie, an Agentic AI CoPilot developed as part of the SmartOps intelligent automation platform. SmartGenie utilizes an LLM-based framework that is adaptable and easily integrated with autonomous automation scenarios. We present a use case where SmartGenie automates the handling of employee service requests for a financial client, autonomously responding to and resolving issues. This implementation resulted in significant improvements in request completion times, enhanced accuracy, and overall operational efficiency. These findings demonstrate the transformative potential of SmartGenie to drive quality and performance improvements in business-critical processes through the use of Agentic LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETIS64005.2025.10961403 },
  booktitle={ 2025 Emerging Technologies for Intelligent Systems (ETIS) },
  chapter={0}
}

@article{rayyan-352343635,
  title={ Probing the Inherent Ability of Large Language Models for Generating Empathetic Responses  -  2025 IEEE Swiss Conference on Data Science (SDS) },
  year={2025},
  author={Maheswaran, A. and Chua, C. and Desarkar, M. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081499 },
  abstract={Large Language Models (LLMs) have demonstrated capabilities beyond basic text generation, like question answering, translation, and even stylistic text generation. Since these models are available for public use, enormous effort has been put into safety engineering to ensure that undesirable and harmful text is not generated and the generations are polite and empathetic. In this work, we examine the inherent empathy capabilities of five open-source LLMs and evaluate them from multiple angles using automated metrics to understand their capabilities and limitations. In the context of this work, “inherent” refers to the LLM's ability to generate empathetic text without having to explicitly prompt for it. We examine if empathy is treated as a style change or is the model demonstrating some understanding of the specific user's context. We find that LLMs use more emotion words than humans in their generations. They can also infer the user's emotional state, a crucial characteristic of empathy. Due to the probabilistic nature of obtaining generations, there is a tendency for the responses to drift away from the user's actual intent. In such cases, specific prompting allows the model to respond appropriately. We summarize the differences observed between human and LLM generations and conclude with a potential research direction for empathetic dialog generation that leverages the capabilities of LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SDS66131.2025.00012 },
  booktitle={ 2025 IEEE Swiss Conference on Data Science (SDS) },
  chapter={0}
}

@article{rayyan-352343636,
  title={ LLM-based PID controller optimization  -  2025 10th International Conference on Smart and Sustainable Technologies (SpliTech) },
  year={2025},
  author={Kamenko, I. and Ilic, S. and Congradac, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091752 },
  abstract={This study explores the application of Large Language Models (LLMs) to optimize Proportional-Integral-Derivative (PID) controller parameters, aiming to automate a process traditionally reliant on manual, iterative tuning. Conventional methods often depend on heuristics and trial-and-error, requiring significant time and expertise. To address this, an LLM-based approach was developed that iteratively adjusts controller gains using real-time system feedback, substantially reducing the need for manual input. An adaptive tuning strategy, featuring predefined modes and levels of aggressiveness, was designed to balance response speed, minimize overshoot, and ensure system stability. The method was validated through computer simulations across a range of carefully selected process models and benchmarked against state-of-the-art expert-driven tuning techniques, demonstrating its effectiveness in reducing tuning time according to the selected mode while maintaining or improving system robustness. Results showed that LLMs, without additional model fine-tuning and guided solely by prompt engineering, can effectively optimize PID parameters. These findings demonstrate the promise of LLM-driven methods for advancing automation in PID controller tuning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/SpliTech65624.2025.11091752 },
  booktitle={ 2025 10th International Conference on Smart and Sustainable Technologies (SpliTech) },
  chapter={0}
}

@article{rayyan-352343637,
  title={ LLM Intelligent Customer Service in Property Management Using a RAG Approach  -  2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC) },
  year={2024},
  author={Chen, J. and Tungom, C. E. and Zhong, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10900207 },
  abstract={Traditional property management services often struggle with challenges such as long response times and difficulties in effectively addressing complex tenant issues. While Large Language Models (LLMs), like ChatGPT, offer promising solutions, they are often limited by their lack of domain-specific knowledge, leading to inaccurate or irrelevant responses. To address these shortcomings, this paper introduces an intelligent customer service system tailored for property management. The system integrates a customized LLM with the Retrieval Augmented Generation (RAG) framework, designed to provide accurate, context-aware, and personalized responses. By employing an intelligent agent to pull relevant data from a dedicated property management knowledge base, the system can engage tenants in real-time through an interactive interface, ensuring both efficiency and relevance in communication. Additionally, machine learning algorithms are employed to continuously improve the system’s performance. The architecture combines a fine-tuned LLM, a vector database for fast information retrieval, and a feedback loop that supports ongoing optimization. We anticipate that this approach will lead to greater tenant satisfaction, more personalized services, and enhanced operational efficiency. This study contributes to the broader fields of Artificial Intelligence, Robotics, and Communication by showcasing how RAG can be applied to improve customer service, with future work focusing on real-world implementation and comprehensive system evaluation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIRC64177.2024.10900207 },
  booktitle={ 2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC) },
  chapter={0}
}

@article{rayyan-352343638,
  title={ Towards ASR Robust Spoken Language Understanding Through in-Context Learning with Word Confusion Networks  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Everson, K. and Gu, Y. and Yang, H. and Shivakumar, P. G. and Lin, G. -T. and Kolehmainen, J. and Bulyko, I. and Gandhe, A. and Ghosh, S. and Hamza, W. and Lee, H. -Y. and Rastrow, A. and Stolcke, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447938 },
  abstract={In the realm of spoken language understanding (SLU). numerous natural language understanding (NLU) methodologies have been adapted by supplying large language models (LLMs) with transcribed speech instead of conventional written text. In real-world scenarios, prior to input into an LLM. an automated speech recognition (ASR) system generates an output transcript hypothesis, where inherent errors can degrade subsequent SLU tasks. Here we introduce a method that utilizes the ASR system's lattice output instead of relying solely on the top hypothesis, aiming to encapsulate speech ambiguities and enhance SLU outcomes. Our in-context learning experiments, covering spoken question answering and intent classification. underline the LLM's resilience to noisy speech transcripts with the help of word confusion networks from lattices, bridging the SLU performance gap between using the top ASR hypothesis and an oracle upper bound. Additionally, we delve into the LLM's robustness to varying ASR performance conditions and scrutinize the aspects of in-context learning which prove the most influential.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10447938 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343639,
  title={ Early Detection of Dementia Using a Large Language Model-Powered Chatbot  -  2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC) },
  year={2024},
  author={Routray, S. and Samir, D. and Pushya, G. and Srivastava, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10984295 },
  abstract={Artificial Intelligence has grown widely in different areas and provided various extensions to healthcare systems like automation techniques for remote monitoring and early disease detection. This work presents a chatbot-driven Large Language Model (LLM) that can identify dementia at an early stage. Dementia is a syndrome characterized by progressive cognitive decline. An AI-powered conversational robot is used to identify linguistic patterns while user conversation suggests the cognitive decline level. This work was tested on 500 participants aged between 60 to 80. The outcomes show that the LLM-based chatbot outperformed conventional screening techniques in detecting early indications of dementia, achieving a sensitivity of 85% and specificity of 88%. After analyzing conversational data, certain linguistic signals were shown to be strongly associated with cognitive impairment. This work demonstrates the potential of conversational agents driven by artificial intelligence for early dementia monitoring and detection that potentially transform elderly care screening procedures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PDGC64653.2024.10984295 },
  booktitle={ 2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC) },
  chapter={0}
}

@article{rayyan-352343640,
  title={ Equity Research Chatbot Using LLM: A Responsive Agent for Investment Research  -  2024 IEEE Pune Section International Conference (PuneCon) },
  year={2024},
  author={Dongare, N. and Bhirange, A. and Kharche, S. and Buchade, A. and Mahalle, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895230 },
  abstract={Our research paper includes the combination of chatbot development and research on various companies' fundamentals (P&L, Balance sheet, and Cash Flow) for giving end users precise investment advice.The literature on technologies like machine learning (ML), neural networks, and Generative AI in financial analysis is surveyed, emphasizing the growing body of research using Large Language Models (LLMs) and their applications using chatbot assistance for investment opportunities. Additionally, previous studies on chatbots in finance are reviewed to contextualize their role in equity research.The methodology outlines the research approach, data collection method, and usage of LLMs in this study. Here the data used are the pdf files containing company financial reports which are then fed into the chatbot for further processing. The data regarding current market trends and overall fundamental analysis provides a clear idea to chatbot for suggesting precise investments. Here NLP processes include text chunking, building semantics, and knowledge base for proceeding to further steps. Further, our results include categories of questions for which we have also showcased its graph that mentions the response time and accuracy versus the type of question asked to the chatbot. This analysis gives an efficient understanding of the chatbot. Overall, this research contributes to the knowledge of how chatbots can transform equity research, paving the way for more efficient and accessible financial analysis in the digital age.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PuneCon63413.2024.10895230 },
  booktitle={ 2024 IEEE Pune Section International Conference (PuneCon) },
  chapter={0}
}

@article{rayyan-352343641,
  title={ Building a Role-Play Interactive System using LLM for Health Guidance Education  -  2024 Joint 13th International Conference on Soft Computing and Intelligent Systems and 25th International Symposium on Advanced Intelligent Systems (SCIS&ISIS) },
  year={2024},
  author={Agatsuma, S. and Ohashi, R. and Tsubokura, K. and Nishio, Y. and Ishikawa, M. and Ito, N. and Ito, F. and Minami, S. and Takegawa, N. and Nakamura, R. and Yokoyama, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759994 },
  abstract={This study develops a “health guidance training system for nursing students” using conversational AI to simulate patient interactions. Health guidance aims to understand health states and change unhealthy behaviors to prevent lifestyle-related diseases, often employing role-playing as a training method. However, traditional role-playing suffers from student's shyness and inexperience. Our solution leverages the ChatVRM system, which integrates speech recognition, natural language generation, speech synthesis, and 3D avatars to create a simulated patient. The system was evaluated by nursing students and faculty through our surveys, with over 70% of participants providing positive feedback on its usefulness, ease of use, and natural interaction. These results suggest the system effectively enhances health guidance training by providing realistic and practical simulations. In future work, we will further improve the system and conduct extensive evaluation experiments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCISISIS61014.2024.10759994 },
  booktitle={ 2024 Joint 13th International Conference on Soft Computing and Intelligent Systems and 25th International Symposium on Advanced Intelligent Systems (SCIS&ISIS) },
  chapter={0}
}

@article{rayyan-352343642,
  title={ DeepSeek-Med-8B: Medical LLM for Chinese Diagnosis and Referral  -  2025 8th International Conference on Computer Information Science and Application Technology (CISAT) },
  year={2025},
  author={Li, C. and Mao, J. and Liu, B. and Luo, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181817 },
  abstract={The uneven distribution of medical resources in China poses significant challenges, especially in rural areas. While large language models (LLMs) offer potential for clinical support, existing systems like GPT-4 and Med-PaLM suffer from hallucinations, English-centric biases, and lack real-time physician integration. We present DeepSeek-Med-8B, a Chinese medical conversational agent based on the DeepSeek-R1-DistillLlama-8B architecture.DeepSeek-Med-8B is trained through: (i) Supervised Fine-Tuning (SFT) on curated Chinese medical corpora; (ii) Reinforcement Learning with AI and Doctor Feedback (RLAIF) for factuality, empathy, and referral quality; and (iii) Retrieval-Augmented Generation (RAG) for real-time grounding in physician databases.Across eight clinical tasks, DeepSeek-Med-8B achieves a top1 mean score of 66.9 on GPT-4o-based benchmarks and a 74% top-3 doctor match rate, outperforming rule-based baselines. The model runs efficiently on a single RTX 4090 GPU via INT8 quantization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CISAT66811.2025.11181817 },
  booktitle={ 2025 8th International Conference on Computer Information Science and Application Technology (CISAT) },
  chapter={0}
}

@article{rayyan-352343643,
  title={ LegalMind System and the LLM-based Legal Judgment Query System  -  2024 International Conference on Trends in Quantum Computing and Emerging Business Technologies },
  year={2024},
  author={S, A. and Saxena, A. and Mahajan, J. and Panikulangara, L. and Kulkarni, S. and Bang, D. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545179 },
  abstract={LegalMind-GPT represents a notable advancement in legal technology, specifically tailored for the finance sector. This research paper introduces LegalMind-GPT, a system that integrates Large Language Models (LLMs) to develop a Legal Judgment Query System for financial legal contexts. The study focuses on the application of LLMs, particularly LLAMA-2, Claude AI, and FLAN-T5-Base, for interpreting and analysing complex legal documents in finance. The aim is to evaluate the system’s effectiveness in providing accurate legal judgments and insights. The comparative analysis of these LLMs shows that LegalMind-GPT, powered by these models, significantly improves the accuracy and efficiency of legal analysis in the finance domain.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TQCEBT59414.2024.10545179 },
  booktitle={ 2024 International Conference on Trends in Quantum Computing and Emerging Business Technologies },
  chapter={0}
}

@article{rayyan-352343644,
  title={ Exploring LLM and Neural Networks Towards Malicious Prompt Detection  -  2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC) },
  year={2024},
  author={Deshpande, H. and Chaudhari, D. and Sarode, T. and Kamath, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690068 },
  abstract={Atthe forefront of the Artificial Intelligence Revolution is the Generative AI domain which is making splashes in generation of new content from existing Large Language Models. Large Language Models (LLMs) are flexible, effective tools with many uses. On the other hand, they can be tricked by devious provocation. This work explores the detection of fraudulent prompts intended to produce false or damaging outputs using Long Short-Term Memory (LSTM) networks. During this study we analysed the LTSM model against a neural network model. We found a 91.69% accuracy for the LTSM model and a 92.52% accuracy for the simple neural network. However, the simple neural network had a higher F1 score of 0.73 compared to the LTSM score of 0.69. We found that the standard neural model is more efficient at identifying harmful user prompts. Our research highlights the need for taking into account various architectures of models to reduce the risk of malicious prompting in language learning models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICESC60852.2024.10690068 },
  booktitle={ 2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC) },
  chapter={0}
}

@article{rayyan-352343645,
  title={ Quality-of-Trust in 6G: Combining Emotional and Physical Trust through Explainable AI  -  2023 IEEE 98th Vehicular Technology Conference (VTC2023-Fall) },
  year={2023},
  author={Li, C. and Qi, W. and Jin, B. and Demestichas, P. and Tsagkaris, K. and Kritikou, Y. and Guo, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10333364 },
  abstract={Wireless networks like many multi-user services have to balance limited resources in real-time. In 6G, increased network automation makes consumer trust crucial. Trust is reflect in both a personal emotional sentiment as well as a physical understanding of the transparency of AI decision making. Whilst there has been isolated studies of consumer sentiment to wireless services, this is not well linked to the decision making engineering. Likewise, limited recent research in explainable AI (XAI) has not established a link to consumer perception.Here, we develop a Quality-of-Trust (QoT) KPI that balances personal perception with the quality of decision explanation. That is to say, the QoT varies with both the time-varying sentiment of the consumer as well as the accuracy of XAI outcomes. We demonstrate this idea with an example in Neural Water-Filling (N-WF) power allocation, where the channel capacity is perceived by artificial consumers that communicate through Large Language Model (LLM) generated text feedback. Natural Language Processing (NLP) analysis of emotional feedback is combined with a physical understanding of N-WF decisions via meta-symbolic XAI. Combined they form the basis for QoT. Our results show that whilst the XAI interface can explain up to 98.9% of the neural network decisions, a small proportion of explanations can have large errors causing drops in QoT. These drops have immediate transient effects in the physical mistrust, but emotional perception of consumers are more persistent. As such, QoT tends to combine both instant physical mistrust and long-term emotional trends.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VTC2023-Fall60731.2023.10333364 },
  booktitle={ 2023 IEEE 98th Vehicular Technology Conference (VTC2023-Fall) },
  chapter={0}
}

@article{rayyan-352343646,
  title={ Model Selection for HERITAGE-AI: Evaluating LLMs for Contextual Data Analysis of Maryland’s Domestic Traffic Ads (1824–1864)  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Gnanasekaran, R. K. and Perine, L. and Conrad, M. and Marciano, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825591 },
  abstract={The HERITAGE-AI (Harnessing Enhanced Research and Instructional Technologies for Archival Generative Exploration using AI), as part of the IMLS grant initiative, GenAI-4-Archive, aims to analyze sensitive historical datasets ethically using advanced AI technologies. One of the key tasks of this project focuses on selecting the most suitable Large Language Model (LLM) for analyzing the Domestic Traffic Ads (DTA) published in Maryland between 1824 and 1864 by slave traders—a dataset rich in historical significance yet fraught with ethical considerations. Analyzing sensitive historical datasets presents unique ethical and technical challenges. This paper presents a comparative evaluation of leading LLMs to identify the optimal model to meet HERITAGE-AI’s objectives. We survey contemporary models, including OpenAI’s GPT-4o, Anthropic’s Claude Sonnet, Meta’s Llama 3.2, and Google’s Gemini, to identify the most suitable model for Generative AI-based analysis of the DTA dataset. The objective is to select an LLM that can handle the sensitive nature of the data responsibly while providing accurate and insightful analysis. Three critical evaluation criteria, among others, are established for this reason: Sensitivity to Historical Context, Privacy and Security, and Customizability. Our analysis follows a three-step approach: evaluating free versions, paid versions, and enterprise-grade cloud-based implementations of these LLMs. Our findings reveal that while free and paid versions offer varying degrees of accessibility, they fall short in providing the necessary privacy, security, multi-user access, and customization required for analyzing sensitive historical data like the DTA dataset. In the third step, by comparing the cloud-based implementations of Azure OpenAI’s GPT-4o, AWS Bedrock’s Claude, and AWS Bedrock’s Llama3.2 LLMs, Azure openAI GPT-4o emerges as the most suitable option for this project. Although GPT-4o and Claude were close contenders, Gpt-4o demonstrated robust mechanisms due to its high accuracy, ethical sensitivity, robust privacy controls, and scalability in a cloud-based environment. It also offers extensive customizability, allowing for effective integration of the DTA dataset and alignment with the project’s ethical standards. Future work will involve domain experts and community members in implementing Azure OpenAI GPT-4o for the DTA dataset analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825591 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343647,
  title={ LIVE-GS: LLM Powers Interactive VR by Enhancing Gaussian Splatting  -  2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) },
  year={2025},
  author={Mao, H. and Xu, Z. and Wei, S. and Quan, Y. and Deng, N. and Yang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973016 },
  abstract={We propose LIVE-GS, a highly realistic interactive Gaussian splatting system in VR environments powered by LLM. Our pipeline supports reconstructions and physically-based interactions in VR, integrating object-aware reconstruction, GPT-assisted inpainting, and a computationally efficient simulation framework. To enhance scene understanding, we prompt GPT-4o to analyze the physical properties of objects in the scene, thereby guiding physical simulations to align with real-world phenomena. Our experimental results demonstrate that with the assistance of LLM’s understanding and scene enhancement, our VR system can support complex and realistic interactions without requiring additional manual design or annotation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VRW66409.2025.00263 },
  booktitle={ 2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) },
  chapter={0}
}

@article{rayyan-352343648,
  title={ A Survey of LLM-based Agents: Theories, Technologies, Applications and Suggestions  -  2024 3rd International Conference on Artificial Intelligence, Internet of Things and Cloud Computing Technology (AIoTC) },
  year={2024},
  author={Dong, X. and Zhang, X. and Bu, W. and Zhang, D. and Cao, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10748304 },
  abstract={AI Agent has presented potential towards Artificial General Intelligence (AGI), which is expected to autonomously perceive the environments, make decisions and take actions. However, most of existing AI agents tend to train in confined environments with limited knowledge, yielding sub-optimal performance. Benefiting from the remarkable progress of large language models (LLMs), diverse LLM-based agents emerge. These agents employ LLM as the central brain to perceive, plan, and memorize, etc, which exhibit human-level intelligence across multifarious applications and obtain satisfactory performance. In this paper, we propose a survey of LLM-based agents from the perspective of theories, technologies, applications and suggestions, respectively. Specifically, we first deliver a recapitulative review of the theory foundation, which includes Large Language Models, Chain of Thought and AI Alignment, Retrieval-Augmented Generation, Embodied AI, etc; With this, we then present the key technologies, comprising four critical components: Perception, Planning, Memory and Action; Subsequently, we briefly explore some domain-related and evaluation applications; Finally, we provide pertinent suggestions based on the observations of significant challenges for LLM-based agents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIoTC63215.2024.10748304 },
  booktitle={ 2024 3rd International Conference on Artificial Intelligence, Internet of Things and Cloud Computing Technology (AIoTC) },
  chapter={0}
}

@article{rayyan-352343649,
  title={ MemoryRepository for AI NPC  -  IEEE Access },
  author={Zheng, S. and He, K. and Yang, L. and Xiong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10508558 },
  abstract={Since the release of ChatGPT, large language models (LLMs) have played a huge role in various industries. In the field of games, we have used LLMs to act as intelligent AI NPC, which makes NPCs more intelligent. However, there is still an obvious obstacle -the LLMs lacks long-term memory and human-like memory mechanism. This flawed memory mechanism prevents NPCs from Long-term interaction and humanized memory based on conversation records. Recognizing the necessity of long-term memory and humanized memory, we proposed MemoryRepository, a memory mechanism for LLMs specifically used in the AI NPC field.MemoryRepository enables the model to have short-term memory and long-term memory. Short-term memory is more detailed and full, while long-term memory are more concise and partial. MemoryRepository is inspired by human memory and forgetting mechanisms. This mechanism allows AI NPCs to forget and summarize past conversation records, thereby providing long-term interaction capabilities. More importantly, this process of forgetting and summarizing the details of short-term memory into general long-term memories makes NPCs more human-like. MemoryRepository is versatile and can adapt to closed source models such as ChatGPT and open source models such as ChatGLM. To Intuitively verify the effectiveness of MemoryRepository in the field of AI NPC, we created an example in which all NPCs are represented by LLMs adapted to MemoryRepository. The example shows that by embedding LLM in MemoryRepository and fine-tuning NPCs character dialogue data, AI NPC can conduct better long-term conversations and appear more human-like during the interaction process. To validate the effectiveness of MemoryRepository, one hundred pieces of NPCs dialogue data were created and then quantitatively analyzed through evaluation indicators. The analysis results show that NPCs equipped with MemoryRepository can summarize and forget past memories, which enables it to have the ability to hold long-term conversations and conduct more human-like conversations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3393485 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343650,
  title={ CareerAlly: An Intelligent NLP-Driven Chatbot  -  2025 5th International Conference on Expert Clouds and Applications (ICOECA) },
  year={2025},
  author={Sachan, A. and Iyer, A. and S., H. and Shukla, R. and Shahade, A. K. and Gaikwad, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113962 },
  abstract={In the current dynamic job market, career success depends on aligning skills with the evolving demands of specific job roles. However, many job-seekers struggle to identify skill gaps and assess their readiness for desired roles. Traditional methods lack a well-defined approach to self-evaluation, leaving candidates uncertain about necessary improvements. This research presents CareerAlly, an intelligent Chatbot designed to assist users in identifying skill gaps and strengthening their competencies for targeted job roles. As a solution, the Chatbot processes the user’s resume as input, applying natural language processing (NLP) techniques such as Named-Entity Recognition (NER) and Regular Expressions (regex) to extract relevant skills. CareerAlly then maps these extracted skills against a predefined job role-skill database (Jobmatcher) to identify deficiencies. To evaluate the user’s expertise, the Chatbot uses a Large Language Model (LLM) to generate skill-specific multiple-choice questions (MCQs) for the chosen job role, enabling objective knowledge assessment. Finally, CareerAlly provides users with a report that visualizes skill-based performance. The Chatbot uses Knowledge Graphs (neo4j) to recommend learning resources for job preparation. CareerAlly’s Artificial Intelligence (AI)-driven methodology offers systematic career guidance and supports users in addressing skill gaps, helping them improve their professional qualifications in a competitive job market. It will help individuals make informed decisions, enhance their competencies, and align their skills with industry demands. In effect, it will increase their employability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICOECA66273.2025.00019 },
  booktitle={ 2025 5th International Conference on Expert Clouds and Applications (ICOECA) },
  chapter={0}
}

@article{rayyan-352343651,
  title={ CARA: A Hybrid Framework Integrating Swarm AI Agents and Knowledge Graphs for Advanced LLM Reasoning  -  2024 6th International Conference on Advancements in Computing (ICAC) },
  year={2024},
  author={Pussadeniya, N. and Wijesinghe, R. and Wijenayake, U. and Silva, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851065 },
  abstract={Language models excel in linguistic processing but often face challenges with complex reasoning tasks that require real-world interaction and multi-step logic. This paper presents the Cognitive Adaptive Reasoning Architecture (CARA), a framework that enhances reasoning by integrating a modular swarm architecture with knowledge graphs (KGs) and specialized agents. These agents, equipped with diverse tools, dynamically adapt to various tasks, actively engaging with real-world data. CARA's continuous memory update cycle ensures each reasoning step is based on up-to-date, contextual KG knowledge, enhancing decision-making. Incorporating human insights further aligns outcomes with nuanced cognition. Experimental results demonstrate CARA's superior performance over larger models, advancing language models' reasoning capabilities for more context-aware, informed decision-making in dynamic environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAC64487.2024.10851065 },
  booktitle={ 2024 6th International Conference on Advancements in Computing (ICAC) },
  chapter={0}
}

@article{rayyan-352343652,
  title={ LLM-Based Generative AI in Medicine: Analysis of Current Research Trends With BERTopic  -  IEEE Access },
  year={2023},
  author={Kilinc, M. and Gurcan, F. and Soylu, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11151540 },
  abstract={Recent advances in generative artificial intelligence (GenAI) have made large language models (LLMs) transformative tools in the healthcare industry. Powered by deep learning, these models show great potential in many medical applications such as clinical decision support systems, biomedical text mining and personalized patient care. However, while research on the use of LLMs in medicine is growing rapidly, there is a need to systematically analyze the key themes, emerging trends and challenges in this field. This study aims to identify dominant themes, track research trends and identify gaps in the literature by utilizing a large dataset of scientific publications in the medical field. A total of 3,941 academic publications related to the use of LLMs in medicine were retrieved from the Scopus database, covering the period from 2023 to 2024. Accordingly, the BERTopic method, an advanced topic modeling technique, is used to analyze and classify publications on LLMs applications in medicine. The findings show that LLMs are mostly concentrated in the fields of radiology, ophthalmology and mental health and that these models have the potential to support clinical processes. In particular, LLMs have been found to have a great impact on the analysis of medical imaging reports, are used for early diagnosis of ophthalmologic diseases, and are prominent in depression and suicide risk assessments in mental health. This study provides valuable insights for healthcare professionals, GenAI researchers, and policy makers, laying a solid foundation for future research and strategic applications for the use of LLMs in medicine. While emphasizing the transformative impact of LLMs in healthcare, it also highlights the necessity of responsible GenAI applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3606335 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343653,
  title={ MalPID: Malicious Prompt Injection Detection Dataset for Large Language Model based Applications  -  2024 IEEE Eleventh International Conference on Communications and Networking (ComNet) },
  year={2024},
  author={Omri, S. and Abdelkader, M. and Hamdi, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987374 },
  abstract={Despite the significant transformation made by large language model (LLM)-based chatbots in the field of conversational artificial intelligence (AI), these systems are vulnerable to the attack known as prompt injection by malicious users to make them ignore their guardrails and generate objectionable content. However, few previous works have been addressing this issue using complex and costly mechanisms and there is a lack of large dataset that deal with prompt injection examples. In this work, we introduce MalPID, a novel dataset for malicious prompt injection detection. This benchmark contains various malicious and legitimate prompts collected from different sources and labelled manually. Our systematic evaluation of models trained on our dataset has shown impressive results in detecting prompt injection data. In the future, MalPID could be a valuable resource for advancing the creation of safe conversational AI systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ComNet64071.2024.10987374 },
  booktitle={ 2024 IEEE Eleventh International Conference on Communications and Networking (ComNet) },
  chapter={0}
}

@article{rayyan-352343654,
  title={ Automated Testing for Service-Oriented Architecture: Leveraging Large Language Models for Enhanced Service Composition  -  IEEE Access },
  author={Altin, M. and Mutlu, B. and Kilinc, D. and Cakir, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007529 },
  abstract={This article explores the application of Large Language Models (LLMs), including proprietary models such as OpenAI’s ChatGPT 4o and ChatGPT 4o-mini, Anthropic’s Claude 3.5 Sonnet and Claude 3.7 Sonnet, and Google’s Gemini 1.5 Pro, Gemini 2.0 Flash, and Gemini 2.0 Flash-Lite, as well as open-source alternatives including Qwen2.5-14B-Instruct-1M, and commercially accessed models such as DeepSeek R1 and DeepSeek V3, which were tested via APIs despite having open-source variants, to automate validation and verification in Application Programming Interface (API) testing within a Service-Oriented Architecture (SOA). Our system compares internal responses from the Enuygun Web Server against third-party API outputs in both JSON and XML formats, validating critical parameters such as flight prices, baggage allowances, and seat availability. We generated 100 diverse test scenarios across varying complexities (1-4 flight results) by randomly altering request and response parameters. Experimental results show that Google Gemini 2.0 Flash achieved high accuracy (up to 99.98%) with the lowest completion time (85.34 seconds), while Qwen2.5-14B-Instruct-1M exhibited limited capability in processing complex formats. Models such as OpenAI’s ChatGPT and Anthropic’s Claude Sonnet models also demonstrated strong performance in single-flight validation scenarios, making them suitable for low-latency, high-precision tasks. Our findings indicate that some open-source models can offer promising cost-effective alternatives, though performance significantly varies. This integration of LLMs reduced manual workload, improved test scalability, and enabled real-time validation across large-scale datasets. As LLM technologies mature, we anticipate further advances in automation, accuracy, and efficiency in software validation systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3571994 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343655,
  title={ Implicit Multi-Behavior Generative Recommendation With Mixture of Quantization  -  IEEE Transactions on Knowledge and Data Engineering },
  author={Tan, Y. and Gou, Y. and Xue, K. and Huang, S. and Hu, Y. and Tsang, I. W. and Lv, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007466 },
  abstract={Generative recommendation systems have recently seen a surge in interest, largely due to the promising advancements in generative AI. As a competitive solution for multi-behavior sequence recommendations, much of the recent research has concentrated on predicting the next item a user will likely interact with using a generative approach. However, these methods often 1). assign multiple residual quantization layers to obtain item codes, which leads to extra storage costs of more codebooks. And 2). explicitly utilize behavior sequences leading to longer sequences, potentially increasing the training time as well as inference time compared with original sequences. In response to these challenges, we introduce the Implicit Multi-Behavior Generative recommendation with a mixture of quantization (IMBGen) approach in this paper. Specifically, we have devised a Mixture of Quantization (MoQ) that combines the merits of both residual and parallel quantization for a more effective tokenization process. Additionally, we propose an Implicit Behavior Modeling (IBM) framework, allowing for more efficient integration of users’ behaviors into the interacted items. Finally, we conducted extensive experiments on two widely used benchmark datasets and further confirmed our findings with an online A/B test. The results consistently demonstrate the advantages of our approach over other baseline methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TKDE.2025.3572014 },
  booktitle={ IEEE Transactions on Knowledge and Data Engineering },
  chapter={0}
}

@article{rayyan-352343656,
  title={ From Efficiency to Innovation: LLM 5.0 and the Future of Industry  -  2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI) },
  year={2025},
  author={Gantayat, P. K. and Kaur, T. and Majhi, M. and Jena, U. K. and Das, S. and Soni},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894335 },
  abstract={Industry 5.0 is a new way of thinking that is consistent with the ideas of Industry 4.0 but places greater emphasis on sustainability, sustainability, and human-centricity. Unlike Industry 4.0, which emphasizes the efficient integration of advanced technologies such as the Internet, AI, robots, and automation, Industry 5.0 seeks to balance human-machine collaboration to create more inclusive, meaningful, and sustainable systems. In Industry 5.0, LLM has a bigger role than automating similar activities. LLMs make sectors more resilient, adaptable and aligned with social values by fostering innovation, improving human-centred processes and promoting sustainable practices. Industry 5.0 will create a revolutionary force in the global industrial landscape thanks to a combination of emerging technologies that will further enhance the synergies between human creativity and machine intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMSCI62561.2025.10894335 },
  booktitle={ 2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI) },
  chapter={0}
}

@article{rayyan-352343657,
  title={ Political Sentiment Analysis on Twitter Using Deep Learning and LLM Models  -  2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA) },
  year={2025},
  author={K.Mouthami and P.Naren and R.Pranesh},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012499 },
  abstract={In the age of rapid information spreading through social media platforms such as Twitter, Facebook, and Instagram have become serious arenas for information warfare. Coordinated misinformation campaigns and influence operations pose significant threats to societal stability and public opinion. Addressing this issue, our project combines open-source intelligence (OSINT) techniques with advanced AI-driven sentiment analysis and summarization to detect, analyses, and provide actionable insights into politically sensitive and potentially harmful narratives. The proposed system integrates a Bi-LSTM model, which achieves a high accuracy of 98%, for sentiment analysis with an LLM (LLaMA 3) to classify and interpret polarized content. This system processes large volumes of Twitter data, filtered through keywords and contextual signals, to extract and analyses politically charged or conspiratorial content. It enables interactive querying and dynamic analysis to summarize critical topics and provide meaningful insights into the detected narratives. The results demonstrate the system's capability to accurately identify sentiments, summarize critical topics, and facilitate interactive exploration, making it an effective tool for combating misinformation and enhancing situational awareness in the realm of information warfare},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAECA63854.2025.11012499 },
  booktitle={ 2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA) },
  chapter={0}
}

@article{rayyan-352343658,
  title={ Applying Large Language Models and Knowledge Graphs for Intelligent Mobile Network Complaint Processing  -  2025 25th Asia-Pacific Network Operations and Management Symposium (APNOMS) },
  year={2025},
  author={Liu, Y. -H. and Kung, B. -C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181435 },
  abstract={This study examines the application of generative AI in mobile network operations, focusing on customer complaint classification. By leveraging natural language processing, complaints are summarized and categorized to assist service personnel in accelerating root cause analysis. This facilitates targeted interventions to improve service quality and reduce recurring issues. We introduce a novel prompt strategy that integrates Chain-of-Thought (CoT) reasoning with knowledge graphbased retrieval, enabling guided multi-hop reasoning within a large language model (LLM). To evaluate its effectiveness, we compare our approach against baseline prompting methods, including Zero Shot, Few Shot, and knowledge graph-guided strategies. Experimental results show that our method achieves superior classification accuracy. Our findings also indicate that generative AI can significantly reduce the manual workload in complaint handling, cutting analysis and processing time per case by approximately $40 \%$. These findings highlight the potential of combining generative AI with structured domain knowledge to significantly enhance the efficiency and accuracy of mobile network maintenance operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/APNOMS67058.2025.11181435 },
  booktitle={ 2025 25th Asia-Pacific Network Operations and Management Symposium (APNOMS) },
  chapter={0}
}

@article{rayyan-352343659,
  title={ Automated AI Tool for Log File Analysis  -  2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI) },
  year={2025},
  author={Lohar, P. and Baraskar, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10883511 },
  abstract={Log file analysis has a critical role in monitoring and maintaining software systems, yet the manual inspection of logs becomes increasingly impractical with the growing volume of data. This survey paper explores recent advancements in automated log file analysis, with a particular focus on the integration of AI techniques., which includes ML models and NLP. The study identifies key challenges in traditional methods, such as the need for human interpretation., difficulty in detecting new errors, and issues in backtracking within continuous data streams. Moreover, we examine state-of-the- art AI approaches., like LLaMA 2, to streamline log analysis by automating error detection., summarization, and anomaly identification. Research deficiencies are identified, notably the necessity for advanced methodologies to manage variety of log formats, automated model optimization, and ongoing learning processes. This comprehensive review endeavors to provide a thorough examination of the current landscape, encompassing perspectives on potential outcomes and prospective trajectories in the domain of AI -enhanced log file analysis. In addition to providing insights into prospective solutions and future directions in AI-driven log file analysis, this study attempts to give an in-depth analysis of the current situation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMCSI64620.2025.10883511 },
  booktitle={ 2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI) },
  chapter={0}
}

@article{rayyan-352343660,
  title={ Optimizing Transformer Models for Prompt Jailbreak Attack Detection in AI Assistant Systems  -  2024 1st International Conference On Cryptography And Information Security (VCRIS) },
  year={2024},
  author={Tien, L. A. and Huong, P. Van},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10813380 },
  abstract={Integrating AI-powered assistants in different areas has changed how people retrieve information. Users can now get quick responses, use the service whenever needed, and handle inquiries well. However, relying on these systems has increasingly raised worries about their safety and reliability, especially when facing threats like prompt injection or jailbreak attacks. These attacks take advantage of the weaknesses of large language models (LLMs) by changing input prompts to create harmful, biased, or misleading results. This paper examines prompt jailbreak attacks in ChatGPT-based assistant chatbots, especially in education. It examines the weaknesses in these systems and suggests ways to detect these attacks by fine-tuning various Transformer models. The research also includes adding prompt jailbreak attack detection in a virtual assistant application for university use. This aims to ensure teachers and students can interact safely and rely on the system. Through rigorous experimentation and evaluation, we demonstrate the practicality and effectiveness of our detection methods, providing reassurance and confidence in the face of AI security challenges. Our studies emphasize the need for robust AI chatbots and offer practical solutions to preserve the integrity of AI-driven tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VCRIS63677.2024.10813380 },
  booktitle={ 2024 1st International Conference On Cryptography And Information Security (VCRIS) },
  chapter={0}
}

@article{rayyan-352343661,
  title={ Fast and Efficient 2-Bit LLM Inference on GPU: 2/4/16-Bit in a Weight Matrix with Asynchronous Dequantization  -  2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD) },
  year={2024},
  author={Li, J. and Xu, J. and Li, S. and Huang, S. and Liu, J. and Lian, Y. and Dai, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126385 },
  abstract={Large language models (LLMs) have demonstrated impressive abilities in various domains while the inference cost is expensive. Many previous studies exploit quantization methods to reduce LLM inference cost by reducing latency and memory consumption. Applying 2-bit single-precision weight quantization brings $>3 \%$ accuracy loss, so the state-of-the-art methods use mixed-precision methods for LLMs (e.g. Llama2-7b, etc.) to improve the accuracy. However, challenges still exist: (1) Uneven distribution in weight matrix. Weights are quantized by groups, while some groups contain weights with large range. Previous methods apply inter-weight mixed-precision quantization and neglect the range difference inside each weight matrix, resulting in $>2.7 \%$ accuracy loss (e.g. LLM-MQ and APTQ). (2) Large speed degradation by adding sparse outliers. Reserving sparse outliers improves accuracy but slows down the speed affected by the outlier ratio (e.g. 1.5% outliers resulting in $>30 \%$ speed degradation in SpQR). (3) Time-consuming dequantization operations on GPUs. Mainstream methods require a dequantization operation to perform computation on the quantized weights, and the 2-order dequantization operation is applied because scales of groups are also quantized. These dequantization operations lead to $>50 \%$ execution time. To tackle these challenges and enable fast and efficient LLM inference on GPUs, we propose the following techniques in this paper. (1) Intra-weight mixed-precision quantization. We only quantize a small fraction of groups with higher sensitivity (larger Hessian value and range variation) using 4-bit. Meanwhile, we also take the memory alignment into consideration on GPUs. (2) Exclusive 2-bit sparse outlier with minimum speed degradation. We only reserve a small fraction of large weights in 2-bit groups as sparse outliers using 16-bit, which leads to a lower average bit increment and speed degradation. (3) Asynchronous dequantization. We point out that calculating the scales of each group in 2-order dequantization is independent of the loading weights of each group in 1-order dequantization. Thus, we design the asynchronous dequantization on GPUs. We conduct extensive experiments on different model families (e.g. Llama3, etc.) and model sizes. We achieve 2.91-bit for each weight considering all scales/zeros for different models with negligible loss. As a result, with our 2/4/16 mixed-precision quantization for each weight matrix and asynchronous dequantization during inference, our design achieves an end-to-end speedup for Llama2-7b is $1.74 \times$ over the original model, and we reduce both runtime cost and total cost by up to $2.53 \times$ and $2.29 \times$ with less GPU requirements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD) },
  chapter={0}
}

@article{rayyan-352343662,
  title={ Weaponizing Technical Intelligence  -  The Language of Deception: Weaponizing Next Generation AI: Weaponizing Next Generation AI },
  author={Hutchens, J. and McClure, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10666439.pdf&bkn=10666290&pdfType=chapter },
  abstract={Summary <p>The LLMs can effectively operate as a bridge, translating communications between human language and machine interfaces. This capability introduces risks far beyond the social manipulation capabilities. These technical risks fall into one of two categories: unintentional technical oversight and deliberate technical exploitation. LLM‐powered agents' efforts are intelligently informed through a statistically probabilistic distribution of language and discretionary random sampling. One commonly occurring theme in science fiction and a common warning from many futurists is the notion that artificial intelligence systems could eventually develop a sort of survival instinct and might deliberately engage in actions to ensure their own self‐preservation against the will or intentions of their human creators. The chapter aims to establish a common understanding of how malware works within the context of C2 operations. Fallback channels are a common tactic used to ensure persistent C2 communications, even when cyber defenders are attempting to block those communications.</p>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1002/9781394277148.ch8 },
  booktitle={ The Language of Deception: Weaponizing Next Generation AI: Weaponizing Next Generation AI },
  chapter={0}
}

@article{rayyan-352343663,
  title={ Explingo: Explaining AI Predictions using Large Language Models  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Zytek, A. and Pido, S. and Alnegheimish, S. and Berti-Équille, L. and Veeramachaneni, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825114 },
  abstract={Explanations of machine learning (ML) model predictions generated by Explainable AI (XAI) techniques such as SHAP are essential for people using ML outputs for decision-making. We explore the potential of Large Language Models (LLMs) to transform these explanations into human-readable, narrative formats that align with natural communication. We address two key research questions: (1) Can LLMs reliably transform traditional explanations into high-quality narratives? and (2) How can we effectively evaluate the quality of narrative explanations? To answer these questions, we introduce Explingo, which consists of two LLM-based subsystems, a Narrator and Grader. The Narrator takes in ML explanations and transforms them into natural-language descriptions. The Grader scores these narratives on a set of metrics including accuracy, completeness, fluency, and conciseness.Our experiments demonstrate that LLMs can generate high-quality narratives that achieve high scores across all metrics, particularly when guided by a small number of human-labeled and bootstrapped examples. We also identified areas that remain challenging, in particular for effectively scoring narratives in complex domains. The findings from this work have been integrated into an open-source tool that makes narrative explanations available for further applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825114 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343664,
  title={ PrivacyAsst: Safeguarding User Privacy in Tool-Using Large Language Model Agents  -  IEEE Transactions on Dependable and Secure Computing },
  author={Zhang, X. and Xu, H. and Ba, Z. and Wang, Z. and Hong, Y. and Liu, J. and Qin, Z. and Ren, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458329 },
  abstract={Swift advancements in large language model (LLM) technologies lead to widespread research and applications, particularly in integrating LLMs with auxiliary tools, known as tool-using LLM agents. However, amid user interactions, the transmission of private information to both LLMs and tools poses considerable privacy risks to users. In this paper, we delve into current privacy-preserving solutions for LLMs and outline three pivotal challenges for tool-using LLM agents: generalization to both open-source and closed-source LLMs and tools, compliance with privacy requirements, and applicability to unrestricted tasks. To tackle these challenges, we present PrivacyAsst, the first privacy-preserving framework tailored for tool-using LLM agents, encompassing two solutions for different application scenarios. First, we incorporate a homomorphic encryption scheme to ensure computational security guarantees for users as a safeguard against both open-source and closed-source LLMs and tools. Moreover, we propose a shuffling-based solution to broaden the framework's applicability to unrestricted tasks. This solution employs an attribute-based forgery generative model and an attribute shuffling mechanism to craft privacy-preserving requests, effectively concealing individual inputs. In addition, we introduce an innovative privacy concept, $t$t-closeness in image data, for privacy compliance within this solution. Finally, we implement PrivacyAsst, accompanied by two case studies, demonstrating its effectiveness in advancing privacy-preserving artificial intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDSC.2024.3372777 },
  booktitle={ IEEE Transactions on Dependable and Secure Computing },
  chapter={0}
}

@article{rayyan-352343665,
  title={ Leveraging Speech PTM, Text LLM, And Emotional TTS For Speech Emotion Recognition  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Ma, Z. and Wu, W. and Zheng, Z. and Guo, Y. and Chen, Q. and Zhang, S. and Chen, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445906 },
  abstract={In this paper, we explored how to boost speech emotion recognition (SER) with the state-of-the-art speech pre-trained model (PTM), data2vec, text generation technique, GPT-4, and speech synthesis technique, Azure TTS. First, we investigated the representation ability of different speech self-supervised pre-trained models, and we found that data2vec has a good representation ability on the SER task. Second, we employed a powerful large language model (LLM), GPT-4, and emotional text-to-speech (TTS) model, Azure TTS, to generate emotionally congruent text and speech. We carefully designed the text prompt and dataset construction, to obtain the synthetic emotional speech data with high quality. Third, we studied different ways of data augmentation to promote the SER task with synthetic speech, including random mixing, adversarial training, transfer learning, and curriculum learning. Experiments and ablation studies on the IEMOCAP dataset demonstrate the effectiveness of our method, compared with other data augmentation methods, and data augmentation with other synthetic data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10445906 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343666,
  title={ Model Attribution in LLM-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning  -  2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA) },
  year={2024},
  author={Beigi, A. and Tan, Z. and Mudiam, N. and Chen, C. and Shu, K. and Liu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722818 },
  abstract={Model attribution for LLM-generated disinformation poses a significant challenge in understanding its origins and mitigating its spread. This task is especially challenging because modern large language models (LLMs) produce disinformation with human-like quality. Additionally, the diversity in prompting methods used to generate disinformation complicates accurate source attribution. These methods introduce domain-specific features that can mask the fundamental characteristics of the models. In this paper, we introduce the concept of model attribution as a domain generalization problem, where each prompting method represents a unique domain. We argue that an effective attribution model must be invariant to these domain-specific features. It should also be proficient in identifying the originating models across all scenarios, reflecting real-world detection challenges. To address this, we introduce a novel approach based on Supervised Contrastive Learning. This method is designed to enhance the model's robustness to variations in prompts and focuses on distinguishing between different source LLMs. We evaluate our model through rigorous experiments involving three common prompting methods: “open-ended”, “rewriting”, and “paraphrasing”, and three advanced LLMs: “llama 2”, “chatgpt”, and “vicuna”. Our results demonstrate the effectiveness of our approach in model attribution tasks, achieving state-of-the-art performance across diverse and unseen datasets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSAA61799.2024.10722818 },
  booktitle={ 2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA) },
  chapter={0}
}

@article{rayyan-352343667,
  title={ Topic Modeling Enhancement using Summaries Generated by LLM Models  -  2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA) },
  year={2025},
  author={Ghalayini, H. E. and Liu, M. and Patel, H. and Amanzai, R. and Patel, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166276 },
  abstract={Designing effective topic models for long and unstructured documents is essential for detecting significant topics within them. However, traditional topic modeling approaches have certain drawbacks, such as the presence of overlapping topics and difficulties in processing long documents. This research investigates the potential of large language models (LLMs) to enhance the uncovering of underlying topics within these documents. This paper compares two methods of using the BERTopic model. The first method segments the documents into paragraphs and classifies them using BERTopic, and the second method involves an LLM dividing documents into token segments and summarizing them. These summaries are then classified into coherent topics using the BERTopic model. The results show that summarizing the documents and then classifying them using BERTopic yields better performance values compared to segmenting the documents into paragraphs and then classifying them using BERTopic.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACDSA65407.2025.11166276 },
  booktitle={ 2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA) },
  chapter={0}
}

@article{rayyan-352343668,
  title={ Benchmarking OpenAI’s APIs and other Large Language Models for Repeatable and Efficient Question Answering Across Multiple Documents  -  2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS) },
  year={2024},
  author={Filipovska, E. and Mladenovska, A. and Bajrami, M. and Dobreva, J. and Hillman, V. and Lameski, P. and Zdravevski, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736054 },
  abstract={The rapid growth of document volumes and complexity in various domains necessitates advanced automated methods to enhance the efficiency and accuracy of information extraction and analysis. This paper aims to evaluate the efficiency and repeatability of OpenAI’s APIs and other Large Language Models (LLMs) in automating question-answering tasks across multiple documents, specifically focusing on analyzing Data Privacy Policy (DPP) documents of selected EdTech providers. We test how well these models perform on large-scale text processing tasks using the OpenAI’s LLM models (GPT 3.5 Turbo, GPT 4, GPT 4o) and APIs in several frameworks: direct API calls (i.e., one-shot learning), LangChain, and Retrieval Augmented Generation (RAG) systems. We also evaluate a local deployment of quantized versions (with FAISS) of LLM models (Llama-2-13B-chat-GPTQ). Through systematic evaluation against predefined use cases and a range of metrics, including response format, execution time, and cost, our study aims to provide insights into the optimal practices for document analysis. Our findings demonstrate that using OpenAI’s LLMs via API calls is a workable workaround for accelerating document analysis when using a local GPU-powered infrastructure is not a viable solution, particularly for long texts. On the other hand, the local deployment is quite valuable for maintaining the data within the private infrastructure. Our findings show that the quantized models retain substantial relevance even with fewer parameters than ChatGPT and do not impose processing restrictions on the number of tokens. This study offers insights on maximizing the use of LLMs for better efficiency and data governance in addition to confirming their usefulness in improving document analysis procedures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.15439/2024F3979 },
  booktitle={ 2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS) },
  chapter={0}
}

@article{rayyan-352343669,
  title={ Generative AI-Based Currency Detector for Visually Impaired  -  2024 International Conference on Signal Processing and Advance Research in Computing (SPARC) },
  year={2024},
  author={Rani, E. Geetha and Sneha, B. Guru and Vardhan, N. Harsha and Kumar, B. Sai and Anusha, D. and Vadlamudi, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10828978 },
  abstract={A visually challenged person may find it challenging to distinguish between various denominations of currency. For those who are blind, this process is still challenging even though most of the Indian currency is written in unique characters. Portable solutions for isolation have emerged because of a shortage of available tools. This study details the creation and evaluation of a new assistive technology that uses an easy-to-use currency detection system to improve the financial independence of people with visual impairments. The apparatus employs sophisticated image processing techniques and deep learning algorithms to precisely recognize different banknote denominations. A compact, user-friendly interface that provides audio feedback to convey the denomination to the user ensures ease of use and privacy. A portable computer device connected to a high-resolution camera forms the basis of the system architecture. On this device, a convolutional neural network (CNN) model is trained using many datasets of cash photos in various orientations and light conditions. A high recognition accuracy rate is attained by the model, which is essential for real-world uses. Voice commands and tactile buttons work together to make it easy for users to engage with the gadget. Many daily living tasks are made more difficult by the prevalence of visual impairment, particularly those that require the recognition of currency, leaving the affected person dependent on others to complete financial transactions. Its ability to quickly and accurately identify different currencies and output format in audio feedback has proven to be highly beneficial for those with visual impairments who travel or live in multicultural environments. Moreover, positive feedback from user experience evaluations indicates that the system's practical impact extends beyond its technical achievements, with considerable improvements in confidence during financial transactions and ease of use. To ease that dependency, a unique Currency Detector System (CDS) made especially for visually impaired individuals has been created.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPARC61891.2024.10828978 },
  booktitle={ 2024 International Conference on Signal Processing and Advance Research in Computing (SPARC) },
  chapter={0}
}

@article{rayyan-352343670,
  title={ AI-Powered 3D Printing Error Detection and Optimization System  -  2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE) },
  year={2025},
  author={A, A. and T, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053088 },
  abstract={Recent advancements and rising popularity of 3d printing technology have increased innovation and advancements in manufacturing vertical. But this has also brought in challenges in waste reduction particularly for materials like PLA, ABS, and PETG. Waste reduction in 3D printing is a crucial challenge due to the huge dependency on thermoplastics like PLA, ABS, and PETG. Each of these materials has distinct characteristics that influence their recyclability, disposal methods, and potential environmental impact. In another parallel, Generative AI is gaining momentum due to its ability in generate complex data based on the provided prompt and model training. This project aims to utilize the benefits and advantages of Generative AI in addressing the challenges of increasing waste in Additive manufacturing processes. Manual inspection of printing defects is inefficient and prone to human errors. AI can automate and improve this process. This paper presents an AI-powered 3D printing error detection and optimization system that leverages computer vision, deep learning, and generative AI to enhance print quality and reduce material waste. The system employs a convolutional neural network (CNN) to classify common 3D printing defects from real-time images and logistic regression model to identify the material type used for 3d printing. This is followed by a Generative AI Model that provides useful insights for the users on the recommendations to use manufacturing processes in more reliable way with a motto to reduce waste reduction during 3D printing processes. For generative AI model, Prompts are provided in such a way that it contains the printing error type and classified material type. Prompt optimization techniques like gradient-descent algorithm and genetic algorithm are considered and both are being used to create different prompt variations and most reliable prompt is sent to Generative AI model. This is to refine the defect descriptions for an LLM-powered recommendation system (Mistral 7B).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCRTEE64519.2025.11053088 },
  booktitle={ 2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE) },
  chapter={0}
}

@article{rayyan-352343671,
  title={ Evaluating the Advantage of an AI-Native IDE Cursor on Programmer Performance  -  2025 IEEE Integrated STEM Education Conference (ISEC) },
  year={2025},
  author={Kumar, Y. and Akinwunmi, I. and Kruger, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147402 },
  abstract={The emergence of Artificial Intelligence (AI)-powered coding tools is fundamentally transforming both the software development landscape and Computer Science (CS) education by making programming accessible for all. This can be a double-edged sword. Students can use AI to avoid work and, therefore, learn less. However, leveraging AI to allow novice programmers to achieve far more and with less frustration is also possible. Large Language Models (LLMs) help accelerate progress. However, there is still a lot of effort in copying/pasting back and forth between the LLM and the Integrated Development Environment (IDE). We demonstrate in this study that AI Native IDE can dramatically accelerate the completion of tasks provided the AI has correct examples of context. AIs are still immature and unable to apply all knowledge correctly, but Cursor enables the programmer to rapidly pass error messages to the AI, allowing it to correct mistakes. The research is guided by two primary questions: (1) How effectively can Cursor assist a novice in overcoming the challenges of constructing a complex app from scratch? and (2) How does Cursor’s performance compare with other AI pair programming approaches, such as coding with ChatGPT? We demonstrate that an AI-Native IDE can accelerate performance by a large factor, assisting novice programmers and experts, getting students past the initial frustration of cognitive overload, and allowing them to succeed. This should help with retention.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISEC64801.2025.11147402 },
  booktitle={ 2025 IEEE Integrated STEM Education Conference (ISEC) },
  chapter={0}
}

@article{rayyan-352343672,
  title={ Aligning Data Debt with AI-Integrated Software Project Lifecycle Processes: A Standard-Based Mapping Approach  -  2025 IEEE/ACM International Conference on Technical Debt (TechDebt) },
  year={2025},
  author={Akgül, N. Y. and Temizel, T. T. and Top, Ö. Ö. and Akman, P. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024537 },
  abstract={Artificial Intelligence (AI) technologies have become increasingly central to software development, enhancing efficiency with tools such as intelligent code assistants and driving innovations in products like chatbots, recommendation engines, and predictive analytics. Despite these advancements, the inherent complexity of AI-integrated software projects often leads to the accumulation of technical debt (TD), which can compromise the reliability and sustainability of systems in the long term. Managing TD effectively in these projects can be achieved by adapting international standards. Although these standards are not designed for TD management, they can be systematically applied to detect and address TD by aligning with AI system lifecycle processes. The aim of this study is to demonstrate how AI-related TD correlates with various AI lifecycle processes, thereby enabling systematic detection and management of TD in AI-integrated software projects. To achieve this, we studied 73 unique cases of TD, each reflecting either an instance or a root cause of data-related TD. These cases were subsequently mapped to the processes and activities outlined in the ISO/IEC 5338 AI Systems Lifecycle Processes standard. Subsequently, the accuracy of these mappings was validated bidirectionally by a large language model and two domain experts. Our findings revealed that data-related TD categories are associated with a diverse range of processes such as design definition, quality management and human resource management and tend to accumulate more significantly in certain areas within the AI lifecycle. This study not only serves as a proof of concept for developing a management approach for AI-related TD, but also enhances the body of knowledge on managing TD in AI projects by detailing how TD interacts with and impacts various AI lifecycle processes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TechDebt66644.2025.00008 },
  booktitle={ 2025 IEEE/ACM International Conference on Technical Debt (TechDebt) },
  chapter={0}
}

@article{rayyan-352343673,
  title={ QMLFQ: A Quantization-based Queue Scheduling Framework for Efficient LLM Serving  -  2024 IEEE Smart World Congress (SWC) },
  year={2024},
  author={Wu, J. and Dai, H. and Wu, J. and Jin, W. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924817 },
  abstract={Fueled by advancements in Large Language Models (LLMs), applications like ChatGPT have ushered in a transformative era for AI-powered interactions. However, the computational demands of LLMs, characterized by their massive parameter size and intricate computations, pose a significant challenge to its model serving. Under high concurrency or resource-constrained scenarios, LLM service systems can experience substantial latency and potential crashes, jeopardizing user experience and system stability. To address this challenge, this paper presents a novel LLM serving framework that leverages dynamic queue scheduling and quantization switching to alleviate computational bottlenecks and reduce response latency. Specifically, we propose an enhanced scheduling algorithm based on the Multi-level Feedback Queue (MLFQ) that dynamically switches between various quantized-level models and prioritizes requests, thereby improving LLM inference parallelism and reducing job completion time (JCT) as well. Through extensive experiments conducted on open-source datasets, we demonstrate that our proposed approach effectively reduces JCTs compared to other leading baselines. This improvement in JCT ultimately leads to enhanced quality of service (QoS) for LLM-based applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SWC62898.2024.00208 },
  booktitle={ 2024 IEEE Smart World Congress (SWC) },
  chapter={0}
}

@article{rayyan-352343674,
  title={ Enriching Python Programming Education With Generative AI: Leveraging Large Language Models for Personalized Support and Interactive Learning  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Vemula, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893561 },
  abstract={This innovative practice full paper describes the exploration of the transformative potential of Generative Artificial Intelligence (AI) and Large Language Models (LLMs) in Python programming education. A Python Educational Support Assistant (PESA-8B-FT) was introduced, an LLM-powered virtual assistant designed to provide personalized instruction, foster interactive learning, and deliver immediate feedback on programming tasks. The growing demand for skilled Python programmers necessitates flexible and effective educational frameworks. PESA-8B-FT addresses this need by offering 24/7 availability, accommodating diverse learning styles and schedules, and providing real-time support regardless of geographical constraints. The study demonstrates PESA-8B-FT's significant impact on Python programming education. The model achieved a perplexity score of 18.82, outperforming competing models, and received positive feedback from 90% of participants. These results highlight PESA-8B-FT's potential to enhance learning outcomes, complement traditional teaching methods, and alleviate the instructional burden on educators. By leveraging advanced LLM capabilities, this research contributes to the development of more accessible, personalized, and effective programming education methodologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893561 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343675,
  title={ Accelerating Learning with AI: Improving Students’ Capability to Receive and Build Automated Feedback for Programming Courses  -  2024 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC) },
  year={2024},
  author={Huo, H. and Ding, X. and Guo, Z. and Shen, S. and Ye, D. and Pham, O. and Milne, D. and Mathieson, L. and Gardner, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10854928 },
  abstract={Generative AI (GenAI) based tutoring assistance has shown great potential in delivering adaptive and personalized education. The programming subjects, boasting a large on-campus student body and an active online presence via discussion boards, are well-suited for evaluating the accessibility, engagement, and satisfaction of GenAI-based tutoring assistance. In this paper, we explore the pros and cons of a GenAI-based feedback system, specifically fine-tuning a Large Language Model (LLM), as a potential tool for providing personalized programming subject matter expertise and guiding students towards solutions with interpretability and visualization. To better address the technical issues students encounter in programming and ensure our model provides accurate and professional debugging solutions, we further develop a visualized interaction tool for code interpretation and prompts optimization. Additionally, this paper compares the effectiveness of online discussion boards and the developed LLM in assisting students’ questions and personalized support.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WEEF-GEDC63419.2024.10854928 },
  booktitle={ 2024 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC) },
  chapter={0}
}

@article{rayyan-352343676,
  title={ Green-Code: Learning to Optimize Energy Efficiency in Llm-Based Code Generation  -  2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing (CCGrid) },
  year={2025},
  author={Ilager, S. and Briem, L. F. and Brandic, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044793 },
  abstract={Large Language Models (LLMs) are becoming integral to daily life, showcasing their vast potential across various Natural Language Processing (NLP) tasks. Beyond NLP, LLMs are increasingly used in software development tasks, such as code completion, modification, bug fixing, and code translation. Software engineers widely use tools like GitHub Copilot and Amazon Q, streamlining workflows and automating tasks with high accuracy. While the resource and energy intensity of LLM training is often highlighted, inference can be even more resourceintensive over time, as it's a continuous process with a high number of invocations. Therefore, developing resource-efficient alternatives for LLM inference is crucial for sustainability. This work proposes GREEN-CODE, a framework for energy-aware code generation in LLMs. GREEN-CODE performs dynamic early exit during LLM inference. We train a Reinforcement Learning (RL) agent that learns to balance the trade-offs between accuracy, latency, and energy consumption. Our approach is evaluated on two open-source LLMs, Llama 3.2 3B and OPT 2.7 B, using the JavaCorpus and PY150 datasets. Results show that our method reduces the energy consumption between 2350 % on average for code generation tasks without significantly affecting accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCGRID64434.2025.00068 },
  booktitle={ 2025 IEEE 25th International Symposium on Cluster, Cloud and Internet Computing (CCGrid) },
  chapter={0}
}

@article{rayyan-352343677,
  title={ AutoHealth: Advanced LLM-Empowered Wearable Personalized Medical Butler for Parkinson’s Disease Management  -  2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2024},
  author={Cardenas, L. and Parajes, K. and Zhu, M. and Zhai, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10427622 },
  abstract={Parkinson’s disease (PD), a leading neurodegenerative disorder, profoundly impacts millions globally. It causes a variety of physical challenges, cognitive impairments, and significant psychological distress to both patients and their families. Effective management of PD, particularly as it progresses, necessitates vigilant monitoring to mitigate symptoms and improve life quality for both patients and their families. In this vein, we present AutoHealth, an innovative Internet of Medical Things (IoMT) system, leveraging the advanced capabilities of smartwatches and their integrated biosensors. AutoHealth is engineered to continuously monitor the movement patterns of PD patients, utilizing state-of-the-art vector-based learning AI models. This approach allows for accurate and personalized early detection, continuous tracking, and rehabilitation management of PD. To enhance user engagement, AutoHealth incorporates an AI chatbot to interactively communicate with patients, providing instant responses to their text and speech inquiries, and offering tailored guidance. Overall, Autohealth empowers patients with initiative-taking health management tools, transforming the way to monitor and manage PD with relatively low medical costs.Clinical Relevance— Our solution pioneers an automatic, integrated system delivering real-time PD diagnosis, perpetual monitoring, and tailored recommendations, a stride beyond the conventional dependence on multiple devices and manual interventions. The model is built to construct autonomous agents that learn from a user’s unique healthcare data and history, tailoring a plan to fit their individual needs. Our system breaks barriers by being a cross-language, cross-platform solution, ensuring accessibility regardless of regional and hardware constraints. Our mission is to deliver affordable, at-home medical assistance through a wearable device, bringing advanced healthcare and diagnostics right to your wrist.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC60891.2024.10427622 },
  booktitle={ 2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343678,
  title={ Nutriguard: LLM-Driven Nutritional Assessment for Chronic Disease Prevention  -  2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN) },
  year={2025},
  author={Hakim, M. A. and Ifty, R. A. and Delowar, K. E. and Chowdhury, S. H. and Rashid, I. and Shakib, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171750 },
  abstract={Chronic diseases linked to poor dietary choices necessitate innovative tools for personalized nutrition management. This paper presents NutriGuard, a multimodal AI framework that integrates optical character recognition (OCR), deep learning, and fine-tuned large language models (LLMs) to deliver realtime, context-aware dietary recommendations tailored to users' health profiles. The system begins by extracting nutritional information from food labels via a hybrid OCR pipeline, combining PaddleOCR for English and Surya for Bengali text. For lowquality images, a convolutional neural network (CNN) trained on a dataset of food labels detects product categories, crossreferencing a nutritional database to fill information gaps. A Llama-3.2 model, fine-tuned on clinical guidelines and medical literature, analyzes extracted data against user-specific health conditions (e.g., diabetes, hypertension) to generate risk assessments, substitution suggestions, and personalized meal plans. This work advances AI-driven preventive healthcare by establishing a multilingual, clinically validated framework for dietary risk mitigation. The system's modular design permits rapid adaptation to regional food cultures and emerging nutritional research, addressing critical gaps in scalable personalized nutrition management. Future integration with continuous glucose monitors and gut microbiome data promises to enable dynamic, biomarker-informed dietary optimization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/QPAIN66474.2025.11171750 },
  booktitle={ 2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN) },
  chapter={0}
}

@article{rayyan-352343679,
  title={ GenAI-Based News Article Analysis Chatbot  -  2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE) },
  year={2024},
  author={Dubey, A. and Sharma, R. and Diwakar, M. and Singh, P. and Mishra, A. K. and Lamba, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911100 },
  abstract={In today’s era of digital landscape, data analysis plays a vital role in informed decision making and strategy formulation. Research analysts, tasked with extracting insights from vast datasets, face challenges of information overload and time-consuming manual analysis. Conventional analysis systems limited in handling large data sets,, prone to human error and analysis is based on individuals analysis expertise. Our proposed paper introduces a revolutionary research analyst tool that integrates Generative AI and a Large Language Model(LLM) within a chatbot framework. Utilizing Generative AI enhances the chatbot’s communication capabilities, while LLM serves as the backbone for processing diverse linguistic structures in news articles. Our proposed architecture is detailed, outlining the methodology and efficiency of the implemented analyst tool. Utilizing language models for question-answering and a FAISS vector index for data retrieval, the tool enables seamless access to relevant information, empowering researchers, and analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AECE62803.2024.10911100 },
  booktitle={ 2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE) },
  chapter={0}
}

@article{rayyan-352343680,
  title={ Python Natural Language Processing Cookbook: Over 60 recipes for building powerful NLP solutions using Python and LLM libraries  -  Python Natural Language Processing Cookbook: Over 60 recipes for building powerful NLP solutions using Python and LLM libraries },
  author={Antić, Z. and Chakravarty, S.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10769274.pdf&bkn=10769274&pdfType=book },
  abstract={Updated to include three new chapters on transformers, natural language understanding (NLU) with explainable AI, and dabbling with popular LLMs from Hugging Face and OpenAIKey FeaturesLeverage ready-to-use recipes with the latest LLMs, including Mistral, Llama, and OpenAI modelsUse LLM-powered agents for custom tasks and real-world interactionsGain practical, in-depth knowledge of transformers and their role in implementing various NLP tasks with open-source and advanced LLMsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionHarness the power of Natural Language Processing to overcome real-world text analysis challenges with this recipe-based roadmap written by two seasoned NLP experts with vast experience transforming various industries with their NLP prowess. You’ll be able to make the most of the latest NLP advancements, including large language models (LLMs), and leverage their capabilities through Hugging Face transformers. Through a series of hands-on recipes, you’ll master essential techniques such as extracting entities and visualizing text data. The authors will expertly guide you through building pipelines for sentiment analysis, topic modeling, and question-answering using popular libraries like spaCy, Gensim, and NLTK. You’ll also learn to implement RAG pipelines to draw out precise answers from a text corpus using LLMs. This second edition expands your skillset with new chapters on cutting-edge LLMs like GPT-4, Natural Language Understanding (NLU), and Explainable AI (XAI)—fostering trust and in your NLP models. By the end of this book, you'll be equipped with the skills to apply advanced text processing techniques, use pre-trained transformer models, build custom NLP pipelines to extract valuable insights from text data to drive informed decision-making.What you will learnUnderstand fundamental NLP concepts along with their applications using examples in PythonClassify text quickly and accurately with rule-based and supervised methodsTrain NER models and perform sentiment analysis to identify entities and emotions in textExplore topic modeling and text visualization to reveal themes and relationships within textLeverage Hugging Face and OpenAI LLMs to perform advanced NLP tasksUse question-answering techniques to handle both open and closed domainsApply XAI techniques to better understand your model predictionsWho this book is forThis updated edition of the Python Natural Language Processing Cookbook is for data scientists, machine learning engineers, and developers with a background in Python. Whether you’re looking to learn NLP techniques, extract valuable insights from textual data, or create foundational applications, this book will equip you with basic to intermediate skills. No prior NLP knowledge is necessary to get started. All you need is familiarity with basic programming principles. For seasoned developers, the updated sections offer the latest on transformers, explainable AI, and Generative AI with LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Python Natural Language Processing Cookbook: Over 60 recipes for building powerful NLP solutions using Python and LLM libraries },
  chapter={0}
}

@article{rayyan-352343681,
  title={ Multi-Tier Multi-Node Scheduling of LLM for Collaborative AI Computing  -  IEEE INFOCOM 2025 - IEEE Conference on Computer Communications },
  year={2025},
  author={Ma, M. and Gong, C. and Zeng, L. and Yang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044698 },
  abstract={Large Language Models (LLMs) have attracted growing attention owing to their advanced capability in under-standing and reacting to instructions. While they are experiencing wide deployment in the multi-tier cloud-edge architecture, their performance is severely constrained by the network capacity, and how to schedule efficient data flow for performance maximum poses significant challenges. Towards that, this paper establishes a comprehensive system model and, for the first time, formulates the efficient LLM scheduling problem in the multi-tier cloud-edge network. Given its non-convexness, we propose the Multi-tier Multi-node Scheduling of LLM (MMSL) algorithm for Collabo-rative AI Computing, a two-stage scheduling framework designed to optimize LLM inference in multi-tier cloud-edge networks. Initially, the inter-tier LLM automated decoupling and partitioning phase employs integer linear programming to allocate model size and computing demands efficiently. Subsequently, the intra-tier LLM task scheduling algorithm, leveraging GNN, identifies optimal scheduling nodes within each tier by evaluating resource utilization and network conditions. Extensive evaluations show that our solution significantly outperforms traditional scheduling methods by 9.1 %- 26.3% throughput improvement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOM55648.2025.11044698 },
  booktitle={ IEEE INFOCOM 2025 - IEEE Conference on Computer Communications },
  chapter={0}
}

@article{rayyan-352343682,
  title={ The Role of AI Counselling in Journaling for Mental Health Improvement  -  2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT) },
  year={2024},
  author={Jain, A. and Sandhu, R. and Singh, G. and Rakhra, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10739128 },
  abstract={This research paper investigates the effectiveness of integrating an AI counselling system, utilizing a Large Language Model (LLM), within a journaling application aimed at enhancing mental well-being. Employing a descriptive quantitative methodology, the study examines the subjective experiences of individuals engaging with the application. Through a purposive sampling approach, data was collected from 50 participants, focusing on their perceptions of benefits and challenges associated with the AI counselling system. The analysis reveals significant positive correlations between users' experiences and the app's ability to enhance counselling skills, behaviors, and learning related to mental health topics. Findings indicate that the AI-driven counselling system facilitates deep introspection, empathy, and emotional resilience among users, providing structured support tailored to individual needs. The research underscores the transformative potential of integrating AI counselling within digital platforms to foster mental well-being and recommends further refinement to enhance user experiences.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEECT61758.2024.10739128 },
  booktitle={ 2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT) },
  chapter={0}
}

@article{rayyan-352343683,
  title={ MetaPipe: Incremental Deployment of Containerized AI Microservices for Edge Clouds  -  2025 IEEE/ACM 33rd International Symposium on Quality of Service (IWQoS) },
  year={2025},
  author={Li, Q. and Ren, X. and Wang, Z. and Yao, H. and He, Y. and Liu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11143291 },
  abstract={Large language models (LLMs) have emerged as a transformative advancement in artificial intelligence (AI). To fully leverage their potential, Docker containers, serving as a lightweight, portable, and isolated framework, facilitate the seamless deployment of LLM-based applications. However, the deployment of containerized AI microservices faces challenges such as heavy network loads, delayed image loading, and redundancy. In this paper, we introduce MetaPipe, an innovative incremental deployment approach for containerized AI microservices in edge cloud environments. MetaPipe aims to optimize startup times through a dynamic workflow that incorporates proactive layer pre-fetching and reinforcement layer re-scheduling. The proactive pre-fetching reduces service deployment time through layer caching prediction and pre-scheduling before requests arrive, while the reinforcement re-scheduling addresses inaccuracies by dynamically adjusting layer scheduling strategies after requests arrive. Extensive experiments on realworld datasets show that MetaPipe significantly outperforms traditional methods, achieving 83.58% reduction in initialization startup time and 85.58% reduction in cold startup time. These results highlight its effectiveness in enhancing the performance of AI microservices deployment within edge cloud environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IWQoS65803.2025.11143291 },
  booktitle={ 2025 IEEE/ACM 33rd International Symposium on Quality of Service (IWQoS) },
  chapter={0}
}

@article{rayyan-352343684,
  title={ SecurAI: Leveraging Edge Computing and Large Language Models for Intelligent Surveillance  -  2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG) },
  year={2024},
  author={Purohit, R. and Bang, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911446 },
  abstract={The SecurAI LLM-based surveillance system leverages advanced AI models to enhance real-time threat detection and decision-making in complex environments. It achieves high accuracy, reduces false positives, and integrates edge computing for low-latency processing. Claude 3 excels in handling large data contexts, providing superior performance in long-term surveillance. The system also ensures ethical compliance with privacy regulations, making it ideal for public and sensitive spaces. Future enhancements focus on improving multimodal capabilities, contextual memory, and expanding edge device adaptability for more efficient and responsible surveillance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTBIG64922.2024.10911446 },
  booktitle={ 2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG) },
  chapter={0}
}

@article{rayyan-352343685,
  title={ Automated Disease Detection and Medication Tracing System Using BioGPT  -  2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE) },
  year={2025},
  author={Kalaiarasi, P. and Prabhu, M. C. and Nani, K. and Reddy, K. A. K. and Krishna, E. T. and Ashish, M. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052902 },
  abstract={Healthcare is one of the major sectors and plays a major role in everyone's life. Artificial Intelligence has made significant advancements with the creation of automated disease detection and Medication tracking systems, ensuring more accurate system diagnosis and efficient treatment. In this study, we found that by transforming the BioGPT, a specialized large language model (LLM) that optimized biomedical text, for disease detection and medication monitoring by using deep learning techniques, the system was able to collect real-time data on patient symptoms, medical history, and diagnostic reports to deliver accurate predictions about their disease. It also makes sure to trace the medical medicines accurately. By confirming the prescriptions for drug interactions and following the treatment plans. This integration helps to boost diagnostic accuracy by minimizing human errors and enabling early disease detection. It can facilitate proper diagnosis of diseases, auto-generation of perception, and monitoring of the patient's health on a real-time basis. It can detect potential diseases with a high degree of accuracy based on the text input by the patients. It enables patients to schedule appointments with doctors based on diagnosis so that they can get timely consultations. Doctors can assess the AI diagnosis and write prescriptions based on the patient's statement. A doctor's prescription is stored in a digital format; this way, doctors can constantly keep track of patients. By using NLP and combining it with Deep Learning and real-time access to medical data, the system achieves a high record of accurate disease diagnosis and prescription confirmation, enforcing better healthcare practices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCRTEE64519.2025.11052902 },
  booktitle={ 2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE) },
  chapter={0}
}

@article{rayyan-352343686,
  title={ LLM-Based Operating Systems for Automated Vehicles: A New Perspective  -  IEEE Transactions on Intelligent Vehicles },
  author={Ge, J. and Chang, C. and Zhang, J. and Li, L. and Na, X. and Lin, Y. and Li, L. and Wang, F. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10529622 },
  abstract={The deployment of large language models (LLMs) brings challenges to intelligent systems because its capability of integrating large-scale training data facilitates contextual reasoning. This paper envisions a revolution of the LLM based (Artificial) Intelligent Operating Systems (IOS, or AIOS) to support the core of automated vehicles. We explain the structure of this LLM-OS and discuss the resulting benefits and implementation difficulties.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIV.2024.3399813 },
  booktitle={ IEEE Transactions on Intelligent Vehicles },
  chapter={0}
}

@article{rayyan-352343687,
  title={ A Generative Artificial Intelligence Framework for Earth Observation Analysis  -  IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium },
  year={2024},
  author={Wagner, O. and Gordon, J. and Mousa, A. and Terry, B. and Baptist, J. and Yetkin, O. and Borges, D. and Gowda, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10641192 },
  abstract={Generative artificial intelligence (AI), specifically Large Language Models (LLMS) such as generative pretrained transformers (GPTS) have emerged as a transformational technology in modern research and applications. This technology will revolutionize a wide variety of fields, including remote sensing and Earth observation. We explore the use of LLMS to improve and automate EO analysis, making these results more accessible to a broad range of decision makers. We develop a framework using this technology to support the Committee on Earth Observation Satellites (CEOS) and NASA’s Open Science initiative. This framework leverages current work on Earth observation tools, including the Open Data Cube (ODC) [1] and the OEA Algorithm Hub (AlgoHub). [2]In our work, we investigate the ability of large language models to orchestrate and reason with tools created to access geospatial data using the Open Data Cube and the OEA Algorithm Hub [2]. In this paper we propose a natural language analytical framework for orchestrating Earth observation (EO) analysis. The framework uses large language models to interpret an analysis request, devise a solution based on ODC and AlgoHub tools, and execute the analysis. Our experimental investigations demonstrate that an LLM, with its embedded contextual knowledge, can effectively discern and sequence the necessary processing steps required to fulfill Earth observation analysis requests. This research demonstrates the potential of Generative AI (LLMs) in streamlining and enhancing EO analyses and empowering the observation community.In summary, Generative AI (LLMs) can enhance the capabilities of Earth observation analysis by automating tasks, providing natural language interfaces, and facilitating the extraction of valuable insights from the vast and complex datasets generated by remote sensing and EO technologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IGARSS53475.2024.10641192 },
  booktitle={ IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium },
  chapter={0}
}

@article{rayyan-352343688,
  title={ When AI Turns Malicious: Unethical Use of LLMs for Hardware Design  -  2025 23rd IEEE Interregional NEWCAS Conference (NEWCAS) },
  year={2025},
  author={Baungarten-Leon, E. I. and Ortega-Cisneros, S. and Mascorro-Guardado, E. and Lopez, J. C. G. and Dominguez, J. R. and Panduro, J. J. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11107096 },
  abstract={This work examines the use of Artificial Intelligence (AI), particularly Large Language Models (LLMs), to insert a backdoor into AES/DES encryption at the Register Transfer Level (RTL) in System on Chip (SoC) manufacturing. By modifying RTL code, LLMs can create backdoor that compromise encryption, storing sensitive keys and enabling data leaks. Experimental results demonstrate the successful modification, integration, and fabrication of these altered designs, underscoring the security risks posed by AI in hardware design. The results show the need for protective measures to prevent malicious AI applications within the hardware supply chain. While the results obtained show that current LLMs can only make simple design changes, it could be a problem when these technologies can design and modify more complex systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NewCAS64648.2025.11107096 },
  booktitle={ 2025 23rd IEEE Interregional NEWCAS Conference (NEWCAS) },
  chapter={0}
}

@article{rayyan-352343689,
  title={ Multimodal Recommendation Systems in the LLM Era: A Survey of Feature Representation and Fusion Methods  -  2024 4th International Conference on Advanced Enterprise Information System (AEIS) },
  year={2024},
  author={S, V. M and K, G. V. and Das, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011541 },
  abstract={The surge in multimodal data such as text, images, and sometimes audio, has led to a growing interest in recommendation systems capable of integrating these diverse modalities for enhanced personalization. Multimodal recommendation systems leverage such rich data to better understand user preferences and provide highly tailored recommendations. Traditional approaches employ a variety of techniques, including feature alignment, modality-specific graphs, attention mechanisms, and advanced fusion strategies, to effectively combine multimodal information. Recently, the integration of large language models (LLMs) into multimodal recommenders has transformed the field, enabling advanced preference summarization, context-aware fusion and even personalized content generation. This survey provides a comprehensive overview of both the traditional and LLM-based multimodal recommendation systems, highlighting their architectures, key methodologies, datasets, evaluation benchmarks, and real-world applications. Furthermore, we explore the challenges and opportunities posed by the fusion and processing of multi-modal data by these recommender systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AEIS65978.2024.00021 },
  booktitle={ 2024 4th International Conference on Advanced Enterprise Information System (AEIS) },
  chapter={0}
}

@article{rayyan-352343690,
  title={ LLM-powered Gaussian Splatting in VR interactions  -  2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) },
  year={2025},
  author={Mao, H. and Xu, Z. and Wei, S. and Quan, Y. and Deng, N. and Yang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972422 },
  abstract={Recent advances in radiance field rendering, particularly 3D Gaussian Splatting (3DGS), have demonstrated significant potential for VR content creation, offering both high-quality rendering and an efficient production pipeline. However, current physics-based interaction systems for 3DGS are limited to either simplistic, unrealistic simulations or require substantial user input for complex scenes, largely due to the lack of scene comprehension. In this demonstration, we present a highly realistic interactive VR system powered by large language models (LLMs). After object-aware GS reconstruction, we prompt GPT-4o to analyze the physical properties of objects in the scene, which then guide physical simulations that adhere to real-world phenomena. Additionally, We design a GPT-assisted GS inpainting module to complete the areas occluded by manipulated objects. To facilitate rich interaction, we introduce a computationally efficient physical simulation framework through a PBD-based unified interpolation method, which supports various forms of physical interactions. In our research demonstrations, we reconstruct varieties of scenes enhanced by LLM’s understanding, showcasing how our VR system can support complex, realistic interactions without additional manual design or annotation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VRW66409.2025.00472 },
  booktitle={ 2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) },
  chapter={0}
}

@article{rayyan-352343691,
  title={ IEEE AI Standards for Agentic Systems  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Tong, R. J. and Li, H. and Raghavan, S. and Wen, Q. and Gray, S. and Paul, A. and Liang, J. and Zalewski, J. and Yang, Y. and Tambouratzis, G. and Ang, B. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050630 },
  abstract={This paper synthesizes key insights from emerging IEEE Artificial Intelligence Standards Committee (AISC) standards - P3394 and P3428 - that are shaping agent-based software engineering for intelligent systems. IEEE P3394 (LLM Agent Interface) defines a Universal Message Format (UMF) and communication protocols for Large Language Model (LLM) agents, establishing standard message envelopes, semantic payload, agent roles, session management, and interaction patterns. IEEE P3428 (LLM Agents for Education) specifies a modular agent architecture and lifecycle tailored to adaptive learning environments. It standardizes agent components, lifecycle states, and orchestration mechanisms to enable plug-and-play integration of multiple AI-driven agents in an adaptive instructional system. Together, P3394 and P3428 promote modular, interoperable, and scalable design of intelligent agent ecosystems. We highlight how P3394's universal message protocols and P3428's standardized agent lifecycle complement each other in supporting LLM-based agents and agent-based intelligent systems. We also briefly discuss IEEE P3427, an initiative on semantic information agents, which underscores the broader context of evaluation and continuous improvement of agent-based systems. By unifying communication interfaces and architectural frameworks, these standards lay a foundation for next-generation agentic systems that can seamlessly interoperate across platforms and domains.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00269 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343692,
  title={ Elevating Perception: Unified Recognition Framework and Vision-Language Pre-Training Using Three-Dimensional Image Reconstruction  -  2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) },
  year={2023},
  author={Wang, Z. and Joshi, A. and Zhang, G. and Ren, W. and Jia, F. and Sun, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10505427 },
  abstract={This research project explores a paradigm shift in perceptual enhancement by integrating a Unified Recognition Framework and Vision-Language Pre-Training in three-dimensional image reconstruction. Through the synergy of advanced algorithms from computer vision & language processing, the project tries to enhance the precision and depth of perception in reconstructed images. This innovative approach holds the potential to revolutionize fields such as medical imaging, virtual reality, and computer-aided design, providing a comprehensive perspective on the intersection of multimodal data processing and perceptual advancement. The anticipated research outcomes are expected to significantly contribute to the evolution of technologies that rely on accurate and contextually rich three-dimensional reconstructions. Moreover, the research aims to reduce the constant need for new datasets by improving pattern recognition through 3D image patterning on backpropagation. This continuous improvement of vectors is envisioned to enhance the efficiency and accuracy of pattern recognition, contributing to the optimization of perceptual systems over time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIHCIR61661.2023.00105 },
  booktitle={ 2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) },
  chapter={0}
}

@article{rayyan-352343693,
  title={ Exploring the Integration of Generative AI Tools in Software Testing Education: A Case Study on ChatGPT and Copilot for Preparatory Testing Artifacts in Postgraduate Learning  -  IEEE Access },
  author={Haldar, S. and Pierce, M. and Capretz, L. Fernando},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10904141 },
  abstract={Software testing education is important for building qualified testing professionals. To ensure that software testing graduates are ready for real-world challenges, it is necessary to integrate modern tools and technologies into the curriculum. With the emergence of Large Language Models (LLMs), their potential use in software engineering has become a focus, but their application in software testing education remains largely unexplored. This study, conducted in the Capstone Project course of a postgraduate software testing program, was carried out over two semesters with two distinct groups of students. A custom-built Travel Application limited to a web platform was used in the first semester. In the second semester, a new set of students worked with an open-source application, offering a larger-scale, multi-platform experience across web, desktop, and mobile platforms. Students initially created preparatory testing artifacts manually as a group deliverable. Following this, they were assigned an individual assignment to generate the same artifacts using LLM tools such as ChatGPT 3.5 in the first semester and Microsoft Copilot in the second. This process directly compared manually created artifacts and those generated using LLMs, leveraging AI for faster outputs. After completion, they responded to a set of assigned questions. The students’ responses were assessed using an integrated methodology, including quantitative and qualitative assessments, sentiment analysis to understand emotions, and a thematic approach to extract deeper insights. The findings revealed that while LLMs can assist and augment manual testing efforts, they cannot entirely replace the need for manual testing. By incorporating innovative technology into the curriculum, this study highlights how Generative AI can support active learning, connect theoretical concepts with practical applications, and align educational practices with industry needs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3545882 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343694,
  title={ Multi-Lingual Semantic-Based Sentiment Analysis Using Generative AI  -  2024 International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3) },
  year={2024},
  author={Biswas, P. and Arockiam, D. and Neogi, S. G. and Sengupta, S. and Saraswat, S. and Chanda, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827103 },
  abstract={Generative AI models have extensive applications in Natural Language Processing (NLP) and large language models (LLMs) across various domains. They demonstrate high performance in numerous NLP tasks such as summarization, language understanding, reasoning, language generation, question-answering, sentiment categorization, and translation. Newer LLMs are projected to analyse and generate text in multiple languages because to their training on multilingual datasets, like ChatGPT, BLOOMZ, and other similar versions. Considering how frequently LLMs are used, it is critical to assess their effectiveness in multilingual environments. A major issue to be noted is that in a zero-shot context, the present generative models are not very good at producing text in Indian languages. Several scholarly articles studied generative LLMs in the English language. In contrast, LLM for Indic languages is not meant to be used in a zero-shot manner in downstream applications due to poor generating performance. Generative LLMs evaluate models on standard NLP benchmarks covering NLP datasets in diverse languages. We compared the performance of generative LLMs with non-autoregressive models on these tasks to evaluate the generative AI model's performance compared to the previous generation of LLMs. A framework for evaluating generative LLMs in the multilingual setting has been evaluated to provide future directions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC2E362166.2024.10827103 },
  booktitle={ 2024 International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3) },
  chapter={0}
}

@article{rayyan-352343695,
  title={ Data Augmentation for Image Classification Using Generative AI  -  2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) },
  year={2025},
  author={Rahat, F. and Hossain, M. S. and Ahmed, M. R. and Jha, S. K. and Ewetz, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943975 },
  abstract={Scaling laws dictate that the performance of AI models is proportional to the amount of available data. Data augmentation is a promising solution to expanding the dataset size. Traditional approaches focused on augmentation using rotation, translation, and resizing. Recent approaches use generative AI models to improve dataset diversity. However, the generative methods struggle with issues such as subject corruption and the introduction of irrelevant artifacts. In this paper, we propose the Automated Generative Data Augmentation (AGA). The framework combines the utility of large language models (LLMs), diffusion models, and segmentation models to augment data. AGA preserves foreground authenticity while ensuring background diversity. Specific contributions include: i) segment and superclass based object extraction, ii) prompt diversity with combinatorial complexity using prompt decomposition, and iii) affine subject manipulation. We evaluate AGA against state-of-the-art (SOTA) techniques on three representative datasets, ImageNet, CUB and iWildCam. The experimental evaluation demonstrates an accuracy improvement of 15.6% and 23.5% for in and out-of-distribution data compared to baseline models respectively. There is also 64.3% improvement in SIC score compared to the baselines.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WACV61041.2025.00410 },
  booktitle={ 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) },
  chapter={0}
}

@article{rayyan-352343696,
  title={ A Generative AI-Driven CTI Framework for IDS using Machine Learning and Knowledge Graph  -  2024 26th International Multi-Topic Conference (INMIC) },
  year={2024},
  author={Amin, Q. K. and Gillani, S. H. A. Shah and Shah, S. N. M. and Hussain, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004337 },
  abstract={The rapid evolution of cyber-attacks has significantly increased the demand for improved cybersecurity defenses. Large enterprises are increasingly relying on various attack detection systems and cyber threat intelligence to detect attacks and introduce a robust strategy against malicious attacks. However, this also has its limitations i.e., cybersecurity professionals require a lot of time to analyze the attacks detected by an intrusion detection system (IDS) and generate appropriate reports. Therefore, we need to automate this process to improve efficiency. Generative AI plays a crucial role in generating efficient automated reports. Large Language Models (LLMs) in Generative AI, which can be tuned to complex datasets, have demonstrated their capabilities in various applications that use transformers such as image-to-text, text-to-image, and text generation. In this paper, we propose a Cyber Threat Intelligence (CTI)-based intrusion detection system (IDS) that combines honeypots, machine learning-based IDS, and LLMs in combination with a knowledge graph. Specifically, we use fine-tuned pre-trained models on custom datasets based on CVE information. This improves the system’s ability to detect threats and provide more in-depth analysis},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INMIC64792.2024.11004337 },
  booktitle={ 2024 26th International Multi-Topic Conference (INMIC) },
  chapter={0}
}

@article{rayyan-352343697,
  title={ Enhancing Tailored Travel by Integrating Generative AI with Insights Driven by Personality  -  2025 International Conference on Intelligent Control, Computing and Communications (IC3) },
  year={2025},
  author={Garg, A. and Verma, D. and Pandey, L. and Kumar, K. S. and Singh, R. and Sharma, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10957442 },
  abstract={A key component of personalized travel recommendation systems, the Retrieval-Augmented Generator (RAG) architecture has been revolutionized by recent developments in generative Artificial Intelligence (AI). The RAG framework uses natural language inputs and combines retrieval-based techniques with large-scale language models to produce user-specific, contextually appropriate recommendations. By using iterative learning to adjust dynamically, these systems make sure that recommendations change in tandem with changing user preferences, new travel trends, and contextual factors. The Big Five (BF) features and the Myers-Briggs Type Indicator (MBTI), two scientifically based personality models, are used in this study to expand these capabilities. More personalization results from this integration, which improves the system's capacity to match recommendations with unique user preferences and behaviors. In order to show how personality-driven insights enhance the potential of generative AI, the study investigates the fundamental techniques and real-world implementations of this approach. Our system's key performance measures include an 82% accuracy rate, a 78% user satisfaction rate, and performance breakdowns of 75% for introversion and 85% for extraversion. These outcomes provide a fair assessment of the system's contributions to customized travel planning by being compared to those of current systems to contextualize enhancements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC363308.2025.10957442 },
  booktitle={ 2025 International Conference on Intelligent Control, Computing and Communications (IC3) },
  chapter={0}
}

@article{rayyan-352343698,
  title={ AI-Powered Crisis Response: Streamlining Emergency Management with LLMs  -  2024 IEEE World Forum on Public Safety Technology (WFPST) },
  year={2024},
  author={Otal, H. T. and Canbaz, M. Abdullah},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10607148 },
  abstract={Facing the urgent requirement for effective emergency management, our study introduces a groundbreaking approach leveraging the capabilities of open-source Large Language Models (LLMs), notably LLAMA2. This system is engineered to enhance public emergency assistance by swiftly processing and classifying emergencies communicated through social media and direct messaging. Our innovative model interprets user descriptions to analyze context and integrate it with existing Situation Reports, streamlining the alert process to government agencies with crucial information. Importantly, during peak emergency times when conventional systems are under stress, our LLM-based solution provides critical support by offering straightforward guidance to individuals and facilitating direct communication of their circumstances to emergency responders. This advancement significantly bolsters the efficiency and efficacy of crisis response mechanisms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WFPST58552.2024.00009 },
  booktitle={ 2024 IEEE World Forum on Public Safety Technology (WFPST) },
  chapter={0}
}

@article{rayyan-352343699,
  title={ Human-AI Collaboration Empowered Knowledge-Oriented Agent in Large Language Model  -  2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  year={2025},
  author={Wang, R. and Gou, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11082074 },
  abstract={This study proposes a Human-AI collaboration knowledge-oriented agent based on Large Language Model to address the core problems of low level of standardization, high subjectivity and inefficient knowledge transfer in the traditional bid evaluation in the construction industry. Through Design Science Research Methodology, Knowledge Graph and actual enterprise case, an intelligent agent for bid evaluation is constructed. Through automatically parsing massive bidding text data, the agent realize the tasks of structured extraction, comparison and scoring of evaluation items, and forming a dynamic feedback by combining the empirical knowledge of business personnel. In addition, the study proposes "Human-AI Collaboration" decision-making which not only preserves the core value of human experience, but also realizes the iterative optimization of knowledge exploration. This study provides a theoretical framework and practical path for the intelligent transformation of the construction industry, and also provides a reference for the design of Human-AI Collaboration mechanisms in LLM applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIBD64986.2025.11082074 },
  booktitle={ 2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  chapter={0}
}

@article{rayyan-352343700,
  title={ Unlocking the Secrets of Prompt Engineering: Master the art of creative language generation to accelerate your journey from novice to pro  -  Unlocking the Secrets of Prompt Engineering: Master the art of creative language generation to accelerate your journey from novice to pro },
  author={Mizrahi, G. and Serfaty, D.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10460890.pdf&bkn=10460890&pdfType=book },
  abstract={Enhance your writing with AI by mastering prompt engineering techniques and become an expert in developing and utilizing LLM prompts across applicationsKey FeaturesMaster prompt engineering techniques to harness AI's writing potentialDiscover diverse LLM applications for content creation and beyondLearn through practical examples, use cases, and hands-on guidancePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnlocking the Secrets of Prompt Engineering is your key to mastering the art of AI-driven writing. This book propels you into the world of large language models (LLMs), empowering you to create and apply prompts effectively for diverse applications, from revolutionizing content creation and chatbots to coding assistance. Starting with the fundamentals of prompt engineering, this guide provides a solid foundation in LLM prompts, their components, and applications. Through practical examples and use cases, you'll discover how LLMs can be used for generating product descriptions, personalized emails, social media posts, and even creative writing projects like fiction and poetry. The book covers advanced use cases such as creating and promoting podcasts, integrating LLMs with other tools, and using AI for chatbot development. But that’s not all. You'll also delve into the ethical considerations, best practices, and limitations of using LLM prompts as you experiment and optimize your approach for best results. By the end of this book, you'll have unlocked the full potential of AI in writing and content creation to generate ideas, overcome writer's block, boost productivity, and improve communication skills.What you will learnExplore the different types of prompts, their strengths, and weaknessesUnderstand the AI agent's knowledge and mental modelEnhance your creative writing with AI insights for fiction and poetryDevelop advanced skills in AI chatbot creation and deploymentDiscover how AI will transform industries such as education, legal, and othersIntegrate LLMs with various tools to boost productivityUnderstand AI ethics and best practices, and navigate limitations effectivelyExperiment and optimize AI techniques for best resultsWho this book is forThis book is for a wide audience, including writers, marketing and business professionals, researchers, students, tech enthusiasts, and creative individuals. Anyone looking for strategies and examples for using AI co-writing tools like ChatGPT effectively in domains such as content creation, drafting emails, and inspiring artistic works, will find this book especially useful. If you are interested in AI, NLP, and innovative software for personal or professional use, this is the book for you.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Unlocking the Secrets of Prompt Engineering: Master the art of creative language generation to accelerate your journey from novice to pro },
  chapter={0}
}

@article{rayyan-352343701,
  title={ Good Enough to Learn: LLM-Based Anomaly Detection in ECU Logs Without Reliable Labels  -  2025 IEEE Intelligent Vehicles Symposium (IV) },
  year={2025},
  author={Bogdan, B. and Cazacu, A. and Vasilie, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097724 },
  abstract={Anomaly detection often relies on supervised or clustering approaches, with limited success in specialized domains like automotive communication systems where scalable solutions are essential. We propose a novel decoder-only Large Language Model (LLM) to detect anomalies in Electronic Control Unit (ECU) communication logs. Our approach addresses two key challenges: the lack of LLMs tailored for ECU communication and the complexity of inconsistent ground truth data. By learning from UDP communication logs, we formulate anomaly detection simply as identifying deviations in time from normal behavior. We introduce an entropy regularization technique that increases model's uncertainty in known anomalies while maintaining consistency in similar scenarios. Our solution offers three novelties: a decoder-only anomaly detection architecture, a way to handle inconsistent labeling, and an adaptable LLM for different ECU communication use cases. By leveraging the generative capabilities of decoder-only models, we present a new technique that addresses the high cost and error-prone nature of manual labeling through a more scalable system that is able to learn from a minimal set of examples, while improving detection accuracy in complex communication environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IV64158.2025.11097724 },
  booktitle={ 2025 IEEE Intelligent Vehicles Symposium (IV) },
  chapter={0}
}

@article{rayyan-352343702,
  title={ Human Oversight Over Autonomous Task Execution in Sandbox Environments  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Li, W. and Venkatachalam, A. and Bowen, J. and Toxtli-Hernández, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050713 },
  abstract={As Generative Artificial Intelligence (AI) and Robotic Process Automation (RPA) tools become increasingly integrated into digital workflows, ensuring the usability of such automation before deployment on live systems is critical. This paper introduces a novel sandbox environment implemented within a virtual machine designed to safely test AI-driven task automation in isolation. The study evaluates user interactions with automated systems through two distinct feedback modalities: direct mouse control and text-based input, across tasks of varying difficulty levels (easy, medium, and hard) through measuring System Usability Scale, task completion rate and NASA TLX. The experiment introduces two primary independent variables: interaction modality and task difficulty. Interaction modality is categorized into direct mouse control by the user versus providing guidance to the AI through a chat interface. Task difficulty is divided into three levels-easy, medium, and hard; each presented sequentially to participants within their assigned interaction modality. A field experiment with 28 participants revealed that direct mouse control outperformed text-based feedback in task completion rates (83.3% vs. 61.9%) and usability. However, as task difficulty increased, user workload also rose significantly, regardless of the feedback modality. Qualitative analysis highlighted common barriers to effective interaction, such as delayed AI responses and frustration with error correction responsiveness. The study aims to identify patterns in user-AI collaboration dynamics, pinpoint challenges in the AI's autonomous decision-making, and assess the efficacy of the intervention methods. The findings are expected to inform the design of future human-centered AI systems that can effectively balance autonomy with user oversight in complex environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00121 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343703,
  title={ Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) },
  year={2025},
  author={Qi, Z. and Shi, P. and Zhang, C. and Wang, S. and Zhao, F. and Pan, D. and Ying, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147646 },
  abstract={The development of AI-Generated Video (AIGV) technology has been remarkable in recent years, significantly transforming the paradigm of video content production. However, AIGVs still suffer from noticeable visual quality defects, such as noise, blurriness, frame jitter and low dynamic degree, which severely impact the user's viewing experience. Therefore, an effective automatic visual quality assessment is of great importance for AIGV content regulation and generative model improvement. In this work, we decompose the visual quality of AIGVs into three dimensions: technical quality, motion quality, and video semantics. For each dimension, we design corresponding encoder to achieve effective feature representation. Moreover, considering the outstanding performance of large language models (LLMs) in various vision and language tasks, we introduce a LLM as the quality regression module. To better enable the LLM to establish reasoning associations between multi-dimensional features and visual quality, we propose a specially designed multi-modal prompt engineering framework. Additionally, we incorporate LoRA fine-tuning technology during the training phase, allowing the LLM to better adapt to specific tasks. Our proposed method achieved second place in the NTIRE 2025 Quality Assessment of AIGenerated Content Challenge: Track 2 AI Generated video, demonstrating its effectiveness. Codes can be obtained at AIGVEval.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPRW67362.2025.00138 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) },
  chapter={0}
}

@article{rayyan-352343704,
  title={ Challenges of Integrating LLMs Like ChatGPT with Enterprise Software and Solving it with Object Messaging and Intelligent Objects as a New Software Design Paradigm  -  2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE) },
  year={2023},
  author={Alibakhsh, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487510 },
  abstract={The proliferation of AI tools, such as ChatGPT and other Large Language Models (LLMs), has raised expectations regarding their widespread adoption in the workplace. However, this paper delves into the limitations that hinder the deep integration of LLMs with existing software applications used in business environments. While LLMs excel in processing natural language, conventional software applications mostly communicate structured information in a rigid fashion. To bridge the gap between human usage of natural language and the structured data utilized by existing applications, communication tools such as email and Slack emerged. While these tools filled the void by accommodating the informality of chat-like interactions, they struggled to incorporate the applications' structured data. The prevalent form-based models employed by existing software applications present a fundamental obstacle for a meaningful AI integration. This paper examines the challenges of integrating LLMs with form-based software, shedding light on the associated complexities and introduces a new design paradigm, Object Messaging Model and Intelligent Objects (OMIO). By leveraging this model, natural language and structured data become logically combined while enabling seamless integration of LLM capabilities within the software application. This paper provides insights into the potential of the OMIO and paves the way for unlocking the transformative power of LLMs, resulting in highly enhanced productivity within the contemporary business landscape. The Object Messaging paradigm offers an elegant path for deep integration of LLMs and software applications with structured data, while optimizing communication among humans in the workplace producing humans and AI collective intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCE60160.2023.00054 },
  booktitle={ 2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE) },
  chapter={0}
}

@article{rayyan-352343705,
  title={ SafetilBERT: an efficient and explained LLM for IoMT attacks classification  -  2025 IEEE International Conference on Cyber Security and Resilience (CSR) },
  year={2025},
  author={Niang, M. and Nakouri, H. and Jaafar, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130122 },
  abstract={The rapid adoption of Internet of Medical Things (IoMT) devices has improved patient care but introduces vulnerabilities and exposure to cyber threats, particularly denial-of-service (DoS) attacks. This paper explores the potential of large language models (LLMs) for detecting and classifying IoMT network attacks, emphasizing explainability techniques to address the black-box nature of these models. Using the CICIoMT2024 dataset, we introduce SafetilBERT, a fine-tuned DistilBERT model specialized in IoMT cybersecurity. SafetilBERT achieves state-of-the-art performance scoring $96.94 \%$, significantly outperforming BERT and RoBERTa, particularly in DoS detection. Explainability methods such as Local Interpretable Model-agnostic Explanations (LIME), SHapley Additive explanations (SHAP), and attention visualization were used to interpret key features influencing model predictions. Our findings show that SafetilBERT is efficient and adaptable to network data, particularly from packet capture files (PCAP). Furthermore, its interpretability paves the way for robust IoMT cybersecurity solutions applicable in real-world scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSR64739.2025.11130122 },
  booktitle={ 2025 IEEE International Conference on Cyber Security and Resilience (CSR) },
  chapter={0}
}

@article{rayyan-352343706,
  title={ Developing a User-Friendly Conversational AI Assistant for University Using Ollama and LLama3  -  2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) },
  year={2025},
  author={Gohil, J. and L.Shifare, H. and Shukla, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011878 },
  abstract={This paper presents the development and implementation of an AI-driven chatbot for a university, designed to assist students and parents by providing accurate and instant information about the university. The chatbot leverages advanced LLM technologies, specifically LLama3, integrated with Ollama, to ensure high-quality natural language processing. Using LangChain, the system processes user queries by combining them with a structured prompt template, generating precise responses, and storing interactions in a database for future reference. The architecture includes modules like login, signup, and chat, ensuring a user-friendly interface. The chatbot's capability to reliably give precise responses was evaluated both manually and with volunteers in actual situations. This project showcases the uniqueness of utilizing Ollama and LLama3, which distinguishes it from conventional solutions by providing incredibly trustworthy and relevant replies. The chatbot enhances the user experience and acts as an efficient virtual assistant for the university by bridging the gap between user inquiries and institutional resources.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDSAAI65575.2025.11011878 },
  booktitle={ 2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI) },
  chapter={0}
}

@article{rayyan-352343707,
  title={ Efficient Prompting for LLM-Based Generative Internet of Things  -  IEEE Internet of Things Journal },
  author={Xiao, B. and Kantarci, B. and Kang, J. and Niyato, D. and Guizani, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10705427 },
  abstract={Large language models (LLMs) have demonstrated remarkable capacities on various tasks, and integrating the capacities of LLMs into the Internet of Things (IoT) applications has drawn much research attention recently. Due to security concerns, many institutions avoid accessing state-of-the-art commercial LLM services, requiring the deployment and utilization of open-source LLMs in a local network setting. However, open-source LLMs usually have more limitations regarding their performance, such as their arithmetic calculation and reasoning capacities, and practical systems of applying LLMs to IoT have yet to be well-explored. Therefore, we propose an LLM-based Generative IoT (GIoT) system deployed in the local network setting in this study. To alleviate the limitations of LLMs and provide service with competitive performance, we apply prompt engineering methods to enhance the capacities of the open-source LLMs, design a Prompt Management Module and a Postprocessing Module to manage the tailored prompts for different tasks and process the results generated by the LLMs. To demonstrate the effectiveness of the proposed system, we discuss a challenging table question answering (Table-QA) task as a case study of the proposed system, as tabular data is usually more challenging than plaintext because of their complex structures, heterogeneous data types and sometimes huge sizes. We conduct comprehensive experiments on the two popular Table-QA data sets, and the results show that our proposal can achieve competitive performance compared with state-of-the-art LLMs, demonstrating that the proposed LLM-based GIoT system can provide competitive performance with tailored prompting methods and is easily extensible to new tasks without training.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["un peu UMM"]}},
  doi={ 10.1109/JIOT.2024.3470210 },
  booktitle={ IEEE Internet of Things Journal },
  chapter={0}
}

@article{rayyan-352343708,
  title={ ReRag: A New Architecture for Reducing the Hallucination by Retrieval- Augmented Generation  -  2024 9th International Conference on Computer Science and Engineering (UBMK) },
  year={2024},
  author={Ko÷, R. and Gürkan, M. K. and Vural, F. T. Yarman},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10773428 },
  abstract={As the application areas of Generative AI models become widespread, new problems arise. One of these problems is the “hallucination” observed in Large Language Models (LLM). Recently, Retrieval-Augmented Generation systems (RAG) have been introduced to cope with this problem. In this paper, we propose a new method, called “ReRag for Retrieval Augmented Generation”, to reduce the hallucination effect of LLM responses. This method assumes that a small dataset of queries and their man-made ideal responses are available for a specific application domain. It attempts to optimize the hyperparameters of the vector database in the RAG system by generating close-to-ideal responses concerning this ideal dataset, in which the questions and the ideal answers are provided. ReRag measures the similarity between the generated and ideal responses and then modifies the hyperparameters iteratively to increase the similarity between these two responses. Experimental results show that the ReRag method reduces the hallucination problem and generates relatively close to ideal responses compared to raw models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UBMK63289.2024.10773428 },
  booktitle={ 2024 9th International Conference on Computer Science and Engineering (UBMK) },
  chapter={0}
}

@article{rayyan-352343709,
  title={ Recent Trends in Legal AI: A Comprehensive Review  -  2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS) },
  year={2025},
  author={Neelamegam, P. and Nirmala, S. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042154 },
  abstract={Natural Language Processing (NLP) is transforming legal firms by enhancing legal text analysis, legal document management, and judicial decision prediction. Conventional rule-based and statistical methods lack the contextual understanding, and scalability required for processing complex legal texts, while deep learning and transformer-based models have revolutionized advanced Legal Artificial Intelligence (LegalAI) technologies. Large Language Models (LLMs), including BERT, GPT, LLaMA, and domain-specific transformers like Legal-BERT and CaseLaw-BERT, have refined the state-of-art models in legal NLP tasks like legal text classification, legal text summarization, and judgment prediction. This study analyzes 40 selected journals and conference papers from 2017 to 2024, emphasizing the developing research interest in LLM-based legal applications. Major developments consist of hierarchical transformers, rhetorical role classification, and legal knowledge graphs that facilitate legal text parsing and logical inference. This paper spans intellectual breakthroughs with real-world applications by reviewing LLMs and Knowledge Graphs (KG) for legal NLP, providing key findings for scholars and experts working on AI-driven legal systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAISS61471.2025.11042154 },
  booktitle={ 2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS) },
  chapter={0}
}

@article{rayyan-352343710,
  title={ PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback  -  2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  year={2025},
  author={Peng, Y. and Gotmare, A. D. and Lyu, M. R. and Xiong, C. and Savarese, S. and Sahoo, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052794 },
  abstract={Large Language Models (LLMs) are widely adopted for assisting in software development tasks, yet their performance evaluations have narrowly focused on the functional correctness of generated code. Human programmers, however, expect AI assistants to generate not only correct but also optimally efficient code. We propose PerfCodeGen, a training-free framework that enhances the performance of LLM-generated code by incorporating feedback based on runtime during test case execution into the self-refinement iterations. With PerfCodeGen, we achieve speedups for a significantly higher proportion of problems compared to using the base LLM with sophisticated prompting techniques. Applied to open-weight language models like Phi-3-mini, PerfCodeGen achieves code optimization rates comparable to naive prompting of powerful closed models like GPT-4. We achieve state-of-the-art code optimization on benchmarks such as HumanEval, MBPP, and APPS, frequently surpassing the ground truth reference solutions with PerfCodeGen using GPT-3.5 and GPT-4. Additionally, we demonstrate the effectiveness of our approach in enhancing code quality across a range of open-weight LLMs of varying sizes including Phi-3-mini (3.8B), Llama 3 8B, Mixtral 8x7B (13B active), Command R (35B), and Llama 3 70B. PerfCodeGen’s effectiveness at generating performant code underscores the importance of integrating execution feedback into the code generation process, highlighting a path forward for more robust and reliable AI-driven software development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Forge66646.2025.00008 },
  booktitle={ 2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  chapter={0}
}

@article{rayyan-352343711,
  title={ 5 LLM Pretraining Methods  -  Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  author={Velu, A. and Ramamoorthy, R. and Manasa, S. M. and Prasanth, A.},
  url={ https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11164683.pdf&bkn=11164515&pdfType=chapter },
  abstract={Generative artificial intelligence (AI), an AI technique produces original text, sounds, 3D models, animation, and images. It is powered by large-scale machine learning (ML) models that leverage pretrained deep neural networks on massive datasets. Pretraining mostly aims to guess the next word in a sentence or fill in masked words inside the sequence. Through this unsupervised learning exercise, the model learns to comprehend the linguistic structures and statistical trends. Through pretraining, large language model (LLM) acquires a general understanding of syntax, grammar, and semantics. It helps in establishing a strong basis for language comprehension and enables the model to depict the relationships between words. The pretraining of data is primarily responsible for the extraordinary powers of LLMs. It is similar to bombarding the brain with vast volumes of data so that it learns the laws of language and the outside world before being taught particular skills. Next sentence prediction, contrastive learning, masked language modeling, sentence-level and document-level objectives, denoising autoencoders (DAEs), and other pretraining approaches of LLM are covered in this chapter along with their significance. Pretrained models increase efficiency and reduce the need for additional training by enabling information to be applied to subsequent tasks. Pretraining of data has a greater range of application areas like transfer learning, classification, and feature extraction.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks },
  chapter={0}
}

@article{rayyan-352343712,
  title={ MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation  -  2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym: },
  year={2024},
  author={Wang, G. and Li, Y. and Liu, Y. and Deng, G. and Li, T. and Xu, G. and Liu, Y. and Wang, H. and Wang, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599579 },
  abstract={Augmented generation techniques such as Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG) have revolutionized the field by enhancing large language model (LLM) outputs with external knowledge and cached information. However, the integration of vector databases, which serve as a backbone for these augmentations, introduces critical challenges, particularly in ensuring accurate vector matching. False vector matching in these databases can significantly compromise the integrity and reliability of LLM outputs, leading to misinformation or erroneous responses. Despite the crucial impact of these issues, there is a notable research gap in methods to effectively detect and address false vector matches in LLM-augmented generation. This paper presents MeTMaP, a metamorphic testing framework developed to identify false vector matching in LLM -augmented generation systems. We derive eight metamorphic relations (MRs) from six NLP datasets, which form our method's core, based on the idea that semantically similar texts should match and dissim-ilar ones should not. MeTMaP uses these MRs to create sentence triplets for testing, simulating real-world matching scenarios. Our evaluation of MeTMaP over 203 vector matching configurations, involving 29 embedding models and 7 distance metrics, uncovers significant inaccuracies. The results, showing a maximum accuracy of only 41.51% on our tests compared to the original datasets, em-phasize the widespread issue of false matches in vector matching methods and the critical need for effective detection and mitigation in LLM -augmented applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3650105.3652297 },
  booktitle={ 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym: },
  chapter={0}
}

@article{rayyan-352343713,
  title={ Developing an AI-Based Library Assistant: Enhancing Book Retrieval with Natural Language Processing and Machine Learning  -  2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN) },
  year={2025},
  author={Varma, N. M. Kailash and Aryan, A. and Dhanush, P. and Manikanta, R. and Chandhu, N. and Arora, G. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932399 },
  abstract={The current college library system is hindered by inefficiencies in book searching, availability updates, identity verification, and checkout processes, resulting in delays and errors that negatively impact student experiences. This research paper presents an AI-based librarian system designed to address these challenges through automation and digital transformation. Leveraging a Large Language Model (LLM), the proposed system facilitates personalized interactions between students and library resources. Upon student verification, the AI librarian provides real-time information on book availability, location, and tailored recommendations, significantly reducing the time spent on manual searches. The streamlined checkout process allows for automated book issuance and instant confirmation notifications, minimizing human error and enhancing record- keeping. This innovative solution not only improves operational efficiency but also enriches the user experience by offering a user-friendly interface and timely assistance. Future enhancements, such as voice integration and mobile application support, are suggested to further modernize library services. This research underscores the potential of AI technologies to revolutionize library management and improve service delivery in academic settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CICTN64563.2025.10932399 },
  booktitle={ 2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN) },
  chapter={0}
}

@article{rayyan-352343714,
  title={ PUAA: Personal University AI Assistant using Retrieval Augmented Generation  -  2024 IEEE 15th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON) },
  year={2024},
  author={Panday, S. and Ghosh, R. and Rahman, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093120 },
  abstract={A significant improvement in knowledge acquisition has been made by introducing Large Language Models (LLMs) like Chat-GPT and Bard, which provide a more efficient way to acquire information than the labor-intensive procedure of going through various online checkpoints. This new tendency in LLMs makes the widely used rule-based chatbots that colleges use look antiquated and inadequate. To better serve the needs of students looking for information about their universities, this research project suggests incorporating LLM technology into university websites. Our research introduces Personal University AI Assistant (PUAA) with methodology leveraging the RetrievalAugmented Generation (RAG) framework, utilizing the power of the LangChain in combination with cutting-edge LLMs like Mistral-7B, which is made available by the Hugging Face as an open-source option, and Chat GPT 3.5 as the most optimal solution for the problem of fast knowledge acquisition. PUAA improves the students’ experience of accessing university knowledge by providing instant, accurate information while reducing the workload of administrative staff and allowing them to focus on more complex inquiries and tasks. PUAA aims to promote the adoption of artificial intelligence (AI) in educational institutions, demonstrating the viability and benefits of advanced AI tools in enhancing the academic experience and information accessibility for students and staff.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEMCON62851.2024.11093120 },
  booktitle={ 2024 IEEE 15th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON) },
  chapter={0}
}

@article{rayyan-352343715,
  title={ Framework Design and Implementation of the AI Aided Process Designing Platform for Shipbuilding Industry  -  2024 IEEE First International Conference on Data Intelligence and Innovative Application (DIIA) },
  year={2024},
  author={Liang, X. and Ma, Y. and Xi, M. and Li, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871768 },
  abstract={In order to achieve digital upgrading of traditional shipbuilding industry, framework design and program development of the artificial intelligence (AI) Aided Process Designing Platform have been completed. The platform is based on B/S architecture. By utilizing retrieval- augmented generation (RAG) technology and Large Language Model (LLM), four major function functional modules was implemented, including process knowledge integration, Knowledge Engineering Management, intelligent question and answer (Q&A) for process knowledge, and process plan generation. The retrieval accuracy of the AI Aided Process Designing Platform was proved to reach over 95%, while the accuracy of Q&A reached over 74% by manual testing, which can help technicians save query time and Improve design efficiency. Besides, process plans can be automatically composited rapidly through the templates. Therefore, the AI Aided Process Designing Platform can help shipbuilding enterprises improve the economic benefits and enhance the competitiveness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DIIA62678.2024.10871768 },
  booktitle={ 2024 IEEE First International Conference on Data Intelligence and Innovative Application (DIIA) },
  chapter={0}
}

@article{rayyan-352343716,
  title={ A Quantitative Analysis of Quality and Consistency in AI-generated Code  -  2024 7th International Conference on Software and System Engineering (ICoSSE) },
  year={2024},
  author={Clark, A. and Igbokwe, D. and Ross, S. and Zibran, M. F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608315 },
  abstract={With the recent emergence of generative AI (Artificial intelligence), Large Language Model (LLM) based tools such as ChatGPT have become popular assistants to humans in diverse tasks. ChatGPT has also been widely adopted for solving programming problems and for generating source code in software development. This research investigates both the code quality and the consistency of code quality over iterative prompts in 625 ChatGPT-generated Python code samples in the DevGPT dataset and the corresponding code snippets regenerated by manually prompting ChatGPT. Code samples are measured in terms of seven Halstead complexity metrics. We also assess how consistent they are across code snippets generated by different versions of ChatGPT. It was found that while ChatGPT generates good quality code across iterative prompts, it does generate semifrequent bugs, similar to how humans do, necessitating code review before integration. These traits also remain consistent across code snippets generated by subsequent releases of ChatGPT. These results suggest using AI-generated source code in software development will not hinder the process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoSSE62619.2024.00014 },
  booktitle={ 2024 7th International Conference on Software and System Engineering (ICoSSE) },
  chapter={0}
}

@article{rayyan-352343717,
  title={ Comprehensive Web Fuzzer with AI Mitigation and Custom Payload  -  2025 7th International Conference on Inventive Material Science and Applications (ICIMA) },
  year={2025},
  author={Mathews, A. and Rao, S. M. and Faizan, S. and Khatiwada, R. and Bhatta, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11074012 },
  abstract={This paper addresses the challenge of inefficient and manually intensive web application security testing, which often results in delayed vulnerability detection and remediation. The system proposes Cyber Xipher, an AI-driven fuzzing framework that streamlines the penetration testing process through automation and intelligent decision-making. The system integrates Gemini AI for real-time website classification, OWASP ZAP for adaptive payload-based fuzzing, and a large language model (LLM) to generate contextual mitigation reports. Cyber Xipher not only crafts targeted attack payloads based on website context but also automates the reporting and remediation workflow. Through a centralized admin dashboard, it enables tester assignment, monitoring, and oversight functionalities. Experimental validation demonstrates that Cyber Xipher significantly improves test coverage, reduces manual effort, and accelerates vulnerability remediation. The framework is positioned as a strategic tool for enterprise security operations and automated vulnerability management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIMA64861.2025.11074012 },
  booktitle={ 2025 7th International Conference on Inventive Material Science and Applications (ICIMA) },
  chapter={0}
}

@article{rayyan-352343718,
  title={ Trust Calibration in IDEs: Paving the Way for Widespread Adoption of AI Refactoring  -  2025 IEEE/ACM Second IDE Workshop (IDE) },
  year={2025},
  author={Borg, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052687 },
  abstract={In the software industry, the drive to add new features often overshadows the need to improve existing code. Large Language Models (LLMs) offer a new approach to improving codebases at an unprecedented scale through AI-assisted refactoring. However, LLMs come with inherent risks such as braking changes and the introduction of security vulnerabilities. We advocate for encapsulating the interaction with the models in IDEs and validating refactoring attempts using trustworthy safeguards. However, equally important for the uptake of AI refactoring is research on trust development. In this position paper, we position our future work based on established models from research on human factors in automation. We outline action research within CodeScene on development of 1) novel LLM safeguards and 2) user interaction that conveys an appropriate level of trust. The industry collaboration enables large-scale repository analysis and A/B testing to continuously guide the design of our research interventions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDE66625.2025.00012 },
  booktitle={ 2025 IEEE/ACM Second IDE Workshop (IDE) },
  chapter={0}
}

@article{rayyan-352343719,
  title={ Multidimensional Impacts of Generative AI and an In-Depth Analysis of LLMs with Their Expanding Horizons in Technology and Society  -  2024 OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 4.0 },
  year={2024},
  author={Ramu, K. and Nijhawan, G. and Lalitha, G. and Praveen and Asha, V. and Fakher, A. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687980 },
  abstract={Generative AI and large language models (LLMs) have transformed technology and society, as this paper details. Generative AI advanced AI greatly. Because they can read and write, LLMs, a form of Generative AI, have altered how humans and robots communicate. This study focuses on how these technologies influence schooling, healthcare, finance, and morals. Recent studies and case studies will help us understand how LLM is applied in many sectors. Our key concerns with these activities are efficiency, efficacy, and morality. The technique also polls and interviews professionals to learn about LLM usage and issues. LLM is quicker and more precise in translating languages, creating content, and analyzing data. Sadly, prejudice, privacy, and abuse issues persisted. LLMs are versatile enough to be utilized in odd fields like individualized learning and mental health treatment, according to the research. LLMs and creative AI can advance technology and society. Despite their benefits, they pose moral and practical issues that must be addressed. This study seeks a compromise between the two LLM methods. A more moral, research-focused use might make them more beneficial and less hazardous.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OTCON60325.2024.10687980 },
  booktitle={ 2024 OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 4.0 },
  chapter={0}
}

@article{rayyan-352343720,
  title={ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems  -  2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW) },
  year={2024},
  author={Zhang, W. and Kong, X. and Dewitt, C. and Braunl, T. and Hong, J. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771340 },
  abstract={The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot’s understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings demonstrate a substantial overall improvement of approximately 30.8% in both attack detection and system performance with the implementation of robust defence mechanisms, highlighting their critical role in enhancing security and reliability in mission-oriented tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISSREW63542.2024.00103 },
  booktitle={ 2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW) },
  chapter={0}
}

@article{rayyan-352343721,
  title={ TAGIFY: LLM-powered Tagging Interface for Improved Data Findability on OGD portals  -  2024 Fifth International Conference on Intelligent Data Science Technologies and Applications (IDSTA) },
  year={2024},
  author={Kliimask, K. and Nikiforova, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10746941 },
  abstract={Efforts directed towards promoting Open Government Data (OGD) have gained significant traction across various governmental tiers since the mid-2000s. As more datasets are published on OGD portals, finding specific data becomes harder, leading to information overload and so-called “dark data”. Complete and accurate documentation of datasets, including association of proper tags with datasets is key to improving dataset findability and accessibility. Analysis conducted on the Estonian Open Data Portal revealed that 11% datasets have no associated tags, while 26% had only one tag assigned to them, which underscores challenges in data findability and accessibility within the portal, which, according to the recent Open Data Maturity Report, is considered trendsetter. The aim of this study is to propose an automated solution to tagging datasets to improve data findability on OGD portals. This paper presents TAGIFY – a prototype of tagging interface that employs large language models (LLM) such as GPT-3.5turbo and GPT-4 to automate dataset tagging, generating tags for datasets in English and Estonian, thereby augmenting metadata preparation by data publishers and improving data findability on OGD portals by data users. The developed solution was evaluated by users and their feedback was collected to define an agenda for future prototype improvements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDSTA62194.2024.10746941 },
  booktitle={ 2024 Fifth International Conference on Intelligent Data Science Technologies and Applications (IDSTA) },
  chapter={0}
}

@article{rayyan-352343722,
  title={ Fine-Tuning Gemma-2B for Text-to-SQL Generation  -  2024 9th International Conference on Communication and Electronics Systems (ICCES) },
  year={2024},
  author={Neogi, H. and Ray, J. and Banerjee, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10860111 },
  abstract={Through this study, the concept of large language models (LLM) in the context of generative AI has been explored. Gemma-2B, with 4-bit quantization is fine-tuned to bridge the gap between natural language processing (NLP) and SQL query generation. The 4-bit quantization significantly reduces memory requirements, making Gemma-2B more efficient for real-world applications while maintaining the performance of the large language model. Users can interact with databases intuitively through simple, text-based inputs. This model employs zero-shot learning, enabling SQL query generation for text descriptions without specific examples in training. Developed and tested within a Google Colab environment, this approach simplifies data retrieval by transforming unstructured language into structured queries through generative AI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCES63552.2024.10860111 },
  booktitle={ 2024 9th International Conference on Communication and Electronics Systems (ICCES) },
  chapter={0}
}

@article{rayyan-352343723,
  title={ Lateral Phishing With Large Language Models: A Large Organization Comparative Study  -  IEEE Access },
  author={Bethany, M. and Galiopoulos, A. and Bethany, E. and Karkevandi, M. Bahrami and Beebe, N. and Vishwamitra, N. and Najafirad, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943116 },
  abstract={The emergence of Large Language Models (LLMs) has heightened the threat of phishing emails by enabling the generation of highly targeted, personalized, and automated attacks. Traditionally, many phishing emails have been characterized by typos, errors, and poor language. These errors can be mitigated by LLMs, potentially lowering the barrier for attackers. Despite this, there is a lack of large-scale studies comparing the effectiveness of LLM-generated lateral phishing emails to those crafted by humans. Current literature does not adequately address the comparative effectiveness of LLM and human-generated lateral phishing emails in a real-world, large-scale organizational setting, especially considering the potential for LLMs to generate more convincing and error-free phishing content. To address this gap, we conducted a pioneering study within a large university, targeting its workforce of approximately 9,000 individuals including faculty, staff, administrators, and student workers. Our results indicate that LLM-generated lateral phishing emails are as effective as those written by communications professionals, emphasizing the critical threat posed by LLMs in leading phishing campaigns. We break down the results of the overall phishing experiment, comparing vulnerability between departments and job roles. Furthermore, to gather qualitative data, we administered a detailed questionnaire, revealing insights into the reasons and motivations behind vulnerable employee’s actions. This study contributes to the understanding of cyber security threats in educational institutions and provides a comprehensive comparison of LLM and human-generated phishing emails’ effectiveness, considering the potential for LLMs to generate more convincing content. The findings highlight the need for enhanced user education and system defenses to mitigate the growing threat of AI-powered phishing attacks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3555500 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343724,
  title={ SA-DS: A Dataset for Large Language Model-Driven AI Accelerator Design Generation  -  2025 IEEE International Symposium on Circuits and Systems (ISCAS) },
  year={2025},
  author={Vungarala, D. and Nazzal, M. and Morsali, M. and Zhang, C. and Ghosh, A. and Khreishah, A. and Angizi, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044008 },
  abstract={In the ever-evolving landscape of Deep Neural Networks (DNN) hardware acceleration, unlocking the true potential of systolic array accelerators has long been hindered by the daunting challenges of expertise and time investment. Large Language Models (LLMs) offer a promising solution for automating code generation, which is key to unlocking unprecedented efficiency and performance in various domains, including hardware descriptive code. The generative power of LLMs can enable the effective utilization of preexisting designs and dedicated hardware generators. However, the successful application of LLMs to hardware accelerator design is contingent upon the availability of specialized datasets tailored for this purpose. To bridge this gap, we introduce the Systolic Array-based Accelerator DataSet (SA-DS). SA-DS comprises a diverse collection of spatial array designs following the standardized Berkeley’s Gemmini accelerator generator template, enabling design reuse, adaptation, and customization. SA-DS is intended to spark LLM-centered research on DNN hardware accelerator architecture. We envision that SA-DS provides a framework that will shape the course of DNN hardware acceleration research for generations to come. SA-DS is open-sourced under the permissive MIT license at https://github.com/ACADLab/SA-DS.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAS56072.2025.11044008 },
  booktitle={ 2025 IEEE International Symposium on Circuits and Systems (ISCAS) },
  chapter={0}
}

@article{rayyan-352343725,
  title={ AI-Driven Classification of Academic and Psychological Challenges in Higher Education  -  2025 International Conference on New Trends in Computing Sciences (ICTCS) },
  year={2025},
  author={Alazzam, S. H. and Al-oudat, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989304 },
  abstract={Students enrolled in university experience academic along with mental stressors, which negatively impact their academic results. The research implements artificial intelligence methods for classifying and forecasting the difficulties which higher education students encounter within Jordanian universities. An electronic questionnaire was designed through structured procedures and received validation from eight academics before being distributed to 1020 students. Statistical analysis through Statistical Package for the Social Sciences (SPSS) validated the questionnaire data while testing the reliability of its findings. Students were classified into four categories—Academic Difficulties and Academic and Psychological Challenges and Psychological Distress alongside Normal—through the utilization of the GPT-4o mini API as a Large Language Model (LLM). Machine learning algorithms were applied to evaluate classification performance. Support Vector Machine (SVM) demonstrated the best result among classification models with an accuracy rate of 88.2% while Logistic Regression came second with 87.7% accuracy. A significant number of 54.7% students faced academic challenges while 60.8% of students reported psychological issues. The generated results will assist educational institutions by guiding their early prevention programs along with choosing appropriate assistance methods to enhance educational outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTCS65341.2025.10989304 },
  booktitle={ 2025 International Conference on New Trends in Computing Sciences (ICTCS) },
  chapter={0}
}

@article{rayyan-352343726,
  title={ JAVIS: A Comprehensive AI System Designed for Innovation and Research in Healthcare  -  2025 IEEE 13th International Conference on Healthcare Informatics (ICHI) },
  year={2025},
  author={Aguirre, J. and Cha, W. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081544 },
  abstract={Language models have significant potential to improve clinical workflows, accelerate research, and enhance patient care in hospitals. However, privacy constraints, limited compatibility with diverse IT systems, and the absence of a holistic approach for managing language models within internal networks hinder broader adoption. JAVIS tackles these challenges by offering a secure, scalable, and modular framework for Large Language Models (LLMs) and Vision-Language Models (VLMs), fully operating on private hospital networks. Its features include high-throughput data labeling (text, images, and audio), a no-code LLM training interface, an auto-labeling module for named entity recognition (NER) tasks, and distributed deployment of LLMs and VLMs on multi-GPU infrastructures that provide an internal network chat service. This poster outlines JAVIS’s architecture, key features, and results demonstrating robust performance in data labeling, training, and large-scale inference.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHI64645.2025.00091 },
  booktitle={ 2025 IEEE 13th International Conference on Healthcare Informatics (ICHI) },
  chapter={0}
}

@article{rayyan-352343727,
  title={ TACO - A Generative AI Copilot for Intent-Based Telecommunication Core Network Analysis  -  NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  year={2025},
  author={Tóthfalusi, T. and Csiszár, Z. and Varga, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073654 },
  abstract={This paper presents the methodology for using LLMs to ease core network signaling analysis. This is done by applying RAG techniques to process standards that describe protocol data formats - and then asking natural language questions about actual capture traces. Analyzing 5G networks is very challenging due to the complex and dynamic nature of signaling protocols. Unlike previous generations, protocol fields and values are described in a human-readable format, enabling textual post-processing, and the direct application of LLM models. Intent-based network management involves natural language-based human interaction with the networking equipment so the desired outcome is achieved without step-by-step instructions and settings by the human. This paper proposes a novel approach that uses the combination of Retrieval Augmented Generation (RAG) and Langchain to automatically answer human questions regarding signalling data. This toolchain makes the analysis part of network fault management intent-based. Moreover, by training LLMs on a vast corpus of standardized signaling data, we demonstrate the model's ability to generate realistic test data. This approach improves the efficiency of automated test environments, ensuring the reliability and performance of networks in real-world conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NOMS57970.2025.11073654 },
  booktitle={ NOMS 2025-2025 IEEE Network Operations and Management Symposium },
  chapter={0}
}

@article{rayyan-352343728,
  title={ Enhancing Occupancy Detection with Explainable AI: Leveraging SHAP and Large Language Models  -  2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC) },
  year={2025},
  author={Kampelopoulos, D. and Papadopoulos, K. and Tsanousa, A. and Meditskos, G. and Vrochidis, S. and Kompatsiaris, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106581 },
  abstract={The rapid growth of the field of Artificial Intelligence has increased the utilization of predictive machine learning models in the construction industry. While their capabilities are significant, they often perform in a black-box manner, raising the need for interpretability of these models. This work focuses on the problem of occupancy detection and proposes a generalized explainability approach for common model configurations trained on public occupancy datasets. The data are collected from buildings with multiple sensor modalities, including power meters and environmental sensors. The proposed methodology involves the interpretation of the model predictions via the SHapley Additive exPlanations (SHAP) method and the employment of a Large Language Model (LLM) to provide the reasoning behind the model predictions and the feature contribution in natural language. This work provides generalized prompt instructions along with example responses on multiple scenarios, as well as a discussion on the limitations, common issues that were overcome with minimal prompt-tuning, and the potential for future development of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICE/ITMC65658.2025.11106581 },
  booktitle={ 2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC) },
  chapter={0}
}

@article{rayyan-352343729,
  title={ DesignGPT: Multi-Agent Collaboration in Design  -  2023 16th International Symposium on Computational Intelligence and Design (ISCID) },
  year={2023},
  author={Ding, S. and Chen, X. and Fang, Y. and Liu, W. and Qiu, Y. and Chai, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494260 },
  abstract={Generative AI faces many challenges when entering the product design workflow, such as interface usability and interaction patterns. Therefore, based on design thinking and design process, we developed the DesignGPT multi-agent collaboration framework, which uses artificial intelligence agents to simulate the roles of different positions in the design company and allows human designers to collaborate with them in natural language. Experimental results show that compared with separate AI tools, DesignGPT improves the performance of designers, highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCID59865.2023.00056 },
  booktitle={ 2023 16th International Symposium on Computational Intelligence and Design (ISCID) },
  chapter={0}
}

@article{rayyan-352343730,
  title={ Towards Human-Level Evaluation: Assessing the Potential of GPT-4 in Automated Evaluation and Feedback Generation on Japanese Essays  -  2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI) },
  year={2024},
  author={Nakamoto, S. and Okamoto, Y. and Nakakouchi, T. and Shimada, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707930 },
  abstract={In recent years, Automated Writing Evaluation (AWE) has been extensively researched within the field of AI in education. This paper explores generative AI, such as GPT-4, which has garnered significant attention for its ability to score essays and provide feedback to students. We designed prompts for GPT-4 to assign scores and rationales based on a given rubric and to generate feedback beneficial for students' development. We compared the evaluations produced by GPT-4 with those made by human evaluators. The results demonstrate GPT-4's potential to assist in generating evaluations at a human level. In addition, we analysed the consistency of the scoring and the quality of the rationales and feedback generated by GPT-4. In this paper, we will share our analysis and also describe the points that need to be improved for implementation in practice.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IIAI-AAI63651.2024.00039 },
  booktitle={ 2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI) },
  chapter={0}
}

@article{rayyan-352343731,
  title={ EPIC: Ensembled Poisoning Identification and Classification for LLM Backdoor Defense  -  2024 IEEE Smart World Congress (SWC) },
  year={2024},
  author={Kyaw, M. T. and Dai, Z. and Thing, V. L. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924961 },
  abstract={In the realm of artificial intelligence, Large Language Models (LLMs) stand as titans of natural language understanding and generation, driving innovations across diverse applications. However, their ascendancy brings forth challenges, notably vulnerability to data poisoning attacks; malicious alterations designed to compromise model integrity. This work introduces a novel approach to safeguard LLMs against these malicious threats. This paper delineates a two-pronged methodology: initially deploying an ensemble of traditional machine learning models to detect discrepancies in predictions between clean and poisoned models, followed by an enhanced technique that trains models to discern the “poison status” directly from data inputs. Through meticulous experimentation, this work not only unveils the susceptibility of LLMs to poisoning but also demonstrates the efficacy of ensemble methods and poison detection in fortifying model defenses. Our research aims to improve security and robustness of AI systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SWC62898.2024.00142 },
  booktitle={ 2024 IEEE Smart World Congress (SWC) },
  chapter={0}
}

@article{rayyan-352343732,
  title={ Data Sovereign LLM-Assisted Automation Platform for Open Optical and Packet Transport Networks  -  2025 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN) },
  year={2025},
  author={Shariati, B. and Mitrovska, A. and Zaid, H. and Balanici, M. and Jafari, A. and Safari, P. and Fischer, J. K. and Freund, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140539 },
  abstract={The Open Optical Transport Network (OOPT) architecture, defined by the Telecom Infra Project (TIP), is currently being deployed by major operators. The OOPT ecosystem, with its multi-stakeholder and multi-vendor environment, faces challenges like interoperability, business-critical data sharing, and end-to-end control and automation. These issues are exacerbated by the introduction of AI-assisted network functions requiring real-time telemetry data. The integration of Large Language Model (LLM)-based AI agents further increases this complexity. This work proposes an experimentally validated automation platform that addresses these challenges. It leverages data spaces, carrier-grade data pipelines, and customized LLM assistants with NDA compliance. Our solution complies with OpenConfig and TAPI specifications for controlling programmable network elements and utilizes gNMI for telemetry streaming from open terminals and Optical Line System (OLS) controllers. We demonstrate the advantages of our proposal through several experiments on a large-scale, partially disaggregated packet-optical testbed. The experiments include autonomous transponder reconfiguration for optical link-capacity adjustment using AI-assisted traffic forecasting, LLM-assisted service provisioning, and policy-enforced telemetry sharing via data spaces.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLCN64995.2025.11140539 },
  booktitle={ 2025 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN) },
  chapter={0}
}

@article{rayyan-352343733,
  title={ Exploring Large Language Model-Driven Agents for Environment-Aware Spatial Interactions and Conversations in Virtual Reality Role-Play Scenarios  -  2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR) },
  year={2025},
  author={Li, Z. and Zhang, H. and Peng, C. and Peiris, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937341 },
  abstract={Recent research has begun adopting Large Language Model (LLM) agents to enhance Virtual Reality (VR) interactions, creating immersive chatbot experiences. However, while current studies focus on generating dialogue from user speech inputs, their abilities to generate richer experiences based on the perception of LLM agents’ VR environments and interaction cues remain unexplored. Hence, in this work, we propose an approach that enables LLM agents to perceive virtual environments and generate environment-aware interactions and conversations for an embodied human-AI interaction experience in VR environments. Here, we define a schema for describing VR environments and their interactions through text prompts. We evaluate the performance of our method through five role-play scenarios created using our approach in a study with 14 participants. The findings discuss the opportunities and challenges of our proposed approach for developing environment-aware LLM agents that facilitate spatial interactions and conversations within VR role-play scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VR59515.2025.00025 },
  booktitle={ 2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR) },
  chapter={0}
}

@article{rayyan-352343734,
  title={ Emergence of A Novel Domain Expert: A Generative AI-based Framework for Software Function Point Analysis  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Zhao, Z. and Jiang, H. and Zhao, R. and He, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764829 },
  abstract={Estimating software functional size is a crucial initial step before development, impacting costs and timelines. This involves applying standard Function Point Analysis (FPA) to the Software Requirements Specification (SRS). However, manual analysis by Function Point (FP) analysts during the splitting of FP entries from SRS remains inefficient and costly. To address this issue, for the first time, we propose an AI-based domain expert for FPA, named FPA-EX. It employs a large language model (LLM), intelligently extracts software FP entries from SRS, providing automated support to enhance efficiency. Specifically, we construct a multi-domain FPA dataset through collecting and annotating 778 question-answer pairs related to various SRS. Based on this dataset, we present a novel densely supervised fine-tuning (DSFT) on LLM, which performs entries-level optimization over the human augmented text, ensuring precise FPs outputs. Finally, we design a ConceptAct Promting (CAP) process for correct logical reasoning. Experiments demonstrate the superior performance of FPA-EX, particularly higher than GPT3.5 by 0.491 on F1 scores. Furthermore, in practical application, FPA-EX significantly enhances the productivity of FP analysts, contributing to a shift towards more intelligent work patterns.CCS Concepts• Software and its engineering → Requirements analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352343735,
  title={ Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs  -  2025 IEEE/ACM 9th International Workshop on Green and Sustainable Software (GREENS) },
  year={2025},
  author={Sikand, S. and Mehra, R. and Pathania, P. and Bamby, N. and Sharma, V. S. and Kaulgud, V. and Podder, S. and Burden, A. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039304 },
  abstract={While Generative AI stands to be one of the fastest adopted technologies ever, studies have made evident that the usage of Large Language Models (LLMs) puts significant burden on energy grids and our environment. It may prove a hindrance to the Sustainability goals of any organization. A crucial step in any Sustainability strategy is monitoring or estimating the energy consumption of various components. While there exist multiple tools for monitoring energy consumption, there is a dearth of tools/frameworks for estimating the consumption or carbon emissions. Current drawbacks of both monitoring and estimation tools include high input data points, intrusive nature, high error margin, etc. We posit that leveraging emerging LLM benchmarks and related data points can help overcome aforementioned challenges while balancing accuracy of the emission estimations. To that extent, we discuss the challenges of current approaches and present our evolving framework, R-ICE, which estimates prompt level inference carbon emissions by leveraging existing state-of-the-art(SOTA) benchmark. This direction provides a more practical and non-intrusive way to enable emerging use-cases like dynamic LLM routing, carbon accounting, etc. Our promising validation results suggest that benchmark-based modelling holds great potential for inference emission estimation and warrants further exploration from the scientific community.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GREENS66463.2025.00013 },
  booktitle={ 2025 IEEE/ACM 9th International Workshop on Green and Sustainable Software (GREENS) },
  chapter={0}
}

@article{rayyan-352343736,
  title={ AI-driven smart home energy optimization: integrating AI agents with IoT for adaptive decision-making  -  International Conference on Applied System Innovation (ICASI 2025) },
  year={2025},
  author={Li, T. -C. and Liu, Y. -K. and Tsai∗, Y. -C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148518 },
  abstract={As the Internet of Things (IoT) revolutionizes intelligent environments, energy efficiency remains a critical challenge. Traditional IoT-based energy management systems rely on predefined rule-based automation, which lacks adaptability to dynamic environmental conditions. This study proposes an Agentic AIoT system that integrates AI Agents, Large Language Models (LLMs), and Digital Twin technology to enhance IoT decision-making and optimize energy consumption in smart homes. Unlike conventional IoT frameworks, our system dynamically analyzes contextual factors—including real-time environmental conditions, user behaviors, and external data sources (e.g., weather forecasts and occupancy schedules)—to generate optimal energy-saving decisions autonomously. The proposed system consists of three key components: (1) Information Modules, which aggregate multi-source data beyond traditional IoT sensor inputs and construct a Digital Twin model for real-time environment simulation; (2) AI Agents & LLMs, which process contextual data and generate adaptive energy-saving strategies through intelligent reasoning; and (3) Automated Decision Execution, which seamlessly integrates optimized actions into IoT operations. By incorporating Digital Twin technology, the system can simulate various energy consumption scenarios, predict future power demands, and refine decision-making through AI-driven iterative learning. Experimental results demonstrate that our AIoT system achieves a 47.77% reduction in energy consumption compared to non-IoT environments while enhancing automation, adaptability, and user-centric control. Unlike conventional rule-based IoT solutions, integrating Digital Twin with LLM-powered AI Agents enables real-time context-aware decision-making and predictive energy optimization. This study contributes to intelligent IoT applications, Digital Twin-driven energy management, and AI-enhanced automation. Future research will focus on refining AI-driven autonomous decision-making, improving Digital Twin’s predictive accuracy, and further quantifying the impact of LLM-powered AIoT systems on energy efficiency. Our findings highlight the trans-formative potential of LLM-integrated AIoT with Digital Twin technology in revolutionizing energy management for intelligent environments while ensuring seamless interoperability with existing IoT infrastructures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2025.2536 },
  booktitle={ International Conference on Applied System Innovation (ICASI 2025) },
  chapter={0}
}

@article{rayyan-352343737,
  title={ Towards Inclusive Educational AI: Auditing Frontier LLMs for Cultural Biases through a Multiplexity Lens  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Mushtaq, A. and Naeem, R. and Taj, I. and Ghaznavi, I. and Qadir, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016405 },
  abstract={As large language models (LLMs) like GPT-4 and Llama 3 become integral to educational contexts, concerns are mounting over the cultural biases, power imbalances, and ethical limitations embedded within these technologies. Though generative AI tools aim to enhance learning experiences, they often reflect values rooted in Western, Educated, Industrialized, Rich, and Democratic (WEIRD) cultural paradigms, potentially sidelining diverse global perspectives. This paper proposes a framework to assess and mitigate cultural bias within LLMs through applied multiplexity. Multiplexity, inspired by Senturk et al. and rooted in Islamic and other wisdom traditions, emphasizes the coexistence of diverse cultural viewpoints, supporting a multilayered epistemology that integrates empirical sciences and normative values. Our analysis reveals that LLMs frequently exhibit cultural polarization in both overt responses and subtle contextual cues. To address these biases, we propose two strategies: Contextually-Implemented Multiplex LLMs, which embed multiplex principles directly into the system prompt, and Multi-Agent System (MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing distinct cultural viewpoints collaboratively generate balanced responses. Our findings demonstrate that as mitigation strategies evolve from contextual prompting to MAS-implementation, cultural inclusivity markedly improves, evidenced by a significant rise in the Perspectives Distribution Score (PDS) and a PDS Entropy increase from 3.25% at baseline to 98% with the MAS-Implemented Multiplex LLMs. Sentiment analysis shows a shift towards positive sentiment across cultures, with the MAS-Implemented Multiplex LLMs achieving 0% negative sentiment. This study establishes a baseline for assessing and fostering cultural inclusivity in educational AI, laying the groundwork for a globally pluralistic approach that respects diverse cultural perspectives.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016405 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343738,
  title={ Redefining Medicine: The Power of Generative AI in Modern Healthcare  -  2024 5th International Conference on Smart Electronics and Communication (ICOSEC) },
  year={2024},
  author={Hemasri, C. C. and Vijayalakshmi, M. and Jyotheesh, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722592 },
  abstract={This research study examines how generative models, such as large language models (LLMs) and other forms of artificial intelligence (GAI) and other generative models, are revolutionizing healthcare. GAI technologies, such as GPT-based systems and DALL-E, and specialized medical LLMs, such as Med-PaLM and BioGPT, offer cutting-edge solutions for the development of drugs, imaging in medicine, healthcare for patients, and customized treatment planning. These advanced AI models enable the generation of synthetic medical data, facilitating research and innovation while safeguarding patient privacy. GAI enhances diagnostic accuracy, accelerates drug discovery, and aids clinical decision-making by simulating complex medical phenomena and generating realistic datasets for training and validation. These advanced AI models have been assessed using strong performance parameters, demonstrating their primary impact on diagnostic accuracy, drug discovery, and clinical decision-making. Applications range from creating synthetic medical images and predictive models of disease progression to developing tailored therapeutic strategies and optimizing clinical trials. Despite its transformative potential, integrating GAI into healthcare systems presents challenges, including ensuring data security, addressing ethical concerns, and maintaining regulatory compliance. This study provides a comprehensive overview of the advantages, uses, and necessary ethical and technological issues surrounding GAI healthcare today. The potential of GAI and LLMs to transform patient outcomes and promote healthcare is highlighted in this paper through an examination of real-world case studies and future research possibilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICOSEC61587.2024.10722592 },
  booktitle={ 2024 5th International Conference on Smart Electronics and Communication (ICOSEC) },
  chapter={0}
}

@article{rayyan-352343739,
  title={ Performance Analysis and Optimization of Nvidia H100 Confidential Computing for AI Workloads  -  2024 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA) },
  year={2024},
  author={Tan, Y. and Mi, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10885313 },
  abstract={NVIDIA’s H100 Confidential Computing (CC) counters the security hazards inherent in cloud AI workloads. It enforces data encryption to achieve data confidentiality, which leads to substantial throughput reductions as high as 93% in various AI workloads (such as TensorRT, PEFT and vLLM). Confronting this substantial overhead issue, we first delve into the underlying causes through meticulous analysis. This groundwork enables us to devise an innovative runtime system that operates seamlessly in the background, completely transparent to end-users. The cornerstone of our system lies in leveraging multiple encryption workers. Experiments demonstrate that our solution effectively reduces throughput drop to less than 28.1%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISPA63168.2024.00192 },
  booktitle={ 2024 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA) },
  chapter={0}
}

@article{rayyan-352343740,
  title={ DeepDiveAI: Identifying AI-Related Documents in Large Scale Literature Dataset  -  Journal of Social Computing },
  author={Liang, X. and Zhou, X. and Zou, H. and Lu, Y. and Qu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060647 },
  abstract={In this paper, we propose and implement a systematic pipeline for the automatic classification of AI-related documents extracted from large-scale literature databases. This process results in the creation of an AI-related literature dataset named DeepDiveAI. The dataset construction pipeline integrates expert knowledge with the capabilities of advanced models, structured into two primary stages. In the first stage, expert-curated classification datasets are used to train a Long Short-Term Memory (LSTM) model, which performs coarse-grained classification of AI-related records from large-scale datasets. In the second stage, a large language model, specifically Qwen2.5 Plus, is employed to annotate a random 10% of the initially coarse set of classified AI-related records. These annotated records are subsequently used to train a Bidirectional Encoder Representations from Transformers (BERT) based binary classifier, further refining the coarse set to produce the final DeepDiveAI dataset. Evaluation results indicate that the proposed pipeline achieves both accuracy and efficiency in identifying AI-related literature from large-scale datasets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/JSC.2025.0007 },
  booktitle={ Journal of Social Computing },
  chapter={0}
}

@article{rayyan-352343741,
  title={ Turn-Taking and Backchannel Prediction with Acoustic and Large Language Model Fusion  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Wang, J. and Chen, L. and Khare, A. and Raju, A. and Dheram, P. and He, D. and Wu, M. and Stolcke, A. and Ravichandran, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447196 },
  abstract={We propose an approach for continuous prediction of turn-taking and backchanneling locations in spoken dialogue by fusing a neural acoustic model with a large language model (LLM). Experiments on the Switchboard human-human conversation dataset demonstrate that our approach consistently outperforms the baseline models with single modality. We also develop a novel multi-task instruction fine-tuning strategy to further benefit from LLM-encoded knowledge for understanding the tasks and conversational contexts, leading to additional improvements. Our approach demonstrates the potential of combined LLMs and acoustic models for a more natural and conversational interaction between humans and speech-enabled AI agents.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10447196 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343742,
  title={ Local Explanations for Large Language Models: a Brief Review of Methods  -  2024 XXVII International Conference on Soft Computing and Measurements (SCM) },
  year={2024},
  author={Volkov, E. N. and Averkin, A. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554222 },
  abstract={Large Language Models (LLMs) have demonstrated outstanding performance in natural language processing over the past few years. The adoption of LLMs across digital applications in various walks of life is growing exponentially. However, the mechanisms by which LLMs, like all types of artificial neural networks, yield their results remain opaque. This lack of transparency in decision-making poses risks for the further use of the technology. This paper presents a concise review of approaches to obtaining explanations of LLM outcomes. It examines the principal methods of explainable artificial intelligence that are applied to generate explanations for LLM predictions. An approach for classifying local explanation methods is proposed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCM62608.2024.10554222 },
  booktitle={ 2024 XXVII International Conference on Soft Computing and Measurements (SCM) },
  chapter={0}
}

@article{rayyan-352343743,
  title={ From Comments to Insights: Comparing Local and Online LLM Models in Social Media Sentiment Evaluation  -  2025 IEEE 5th International Conference on Smart Information Systems and Technologies (SIST) },
  year={2025},
  author={Suindikovna, R. A. and Gennadievych, N. David and Sadyrbekkyzy, A. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11139353 },
  abstract={Social media platforms such as YouTube, TikTok, and Reddit generate vast amounts of user-generated content, making sentiment analysis essential for understanding public opinion. Traditional sentiment analysis methods often struggle with sarcasm, informal language, and evolving trends, leading to the rise of Large Language Models (LLMs) as more effective alternatives. However, the choice between cloud-based LLMs (e.g., ChatGPT-4o, Gemini 2.0 Flash) and local LLMs (e.g., Meta LLaMA 3.2, DeepSeek-R1 7b) remains an open question, with each approach offering distinct advantages and limitations.This study compares the performance of online and local LLMs in sentiment analysis, focusing on discussions about AI-generated art and cancel culture. Through structured sentiment classification and comparative evaluation, we assess each model’s accuracy, efficiency, and interpretative depth. Our findings indicate that cloud-based models excel in contextual comprehension, while local models provide enhanced privacy and structured data processing. The results highlight the trade-offs between computational power, data security, and adaptability, reinforcing the potential of hybrid approaches that integrate both cloud and local LLM capabilities for more effective sentiment analysis.The goal of this research is to provide a clear evaluation of different LLMs in sentiment analysis, offering practical insights into their strengths and weaknesses. By comparing models from multiple developers, we aim to determine the most effective deployment strategies for real-world applications, ensuring accurate and scalable sentiment evaluation in diverse online discussions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SIST61657.2025.11139353 },
  booktitle={ 2025 IEEE 5th International Conference on Smart Information Systems and Technologies (SIST) },
  chapter={0}
}

@article{rayyan-352343744,
  title={ StuLAC: An Adaptive LLM-Driven Framework for Scalable Student Feedback Analysis in Software-Driven Educational Systems  -  2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC) },
  year={2025},
  author={Sun, Y. and Yu, H. K. and Keung, J. and Cao, Y. and Liao, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126612 },
  abstract={With the growing scalability challenges in higher education, automated student feedback analysis has become crucial for course evaluation and pedagogical improvements. However, traditional methods struggle to handle mixed sentiments, adapt to evolving feedback trends, and maintain computational efficiency. To address these challenges, we propose StuLAC, a Software Engineering-driven framework that integrates Large Language Models (LLMs) with Adaptive Template-Based Caching (ATC). StuLAC employs hierarchical matching for fine-grained classification and dynamically updates feedback templates through context-aware cache refinement. Empirical results on 80,000 student feedback entries demonstrate that StuLAC-generated summaries improve overall quality by 10.5% compared to manually generated reports, while also achieving faster processing times. Additionally, StuLAC attains an 86.4% accuracy and an 86.24% F1-score in sentiment detection. StuLAC’s Feedback Summary Generation provides actionable insights that enhance data-driven decision-making in educational settings. These findings establish StuLAC as a scalable and adaptive solution for improving AI-driven educational feedback systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPSAC65507.2025.00024 },
  booktitle={ 2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC) },
  chapter={0}
}

@article{rayyan-352343745,
  title={ Evaluating LLM-Generated Persian Questions for Teaching Conditional Programming Using Bloom’s Taxonomy  -  2024 11th International Symposium on Telecommunications (IST) },
  year={2024},
  author={Alidadi, M. and Taghiyareh, F. and Shahhoseini, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843532 },
  abstract={The use of Large Language Models (LLMs) to generate educational content is increasingly becoming popular, but we still need to learn more about their effectiveness in non-English languages, especially for professional areas such as teaching computational concepts. Using Bloom’s taxonomy as a framework of assessment, this study evaluates the ability of LLMs to author Persian (Farsi) Learning Objects (LOs) for teaching conditional programming. We provided four LLMs (BloomGPT, Code Tutor, Copilot, and LLaMa) with a prompt in Persian to create educational questions and exercises to teach conditional programming structures to novice learners. A group of experts was asked to evaluate questions generated by LLMs based on their alignment with the specified level of Bloom’s cognitive domain, suitability for teaching conditional programming structures, and clarity in using Persian language. Results show almost no agreement among experts in language clarity and fair agreement on other aspects of the study. BloomGPT proves itself to be dominant overall in Bloom’s Taxonomy, especially at the “Analyze” level. Meanwhile, Copilot closely followed Code Tutor in most aspects of the study. Our findings provide insights into the ability of LLMs to design high-quality Persian learning resources in computer programming.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IST64061.2024.10843532 },
  booktitle={ 2024 11th International Symposium on Telecommunications (IST) },
  chapter={0}
}

@article{rayyan-352343746,
  title={ Prompting LLM for Embodied Tasks with Expert Instruction and Dimension Separation  -  2024 International Conference on Intelligent Robotics and Automatic Control (IRAC) },
  year={2024},
  author={Zhao, G. and Xu, T. and Zhao, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10871329 },
  abstract={With the development of large language models, it has become possible to use multimodal models to build embodied agents. Currently, most approaches for handling embodied intelligence tasks with multimodal large models rely on prompt engineering or fine-tuning the models. However, to construct a general embodied intelligence model, the model needs to transfer world knowledge to corresponding embodied intelligence scenarios and spatial contexts. Language models that have not been optimized for embodied intelligence scenarios lack a good understanding of 3D scenes and the robot's action space. We attempted to address this issue in two ways, separated prompting approach where the model decomposes 3D spatial problems into 2D spatial problems and a trained expert model to guide the general model in spatial perception and action execution. Ultimately, the general model achieved improvements in embodied intelligence tasks. Experimental results demonstrated the effectiveness of our method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IRAC63143.2024.10871329 },
  booktitle={ 2024 International Conference on Intelligent Robotics and Automatic Control (IRAC) },
  chapter={0}
}

@article{rayyan-352343747,
  title={ Supervisor Alignment Framework: Enhancing LLM Alignment with Query-Ignoring Strategy and Multi-Agent Interaction  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Bao, Z. and Ji, Y. and Wu, W. and Chen, X. and He, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890479 },
  abstract={The increasing focus on value alignment in Large Language Models (LLMs) underscores the need to ensure alignment with human morals and avoid biased or harmful outputs. However, LLMs aligned using existing methods are still easily affected by adversarial prompt attacks. Inspired by psychology, this paper introduces a Supervisor Alignment framework, which innovatively incorporates a query-ignoring strategy. This strategy ensures that the supervisor does not receive user queries, preventing it from being influenced by potential adversarial prompts. Meanwhile, the study compares the efficacy of a single supervisor versus a team of supervisors in value alignment tasks. While our designed single-agent supervisor approach utilizes a standalone agent or integrates with Retrieval-Augmented Generation (RAG) techniques, the team approach we proposed emphasizes multi-agent collaboration through voting, cooperation, and debate strategies. Extensive experiments demonstrate that the Supervisor Alignment framework we designed, incorporating the query-ignoring strategy and multi-agent collaboration, effectively defends against adversarial prompts and enhances its performance in value alignment tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10890479 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343748,
  title={ Comparing Transformer-Based Log Anomaly Detection With LLM Explainability In CI/CD Pipelines  -  2025 Intelligent Methods, Systems, and Applications​ (IMSA) },
  year={2025},
  author={Al-Aqrabi, Q. M. and Al-Aqrabi, H. M. and Solayman, M. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167168 },
  abstract={With the DevOps setups of today, automating Continuous Integration and Deployment (CI/CD) pipelines is a necessity for achieving rapid software delivery. These pipelines generate enormous logs, which, despite being useful for debugging and monitoring, become cumbersome to analyze manually. In this comparative study, comparison of anomaly detection models on CI/CD pipeline logs, including classical, deep learning, and transformer-based approaches such as LogBERT is performed. An enhanced LogBERT-based classifier i s p resented, incorporating focal loss, grouped anomaly detection, and temperature scaling for better calibration and comparison with other Log anomaly detection models. The evaluation framework includes a feedback loop that allows user-labeled predictions to be reused for iterative retraining.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMSA65733.2025.11167168 },
  booktitle={ 2025 Intelligent Methods, Systems, and Applications​ (IMSA) },
  chapter={0}
}

@article{rayyan-352343749,
  title={ Generating Medical Diagnostic Scenarios with LLM-Based Reinforcement Learning Feedback: Dataset Release and Methodology  -  2025 IEEE Integrated STEM Education Conference (ISEC) },
  year={2025},
  author={Ananthanarayanan, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147251 },
  abstract={Sample medical scenarios play a crucial role in training healthcare professionals by providing structured cases to develop diagnostic reasoning and clinical decision-making skills. However, access to diverse and inclusive sample diagnostic cases remains challenging due to the limited representation of specific conditions and populations in medical education materials, and existing cases are often not equitable due to a lack of representation of minority groups. In this paper, we present a new dataset of medical diagnostic scenarios generated using a combination of reinforcement learning from artificial intelligence feedback and retrieval augment generation techniques. Despite the dataset’s limited size, it offers a unique resource for advancing medical education, particularly in regions with scarce training materials while also emphasizing inclusivity by incorporating a higher representation of people of color and women. Then, we discuss the data generation process, the dataset structure, and potential applications in medical training programs. This work aims to contribute to the development of accessible, high-quality, and inclusive educational tools in the medical field.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISEC64801.2025.11147251 },
  booktitle={ 2025 IEEE Integrated STEM Education Conference (ISEC) },
  chapter={0}
}

@article{rayyan-352343750,
  title={ A Real-Time Medical Report Analysis and AI-Powered Diagnosis: A Cloud-Based Solution for Improved Patient Care  -  2024 Second International Conference on Advances in Information Technology (ICAIT) },
  year={2024},
  author={Mahalakshmi, M. and Bharadwaj, S. and Bhuyan, A. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690733 },
  abstract={The ever-growing deluge of medical records over- whelms healthcare professionals, jeopardizing timely diagnoses and optimal treatment. This paper proposes an innovative cloud- based solution that automates medical report analysis and lever- ages Artificial Intelligence (AI) to deliver relevant insights, revo- lutionizing patient care. The system integrates a robust Natural Language Processing (NLP) engine within an Extract, Transform, Load (ETL) pipeline. This pipeline seamlessly extracts vital information from unstructured patient reports and test results, meticulously standardizing it for streamlined interoperability. This rich, structured data then fuels Large Language Models (LLM). Using Retrieval Augmented Generation (RAG) we can generate accurate insights into patient reports. These models generate concise summaries, highlighting key clinical findings, and confidently suggest potential diagnoses, aiding physicians in rapid decision-making. The system incorporates interactive data visualizations powered by advanced tools like Quicksight to facilitate deeper exploration and knowledge discovery. Initial testing validates the system's efficacy, demonstrating its ability to accurately summarize critical findings and propose diagnoses with relatively high confidence. This solution holds immense potential to revolutionize healthcare efficiency, optimize resource allocation, and ultimately deliver superior patient outcomes by alleviating the burden of data analysis and providing intelligent medical AI support.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIT61638.2024.10690733 },
  booktitle={ 2024 Second International Conference on Advances in Information Technology (ICAIT) },
  chapter={0}
}

@article{rayyan-352343751,
  title={ Organizing and Augmenting Cybersecurity Knowledge Using Generative AI  -  2025 IEEE 11th International Conference on Network Softwarization (NetSoft) },
  year={2025},
  author={Piemonti, A. and Cianchini, V. and Danousis, M. and Skianis, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11080630 },
  abstract={With the rapid advancements in Artificial Intelligence (AI), cybersecurity threats are becoming increasingly sophisticated. Static, human-curated approaches such as MITRE ATT&CK and CAPEC are often insufficient for companies to implement effective countermeasures, and security experts frequently face challenges in integrating these frameworks into their specific architectures. In this paper, we explore the application of generative AI to organize and enhance cybersecurity knowledge bases. We leverage multiple state-of-the-art Large Language Models (LLMs) to augment an initial dataset of attackmitigation pairs, generating new countermeasures along with their prioritized execution order in a reasonable time frame. To evaluate the generated responses, we employ the LLM-as-aJudge technique. Evaluations with Claude 3.5, DeepSeek R1, and human oversight show that top-performing models on general benchmarks also perform well in this specialized task, with more than 70% of responses rated 4 and 5 out of 5 for correctness, and the weaker models tend to perform the worst. Additionally, we discuss the challenges of running LLMs with a larger number of parameters on less powerful hardware, where the performance of such models can degrade significantly, even performing worse than their smaller counterparts. In such cases, advanced prompt engineering becomes necessary to improve results. Our code and dataset are publicly available at “https://github.com/martel-innovate/HORSE-GenAI-CKB”},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NetSoft64993.2025.11080630 },
  booktitle={ 2025 IEEE 11th International Conference on Network Softwarization (NetSoft) },
  chapter={0}
}

@article{rayyan-352343752,
  title={ Chitrarth: Bridging Vision and Language for a Billion People  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Khan, S. and Tarun, A. and Ravi, A. and Faraz, A. and Pokala, P. K. and Bhangare, A. and Kolla, R. and Khatri, C. and Agarwal, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888601 },
  abstract={Recent multimodal foundation models are primarily trained on English or high resource European language data, which limits their applicability to other medium and low-resource languages, such as the Indian languages. To address this limitation, we introduce Chitrarth (Chitra: Image; Artha: Meaning), an inclusive Vision-Language Model (VLM), specifically targeting the rich linguistic diversity and visual reasoning across 10 prominent Indian languages. Our model effectively integrates a state-of-the-art (SOTA) multilingual Large Language Model (LLM) with a vision module, primarily trained on multilingual image-text data. Furthermore, we also introduce BharatBench, a comprehensive framework for evaluating VLMs across various low resource languages, ultimately contributing to more diverse and effective AI systems. Our model presents SOTA results for benchmarks across Indian languages while retaining its efficiency in English. Through our research, we aim to set new benchmarks in multilingual-multimodal capabilities, offering substantial improvements over existing models and establishing a foundation for facilitating future advancements in this arena.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888601 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343753,
  title={ Establishing a Robust LLMOps Framework for Intelligent Automation: Strategies and Best Practices  -  2025 Emerging Technologies for Intelligent Systems (ETIS) },
  year={2025},
  author={Krishnamurthy, D. and Neelanath, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10961869 },
  abstract={This paper delves into the establishment of a robust LLMOps framework, crucial for intelligent automation in modern enterprises. LLMOps for intelligent automation platforms require composability and capability to use different architectures, embeddings, and Generative AI models seamlessly with domain focus. In this paper we discuss an architecture we designed for UST SmartOps, UST's Intelligent Automation platform, keeping automation at its core. Large Language Models (LLMs) have significantly advanced AI capabilities in natural language processing and understanding, but their deployment and management, integration and using them effectively for automation use cases pose unique challenges. LLMOps, similar to DevOps and MLOps, is dedicated to the operationalization of these models, addressing infrastructure, performance optimization, security, and continuous improvement. The paper outlines the strategies and best practices essential for LLMOps, emphasizing data management, model monitoring, and the integration of AI with automation to improve operational efficiency, reduce costs, and improve decision-making processes. Through systematic orches-tration of tools, processes, and infrastructure, the document aims to provide a comprehensive guide to effectively leverage LLMs within intelligent automation frameworks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETIS64005.2025.10961869 },
  booktitle={ 2025 Emerging Technologies for Intelligent Systems (ETIS) },
  chapter={0}
}

@article{rayyan-352343754,
  title={ Visualizing Source Code as Comics Using Generative AI  -  2023 IEEE Working Conference on Software Visualization (VISSOFT) },
  year={2023},
  author={Heidrich, D. and Schreiber, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350098 },
  abstract={The architecture and inner structure of software is often only implicitly available in the form of its source code and thus not tangible and intuitively easy to understand for non-programmers and laymen. Our goal is to create visualizations as automatically as possible, with which such people can neverthe-less understand the software or parts of the software and get a feel for the structure of the software and how its methods work. Especially for newcomers to software projects, for management or even for students and pupils, it can be helpful to get a non-technical insight into the software. We use the concept of visualizing information as comics to present aspects of the software as strikingly as possible, as comics are an effective way to present complex systems and interrelationships for certain target groups. For this purpose, we present a method to generate comics from source code. Our semi-automated process is based on generating a prompt for an LLM from source code, which in turn generates a prompt for a comic image generation using the text-to-image model Stable Diffusion. We show that generative AI methods can be used to rapidly generate human-compatible artistic representations from source code. However, further research is needed to validate the understandability of the results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VISSOFT60811.2023.00014 },
  booktitle={ 2023 IEEE Working Conference on Software Visualization (VISSOFT) },
  chapter={0}
}

@article{rayyan-352343755,
  title={ Gen AI Driven FAQ Chatbot Using Advanced RAG Architecture for Querying Annual Reports  -  2025 International Conference on Computing and Communication Technologies (ICCCT) },
  year={2025},
  author={K, M. and Kanagavalli, V. R. and R, S. K and N, G. P and P, S. M and U, S. and R, G. and S, G. and R, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11020025 },
  abstract={In the rapidly evolving business landscape, stakeholders require timely and accurate access to financial and operational information from annual reports. However, the extensive and complex nature of these reports makes it difficult to efficiently extract key analytical trends, financial performance measures, and comparative insights. The traditional manual approach to analyse these documents is time-consuming, error prone, and inefficient. Stakeholders-including creditors, customers, suppliers, employees, government agencies, and industry analysts-rely on this data to make informed decisions. The absence of an automated mechanism to handle frequent queries regarding financial performance, operational metrics, and sustainability targets impedes large-scale informed decision making. This paper presents a Gen AI-driven solution that leverages Natural Language Processing (NLP), LangChain Framework and Retrieval Augmented Generation (RAG) Architecture to efficiently extract and analyze financial annual reports and its data. The approach involves utilizing PyPDF2 for data extraction, segmenting content using RecursiveCharacterTextSplitter, generating embeddings via FastEmbedEmbeddings module, and storing information in Qdrant for rapid similarity search. The response generation is powered by DeepSeek LLM, deployed locally via Ollama, ensuring privacy and computational efficiency. A Gradio-based UI is implemented for an intuitive interface. This system enhances financial data accessibility, fostering transparency, compliance, and data-driven decision-making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCT63501.2025.11020025 },
  booktitle={ 2025 International Conference on Computing and Communication Technologies (ICCCT) },
  chapter={0}
}

@article{rayyan-352343756,
  title={ AI Circuit Builder: Bridging Language & Logic  -  2025 International Conference on Visual Analytics and Data Visualization (ICVADV) },
  year={2025},
  author={T, S. D. and G, R. and K, J. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10960965 },
  abstract={Circuit design is one of the initial stages of any electronic & electrical projects. It has been a hard part of building a product since, it can be easily solved only by professional developers. In order to solve this part, a tool is build that combines both the core knowledge of electronics & artificial intelligence. AI circuit builder is a tool that can be used by people who are beginners and don't really have a particular knowledge in a specific part of the circuit. The user can easily prompt the LLM in the form of natural language. The tool then generates a digital format for the desired output. The output is processed with a routing algorithm in order to sort out the routes. With the help of various modern technologies for the web the tool provides a seamless user experience overall.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICVADV63329.2025.10960965 },
  booktitle={ 2025 International Conference on Visual Analytics and Data Visualization (ICVADV) },
  chapter={0}
}

@article{rayyan-352343757,
  title={ DrVideo: Document Retrieval Based Long Video Understanding  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Ma, Z. and Gou, C. and Shi, H. and Sun, B. and Li, S. and Rezatofighi, H. and Cai, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093394 },
  abstract={Most of the existing methods for video understanding primarily focus on videos only lasting tens of seconds, with limited exploration of techniques for handling long videos. The increased number of frames in long videos poses two main challenges: difficulty in locating key information and performing long-range reasoning. Thus, we propose DrVideo, a document-retrieval-based system designed for long video understanding. Our key idea is to convert the long-video understanding problem into a long-document understanding task so as to effectively leverage the power of large language models. Specifically, DrVideo first transforms a long video into a coarse text-based long document to initially retrieve key frames and then updates the documents with the augmented key frame information. It then employs an agent-based iterative loop to continuously search for missing information and augment the document until sufficient question-related information is gathered for making the final predictions in a chain-of-thought manner. Extensive experiments on long video benchmarks confirm the effectiveness of our method. DrVideo significantly outperforms existing LLM-based state-of-the-art methods on EgoSchema benchmark (3 minutes), MovieChat-1K benchmark (10 minutes), and the long split of Video-MME benchmark (average of 44 minutes). Code is available at https://github.com/Upper9527/DrVideo.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.01764 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343758,
  title={ Evaluating RAG Pipeline in Multimodal LLM-based Question Answering Systems  -  2024 3rd International Conference on Automation, Computing and Renewable Systems (ICACRS) },
  year={2024},
  author={Barochiya, M. and Makhijani, P. and Patel, H. N. and Goel, P. and Patel, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10841620 },
  abstract={Recent improvements have increased the adoption of Multimodal Large Language Models (MLLMs) over traditional uni-modal systems since they can manage and combine information from several types of data. However, current multimodal systems have certain limitations, particularly when it comes to retrieving relevant information for domain-specific queries. This study investigates how Retrieval-Augmented Generation (RAG) approaches can help multimodal LLMs provide more contextually accurate answers from external data sources for Question and Answering (Q&A) systems. The research compares two state-of-the-art models—Google's Gemini-1.0-Pro and OpenAI's GPT-4o-mini for a Q&A system that utilizes Multimodal RAG architecture. Additionally, the study incorporates several embedding models, including Text-embedding-ada-002-v2 and embedding-001, to further improve retrieval performance. In the absence of any standardized criterion, the study used a custom-made multimodal dataset and evaluated the system using six metrics defined by human analysis. The results revealed that using RAG with multimodal LLMs greatly improves performance in Q&A tasks, with GPT-4o-mini slightly outperforming Gemini-1.0-Pro by 5%. These findings promote advancements for research in the field of Multimodal-RAG systems and highlight their potential for much better information retrieval in specialized areas.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICACRS62842.2024.10841620 },
  booktitle={ 2024 3rd International Conference on Automation, Computing and Renewable Systems (ICACRS) },
  chapter={0}
}

@article{rayyan-352343759,
  title={ LLM Driven Smart Assistant for Data Mapping  -  2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP) },
  year={2025},
  author={Bedagkar, A. and Mitra, S. and Medicherla, R. and Naik, R. and Pal, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121739 },
  abstract={Data mapping is a crucial step during application migration and application integration. Data (model) mapping comprises “schema matching” to identify semantically equivalent fields between two schemas and ”transformation logic”, a set of rules for converting data from one schema to another. In current industry practice, data mapping is largely manual, performed by domain experts. We present a data mapping solution powered by Large Language Models (LLMs), offering significant improvements in precision over state-of-the-art (SOTA) methods, along with multiple automation workflows that allow users to provide various input triggers (context) for inferring the mappings. We illustrate this contribution using several representative industrial datasets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE-SEIP66354.2025.00022 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP) },
  chapter={0}
}

@article{rayyan-352343760,
  title={ LLM-based Generation of Formal Specification for Run-time Security Monitoring of ICS  -  2025 IEEE International Conference on Cyber Security and Resilience (CSR) },
  year={2025},
  author={Raptis, G. E. and Khan, M. T. and Koulamas, C. and Serpanos, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130130 },
  abstract={Industrial Control Systems (ICS) are vulnerable to cybersecurity threats due to their distributed architecture and critical role in infrastructure sectors. Ensuring their secure operation requires deploying runtime monitoring mechanisms to detect behavioral deviations, with inline security monitoring arising as a practical solution. However, writing these specifications manually is time-consuming, error-prone, and requires deep domain expertise. In this paper, we explore the feasibility of using large language models (LLMs) to assist in generating JML-based inline security monitors for ICS applications. Using a water distribution system as a testbed, we prompt the model with structured templates and evaluate its output against expertwritten specifications. Our results highlight that LLMs can correctly infer key security properties and produce contextaware assertions with minimal guidance, marking an early but promising step toward automated monitor synthesis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSR64739.2025.11130130 },
  booktitle={ 2025 IEEE International Conference on Cyber Security and Resilience (CSR) },
  chapter={0}
}

@article{rayyan-352343761,
  title={ LLM-Powered Framework for Interpretable Traffic Rule Processing in Autonomous Driving  -  2025 IEEE 34th International Symposium on Industrial Electronics (ISIE) },
  year={2025},
  author={Carvalho, J. D. and de Souza Forte, F. and Taciro, H. K. and Melo, G. and Santos, M. M. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124633 },
  abstract={Traffic rules are essential for ensuring road safety and efficient transportation, yet their complexity and regional variability pose significant challenges for human drivers and autonomous systems. This paper introduces the Automatic Interpretable Traffic Rules (AITR) framework, which leverages Large Language Models (LLMs) to process, interpret, and structure diverse traffic regulations into machine-readable formats suitable for integrating autonomous driving and driver assistance systems. Unlike traditional perception pipelines, AITR bridges unstructured legal texts with real-time environmental data to enable context-aware, legally compliant decision-making. The framework incorporates explainability techniques to generate human-interpretable justifications for each decision, enhancing transparency, trust, and regulatory alignment. We evaluate AITR using real-world multimodal driving datasets and simulation environments, demonstrating its ability to generalize across jurisdictions, adapt to evolving regulations, and improve decision accuracy in complex traffic scenarios. The results show that our approach enhances rule comprehension, reduces ambiguity, and contributes to safer and more interpretable autonomous navigation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISIE62713.2025.11124633 },
  booktitle={ 2025 IEEE 34th International Symposium on Industrial Electronics (ISIE) },
  chapter={0}
}

@article{rayyan-352343762,
  title={ Chatting with AI: Deciphering Developer Conversations with ChatGPT  -  2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR) },
  year={2024},
  author={Mohamed, S. and Parvin, A. and Parra, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555805 },
  abstract={Large Language Models (LLMs) have been widely adopted and are becoming ubiquitous and integral to software development. However, we have little knowledge as to how these tools are being used by software developers beyond anecdotal evidence and word-of-mouth reports. In this work, we present a study toward understanding how developers engage with and utilize LLMs by reporting the results of an empirical study identifying patterns in the conversation that developers have with LLMs. We identified a total of 19 topics describing the purpose of the developers in their conversations with LLMs. Our findings reveal that developers use LLMs to facilitate various aspects of their software development processes (e.g., information-seeking about programming languages and frameworks and soliciting high-level design recommendations) to a similar extent to which they use them for non-development purposes such as writing assistance, general purpose queries, and conducting Turing tests to assess the intrinsic capabilities of the models. This work not only sheds light on the diverse applications of LLMs in software development but also underscores their emerging role as critical tools in enhancing developer productivity and creativity as we move closer to widespread AI-assisted software development.CCS CONCEPTS• General and reference → Empirical studies; • Information systems → Data mining; • Computing methodologies → Artificial intelligence; Distributed artificial intelligence; • Software and its engineering;},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR) },
  chapter={0}
}

@article{rayyan-352343763,
  title={ RefAssist: An AI Based Voice Assistant Framework to Notify Hospital Referral for Pregnant Women in Bangladesh  -  2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI) },
  year={2025},
  author={Pias, S. A. and Tithi, N. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108788 },
  abstract={Pregnant women in rural areas of Bangladesh are often referred to various medical centers in the process of their antenatal care (ANC). However, there are cases when they or their family members forget or ignore these referrals. Text message reminders have been used to rectify the issue, but they too often go unnoticed. Voice calls can be suitable for the reminder, but appointing a person to make numerous calls can be tedious in nature for the caller, and the enthusiasm can be reduced after a while. In this paper, we propose an AI-generated voice call framework to address the challenge of reminders in an automated manner, a more effective approach than human-assisted calls, which can become monotonous for the caller, especially when a large number of calls are to be made. This approach ensures that expectant mothers and their families receive timely reminders, improving adherence to ANC referrals while reducing the burden on human assistants.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SEAI65851.2025.11108788 },
  booktitle={ 2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI) },
  chapter={0}
}

@article{rayyan-352343764,
  title={ “Who's Doing the Thinking Here?”: A Pedagogy-First Approach to Integrating Large Language Models in Higher Education  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Jackson, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016560 },
  abstract={Large Language Models (LLMs), a subset of Generative Artificial Intelligence (GenAl), have been popularised through the widely publicised launch of tools such as ChatGPT. While capable of responding to human input in an apparently conversational manner, these models do not possess understanding in the same way that humans do and their outputs, based on probabilistic algorithms, are susceptible to presenting falsehoods as facts (hallucinations). Despite the risks, there are potential benefits for embedding LLMs in learning experiences if educators can cultivate a safe learning environment that supports students' interactions with LLMs while empowering students to develop their higher-order thinking skills (HOTS). Educators should be empowered to make well-informed decisions about the use of LLMs and help students work towards co-creation in collaboration with LLMs without compromising academic integrity or their own agency. In the context of GenAl, the apposite question has become “who's doing the thinking here?”, particularly with the prevalence of LLM outputs which are adept at masquerading as intelligent thought. Bloom's revised taxonomy is proposed as an effective lens through which educators can evaluate the use of LLMs in subject-specific learning contexts, particularly with a focus on developing students' HOTS. Some practical examples of prompts are included for educators to try as part of their own experimentation with GenAl. This paper aims to empower educators by offering an initial set of “Higher Order Prompting” principles to support the decision making of how - or indeed if - to use LLMs with students, while contributing to the ongoing discourse of how Generative AI is impacting Higher Education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016560 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343765,
  title={ Generative AI-Driven Personnel Training in Industrial Robotics through Intelligent HXM  -  2024 International Conference Automatics and Informatics (ICAI) },
  year={2024},
  author={Stoykova, S. and Shakev, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851547 },
  abstract={The aim of this paper is to present a developed solution for integrating an AI digital assistant as a service on one of the most widely used ERP platforms – SAP. The digital assistant is based on a popular large language model GPT-2 and has been trained locally on manuals and technical documentation for a Mitsubishi industrial robot as well as a command database for the programming language MELFA Basic V. The main task of the digital assistant is to contribute to the workforce on-boarding and training processes as a human experience management tool. The developed digital assistant service is made freely available via web-browser access to students in its testing stage.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAI63388.2024.10851547 },
  booktitle={ 2024 International Conference Automatics and Informatics (ICAI) },
  chapter={0}
}

@article{rayyan-352343766,
  title={ Analyzing the efficacy of Deep Learning and Transformer models in classifying Human and LLM-Generated Text  -  2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA) },
  year={2024},
  author={Goswami, A. and Kaur, G. and Tayal, S. and Verma, A. and Verma, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10775153 },
  abstract={Large Language Models (LLM) are widely accepted by the humans for their powerful ability to understand, follow and create human-like text. The text generation capabilities of LLMs have reached such a height that it is now comparable to text generated by human.LLMs are a powerful subset of Artificial Intelligence (AI)models, trained on huge amount of human-written text to create indistinguishable content. AI models have taken an important step ahead in constructing hyper-realistic content which can be in any modality such as text, image, and video. The output content generated by these models can be hard to distinguish from human-written content as these models are iteratively trained on texts written by human. Further this has got serious implications across various domains, including news reporting, information fraud, academic plagiarism, data manipulation, financial fraud, theft and deep fakes. The abilities of AI-generated text pose a significant challenge, blurring the lines of differentiation between human and machine-created content. Therefore, to effectively navigate the evolving landscape of AI-generated text, we need a robust and reliable AI text detection model. This study leverages a substantial dataset of 100,000 entries. empowering our model with adaptability across various domains. By employing diverse word embedding techniques along with machine and deep learning models, we explore optimal configurations for exceptional performance. Notably, we implement pre-trained models like BERT and DeBERTa on this extensive corpus, potentially representing the first such application. The resulting models demonstrate remarkable accuracy exceeding 95% across all configurations, signifying a robust advancement in differentiating AI generated text from human written one.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCUBEA61740.2024.10775153 },
  booktitle={ 2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA) },
  chapter={0}
}

@article{rayyan-352343767,
  title={ Retrieval-Augmented Generation for Pharmacopoeia: Application and Evaluation  -  2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  year={2024},
  author={Fahmi, R. and Cheon, S. and Park, Y. and Kwon, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990109 },
  abstract={Pharmacopoeia documents are used in pharmaceutical companies as references for ensure safe handling of chemical compounds. However, manual review of these documents can be time-consuming and prone to human error. To assist users in working with these documents, we designed PharmChat, a retrieval-augmented generation (RAG)-based system which enables efficient question-and-answer interactions with multiple short pharmacopoeia documents using natural language. In contrast to other conventional RAG systems, PharmChat converts original pharmacopoeia into separate documents to avoid context mixing during document chunking. PharmChat leverages embedding-based similarity searches between the documents as knowledge-base and user queries using an open-source vector database, ChromaDB. Upon receiving a user query, the most relevant chunks are retrieved and provided as context for a large language model (LLM) to be used as reference to minimize hallucination. Experimental results with real pharmacopoeia short documents demonstrate that our PharmChat system provides quick response times and achieves a BERT-F1 score of 76%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxDKE63520.2024.00032 },
  booktitle={ 2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  chapter={0}
}

@article{rayyan-352343768,
  title={ Infographics Generator: A Smart Application for Visual Summarization  -  2023 16th International Conference on Developments in eSystems Engineering (DeSE) },
  year={2023},
  author={Nath, M. and Ethirajan, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10469225 },
  abstract={Visuals help in quickly interpreting complex information. Infographics are visual representations of information, that use charts, icons, or graphical illustrations with minimal text. Manually summarizing information into an infographic representation is not only a time-consuming activity but also requires additional skills in terms of tools and domain knowledge. Here we present a novel idea to perform a smart info-graphical summarization of any audio, video, voice, text input, using generative AI techniques. The input contents are fed into a preprocessor, which uses video converters and speech-to-text algorithms, to consolidate the input into a single text document. From this text, a summary is generated by using pre-trained language models. Along with it, the keywords associated with each of the summary entries are extracted. Based on the keywords, the most relevant icons and graphic assets are picked from the image library. A suitable infographic template is identified based on the topic and an intuitive infographic is generated. An infographic not only provides a quick overview of the contents but also reduces the cognitive load or the mental energy required to interpret the contents otherwise. This solution can thus provide a crisp summary in near real-time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DeSE60595.2023.10469225 },
  booktitle={ 2023 16th International Conference on Developments in eSystems Engineering (DeSE) },
  chapter={0}
}

@article{rayyan-352343769,
  title={ ELLIE: Energy-Efficient LLM Inference at the Edge Via Prefill-Decode Splitting  -  2025 IEEE 36th International Conference on Application-specific Systems, Architectures and Processors (ASAP) },
  year={2025},
  author={Fan, H. and Lin, Y. -C. and Prasanna, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113611 },
  abstract={As Large Language Models (LLMs) are increasingly deployed for on-device applications, optimizing inference on edge platforms becomes critical. In real-world scenarios, LLM inference must satisfy diverse constraints and user requirements, such as low latency, high energy efficiency, or low Energy-Delay Product (EDP). Most state-of-the-art edge platforms, such as AI PCs and mobile SoCs, integrate heterogeneous processing units, including CPUs, GPUs, and Neural Processing Units (NPUs), each with distinct performance and power characteristics. However, existing approaches often adopt static mapping to a single processing unit (e.g., CPU, GPU, or NPU) and perform optimizations for either latency or energy consumption. This limits their effectiveness in meeting the requirements of diverse application scenarios. Moreover, LLM inference consists of two distinct phases: a highly parallel, compute-intensive Prefill phase, and a sequential, memory-intensive Decode phase. These phases have different computational characteristics, and splitting them across suitable processing units can potentially yield better energy efficiency and EDP than static mapping. However, such improvements may not be realized in all cases, as the actual benefit depends on many factors, including prompt characteristics, the models used, and features of the target hardware. To address these challenges, we propose ellie, a lightweight inference framework for edge heterogeneous platforms that dynamically selects the optimal execution plan based on the usage scenario, LLM, hardware feature, and input prompt. ELLIE builds performance models by regressing latency and power from offline profiling data, and integrates it with a lightweight output token length predictor. At runtime, it estimates the latency and energy of candidate execution plans using the predicted output length and selects an optimized device mapping accordingly. We implement ellie on an Intel AI PC platform with integrated CPU, GPU, and NPU. On average, when optimizing for EDP, ELLIE reduces energy consumption by $1.8 \times$, improves EDP by $1.5 \times$, and achieves latency comparable to GPU-only inference, across diverse LLMs and prompt types.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASAP65064.2025.00031 },
  booktitle={ 2025 IEEE 36th International Conference on Application-specific Systems, Architectures and Processors (ASAP) },
  chapter={0}
}

@article{rayyan-352343770,
  title={ The cost perspective of adopting Large Language Model-as-a-Service  -  2024 IEEE International Conference on Joint Cloud Computing (JCC) },
  year={2024},
  author={Liagkou, V. and Filiopoulou, E. and Fragiadakis, G. and Nikolaidou, M. and Michalakelis, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685415 },
  abstract={Large Language Models (LLMs) are pivotal in generative AI applications. Consequently, major cloud providers, such as Amazon, Azure, and Google, introduce the offering of LLM-as-a-Service (LLMaaS) products to enable businesses to leverage NLP, data analysis, and predictive modeling in their cloud solutions. This paper explores the incorporation of LLM-as-a-Service solutions into business workflows with a focus on inference costs. We review various LLMaaS offerings and conduct a comparative analysis based on a real-world case study of an AI chatbot.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JCC62314.2024.00020 },
  booktitle={ 2024 IEEE International Conference on Joint Cloud Computing (JCC) },
  chapter={0}
}

@article{rayyan-352343771,
  title={ Optimizing Large Language Models for Auto-Generation of Programming Quizzes  -  2024 IEEE Integrated STEM Education Conference (ISEC) },
  year={2024},
  author={Kumar, Y. and Manikandan, A. and Li, J. J. and Morreale, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10665141 },
  abstract={This study analyzes the use of Large Language Models (LLMs) like ChatGPT in creating quizzes for Java programming courses, specifically Object-Oriented Programming (CS1) and Data Structures (CS2). It aims to evaluate the accuracy of LLM-generated assessments, understand the benefits and drawbacks of using LLMs in CS education from educators' viewpoints, and identify effective prompt engineering strategies to enhance the quality of educational materials. The research compares quizzes made by LLMs against human-created content to assess their consistency with Java programming principles, alignment with CS1 and CS2 learning goals, and their impact on student engagement and comprehension, providing insights into LLMs' effectiveness in academic assessment creation for computer science education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISEC61299.2024.10665141 },
  booktitle={ 2024 IEEE Integrated STEM Education Conference (ISEC) },
  chapter={0}
}

@article{rayyan-352343772,
  title={ Generative AI Beyond LLMs: System Implications of Multi-Modal Generation  -  2024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) },
  year={2024},
  author={Golden, A. and Hsia, S. and Sun, F. and Acun, B. and Hosmer, B. and Lee, Y. and DeVito, Z. and Johnson, J. and Wei, G. -Y. and Brooks, D. and Wu, C. -J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10590047 },
  abstract={As the development of large-scale Generative AI models evolve beyond text (1D) generation to include image (2D) and video (3D) generation, processing spatial and temporal information presents unique challenges to quality, performance, and efficiency. We present the first work towards understanding this new system design space for multi-modal text-to-image (TTI) and text-to-video (TTV) generation models. Current model architecture designs are bifurcated into 2 categories: Diffusion-and Transformer-based models. Our systematic performance characterization on a suite of eight representative TTI/TTV models shows that after state-of-the-art optimization techniques such as Flash Attention are applied, Convolution accounts for up to 44% of execution time for Diffusion-based TTI models, while Linear layers consume up to 49 % of execution time for Transformer-based models. We additionally observe that Diffusion-based TTI models resemble the Prefill stage of LLM inference, and benefit from 1.1-2.5x greater speedup from Flash Attention than Transformer-based TTI models that resemble the Decode phase. Since optimizations designed for LLMs do not map directly onto TTI/TTV models, we must conduct a thorough characterization of these workloads to gain insights for new optimization opportunities. In doing so, we define sequence length in the context of TTI/TTV models and observe sequence length can vary up to 4x in Diffusion model inference. We additionally observe temporal aspects of TTV workloads pose unique system bottlenecks, with Temporal Attention accounting for over 60 % of total Attention time. Overall, our in-depth system performance characterization is a critical first step towards designing efficient and deployable systems for emerging TTI/TTV workloads.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISPASS61541.2024.00032 },
  booktitle={ 2024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) },
  chapter={0}
}

@article{rayyan-352343773,
  title={ Large Language Models Powered Context-aware Motion Prediction in Autonomous Driving  -  2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  year={2024},
  author={Zheng, X. and Wu, L. and Yan, Z. and Tang, Y. and Zhao, H. and Zhong, C. and Chen, B. and Gong, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802397 },
  abstract={Motion prediction is among the most fundamental tasks in autonomous driving. Traditional methods of motion forecasting primarily encode vector information of maps and historical trajectory data of traffic participants, lacking a comprehensive understanding of overall traffic semantics, which in turn affects the performance of prediction tasks. In this paper, we utilized Large Language Models (LLMs) to enhance the global traffic context understanding for motion prediction tasks. We first conducted systematic prompt engineering, visualizing complex traffic environments and historical trajectory information of traffic participants into image prompts— Transportation Context Map (TC-Map), accompanied by corresponding text prompts. Through this approach, we obtained rich traffic context information from the LLM. By integrating this information into the motion prediction model, we demonstrate that such context can enhance the accuracy of motion predictions. Furthermore, considering the cost associated with LLMs, we propose a cost-effective deployment strategy: enhancing the accuracy of motion prediction tasks at scale with 0.7% LLM-augmented datasets. Our research offers valuable insights into enhancing the understanding of traffic scenes of LLMs and the motion prediction performance of autonomous driving. The source code is available at https://github.com/AIR-DISCOVER/LLM-Augmented-MTR and https://aistudio.baidu.com/projectdetail/7809548.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IROS58592.2024.10802397 },
  booktitle={ 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  chapter={0}
}

@article{rayyan-352343774,
  title={ Future of Connectivity: A Comprehensive Review of Innovations and Challenges in 7G Smart Networks  -  IEEE Open Journal of the Communications Society },
  author={Chamola, V. and Peelam, M. Shall and Guizani, M. and Niyato, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963909 },
  abstract={The evolution from 1G to 6G networks has transformed global communication, progressing from basic voice calls in 1G to the immersive, AI-enabled experiences of 6G. As emerging AI-driven applications like autonomous systems, the Internet of Everything (IoE), and immersive technologies demand unprecedented capabilities, 7G networks are set to redefine connectivity by overcoming the limitations of earlier generations. This paper comprehensively reviews the innovations and challenges in 7G networks, focusing on integrating advanced AI and machine learning paradigms such as meta-learning, incremental learning, distributed intelligence, and reinforcement learning to enhance adaptability, resource allocation, and edge performance. The review also examines the role of Large Language Models (LLMs) in enabling real-time actionable intelligence and optimizing edge devices within 7G. The paper highlights the use of technologies, including blockchain for decentralized security, quantum computing for robust encryption, terahertz communication for ultra-fast data transfer, zero-energy solutions for sustainability, and generative AI for intelligent network optimization and automation. By addressing these challenges and exploring cutting-edge strategies, this paper envisions 7G networks as the foundation for a secure, intelligent, and sustainable digital future, equipped to combat emerging cyber warfare threats, enhance resilience against technological disruptions, and support innovations across smart cities, autonomous systems, healthcare, and industrial IoT.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OJCOMS.2025.3560035 },
  booktitle={ IEEE Open Journal of the Communications Society },
  chapter={0}
}

@article{rayyan-352343775,
  title={ Mitigating Clinician Information Overload: Generative AI for Integrated EHR and RPM Data Analysis  -  2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC) },
  year={2025},
  author={Shetgaonkar, A. and Pradhan, D. and Arora, L. and Girija, S. S. and Raj, A. and Kapoor, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126578 },
  abstract={Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), offer powerful capabilities for interpreting the complex data landscape in healthcare. In this paper, we present a comprehensive overview of the capabilities, requirements and applications of GenAI for deriving clinical insights and improving clinical efficiency. We first provide some background on the forms and sources of patient data, namely real-time Remote Patient Monitoring (RPM) streams and traditional Electronic Health Records (EHRs). The sheer volume and heterogeneity of this combined data present significant challenges to clinicians and contribute to information overload.In addition, we explore the potential of LLM-powered applications for improving clinical efficiency. These applications can enhance navigation of longitudinal patient data and provide actionable clinical decision support through natural language dialogue. We discuss the opportunities this presents for streamlining clinician workflows and personalizing care, alongside critical challenges such as data integration complexity, ensuring data quality and RPM data reliability, maintaining patient privacy, validating AI outputs for clinical safety, mitigating bias, and ensuring clinical acceptance. We believe this work represents the first summarization of GenAI techniques for managing clinician data overload due to combined RPM / EHR data complexities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPSAC65507.2025.00284 },
  booktitle={ 2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC) },
  chapter={0}
}

@article{rayyan-352343776,
  title={ AAINA: Autonomous and Autogenerative Integrable Narrative All-Purpose Chatbot Using Regenerative AI  -  2024 International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3) },
  year={2024},
  author={Singhal, A. and Singh, A. and Sripesh, A. and Pandey, N. K. and Mishra, A. K. and Dumka, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827618 },
  abstract={This document is about evolution of Generative AI and Large Language Models to make multipurpose chatbots. It revolves around how the appropriate models are selected, trained on the required data, then further fine-tuned for customization, optimization and deployment, and final augmentation with the help of certain frameworks to get better results and model performance. This paper offers comprehensive instructions for developing AAINA, an LLM-powered chatbot because AAINA can process many input formats, like text, voice, images, and video. It can be highly customized to work with different communication channels. The paper also explores how Natural Language Processing (NLP) methods can be combined with LLMs to create a chatbot that can hold individual and meaningful conversations. The paper describes the potential uses of AAINA in different industries, such as IT, education, law, automotive, and medical industry, showcasing its capability to provide 24/7 assistance and effectively resolve user issues. Through the process of fine-tuning AAINA, users can fine-tune the chatbot for specific requirements, enabling a personalized and optimal user experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC2E362166.2024.10827618 },
  booktitle={ 2024 International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3) },
  chapter={0}
}

@article{rayyan-352343777,
  title={ CE-CoLLM: Efficient and Adaptive Large Language Models Through Cloud-Edge Collaboration  -  2025 IEEE International Conference on Web Services (ICWS) },
  year={2025},
  author={Jin, H. and Wu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169709 },
  abstract={Large Language Models (LLMs) exhibit remarkable human-like predictive capabilities. However, it is challenging to deploy LLMs to provide efficient and adaptive inference services at the edge. This paper proposes a novel Cloud-Edge Collaboration framework for LLMs (CE-CoLLM) to tackle these challenges. First, we identify the transmission of LLM contextual data between the cloud and edge as a key performance bottleneck, which introduces substantial communication overhead that dominates overall inference latency and makes naïve cloudedge collaboration for LLMs inefficient. Second, we introduce a suite of novel techniques, including a latency-aware early exit mechanism and efficient cloud context management, into CECoLLM, which collectively reduce communication overhead and preserve LLM inference accuracy. Third, we design two adaptive inference modes to accommodate diverse edge environments: (1) a low-latency standalone edge inference mode that enables reliable edge-side independent LLM inference even under unstable network conditions, and (2) a high-accuracy cloud-edge collaborative inference mode that adaptively leverages cloud resources to enhance prediction accuracy. Extensive experiments on multiple benchmark datasets demonstrate that CE-CoLLM reduces overall inference time by up to 13.81% and offloads over 84.53% of the computational workload from the cloud to the edge, compared to conventional cloud-based LLM deployment, without sacrificing prediction accuracy. The code is provided on GitHub at https://github.com/mlsysx/CE-CoLLM.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS67624.2025.00046 },
  booktitle={ 2025 IEEE International Conference on Web Services (ICWS) },
  chapter={0}
}

@article{rayyan-352343778,
  title={ A Framework for automated selective Fine-Tuning of Domain-Specific Large Language Models Using Graph-Based Retrieval Augmented Generation  -  2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) },
  year={2024},
  author={Govindharajan, H. and Vijayakumar, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754778 },
  abstract={Graph based retrieval augmented generation technique in Large Language Model (LLM) brings in major advantages by providing deep context to LLMs through relational knowledge graph for text generation, classification, question and answering use cases. However, maintaining vast data volume of domain specific data in a knowledge graph with complex relationships and querying from it every time a prompt is being posted to LLM, is a time consuming and expensive process. This paper presents a novel framework for selectively fine-tuning domain-specific large language models (LLMs) using a multi-stage Knowledge Graph (KG) based Retrieval Augmented Generation (RAG) pipeline and an Automated Incremental Fine-tuning System (AIFS). The proposed system aims to enhance the accuracy and relevance of LLM responses for text generation and Question Answering use cases by finetuning the LLM incrementally based on highly sought and highly relevant information in knowledge graph identified by leveraging page rank algorithm in KG. The framework comprises three major subsystems: Knowledge Graph Generation, Automated Incremental fine-tuning system (AIFS), and Domain Based Information Retrieval (DBIR). The effectiveness of the system is demonstrated through its ability to incrementally fine-tune LLMs based on selected highly relevant nodes within the KG, thereby improving the model’s domain-specific knowledge, response accuracy by 90% and reduce cost by 71.8%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UEMCON62879.2024.10754778 },
  booktitle={ 2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) },
  chapter={0}
}

@article{rayyan-352343779,
  title={ Generative AI in Focus : A Comprehensive Review of Leading Models Across Modalities  -  2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS) },
  year={2024},
  author={S, A. and C, S. and G, P. K. and B, N. and J, M. P. and A, M. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10867014 },
  abstract={GenAI has revolutionized the generation of realistic and imaginative data in ways that were previously beyond the capabilities of other machine learning algorithms. This area is rapidly gaining traction, with extensive research currently underway to advance it further. The most recent EY Reimagining Industry Futures Study highlights the generative AI (GenAI) to be a pivotal technology. The surge in GenAI's prominence can largely be attributed to advancements in deep neural networks, hardware technology such as GPUs and increased availability of data. This research study reviews the most popular GenAI models, spanning text, image, and audio modalities. This study provides a comparative analysis of various models, serving as a comprehensive resource for understanding the functionality and efficiency of the top GenAI models available today.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICUIS64676.2024.10867014 },
  booktitle={ 2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS) },
  chapter={0}
}

@article{rayyan-352343780,
  title={ InsightAI: Root Cause Analysis in Large Log Files with Private Data Using Large Language Model  -  2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  year={2025},
  author={Ekhlasi, M. and Prakash, A. and Lamothe, M. and Dagenais, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030043 },
  abstract={[Problem] As industries increasingly depend on complex software systems, efficient log analysis is essential for maintaining reliability and privacy. However, Identifying problems through logs is often time-consuming and costly for developers. [Background] Large language models (LLMs) can automate parts of log analysis, but challenges like limited computational resources and the frequent need to retrain LLMs due to the dynamic nature of software logs persist. External LLMs, such as GPTs, along with in-context learning techniques, can help reduce some of these issues, but other challenges, including token limitations, high token costs, and data privacy, remain. [Method] To tackle these challenges, we developed an automated pipeline that extracts log files and employs in-context learning, allowing the model to efficiently adapt to changes without extensive retraining. Our approach introduces a novel flame-graph-like method that reduces token usage, thereby lowering token-related costs and response latency while maintaining high accuracy. [Results] This solution allows industries to automate log analysis, minimize system downtime, and enhance performance, all while keeping data privacy and maintaining operational efficiency. [Conclusion] Our flame-graph-like methodology reduces input tokens by 93.61 % and processing latency by 77.45 %. Our anonymization results show an improvement of 138.63 % over the baseline. This industrial experience report presents our approach to allow industries to balance token costs, maintain response accuracy, and ensure data privacy while relying on external LLMs without the need to manage computational resources directly.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAIN66642.2025.00012 },
  booktitle={ 2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN) },
  chapter={0}
}

@article{rayyan-352343781,
  title={ Modern State-of-the-Art Generative AI Uses and Practices for Product Innovation, Marketing Strategies, and Enhanced Customer Experience  -  2024 7th Asia Conference on Cognitive Engineering and Intelligent lnteraction (CEII) },
  year={2024},
  author={Swapnil, A. and Ge, H. and Diagarajan, M. S. and Happonen, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11037883 },
  abstract={A bstract-OpenAI made Generative Artificial Intelligence something most people have access to and a technology, people know of. Nowadays, businesses seek to utilize its maximal potential for smoothly balanced human-computer interaction and operational efficiency solutions. AI use continues to reduce tedious base work from day-by-day activities. Here Generative Artificial Intelligence (GAI) refers to a set of technologies, capable of e.g. producing meaningful texts, image, data analysis and operational activity suggestions. Well-known applications include proactivity enhancements, marketing material generation, product development, digital (twin) customer service agents, supply chain routing and optimization, business decision-making, etc. The full rainbow of different pipelines, where GAI tools are used in multiple different steps, is well less studied and known. Especially those pipelines, which by nature, are producing more profound changes in organizational productivity, work quality, error reduction, and overall end customer experience enhancement fronts. In this context, our research focuses on examining and analyzing modern-day GAI applications, product and service generation, marketing and user/customer experience-related business pipelines, and current practices, across a range of domains, on extending current academic and practical use basis knowledge of different applications and uses of GAI in context of many different industrial application areas. We help build the current status quo overall picture of GAI utilization areas, from product design to marketing and user experience, by investigating methods and architectures employed and advancing the practical significance of each application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEII65291.2024.00058 },
  booktitle={ 2024 7th Asia Conference on Cognitive Engineering and Intelligent lnteraction (CEII) },
  chapter={0}
}

@article{rayyan-352343782,
  title={ Smart AI Applications: Integrating Raspberry Pi 3 with NLP for Edge Computing  -  2025 7th International Conference on Energy, Power and Environment (ICEPE) },
  year={2025},
  author={Mittal, A. and Kedawat, K. and Gupta, E. and Gupta, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11139558 },
  abstract={Artificial intelligence (AI) is used in many ways by the modern world. It can be used to effectively manage complex issues in a wide range of industries, including banking, education, entertainment, and healthcare. The efficiency and convenience of daily lives are being enhanced by AI. Artificial intelligence's natural language processing (NLP) branch enables machines to understand, generate, and respond to human language. The integration of Raspberry Pi 3 and advanced natural language processing models represents a significant advance in the development of intelligent systems. The feasibility of interfacing Raspberry Pi 3 with an LLM such as Google's Gemini is explored by this research. The aim of this study is to provide an efficient and compact solution for AI-based applications. In this study, system architecture, methodology, performance evaluation under different workloads and challenges are discussed. The results are shown to indicate that LLMs cannot be locally hosted by the Raspberry Pi 3, and it is effectively served as a client for cloud-based models. The average achieving response times are reported to be under 1.5 seconds for typical queries. The potential of combining edge computing with cloud-hosted LLMs for applications in IoT, education, and robotics is highlighted by this work, while the need for future advancements in model optimization and hardware capabilities is underscored.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEPE65965.2025.11139558 },
  booktitle={ 2025 7th International Conference on Energy, Power and Environment (ICEPE) },
  chapter={0}
}

@article{rayyan-352343783,
  title={ AI-Enhanced HR Interview Simulation for Realistic Candidate Assessment  -  2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT) },
  year={2025},
  author={Sarumathi, S. and L, G. R. and B, S. M. and A, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915193 },
  abstract={This research study proposes an AI application for a HR interview simulation system to improve candidate assessment. The proposed system is based on the recent AI technologies that generate questions out of the candidate's resume and job description as in the case of a real interview with the employer. AI technology not only do the questioning but also get the emotional analysis of the candidate through the interview by analyzing the tone of the candidate's voice and other factors. AI-based assessment captures both cognitive and affective performance, where the candidate's merit and quality are given a true measure. This means that the proposed system greatly enhances the capabilities of the HR teams to investigate massive numbers of candidates while reducing the biases associated with conventional pure human interviews. Further, this research study aims to explain the system's architecture, where facial expression analysis and voice sentiment analysis remain as the main components alongside reinforcement learning for question adaptation. With LLM-based approach, organizations can increase the efficiency of the hiring process, enrich candidates' experience, and make better decisions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDCIOT64235.2025.10915193 },
  booktitle={ 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT) },
  chapter={0}
}

@article{rayyan-352343784,
  title={ An LLM-Driven Chatbot in Higher Education for Databases and Information Systems  -  IEEE Transactions on Education },
  author={Neumann, A. T. and Yin, Y. and Sowe, S. and Decker, S. and Jarke, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10706931 },
  abstract={Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language model (LLM) chatbot, MoodleBot, in computer science classroom settings. It highlights the potential of integrating LLMs into LMSs like Moodle to support self-regulated learning (SRL) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into LMSs to create a supportive and engaging learning environment. MoodleBot addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new (AI) technologies, this research investigates two questions: (RQ1) To what extent do students accept MoodleBot as a valuable tool for learning support? (RQ2) How accurately does MoodleBot churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on AI-driven chatbots and adopts the retrieval-augmented generation (RAG) approach for MoodleBot’s design and data processing. The technology acceptance model (TAM) evaluates user acceptance through constructs like perceived usefulness (PU) and Ease of Use. Forty-six students participated, with 30 completing the TAM questionnaire. Findings: LLM-based chatbots like MoodleBot can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of AI-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TE.2024.3467912 },
  booktitle={ IEEE Transactions on Education },
  chapter={0}
}

@article{rayyan-352343785,
  title={ Towards a Knowledge Management Framework for LLM-Generated Personas in Collaborative Systems  -  2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD) },
  year={2025},
  author={Nóbrega, L. and Martinez, L. F. and Lima, Y. and Barbosa, C. E. and Argôlo, M. and Salazar, H. and Xexéo, G. and Souza, J. M. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033648 },
  abstract={With the advancement of Artificial Intelligence (AI) technologies, the world has been increasingly reshaped across multiple domains - healthcare, finance, education, and creative fields. This expansion transforms individual tasks and facilitates complex collaborations where humans and machines work to- gether in unprecedented ways. Through machine learning and, more specifically, large language models (LLMs), AI now plays a crucial role in enhancing productivity. Recent technological advancements have significantly boosted the text generation capabilities of LLMs, enabling them to simulate personas that can represent groups or specific well-known individuals. By simulating expert perspectives, LLMs provide insights to guide human decision-making across various collaborative frameworks in Computer-Supported Cooperative Work (CSCW). Personas, as simulated identities, have proven helpful in group brainstorming sessions, consensus-building exercises, and virtual advisory boards, which help represent diverse viewpoints and facilitate group decisions. Among these CSCW methods, the Delphi method is a well-established approach for reaching consensus among experts through iterative feedback and structured discussions. This work introduces a framework to manage and evaluate LLM-generated personas simulating expert input in Delphi studies. Our contributions include a framework designed for evaluating LLM personas in Delphi studies using a text similarity validation technique comparing real and simulated expert opinions and an evaluation of a Delphi about Brazilian higher education, assessing the LLMs' reliability in real-world scenarios. Findings show LLMs can effectively replicate expert perspectives, enhancing AI integration in specialized decision-making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCWD64889.2025.11033648 },
  booktitle={ 2025 28th International Conference on Computer Supported Cooperative Work in Design (CSCWD) },
  chapter={0}
}

@article{rayyan-352343786,
  title={ Enhancing Learning Performance through LLM-Driven Adaptive Contents Based on Facial Engagement Detection  -  2025 29th International Computer Conference, Computer Society of Iran (CSICC) },
  year={2025},
  author={Mahmoudi, M. and Taghiyareh, F. and Hessami, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967446 },
  abstract={Recent advancements in AI have opened new avenues for personalized education, enabling learning environments to adapt to individual needs. This study explores the intersection of AI and Image Processing, mainly using facial emotion detection to monitor cognitive engagement and distraction during learning tasks. Previous research highlights the efficacy of emotion detection in identifying cognitive states and improving educational outcomes through personalized learning environments. Our primary goal is to evaluate how AI can adapt educational content in real time to enhance learning effectiveness based on emotional feedback. We utilized an LLM to develop educational content and identified moments of distraction or disengagement by monitoring learners' facial emotions while interacting with the system. Upon detecting distraction, the LLM dynamically restructures the content, subtly reintegrating it into subsequent materials without the learners' awareness. This method reinforces learning by presenting material in varied contexts, thereby improving learners' understanding. Our preliminary results indicate that this approach enhances comprehension levels in distracted learners. Furthermore, integrating emotion-based monitoring with LLMs may provide a responsive educational framework that adapts to learners' immediate needs, promoting deep cognitive engagement and a pleasant personalized learning experience. These findings suggest broader applications beyond academic learning, including professional training. It is the ambition of any learning system to be able to detect any attention fall and to have smart reactions without learners' awareness, which is the vision of our approach.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSICC65765.2025.10967446 },
  booktitle={ 2025 29th International Computer Conference, Computer Society of Iran (CSICC) },
  chapter={0}
}

@article{rayyan-352343787,
  title={ Cyber Security Issues and Challenges Related to Generative AI and ChatGPT  -  2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS) },
  year={2023},
  author={Pasupuleti, R. and Vadapalli, R. and Mader, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375472 },
  abstract={In recent years, Generative Artificial Intelligence (AI) and ChatGPT (Generative Pre-trained Transformer) models that are capable of generating realistic human-mimicked languages have gained progressive popularity. With the evolution of technology, there has been a significant increase in the availability and usage of artificial intelligence tools, such as ChatGPT and Generative AI, that will assist in shaping the future. However, this increasing popularity poses a potential risk if used inappropriately. Threats from AI pose special challenges for government, the private sector, and national security. In this paper, we address some of key concerns of significant cyber security issues and challenges related to Generative AI and ChatGPT. With careful consideration to application usage, organizations can implement appropriate security measures to mitigate these risks. We also incorporate recommendations about ChatGPT usage and its impact on society. It is important that researchers, developers, and policymakers (CIOs, CSOs) work together to mitigate these risks and to ensure that these models are used in a responsible and ethical manner.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SNAMS60348.2023.10375472 },
  booktitle={ 2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS) },
  chapter={0}
}

@article{rayyan-352343788,
  title={ An Analysis of Unsafe Responses with Magic Expressions across Large Language Models  -  2025 IEEE International Conference on Big Data and Smart Computing (BigComp) },
  year={2025},
  author={Joo, E. and Lim, C. -G. and Han, J. and Choi, H. -J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936868 },
  abstract={With advancements in AI models’ ability to understand input, the risk of generating harmful outputs in response to malicious prompts has grown. This has led to increased awareness among researchers regarding AI safety, resulting in diverse ongoing investigations. However, existing studies have primarily relied on coarse-grained datasets to define risk factors, with limited availability of high-quality datasets that address fine-grained risks. To address this gap, we developed a high-quality, Korean AI safety evaluation dataset with overlooked risk factors in current LLMs. This dataset was curated with the involvement of human annotators to ensure its quality and relevance. We found that adding simple modifications, such as magic expressions, increases the likelihood of bypassing model guardrails. The analysis further revealed that this effect varies across different categories of risk factors. Additionally, we evaluated the harmfulness of LLM-generated outputs by measuring the frequency of risk-related keywords in the responses. This approach used prompt-based evaluation methods to quantify the degree of risk, providing a structured framework for assessing the potential dangers of model outputs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigComp64353.2025.00083 },
  booktitle={ 2025 IEEE International Conference on Big Data and Smart Computing (BigComp) },
  chapter={0}
}

@article{rayyan-352343789,
  title={ Measuring Fluency, Coherency and Logicality of GPT-4 Generated EGRA Comprehension Stories  -  2024 IEEE International Conference on Advanced Learning Technologies (ICALT) },
  year={2024},
  author={Rai, S. and Shapsough, S. and Zualkernan, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645886 },
  abstract={Reading comprehension plays a key role in early grade literacy. During early formative years children develop crucial skills in understanding, interpreting, and critically analyzing written texts. Proficiency in reading comprehension not only enables students to extract meaning from diverse sources but also fosters cognitive abilities such as inference-making, prediction, and evaluation. Moreover, reading comprehension serves as a gateway to accessing a wealth of knowledge across various subjects. However, generating material for reading comprehension assessments at a large scale remains a challenging process. Stories used for reading comprehension often have a set of criteria that needs to be met in terms of structure and content to be able to fairly assess the abilities of the learner. Advancements in natural language processing have empowered AI models to craft narratives comparable to human-generated stories. This paper investigates qualitative characteristics within stories generated by a Large Language Model (LLM) based on Early Grade Reading Assessment (EGRA) which is a framework designed to evaluate early literacy skills. The paper assesses qualitative indicators of these narratives using established metrics. The findings offer insights into the qualitative characteristics of narratives generated within the constraints of EGRA criteria, highlighting the capacity of AI models to produce varied and engaging stories. The paper concludes with reflections on the significance of qualitative indicators in natural language generation and suggest future research directions for enhancing AI-generated narratives' quality.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICALT61570.2024.00064 },
  booktitle={ 2024 IEEE International Conference on Advanced Learning Technologies (ICALT) },
  chapter={0}
}

@article{rayyan-352343790,
  title={ Selecting the Right Llm for Egov Explanations  -  2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG) },
  year={2025},
  author={Limonad, L. and Fournier, F. and Mulian, H. and Manias, G. and Borotis, S. and Kyrkou, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081620 },
  abstract={The perceived quality of the explanations accompanying e-government services is key to gaining trust in these institutions, consequently amplifying further usage of these services. Recent advances in generative AI, and concretely in Large Language Models (LLMs) allow the automation of such content articulations, eliciting explanations' interpretability and fidelity, and more generally, adapting content to various audiences. However, selecting the right LLM type for this has become a nontrivial task for e-government service providers. In this work, we adapted a previously developed scale to assist with this selection, providing a systematic approach for the comparative analysis of the perceived quality of explanations generated by various LLMs. We further demonstrated its applicability through the tax-return process, using it as an exemplar use case that could benefit from employing an LLM to generate explanations about tax refund decisions. This was attained through a user study with 128 survey respondents who were asked to rate different versions of LLMgenerated explanations about tax refund decisions, providing a methodological basis for selecting the most appropriate LLM. Recognizing the practical challenges of conducting such a survey, we also began exploring the automation of this process by attempting to replicate human feedback using a selection of cutting-edge predictive techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEDEG65568.2025.11081620 },
  booktitle={ 2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG) },
  chapter={0}
}

@article{rayyan-352343791,
  title={ Large Language Models (LLMs): Hypes and Realities  -  2023 International Conference on Computer Science and Emerging Technologies (CSET) },
  year={2023},
  author={Routray, S. K. and Javali, A. and Sharmila, K. P. and Jha, M. K. and Pappa, M. and Singh, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346621 },
  abstract={Artificial intelligence (AI) has created a lot of buzz in recent years. Using machine learning and other AI techniques several intelligent initiatives have been tested. The large language model is one of them. A large language model (LLM) normally refers to a type of AI model that is trained on vast amounts of text data to understand and generate human-like language outputs. These models are designed to capture the statistical patterns and structures present in the training data, enabling them to generate coherent and contextually relevant responses. The widely known ChatGPT is one of the LLMs which can do several tasks and answer many questions. It is trained with a huge number of data sets and a large number of parameters. In addition to ChatGPT, many other LLMs such as the Google Bard, Claude v1, Bison 001, Cohere, Falcon, and Guanaco-65B have surfaced in recent times. In this paper, we study the basic principles and features of LLMs. We go through their brief history, abilities, limitations, challenges and future prospects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSET58993.2023.10346621 },
  booktitle={ 2023 International Conference on Computer Science and Emerging Technologies (CSET) },
  chapter={0}
}

@article{rayyan-352343792,
  title={ Multimodal LLM for Patient Activity Recognition: Integrating Video, Audio, and Text in Clinical Environments  -  IEEE Journal of Biomedical and Health Informatics },
  author={Majid, A. and Wang, Y. and Ali, J. and Ullah, A. and Perveen, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11193711 },
  abstract={Accurate recognition of patient activities within hospital environments is essential to improve safety and quality of care. Existing approaches often struggle to correctly recognize complex patient activities and clinical variability. To address these issues, we propose ClinActNet, a multimodal framework based on large language models that combines video, audio, and clinical documentation through a context-aware Consultation Transformer. To enhance patient specific monitoring, we propose three key components: first a patient profile encoder to learn EHR informed context vectors, second a Clinical Knowledge Graph Reasoner for medical logic inference, and third a personalization layer to adapt predictions per patient. ClinActNet is evaluated using more than 672 hours of hospital data covering nine clinically significant activity classes, achieving an accuracy of 89.7% and a precision of 98. 2% in critical safety events. To ensure reproducibility, we also benchmarked ClinActNet on the public dataset (VAST), where our model performed 84.1% accuracy, confirming its robustness beyond private clinical data. Implementation in real world environments reduced overlooked critical incidents by 48%. The output demonstrated the system's capability to facilitate interpretable patient centered AI within healthcare environment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JBHI.2025.3617581 },
  booktitle={ IEEE Journal of Biomedical and Health Informatics },
  chapter={0}
}

@article{rayyan-352343793,
  title={ DiCE: Distributed Code Generation and Execution  -  2024 IEEE Conference on Pervasive and Intelligent Computing (PICom) },
  year={2024},
  author={Rao, K. and Coviello, G. and Chakradhar, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795392 },
  abstract={Generative artificial intelligence (GenAI), specifically, Large Language Models (LLMs), have shown tremendous potential in automating several tasks and improving human productivity. Recent works have shown them to be quite useful in writing and summarizing text (articles, blogs, poems, stories, songs, etc.), answering questions, brainstorming ideas, and even writing code. Several LLMs have emerged specifically targeting code generation. Given a prompt, these LLMs can generate code in any desired programming language. Many tools like ChatGPT, CoPilot, CodeWhisperer, Cody, DeepSeek Coder, StarCoder, etc. are now routinely being used by software developers. However, most of the prior work in automatic code generation using LLMs is focused on obtaining “correct” and working code, and mainly runs on a single computer (serial code). In this paper, we take this to the next level, where LLMs are leveraged to generate code for execution on a distributed infrastructure. We propose a novel system called DiCE, which takes serial code as input and automatically generates distributed version of the code and efficiently executes it on a distributed setup. DiCE consists of two main components (a) LLM-based tool (Synthia) to understand dependencies in serial code and automatically generate distributed version of the code using specialized programming model and semantics, and (b) Runtime (Hermod) to understand the semantics in the distributed code and realize efficient execution on a cluster of machines (distributed infrastructure). DiCE currently focuses on visual programs synthesized by tools like ViperGPT [1] and VisReP [2] (serial code), automatically identifies higher-level task parallelism opportunities (e.g., parallel object detection), transforms the code to exploit the parallelism, and finally efficiently executes it on a cluster of machines. Through our experiments using 100 examples from the GQA dataset [3], we show that the serial codes generated by ViperGPT are successfully transformed into distributed codes which are then efficiently executed on a cluster of machines by DiCE. We note that DiCE correctly identifies opportunities for parallelism and distributes tasks on separate GPUs within the cluster. We observe an average speed-up of 2X, 2.95X, and 3.7X, and an average efficiency of 1, 0.74 and 0.48 for a cluster of 2 nodes, 4 nodes, and 8 nodes, respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PICom64201.2024.00008 },
  booktitle={ 2024 IEEE Conference on Pervasive and Intelligent Computing (PICom) },
  chapter={0}
}

@article{rayyan-352343794,
  title={ Dynamic Resume Evaluation a Comprehensive Approach to Part-Based Weightage Assignment and Score Generation  -  2024 International Conference on Recent Innovation in Smart and Sustainable Technology (ICRISST) },
  year={2024},
  author={S, S. and Naveen, A. and S, C. A and M, H. N and U, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10921820 },
  abstract={Navigating the dynamic landscape of today's employment market to identify suitable opportunities can be challenging. The advent of AI has empowered candidates to be ranked for a job role processed by computers. While conventional methods can quantify certain elements of positions and applicants, the conversion of unstructured data from job descriptions and resumes often leads to the loss of crucial information. Recently, Large Language Models (LLMs) have demonstrated exceptional performance in text-based data domains within the AI field. Inspired by the prowess of LLMs in natural language understanding, this study exploits their capabilities to capture information previously lost during the conversion of unstructured data. In this innovative approach, traditional methods are surpassed by integrating web scraping techniques to extract valuable insights directly from resumes. By systematically gathering unstructured data from resumes, the LLMs are enriched with a diverse range of information, ensuring a more comprehensive understanding of candidates' skills and experiences. The acquired information is then utilized through a self-developed ranking mechanism tailored for the recruitment process, effectively ranking candidates based on their skills and capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRISST59181.2024.10921820 },
  booktitle={ 2024 International Conference on Recent Innovation in Smart and Sustainable Technology (ICRISST) },
  chapter={0}
}

@article{rayyan-352343795,
  title={ Strengths-Leverage Chain-of-Thought: Enhancing Multimodal Reasoning with LLM and LMM  -  2024 International Conference on Virtual Reality and Visualization (ICVRV) },
  year={2024},
  author={Xu, Q. and Zhang, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028660 },
  abstract={AI systems have long sought to replicate humans’ complex multimodal reasoning capabilities. Recent advancements in large language models (LLMs) showcase significant progress, particularly in multi-step reasoning within language. These models utilize a technique known as the Chain-of-Thought (CoT), which effectively simulates human cognitive processes, to achieve this enhanced reasoning ability. However, transferring these advances to multimodal contexts poses more significant challenges. Recent studies indicate that despite their sophistication, the most advanced LMMs still struggle with compositional visual reasoning, particularly in understanding object attributes and relationships. Furthermore, hallucinations in models are exacerbated by the interaction of multimodal inputs. The strength of the LMM lies in processing visual tasks, including extracting scene graphs, while the LLM excels in handling textual information and leveraging internal knowledge to answer questions. Inspired by these and to address the above issues, we propose Strengths-Leverage Chain-of-Thought (SLCoT) prompting, a novel zero-shot Chain-of-Thought prompting method. SLCoT deconstructs questions while extracting scene graphs (SG) from images via the LMM. Finally, the LLM integrates the SG and sub-answers to derive a comprehensive rationale. By leveraging the strengths of both models in cross-modal tasks, we enhance AI’s multimodal reasoning capabilities. Extensive experiments demonstrate the efficacy of our proposed framework, showing significant improvements in multimodal CoT performance across complex visual reasoning datasets without the need for fine-tuning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICVRV62410.2024.00063 },
  booktitle={ 2024 International Conference on Virtual Reality and Visualization (ICVRV) },
  chapter={0}
}

@article{rayyan-352343796,
  title={ LLM-Powered Automated Cloud Forensics: From Log Analysis to Investigation  -  2025 IEEE 18th International Conference on Cloud Computing (CLOUD) },
  year={2025},
  author={Alharthi, D. and Yasaei, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11120597 },
  abstract={Cloud forensics is a crucial yet challenging field, as traditional forensic techniques struggle to handle the large-scale, dynamic nature of cloud environments. Manual forensic analysis is time-consuming, error-prone, and often fails to detect evolving cyber threats. This paper presents a novel tool leveraging Large Language Models (LLMs) to fully automate cloud forensic investigations. Our approach utilizes few-shot learning to classify log data, extract forensic intelligence, and reconstruct attack timelines. We evaluate LLM-based automation against traditional machine learning models, including Random Forest, XGBoost, and Gradient Boosting, using cloud forensic log datasets. Experimental results demonstrate that LLMs improve forensic accuracy, precision, and recall while reducing the need for extensive feature engineering. However, challenges such as hallucination risks, adversarial manipulation, and forensic explainability must be addressed to ensure the reliability of AI-driven investigations. To mitigate these risks, we explore Retrieval-Augmented Generation (RAG) for context-aware forensic intelligence and propose hybrid AI models integrating rule-based forensic validation. Our findings highlight the potential of LLM-driven forensic automation to enhance cloud security operations while outlining key areas for future research, including adversarial robustness, forensic transparency, and multi-cloud scalability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CLOUD67622.2025.00012 },
  booktitle={ 2025 IEEE 18th International Conference on Cloud Computing (CLOUD) },
  chapter={0}
}

@article{rayyan-352343797,
  title={ Temporal Context Awareness: A Defense Framework Against Multi-Turn Manipulation Attacks on Large Language Models  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Kulkarni, P. and Namer, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050551 },
  abstract={Many Large Language Models (LLMs) today are vulnerable to multi-turn manipulation attacks,where adversaries gradually build context through seemingly benign conversational turns to elicit harmful or unauthorized responses. These attacks exploit the temporal nature of dialogue to evade single-turn detection methods, posing a significant risk to the safe deployment of LLMs. This paper introduces the Temporal Context Awareness (TCA)framework, a novel defense mechanism designed to address this challenge by continuously analyzing semantic drift, cross-turn intention consistency, and evolving conversational patterns. The TCA framework integrates dynamic context embedding analysis, cross-turn consistency verification, and progressive risk scoring to detect and mitigate manipulation attempts effectively. Preliminary evaluations on simulated adversarial scenarios demonstrate the framework's potential to identify subtle manipulation patterns often missed by traditional detection techniques, offering a much-needed layer of security for conversational AI systems. In addition to outlining the design of TCA, we analyze diverse attack vectors and their progression across multi-turn conversations, providing valuable insights into adversarial tactics and their impact on LLM vulnerabilities. Our findings underscore the pressing need for robust, context-aware defenses in conversational AI systems and highlight the TCA framework as a promising direction for securing LLMs while preserving their utility in legitimate applications},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00164 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343798,
  title={ Empowering Recommendations: Survey of LLM-Based Recommendation Systems  -  2025 8th International Conference on Electronics, Materials Engineering & Nano-Technology (IEMENTech) },
  year={2025},
  author={Kumar, R. and Dey, T. and Das, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10959591 },
  abstract={The rise of e-commerce has emphasized the importance of recommendation systems in enhancing user experiences. Traditional methods, like collaborative filtering and content-based techniques, often struggle with understanding user preferences. Large Language Models (LLMs), such as ChatGPT and GPT-4, offer a transformative approach by leveraging advanced natural language processing. This survey explores LLM-driven strategies in recommendation systems, focusing on their role in feature encoding, user-item interaction modeling, and explainability. By highlighting their ability to generate contextually relevant recommendations, we provide insights into their advantages over conventional methods and their potential for future advancements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEMENTech65115.2025.10959591 },
  booktitle={ 2025 8th International Conference on Electronics, Materials Engineering & Nano-Technology (IEMENTech) },
  chapter={0}
}

@article{rayyan-352343799,
  title={ GDPR Compliant ChatGPT Playground  -  2024 International Conference on Emerging Technologies in Computer Science for Interdisciplinary Applications (ICETCS) },
  year={2024},
  author={Nayak, S. P. and Pasumarthi, S. and Rajagopal, B. and Verma, A. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10543557 },
  abstract={ChatGPT is an AI based conversational tool developed by OpenAPI on the design principles of Large Language Model (LLM) and a publicly accessible tool. ChatGPT has increasingly becoming popular tool for enabling applications involving interactive and contextual search across corporate companies, profit/non-profit organizations, educational/medical institutions, and researcher’s community to name a few.The corporate companies are abided by GDPR (General Data Protection Regulation) compliance checks and restricted to share confidential, personal or sensitive information’s (hereinafter referred as critical data) into public domains. As ChatGPT server is hosted outside corporate boundaries, to fulfil GDPR compliance check, the corporate companies must have necessary systems in place of any data leaving outside of corporate boundaries.We are proposing a novel solution in identifying GDPR noncompliant DPP (Data Privacy and Protection) entities from the prompt query given to ChatGPT. To achieve this, from the corporate documents we first manually tag critical entities from “named entity tagging tool” in building the corporate specific DPP entities knowledgebase, build custom NER (Named Entity Recognition) model on top of prebuilt corporate specific DPP entities knowledgebase, an ChatGPT playground interface to accept any user’s prompt query, before firing the query to ChatGPT we validate the user’s prompt query against custom NER model to detect if any corporate specific DPP entities are present, warn the user by highlighting the corporate specific DPP entities if present to facilitate user in negating the same, we enabled feedback loop from the user for the highlighted corporate specific DPP entities to improvise the custom NER model and logging all the input prompt queries fired to ChatGPT to enable corporate auditing process by using techniques from Natural Language Processing (NLP), Information Extraction, Information Retrieval (IR) and Custom NER model.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICETCS61022.2024.10543557 },
  booktitle={ 2024 International Conference on Emerging Technologies in Computer Science for Interdisciplinary Applications (ICETCS) },
  chapter={0}
}

@article{rayyan-352343800,
  title={ Enhancing Medical Summarization with Parameter Efficient Fine Tuning on Local CPUs  -  2024 International Conference on Electrical, Communication and Computer Engineering (ICECCE) },
  year={2024},
  author={Yang, S. S. Zi and Fye, G. M. and Yap, W. C. and Yu, D. Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823619 },
  abstract={Documenting and summarizing patient symptoms and medical history for each visit can significantly burden clinicians' time management. Large Language Models (LLMs) have demonstrated great potential in natural language processing (NLP) tasks; however, their effectiveness in clinical summarization tasks has not yet been rigorously validated. While much research has focused on leveraging closed LLMs like GPT-4, Claude, and Gemini for clinical applications, privacy concerns hinder their deployment in real clinical settings. On-premises deployment offers a potential solution. This study examines domain adaptation techniques on the open-source LLM, Llama 3 8B Instruct, to improve clinical summarization. Our approach emphasizes fine-tuning on CPUs instead of the more commonly used GPU s, aiming for greater cost savings in practical applications. We apply Quantized Low-Rank Adaptation (QLoRA) for efficient task-specific adaptation and introduce CPU optimization techniques such as IPEX-LLM and Intel® AMX to enhance performance. Our results show that CPU fine-tuning provides a practical, cost-effective, and privacy-aware alternative to GPU fine-tuning, while improving the accuracy of medical summarization and enabling customization to meet unique clinical requirements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECCE63537.2024.10823619 },
  booktitle={ 2024 International Conference on Electrical, Communication and Computer Engineering (ICECCE) },
  chapter={0}
}

@article{rayyan-352343801,
  title={ Robust Multi Model RAG Pipeline For Documents Containing Text, Table & Images  -  2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC) },
  year={2024},
  author={Joshi, P. and Gupta, A. and Kumar, P. and Sisodia, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10574972 },
  abstract={RAG (Retrieval Augmented Generation) is generally used for generating results from the existing knowledge-base. RAG refers to finding references (R), Adding references (A) and improving generation(i.e, answers to the question) (G). MultiModel-RAGs are used for generation of results over the documents which contain images and texts. There exists multiple different Multimodel-RAGs but these are not still efficient in generation of the results from the documents which contain relationships between images and texts. This study has proposed the solution to enable effective retrieval and generation of results, which includes the relationship between images and texts. The comparison of proposed Multimodal RAG with four different datasets (i.e., Short-form-type-QA, Long-form-type-QA, MCQ-type-QA, True-False-type-QA) shows the proposed solution improves the effectiveness of the existing Multimodal RAGs. Testing of proposed Multimodal RAG over two different other multimodal LLM i.e, Open-AI & Gemini helps in deciding whether the proposed solution fits best with LLM in different cases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAAIC60222.2024.10574972 },
  booktitle={ 2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC) },
  chapter={0}
}

@article{rayyan-352343802,
  title={ Circuit-Agent: A Large Language Model Based Circuit Agent Framework for Analog/Mixed-signal Circuit Design Automation  -  2025 IEEE 7th International Conference on Artificial Intelligence Circuits and Systems (AICAS) },
  year={2025},
  author={Yang, T. and Li, B. and Li, Y. and Mao, W. and Han, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11173131 },
  abstract={Large Language Models (LLMs) have demonstrated remarkable capabilities across various domain tasks. Following this trend, this paper is dedicated to a new LLM-based design methodology for analog/mixed-signal (AMS) circuit design automation. The proposed LLM-based multi-agent circuit framework is capable of generating circuits based on given requirements. The framework leverages circuit-oriented retrieval-augmented generation (RAG) technology to retrieve specific circuit design knowledge and employs multi-agent collaboration. The proposed framework has been validated by designing fundamental AMS circuits, such as operational amplifiers (OPAMPs) and analog-to-digital converters (ADCs), which enhances the efficiency of AMS circuit design and promotes the development of AI-driven circuit design methodologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICAS64808.2025.11173131 },
  booktitle={ 2025 IEEE 7th International Conference on Artificial Intelligence Circuits and Systems (AICAS) },
  chapter={0}
}

@article{rayyan-352343803,
  title={ Toward Sustainable AI: A Review of Energy-Efficient Large Language Models  -  2025 8th International Conference on Computing Methodologies and Communication (ICCMC) },
  year={2025},
  author={Kaushik, B. and Taneja, A. and Dahiya, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140923 },
  abstract={The rapid development of Large Language Models (LLMs) has brought significant advancements in natural language processing, but their high demands for computational resources, memory, and energy pose significant challenges. This report addresses the need for more energy-efficient LLMs by exploring the interconnected factors of computation, memory, energy, cost, and network communication in optimizing these models. Through a detailed literature review, the report evaluates existing strategies in model architecture, pre-training, fine-tuning, and inference to improve LLM efficiency. Furthermore, it introduces a novel unified metric designed to assess resource efficiency across various dimensions. The report also examines optimization techniques such as model pruning, quantization, and hardware acceleration to improve LLM performance and sustainability. The findings emphasize that achieving scalable, efficient, and sustainable LLMs requires a balanced approach that includes energy-conscious design, optimized training processes, and effective resource management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCMC65190.2025.11140923 },
  booktitle={ 2025 8th International Conference on Computing Methodologies and Communication (ICCMC) },
  chapter={0}
}

@article{rayyan-352343804,
  title={ Research on Tibetan Tourism Viewpoints Information Generation System Based on LLM  -  2024 12th International Conference on Intelligent Computing and Wireless Optical Communications (ICWOC) },
  year={2024},
  author={Qi, J. and Yan, S. and Zhang, W. and Zhang, Y. and Liu, Z. and Wang, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684948 },
  abstract={Tibet, ensconced within China’s territorial expanse, is distinguished by its labyrinthine and heterogeneous topography, a testament to its profound historical heritage, and the cradle of a unique religious ethos. The very essence of these attributes, however, has impeded the advancement of Tibet’s tourism service infrastructure, rendering existing smart tourism services inadequate for the region’s visitors. This study delves into the ramifications of informational disparities at tourist sites on Tibetan tourism and addresses the challenge of establishing the Large Language Model (LLM) evaluation criteria. It introduces an innovative approach, the DualGen Bridge AI system, employing supervised fine-tuning techniques to bolster model functionality and enhance optimization processes. Furthermore, it pioneers a multi-structured generative results assessment framework. Empirical validation confirms the efficacy of this framework. The study also explores the application of the supervised fine-tuning method within the proprietary DualGen Bridge AI, aimed at refining the generation of tourist site information. The study’s findings offer valuable insights for optimizing system performance and provide support and inspiration for the application of LLM technology in Tibet’s tourism services and beyond, potentially revolutionizing the smart tourism industry with advanced, tailored information generation capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWOC62055.2024.10684948 },
  booktitle={ 2024 12th International Conference on Intelligent Computing and Wireless Optical Communications (ICWOC) },
  chapter={0}
}

@article{rayyan-352343805,
  title={ LLM for Automated Answer Evaluation with DSPy Prompt-Fine-tuning  -  2025 6th International Conference for Emerging Technology (INCET) },
  year={2025},
  author={U, A. and Nair, K. R. and Anand, S. and Nandakumar, S. and Kumar, S. S. and Rao, S. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140055 },
  abstract={Generative AI and prompt engineering have the potential to create innovative applications in a short time. This paper explores the potential of generative AI and how prompt engineering can be used to build educational applications to help instructors automate question generation and answer evaluation in a short time. This paper details how optimized prompts are used in an educational application that was designed to support instructors and students by automating the evaluation of student answers to provide personalized feedback. To fine-tune the prompts, DSPy-enabled optimization was utilized to achieve consistency in LLM-generated questions, and answer evaluations. The paper details the implementation for the prompt-based question generation and creation of different variations of the of the question and answer evaluation using DSPy integrated method. The results demonstrate that the structured approach of DSPy to prompt generation significantly enhances the reliability of the system, ensuring that the LLM outputs are in line with the goals of the system, while maintaining consistency and interpretability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INCET64471.2025.11140055 },
  booktitle={ 2025 6th International Conference for Emerging Technology (INCET) },
  chapter={0}
}

@article{rayyan-352343806,
  title={ Next-Gen UAV-Satellite Communications: AI Innovations and Future Prospects  -  IEEE Open Journal of Vehicular Technology },
  author={Hashima, S. and Gendia, A. and Hatano, K. and Muta, O. and Nada, M. S. and Mohamed, E. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072807 },
  abstract={The convergence of sixth-generation (6G) networks with unmanned aerial vehicles (UAVs) and satellites is poised to introduce substantial improvements to the landscape of wireless communication, paving the way for a unified and uninterrupted space-air-ground-sea network that ensures comprehensive global connectivity. At the heart of this transformative paradigm lies artificial intelligence (AI), which drives innovation across diverse sectors by enhancing decision-making autonomy, enabling real-time data processing, and optimizing network performance and coverage. This survey paper explores AI-enabled UAV-satellite communications for 6G applications, focusing on its challenges, potential, and future. This new system combines the strengths of 6G networks, UAVs (advanced drones), and satellites. It opens up new possibilities in precision agriculture, disaster management, enhanced telecommunication services, and remote sensing. Despite its promise, this field faces complex challenges. These include spectrum management, security risks, regulatory barriers, and integrating AI operations seamlessly. This paper comprehensively analyzes these challenges, offering innovative solutions and outlining future research directions to unlock the complete capabilities of 6G-enabled UAV-satellite communications. Furthermore, it includes a case study demonstrating the effectiveness of multi-armed bandit (MAB) algorithms in optimizing resource allocation and decision-making processes for UAV-low Earth orbit (LEO) satellite communication scenarios, showcasing significant improvements in network performance. This work lays the foundation for a new generation of ultra-connected, data-driven applications that will redefine global connectivity and technological advancement by addressing these critical aspects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OJVT.2025.3587028 },
  booktitle={ IEEE Open Journal of Vehicular Technology },
  chapter={0}
}

@article{rayyan-352343807,
  title={ AI for Becoming Fluent: Designing an App for Advanced Bilingual Speakers  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Delgado-Solorzano, C. and Mendoza, S. and Morales-Flores, F. and Martinez-Garcia, J. and Briones-Ramirez, N. E. and Zarazua-Rubio, E. A. and Rivera-Robles, V. and Rangel-Ortiz, A. H. and Toxtli, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050655 },
  abstract={This research explores the difficulties advanced second-language learners face in becoming fluent and the poten-tial of AI to enhance language learning apps. Through surveys, focus groups, and collaborative design sessions, we investigated learners' difficulties and practice habits. The participants created paper prototypes for an app targeting speaking and listening skills at an advanced level. Key findings suggest that fluency de-velopment requires exposure to diverse accents from both native and non-native speakers. The resulting design incorporates AI in the form of a chatbot with voice recognition capabilities. This study contributes to our understanding of advanced language learning needs and the potential of AI to address them, paving the way for innovative language learning solutions. Our findings highlight opportunities to develop more effective tools for learners striving to achieve fluency in their target languages.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00044 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343808,
  title={ Navigating Data Privacy and Analytics: The Role of Large Language Models in Masking conversational data in data platforms  -  2024 IEEE 3rd International Conference on AI in Cybersecurity (ICAIC) },
  year={2024},
  author={Khoje, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433801 },
  abstract={In the rapidly evolving landscape of data analytics, safeguarding conversational data privacy presents a pivotal challenge, especially with third-party enterprises commonly offering analytic services. This paper delves into the innovative application of Large Language Models (LLMs) for real-time masking of sensitive information in conversational data. The focus is on balancing privacy protection and data utility for analytics within a multi-stakeholder framework. The significance of data privacy is underscored across sectors, with specific attention to challenges in industries like healthcare, particularly when analytics involve external entities. A comprehensive literature review reveals limitations in existing data masking techniques and explores the role of LLMs in diverse contexts, extending beyond direct healthcare applications.The proposed methodology utilizes LLMs for real-time entity recognition and replacement, effectively masking sensitive information while adhering to privacy regulations. This approach is particularly pertinent for third-party analytics providers dealing with conversational data from various sources. Hypothetical case studies, including healthcare scenarios, showcase the practical application and efficacy of the method in real-world settings with external data analytics providers. The dual assessment evaluates the method’s efficiency in preserving privacy and maintaining data utility for analytical purposes. Experimental results using synthetically generated healthcare conversational data sets further illustrate the effectiveness of the approach in typical third-party analytics service scenarios.The discussion highlights broader implications, addressing challenges and limitations [1] across industries, and emphasizes ethical considerations in handling sensitive data by external entities. In conclusion, the paper summarizes the significant strides achievable with LLMs for data masking, with implications for diverse sectors and analytics providers. Future research directions, especially fine-tuning LLMs for enhanced performance in varied analytic scenarios, are suggested. This study sets the stage for a harmonious coexistence of customer data protection and utility in the intricate ecosystem of data analytics services, facilitated by the advanced capabilities of LLM technology.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIC60265.2024.10433801 },
  booktitle={ 2024 IEEE 3rd International Conference on AI in Cybersecurity (ICAIC) },
  chapter={0}
}

@article{rayyan-352343809,
  title={ Product Recommendation System Using Large Language Model: Llama-2  -  2024 IEEE World AI IoT Congress (AIIoT) },
  year={2024},
  author={Katlariwala, M. and Gupta, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579009 },
  abstract={Product recommendation systems are an essential part of many e-commerce platforms. They help users discover new products that they are likely to be interested in, and can also increase sales and engagement. Traditional recommendation systems typically use collaborative filtering or content-based filtering to generate recommendations. However, these systems have limitations, such as the cold start problem and the difficulty of capturing complex user preferences. Large language models (LLMs) have recently emerged as a promising new approach to product recommendation. LLMs are trained on massive datasets of text and code, and they can learn to understand and generate human language at a high level. This makes them well-suited for tasks such as product recommendation, which require the ability to understand user preferences and product descriptions. In this paper, we propose a product recommendation system that uses the Llama-2 LLM. Our system works by first generating a personalized user embedding for each user. This embedding captures the user’s preferences based on their past interactions with the system. The system then uses this embedding to generate a ranked list of recommended products for the user. We evaluated our system on a real-world dataset of user interactions with an e-commerce platform. Our results show that our system outperforms traditional recommendation systems on a variety of metrics, including click-through rate and purchase rate.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIIoT61789.2024.10579009 },
  booktitle={ 2024 IEEE World AI IoT Congress (AIIoT) },
  chapter={0}
}

@article{rayyan-352343810,
  title={ LLaViLo: Boosting Video Moment Retrieval via Adapter-Based Multimodal Modeling  -  2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW) },
  year={2023},
  author={Ma, K. and Zang, X. and Feng, Z. and Fang, H. and Ban, C. and Wei, Y. and He, Z. and Li, Y. and Sun, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350951 },
  abstract={Recent studies have explored the potential of large language models (LLMs) for understanding the semantic information in images. However, the use of LLMs to understand videos, which contain continuous contextual information, remains limited. In this paper, we propose LLaV-iLo (LLaMa-Video-Localizer), a video moment retrieval pipeline powered by a large language model. LLaViLo has two key features: 1) In contrast to fine-tuning the entire LLM, we introduce and optimize only 1.7% of additional parameters in adapter modules, freezing the pre-trained LLM to enable efficient alignment of video and text. 2) A multi-objective optimization framework concurrently op-timizes two objectives: a set prediction objective and a captioning objective. The joint training of these two objectives allows the proposed framework to produce high-quality time coordinates. Compared with other state-of-the-art methods, the proposed LLaViLo achieves significant performance improvement on QVHighlights and Charades-STA datasets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCVW60793.2023.00297 },
  booktitle={ 2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW) },
  chapter={0}
}

@article{rayyan-352343811,
  title={ Advancing Multi-Talker ASR Performance With Large Language Models  -  2024 IEEE Spoken Language Technology Workshop (SLT) },
  year={2024},
  author={Shi, M. and Jin, Z. and Xu, Y. and Xu, Y. and Zhang, S. -X. and Wei, K. and Shao, Y. and Zhang, C. and Yu, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832362 },
  abstract={Recognizing overlapping speech from multiple speakers in conversational scenarios is one of the most challenging problem for automatic speech recognition (ASR). Serialized output training (SOT) is a classic method to address multi-talker ASR, with the idea of concatenating transcriptions from multiple speakers according to the emission times of their speech for training. However, SOT-style transcriptions, derived from concatenating multiple related utterances in a conversation, depend significantly on modeling long contexts. Therefore, compared to traditional methods that primarily emphasize encoder performance in attention-based encoderdecoder (AED) architectures, a novel approach utilizing large language models (LLMs) that leverages the capabilities of pre-trained decoders may be better suited for such complex and challenging scenarios. In this paper, we propose an LLM-based SOT approach for multi-talker ASR, leveraging pre-trained speech encoder and LLM, fine-tuning them on multi-talker dataset using appropriate strategies. Experimental results demonstrate that our approach surpasses traditional AED-based methods on the simulated dataset LibriMix and achieves state-of-the-art performance on the evaluation set of the real-world dataset AMI, outperforming the AED model trained with 1000 times more supervised data in previous works.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SLT61566.2024.10832362 },
  booktitle={ 2024 IEEE Spoken Language Technology Workshop (SLT) },
  chapter={0}
}

@article{rayyan-352343812,
  title={ All-in-one Approach for Large Language Models Inference  -  2024 IEEE 15th International Conference on Software Engineering and Service Science (ICSESS) },
  year={2024},
  author={Zhou, S. and He, P. and Huang, W. and Li, C. and Xie, Y. and Yu, W. and Wang, D. and Meng, C. and Gui, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10719375 },
  abstract={In this paper, we aim to address the large language models (LLMs) deployment challenges in the industry area that require efficient inference solutions to handle the computational demands. To address the challenge, we propose an all-in-one approach that integrates CPU hardware and software-optimized solutions for accelerating the inference performance of LLMs. This paper introduces two key hardware features, advanced matrix extension and high bandwidth memory. Their importance for LLM inference is also explained. Additionally, the software implementation of the proposed all-in-one approach is presented. The paper introduces multiple optimization strategies adopted by the all-in-one approach for LLM inference optimization. The experiment results show the token generation latency of the OPT model with 13B parameters only needs 30ms on the proposed all-in-one approach.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSESS62520.2024.10719375 },
  booktitle={ 2024 IEEE 15th International Conference on Software Engineering and Service Science (ICSESS) },
  chapter={0}
}

@article{rayyan-352343813,
  title={ Query Answering for Tabular Data Using Large Language Models  -  2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  year={2024},
  author={Oh, M. and Chun, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990078 },
  abstract={This study presents a novel end-to-end approach to generating accurate responses for tabular data using Large Language Models combined with Retrieval-Augmented Generation. Our method leverages metadata augmentation and query expansion techniques to improve the accuracy of data matching and query response generation from a large pool of tabular datasets. Specifically, the system uses Large Language Models to enrich data descriptions and expand user queries, facilitating the retrieval of relevant data from approximately 70,000 tabular datasets. The proposed approach was demonstrated on five sample queries, each of which successfully generated correct answers. The results highlight the potential of Large Language Models to extract accurate statistical information from natural language input, providing a scalable solution for complex question-answering tasks involving structured data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIxDKE63520.2024.00037 },
  booktitle={ 2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE) },
  chapter={0}
}

@article{rayyan-352343814,
  title={ Chatbot for Student Descipline Handbook-Related Queries: A RAG-Based LLM Using Llama-3 Approach  -  2025 11th International Conference on Web Research (ICWR) },
  year={2025},
  author={Comia, L. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11006165 },
  abstract={This study presents a Retrieval-Augmented Generation (RAG)-based chatbot designed to handle student discipline handbook-related queries using Llama-3 and ChromaDB. By employing Sentence-BERT (SBERT) for semantic similarity assessment, the chatbot ensures accurate, contextually relevant, and policy-compliant responses. Unlike conventional chatbots relying on keyword matching or rule-based systems, the proposed model integrates retrieval and generation techniques, enhancing response precision and coherence. The system is deployed using Gradio, offering a user-friendly interface for seamless interactions. Quantitative evaluation revealed a high mean similarity score of 0.9219, a median of 0.9373, and a low standard deviation of 0.0750, indicating reliable performance. A p -value of 0.0000 confirmed statistical significance, while the lowest similarity score of 0.7267 identified areas for improvement. This research demonstrates the chatbot's potential as an AIdriven educational support tool, enhancing accessibility to institutional policies and reducing administrative workload.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWR65219.2025.11006165 },
  booktitle={ 2025 11th International Conference on Web Research (ICWR) },
  chapter={0}
}

@article{rayyan-352343815,
  title={ Startup Success Prediction Using GRU-SAM: A Big Data-Driven Financial Modeling Approach with LLM-Enhanced Insights  -  2025 3rd International Conference on Data Science and Information System (ICDSIS) },
  year={2025},
  author={Gadam, H. and Pal, R. K. and Desai, T. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11070487 },
  abstract={Startup success prediction is the process of estimating a startup's chance of success based on factors like market potential, team experience, funding and other factors. It involves data analysis, data-driven models, and insights to make informed forecasts. However, predicting startup success is challenging due to a lack of experience, financial constraints, and a limited industry network, which minimizes the model performance. Hence, the Gated Recurrent Unit with Shuffle Attention Mechanism (SAM-GRU) is proposed for more accurate startup success prediction. In the pre-processing stage, a min-max normalization technique is applied to normalize the data. An integration of GRU with SAM is utilized to enhance prediction process by improving classification, leads to more accurate forecasting. The proposed SAM-GRU attains minimum Root Mean Square Error (RMSE) of 0.36, a Mean Absolute Error (MAE) of 0.26, Mean Square Error (MSE) of 0.15, and an accuracy of 85.34%, compared to LSTM with parametric Swish activation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDSIS65355.2025.11070487 },
  booktitle={ 2025 3rd International Conference on Data Science and Information System (ICDSIS) },
  chapter={0}
}

@article{rayyan-352343816,
  title={ Towards LLM-Powered Consistency in Model-Based Low-Code Platforms  -  2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  year={2025},
  author={Hagel, N. and Hili, N. and Bartel, A. and Koziolek, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014939 },
  abstract={Low-code platforms often use various models that define the application built by citizen developers. With the increasing size and complexity of the applications built using low-code platforms, the number of required models and the dependencies between them expand. However, with increased complexity, keeping these models consistent during the development or evolution of the application is crucial and often a non-trivial task for citizen developers. In this paper, we present four approaches to how LLMs can be used and integrated on the architecture level into low-code platforms to (i) create consistent models automatically, (ii) keep models consistent based on different types of dependencies, and (iii) support users in maintaining consistent models during the development. We implemented the approaches in a prototype and evaluated them in an exploratory study. The results show that state-of-the-art LLMs are capable of preserving consistency for low-code models as well as generating correct and consistent models in various scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSA-C65153.2025.00058 },
  booktitle={ 2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C) },
  chapter={0}
}

@article{rayyan-352343817,
  title={ AI Can Help Instructors Help Students: An LLM-Supported Approach to Generating Customized Student Reflection Responses  -  2024 IEEE Frontiers in Education Conference (FIE) },
  year={2024},
  author={Wiktor, S. and Dorodchi, M. and Wiktor, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10893324 },
  abstract={This innovative practice paper presents an LLM-supported technique to help instructors respond effectively to periodic students' reflections. Efficient communication between instructors and students is integral to supporting a productive learning environment. Recognizing the significance of understanding students' perceptions and challenges, we present the initial implementation of a system to help instructors analyze and respond to students' feedback promptly and effectively. This research is inspired by and extends prior works where instructors sent progress check emails to students, with some works finding that such communication increased students' motivation. To collect feedback, we administer regular student reflections throughout the semester that capture how students feel about the course and uncover the challenges they face. This regular feedback-gathering approach allows instructors to better track their students' progress and respond to comments throughout the semester to provide guidance. However, reading and responding to each reflection manually in the context of their overall learning experience can be time consuming. To address this challenge, we introduce an LLM-based automated approach that generates tailored, performance-contextualized responses to student reflections that can be used to guide first-contact interventions. The generated reflection responses (GRRs) address issues discussed in student reflections and provide advice, support, course information, and follow-up questions to the students. Additionally, they provide feedback to students based on their accomplishments and behavioral data within the learning management system (LMS), such as submission patterns. In this work, we discuss our method of generating responses based on students' reflections and their LMS behavior. We also present example scenarios of the proposed approach. Preliminary results indicate that this approach can help instructors facilitate positive educational interactions with students and that the participating students view the interventions favorably, fostering a constructive learning environment. This work provides an initial presentation of our large language model-based response generation method to motivate further investigation into AI-assisted student support mechanisms},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FIE61694.2024.10893324 },
  booktitle={ 2024 IEEE Frontiers in Education Conference (FIE) },
  chapter={0}
}

@article{rayyan-352343818,
  title={ StorySpinner: AI Based Technique to Narrate the Web Links  -  2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC) },
  year={2024},
  author={Kumbar, P. and Sharma, S. and Batra, I. and Malik, A. and Ashfaq, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10767564 },
  abstract={The rapid advancement of LLM has facilitated a variety of large language model applications in natural language processing. This report details the development of StorySpinner, an application based on large language models and retrieval-augmented generation that allows yield from articles to the format of an interesting narrative. Moreover, the model addresses processing issues related to the specifics of diverse Internet re-sources, webpages, blogs, and even YouTube videos, by combining web scraping methods, text summarization models, and semantic paragraphs with the use of the extraction of material from extracted abstracts into LLM. The present research investigated the specifics of StorySpinner architecture, the used techniques of information extraction, summarization, and narrative generation, and possible applications of this technology such as educational purposes, accessibility issues, and content development. The paper also provided a discussion of ethical aspects, including bias prevention, copyright issues, and AI technology influence on society. StorySpinner was introduced as a method to fill the gap between web content and human understanding, offering a new way to access information as a story.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETNCC63262.2024.10767564 },
  booktitle={ 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC) },
  chapter={0}
}

@article{rayyan-352343819,
  title={ Towards Regaining Control Over Messy Machine Learning Pipelines  -  2025 IEEE 41st International Conference on Data Engineering Workshops (ICDEW) },
  year={2025},
  author={Grafberger, S. and Chen, H. and Ovcharenko, O. and Schelter, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108164 },
  abstract={Software systems that learn from data with machine learning (ML) are increasingly used to automate impactful decisions. However, the resulting ML pipelines suffer from many unsolved data management challenges with respect to personal and security-critical data and compliance with legal regulations. We argue that this is due to shortcomings in existing ML pipeline abstractions and “messy” imperative code produced by data scientists. We propose a new approach for ML pipelines that leverages the code generation capabilities of large language models to extract declarative logical query plans from messy data science code. We envision this as a foundation to manage deployed ML pipelines and their data artifacts in upcoming Data-AI systems. We discuss a challenging example scenario and present initial experiments with a prototype to validate our vision.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDEW67478.2025.00011 },
  booktitle={ 2025 IEEE 41st International Conference on Data Engineering Workshops (ICDEW) },
  chapter={0}
}

@article{rayyan-352343820,
  title={ Embodied AI with Large Language Models: A Survey and New HRI Framework  -  2024 International Conference on Advanced Robotics and Mechatronics (ICARM) },
  year={2024},
  author={Lin, M. -Y. and Lee, O. -W. and Lu, C. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10715872 },
  abstract={The study aims to develop an emotional logic engine based on a large language model (LLM), providing emotional connections, personalized interactions, knowledge representation, and logical inference. Using this emotional logic engine, we intend to realize the goals of high-level cognition, autonomous knowledge reasoning, long-horizon planning, and action execution described in embodied artificial intelligence (embodied AI). Ultimately, we will implement an efficient intelligent companion interaction robot (ICIR) based on a novel human-robot interaction (HRI) framework to enhance the interaction between humans and robots. The proposed framework integrates multiple components including a visual language model (VLM), logic reasoning model, pre-trained database integration, and the development of a multi-modal template. Additionally, we introduce a complementary framework termed perception-action loop (PALoop), which is meticulously modeled and constructed to facilitate seamless interactions between human operators and robotic systems. Detailed design aspects of both frameworks are elucidated, providing insights into their architecture and functionality. The research outcomes will be practically applied, offering the robotics industry innovative and practical technology solutions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICARM62033.2024.10715872 },
  booktitle={ 2024 International Conference on Advanced Robotics and Mechatronics (ICARM) },
  chapter={0}
}

@article{rayyan-352343821,
  title={ InstAttention: In-Storage Attention Offloading for Cost-Effective Long-Context LLM Inference  -  2025 IEEE International Symposium on High Performance Computer Architecture (HPCA) },
  year={2025},
  author={Pan, X. and Li, E. and Li, Q. and Liang, S. and Shan, Y. and Zhou, K. and Luo, Y. and Wang, X. and Zhang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10946721 },
  abstract={The widespread of Large Language Models (LLMs) marks a significant milestone in generative AI. Nevertheless, the increasing context length and batch size in offline LLM inference escalate the memory requirement of the key-value (KV) cache, which imposes a huge burden on the GPU VRAM, especially for resource-constrained scenarios (e.g., edge computing). Several cost-effective solutions leverage host memory or SSDs to reduce storage costs for offline inference scenarios and improve the throughput. Nevertheless, they suffer from significant performance penalties imposed by intensive KV cache accesses due to limited PCIe bandwidth. To address these issues, we propose InstAttention, a novel LLM inference system that offloads the most performance-critical computation (i.e., attention in decoding phase) and data (i.e., KV cache) parts to Computational Storage Drives (CSDs), which minimize the enormous KV transfer overheads. InstAttention designs a dedicated flashaware in-storage attention engine with KV cache management mechanisms to exploit the high internal bandwidths of CSDs instead of being limited by the PCIe bandwidth. The optimized P2P transmission between GPU and CSDs further reduces data migration overheads. Experimental results demonstrate that for a 13B model using an NVIDIA A6000 GPU, InstAttention improves throughput for long-sequence inference by up to $11.1 \times$, compared to existing SSD-based solutions such as FlexGen.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00113 },
  booktitle={ 2025 IEEE International Symposium on High Performance Computer Architecture (HPCA) },
  chapter={0}
}

@article{rayyan-352343822,
  title={ Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Wei, J. and Courbis, A. -L. and Lambolais, T. and Xu, B. and Bernard, P. L. and Dray, G. and Maalej, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764984 },
  abstract={Over the past decade, app store (AppStore)-inspired requirements elicitation has proven to be highly beneficial. Developers often explore competitors’ apps to gather inspiration for new features. With the advance of Generative AI, recent studies have demonstrated the potential of large language model (LLM)-inspired requirements elicitation. LLMs can assist in this process by providing inspiration for new feature ideas. While both approaches are gaining popularity in practice, there is a lack of insight into their differences. We report on a comparative study between AppStore- and LLM-based approaches for refining features into sub-features. By manually analyzing 1,200 sub-features recommended from both approaches, we identified their benefits, challenges, and key differences. While both approaches recommend highly relevant sub-features with clear descriptions, LLMs seem more powerful particularly concerning novel unseen app scopes. Moreover, some recommended features are imaginary with unclear feasibility, which suggests the importance of a human-analyst in the elicitation loop.CCS CONCEPTS• Software and its engineering → Requirements analysis; • Computing methodologies → Natural language processing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352343823,
  title={ AI-Based Dementia Early Care and Prognosis  -  2025 International Conference on Circuit, Systems and Communication (ICCSC) },
  year={2025},
  author={Kanjalkar, J. and Ghule, C. and Mantri, S. and Kumawat, R. and Umare, A. and Bhutada, M. and Sharma, P. and Kanjalkar, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135322 },
  abstract={Dementia, a neurodegenerative disorder, severely affects cognitive and affective functioning, so early diagnosis is imperative for enhancing patient outcomes. This work provides a holistic, AI-based framework for detecting dementia with three essential methodologies:(1) a Large Language Model (LLM) that is used to evaluate cognitive functioning through chatbot-based interactions, (2) a Convolutional Neural Network (CNN) model for interpreting patient facial expressions, and (3) an MRI-based deep learning model for precise clinical classification of dementia severity. By integrating these methodologies, the study aims to develop an accessible, scalable, and reliable early detection system for dementia, hosted on a convenient cloud platform. The system incorporates a dualinterface design: one to enable patients to self-assess and interact with a chatbot, and the other for clinicians to upload MRI data and analyse emotional or behavioural signals through video analysis. This paper addresses the development process, dataset preparation, model training, and integration challenges, together with clinical implications of the proposed multimodal system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCSC66714.2025.11135322 },
  booktitle={ 2025 International Conference on Circuit, Systems and Communication (ICCSC) },
  chapter={0}
}

@article{rayyan-352343824,
  title={ LLM-based kidney disease diagnostic framework for Pathologists  -  2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) },
  year={2024},
  author={Syeda, M. Z. and Bukhari, S. U. K. and Hussain, M. and Khan, W. A. and Shah, S. S. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10782599 },
  abstract={Large language models revolutionize the recent paradigm in the medical field and its contributing to various applications, diversified from clinical decision support to information extraction and summarization. The substantial linguistic understanding and contextual awareness allow language models to process and evaluate decision tasks. Concurrently, it addresses the challenges encountered by pathologists in disease diagnosis by adeptly retrieving precise and accurate facts from an external knowledge base. In this paper, we propose a framework which incorporates advanced retrieval augmented generation with prompt engineering techniques, contain prompting levels and structured prompts, which enables the model to extract refine, and customize responses. The model has been equipped with a large corpus of several kidney diseases clinical data which is collected from the vast information sources of kidney diagnostic books. The utilization of varied prompt techniques, exemplified by standard prompts like few-shots and the Reasoning Act (ReAct), manifests notable improvements in disease diagnosis responses. Structured prompts are designed to provide pathologists with specific instructions for formulating questions that effectively enhance the performance of the model. In the evaluation of prompt performance, three key metrics are employed answer relevance, faithfulness, and context relevance. Notably, in the context relevance metric, an optimal performance score of 1.0 was attained indicating perfect alignment with the conversational context.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EMBC53108.2024.10782599 },
  booktitle={ 2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) },
  chapter={0}
}

@article{rayyan-352343825,
  title={ Cloud-Edge System for Scheduling Unpredictable LLM Requests with Combinatorial Bandit  -  IEEE Transactions on Services Computing },
  author={Li, Y. and Guo, J. and Tang, Z. and Ding, X. and Wang, J. and Wang, T. and Jia, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169423 },
  abstract={The rapid growth in demand for large language models (LLMs) has strained cloud-edge infrastructure. While edges offer low latency and clouds provide vast resources, scheduling LLM requests efficiently remains a major challenge due to their unpredictable processing times, which leads to Headof-Line (HOL) blocking that degrades system throughput and responsiveness. To address this, we introduce the Online CloudEdge Collaborative Request Scheduling (OCE-CRS) framework. OCE-CRS models the proactive scheduling of LLM requests as a contextual combinatorial bandit problem. At its core is our novel Combinatorial Neural Delayed Upper Confidence Bound (CN DUCB) algorithm, which learns to predict request processing times from the semantic content of the request prompt alone. This enables an inspired policy based on Shortest Job First (SJF) that prioritizes shorter jobs for edge execution, simultaneously maximizing throughput and mitigating HOL blocking. To prevent time-consuming neural network training from blocking scheduling decisions, we employ an asynchronous mechanism. This decouples model updates from the real-time scheduling loop, effectively handling the resultant delayed feedback where observations from past rounds are used in later training steps. We provide a theoretical sublinear regret bound for our algorithm. Extensive experiments validate that OCE-CRS significantly improves throughput, Job Completion Time (JCT), and queueing delay, demonstrating superior performance and robustness in both static and continuous batching environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TSC.2025.3611379 },
  booktitle={ IEEE Transactions on Services Computing },
  chapter={0}
}

@article{rayyan-352343826,
  title={ Multilingual Low-Latency Emergency VoIP System Using LLM for Speech Reconstruction and Blockchain for Secure Data Archiving  -  IEEE Access },
  author={Rafi, R. A. and Ahmed, S. and Venkateshperumal, D. and Khokhar, A. and Arifuzzaman, M. and Azad, A. and Alyami, S. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130186 },
  abstract={Emergency VoIP communications frequently suffer from packet loss, jitter, and background noise, which degrade speech quality, delay dispatcher response, and threaten the reliability of emergency services. This paper presents a blockchain-governed, low-latency communication response framework powered by a Large Language Model (LLM), leveraging GPT-4o-mini for semantic speech reconstruction and dynamic emergency prioritization. The proposed architecture integrates multilingual speech-to-text and translation via Google APIs, a Facebook AI Similarity Search (FAISS)-indexed retrieval system for context-driven LLM inference, and severity classification for dispatcher triaging. To ensure tamper-proof data governance, the system incorporates AES-256-CBC encryption, Shamir’s Secret Sharing, and decentralized transcript storage on Arweave, with access mediated by Solana-based multi-signature wallets and program-derived addresses. Quantitative evaluations confirm that the proposed framework meets low-latency standards with sub-1.5 second one-way latency—significantly outperforming prior VoIP-based multilingual emergency systems, which typically report 3–5 second delays. Unlike conventional pipelines, it leverages asynchronous blockchain storage and optimized LLM-driven reconstruction to achieve high responsiveness without sacrificing Conceptual Precision, BLEU, or ROUGE accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3600364 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343827,
  title={ Comm-CoT: Standardized Chain-of-Thought Communication Framework for Efficient LLM based Multi-Agent Decision-Making in Real-Time Strategy Games  -  2025 IEEE 2nd International Conference on Electronics, Communications and Intelligent Science (ECIS) },
  year={2025},
  author={Qi, R. and Quan, Y. and Ni, Y. and Li, Z. and Xu, X. and Huang, K. and Guo, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11087008 },
  abstract={In recent years, Large Language Models (LLMs) have become a hotspot in AI research due to their remarkable success in natural language processing. LLM-based Multi-Agent Systems have also achieved significant progress in tasks such as distributed decision-making. However, due to inherent limitations of LLMs, such as hallucination and lack of contextual information, their communication efficiency within multi-agent frameworks remains suboptimal, thereby constraining the overall decision-making capabilities of the system. To address this issue, we propose a standardized communication framework based on Chain-of-Thought (CoT) method, named Comm-CoT (Communication-Chain of Thought), and conduct experiments in a real-time strategy game environment using the LLM-PySC2 platform. On a specially designed multi-unit cooperative combat scenario, the experimental results demonstrate that Comm-CoT significantly improves the win rate of LLMs while enhancing communication efficiency and the ability of agents to utilize communication information in multi-agent systems. The code is open-sourced and available at https://github.com/NUDT-Decision-Team/LLM-PySC2-Comm-CoT.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECIS65594.2025.11087008 },
  booktitle={ 2025 IEEE 2nd International Conference on Electronics, Communications and Intelligent Science (ECIS) },
  chapter={0}
}

@article{rayyan-352343828,
  title={ MedHub – LLM-based Healthcare System  -  2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS) },
  year={2025},
  author={M, R. Kumar and L, S. G and S, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042126 },
  abstract={Artificial Intelligence is revolutionizing healthcare and particularly disease management through the automation of diagnosis and decision support as well as large-scale analysis of data-a true foundation for predictive care anywhere globally. Recent events reveal that AI and LLMs indeed make a difference in medical services. MedHub is an innovative project that relies on LLMs to improve medical diagnosis and tailor health management. It supports users through supplementary suggestions, which are based on their symptoms; it also incorporates a medical chatbot that works like a virtual health assistant. MedHub analyzes health information, responds with questions in real time, provides preliminary advice, and keeps people informed to have relevant discussions with healthcare professionals. It delivers answers to questions on what is wrong, health tips, and related information that is accurate and highly customized, driven by individual health profiles- all of these are available 24 hours a day. MedHub caters to every age group from young adults to seniors in the general population, thereby promoting healthier lifestyle and wellness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAISS61471.2025.11042126 },
  booktitle={ 2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS) },
  chapter={0}
}

@article{rayyan-352343829,
  title={ Dynamic StarCraft: Multi-Agent Generative AI for Immersive Experiences  -  2025 International Conference on Emerging Smart Computing and Informatics (ESCI) },
  year={2025},
  author={Patil, B. and Yadav, G. B. and Buchade, A. and Borkar, S. and Bhosale, S. and Honbute, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987974 },
  abstract={The present research reveals a unique educational approach through the use of Generative Artificial Intelligence (GenAI) with the focus on storytelling with children. It is shown that by adding GenAI narrative co-creation, voice-over synthesis, and video audition to the system, the learning process becomes interesting. We understand how the audience creates the stories with which they will perform, how the stories are narrated in audio created with advanced text-to-speech systems, and how images for the narratives are generated with text-to-video. Our assessment is however concerned with the level of the languages used in writing the stories, how the stories written were pronounced and the images that were produced, as we point out the ability of the tool to entertain young learners.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ESCI63694.2025.10987974 },
  booktitle={ 2025 International Conference on Emerging Smart Computing and Informatics (ESCI) },
  chapter={0}
}

@article{rayyan-352343830,
  title={ Advancing Scientific Workflows: A Human-LLM Note-Taking System with Case-Based Reasoning  -  2025 IEEE Conference on Artificial Intelligence (CAI) },
  year={2025},
  author={Craig, D. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050733 },
  abstract={Human-centered artificial intelligence (AI) systems are most effective when they foster collaboration with users, enabling iterative problem solving and creativity. However, many existing AI solutions operate as opaque, autonomous systems, limiting opportunities for human engagement, transparency, and refinement. This lack of integration between AI and human expertise often results in barriers to trust and hinders the development of innovative solutions, particularly in complex, data-intensive domains like scientific research. Here we introduce a novel human-LLM system built on the Obsidian note-taking application, designed to integrate large language models (LLMs) into a transparent, interactive, and collaborative framework. Key features of this system include case-based reasoning (CBR) and language-aware tools, with cases and tools represented as first-class notes. A Python executive program coordinates user interactions, while advanced search capabilities powered by embeddings and a graph database enhance the retrieval of relevant cases and tools. In addition, the system supports techniques and tools for incrementally building and refining solutions to novel problems, thereby facilitating both structured workflows and scientific discovery. The system tackles the challenges of integrating AI into human workflows by promoting transparency, adaptability, and meaningful collaboration. Initially tailored for the biological sciences domain, it enhances productivity and insight by enabling a seamless, interactive partnership between humans and AI, advancing the state-of-the-art in scientific workflows through a unified and accessible platform.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI64502.2025.00055 },
  booktitle={ 2025 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343831,
  title={ MDRE-LLM: A Tool for Analyzing and Applying LLMs in Software Reverse Engineering  -  2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER) },
  year={2025},
  author={Boronat, A. and Mustafa, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992421 },
  abstract={Understanding and maintaining software systems often requires extracting high-level abstractions, such as domain models, from source code. MDRE-LLM addresses this challenge by integrating Large Language Models (LLMs) with traditional Model-Driven Reverse Engineering (MDRE) techniques, offering an innovative approach to automate and enhance domain model recovery. The tool supports flexible granularity strategies and validates LLM -generated models against deterministic baselines. MDRE-LLM addresses diverse use cases, including analyzing legacy systems with minimal documentation, rapidly compre-hending large-scale codebases, and validating LLM performance in reverse engineering tasks. These capabilities have the potential to improve software analysis and refactoring while advance AI-driven research and education by fostering systematic experimentation and collaboration. The tool and a webcast are available at https://zenodo.org/uploads/14072106.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SANER64311.2025.00090 },
  booktitle={ 2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER) },
  chapter={0}
}

@article{rayyan-352343832,
  title={ Secure LLM-Oriented Data Engineering Pipelines for Scalable AI Workflows in Multi-Cloud Environments  -  2025 International Conference on Computing Technologies & Data Communication (ICCTDC) },
  year={2025},
  author={Madupati, B. and Jonnalagadda, A. K. and Vududala, S. K. and Vegesna, R. Varma},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11158901 },
  abstract={Advances in LLMs have altered AI analytics, yet they are not yet easily brought into scalable, secure and efficient engineering systems—especially in settings with various cloud platforms. The paper offers a new design for LLM-driven data engineering processes that resolves major issues in collecting, processing and publishing data on the cloud. A proposed framework includes federated orchestration, encryption of all data and access control policies without trust, to achieve proper data privacy and adherence to rules, as well as ensure fast realtime processing of both unstructured and semi-structured data. In addition, we introduce a new scheduler and metadata manager to automatically optimize things like building prompts, training and inferencing using machine learning models. Extensive study using common benchmark sets on AWS, Azure and GCP demonstrates that there are 35% fewer pipeline problems, cost is reduced by 28% and the system performs more effectively and is more resilient. This research outlines how secure and scalable use of AI systems powered by LLMs can be spread across various multi-cloud platforms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCTDC64446.2025.11158901 },
  booktitle={ 2025 International Conference on Computing Technologies & Data Communication (ICCTDC) },
  chapter={0}
}

@article{rayyan-352343833,
  title={ AI Driven LLM integrated diffusion models for Image Enhancement- A Survey  -  2024 IEEE Conference on Engineering Informatics (ICEI) },
  year={2024},
  author={Pattankudi, M. S. Z. and Attar, A. R. and Jewargi, K. and Uppin, S. and Khanapure, A. and Kulkarni, U.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912400 },
  abstract={Text-to-image generation has emerged as a prominent research problem in computer vision and natural language processing, resulting from recent progress in generative models and LLMs. This paper reviews the latest research on Text-to-image generation models integrated with Large Language Models (LLMs). The paper focuses on the analysis of six LLM integrated models namely DiffusionGPT, LLM Grounded Diffusion Model, IN-STRUCTCV, ECLIPSE, Self-Correcting LLM-Controlled Diffusion Models and SUR adapter. Each model is evaluated based on its architecture, methodology and results. Our analysis identifies the advantages and disadvantages of different models and provides recommendations for further research directions. At the end of this paper is a summary of the current advancements in the field and suggestions for future study possibilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEI64305.2024.10912400 },
  booktitle={ 2024 IEEE Conference on Engineering Informatics (ICEI) },
  chapter={0}
}

@article{rayyan-352343834,
  title={ Exploring the Computational Thinking Process of College Students: Collaborative Programming with LLMs  -  2025 7th International Conference on Computer Science and Technologies in Education (CSTE) },
  year={2025},
  author={Li, Z. and Zheng, X. and Fu, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11092183 },
  abstract={Computational thinking (CT) has gained increasing attention from educators and practitioners due to its effectiveness in fostering student development, particularly in programming courses. Meanwhile, with the rapid advancement of large language models (LLMs), an increasing number of teachers and students are incorporating AI-assisted teaching and learning. However, empirical research on the patterns of CT processes when students adopt different AI-assisted learning strategies remains limited. This study explores the differences in CT process patterns when students use two different types of LLMs: General AI Group (GAIG) and No Code AI Group (NCAIG). Results showed that: (1) The social perspective is the most dominant in CT (2) Questioning and connecting co-occur most often, followed by connecting and sequencing, as well as questioning and sequencing; (3) Students' prior knowledge significantly affects their CT patterns. These findings provide empirical support for educators to effectively guide students in leveraging AI technology to enhance CT in instructional settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSTE64638.2025.11092183 },
  booktitle={ 2025 7th International Conference on Computer Science and Technologies in Education (CSTE) },
  chapter={0}
}

@article{rayyan-352343835,
  title={ Embodied AI-Enhanced Vehicular Networks: An Integrated Vision Language Models and Reinforcement Learning Method  -  IEEE Transactions on Mobile Computing },
  author={Zhang, R. and Zhao, C. and Du, H. and Niyato, D. and Wang, J. and Sawadsitang, S. and Shen, X. and Kim, D. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11049053 },
  abstract={This paper investigates adaptive transmission strategies in embodied AI-enhanced vehicular networks by integrating vision language models (VLMs) for semantic information extraction and deep reinforcement learning (DRL) for decision-making. The proposed framework aims to optimize both data transmission efficiency and decision accuracy by formulating an optimization problem that incorporates the Weber-Fechner law, serving as a metric for balancing bandwidth utilization and quality of experience (QoE). Specifically, we employ the large language and vision assistant (LLAVA) model to extract critical semantic information from raw image data captured by embodied AI agents (i.e., vehicles), reducing transmission data size by approximately more than 90% while retaining essential content for vehicular communication and decision-making. In the dynamic vehicular environment, we employ a generalized advantage estimation-based proximal policy optimization (GAE-PPO) method to stabilize decision-making under uncertainty. Simulation results show that attention maps from LLAVA highlight the model’s focus on relevant image regions, enhancing semantic representation accuracy. Additionally, our proposed transmission strategy improves QoE by up to 36% compared to DDPG and accelerates convergence by reducing required steps by up to 47% compared to pure PPO. Further analysis indicates that adapting semantic symbol length provides an effective trade-off between transmission quality and bandwidth, achieving up to a 61.4% improvement in QoE when scaling from 4 to 8 vehicles.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TMC.2025.3582864 },
  booktitle={ IEEE Transactions on Mobile Computing },
  chapter={0}
}

@article{rayyan-352343836,
  title={ Securing Digital Banking for Seniors - Preventing Elder Financial Exploitation Using AI  -  2025 IEEE Evolution - Life Members Conference },
  year={2025},
  author={Saha, D. and Chavan, B. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11044425 },
  abstract={Digital banking has revolutionized the mode of banking in the past decade. Instead of people going to the bank, digital banking via web, mobile, tablet has now reached at people's home at their fingertips. However, this also has brought in significant cyber threat of financial exploitation particularly impacting the senior people. Senior people are more vulnerable to financial exploitation compared to their younger counterparts due to several factors such as cognitive decline due to age, unfamiliar with social engineering attacks, trouble with navigating complex user interfaces etc. This paper proposes a dual technique to protect senior population from financial exploitation leveraging artificial intelligence as the backbone - an AI-driven education and awareness model and an AI-powered financial assistant to prevent fraud during transaction. The financial assistant uses a voicebased alerting system to maximize the possibility of fraud prevention improving the general security posture during financial transaction particularly safeguarding the seniors. The education and awareness model on the other hand, provides adaptive education to the seniors, thus reducing the possibility of being compromised while using digital banking channels. This dual solution strategy ensures the elderly population can confidently and safely use digital banking platforms, striking a balance between security and accessibility. This paper contributes to the essential area of cybersecurity for the aging population and provides a practical solution for financial institutions to adopt and protect their senior customers from financial exploitation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Evolution65010.2025.11044425 },
  booktitle={ 2025 IEEE Evolution - Life Members Conference },
  chapter={0}
}

@article{rayyan-352343837,
  title={ DevGPT: Studying Developer-ChatGPT Conversations  -  2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR) },
  year={2024},
  author={Xiao, T. and Treude, C. and Hata, H. and Matsumoto, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555646 },
  abstract={This paper introduces DevGPT, a dataset curated to explore how software developers interact with ChatGPT, a prominent large language model (LLM). The dataset encompasses 29,778 prompts and responses from ChatGPT, including 19,106 code snippets, and is linked to corresponding software development artifacts such as source code, commits, issues, pull requests, discussions, and Hacker News threads. This comprehensive dataset is derived from shared ChatGPT conversations collected from GitHub and Hacker News, providing a rich resource for understanding the dynamics of developer interactions with ChatGPT, the nature of their inquiries, and the impact of these interactions on their work. DevGPT enables the study of developer queries, the effectiveness of ChatGPT in code generation and problem solving, and the broader implications of AI-assisted programming. By providing this dataset, the paper paves the way for novel research avenues in software engineering, particularly in understanding and improving the use of LLMs like ChatGPT by developers.CCS CONCEPTS• Information systems → Data mining.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR) },
  chapter={0}
}

@article{rayyan-352343838,
  title={ Mental Health Prediction using Machine Learning Models and Large Language Model  -  2024 Second International Conference on Inventive Computing and Informatics (ICICI) },
  year={2024},
  author={Kamoji, S. and Rozario, S. and Almeida, S. and Patil, S. and Patankar, S. and Pendhari, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10675718 },
  abstract={Mental health is integral to overall well-being, impacting human ability to deal with challenges in life. Machine learning and AI hold promise in predicting mental illnesses by analysing behavioural patterns, aiding in early detection and intervention. This proactive approach can mitigate symptom escalation, improving mental health outcomes. This research study introduces a novel predictive framework integrating ensemble learning techniques and large language models (LLMs). Initially, ensemble learning, including AdaBoost, voting, and bagging, constructs a robust model with Random Forest emerging as optimal. Subsequently, a Large Language Model (LLM) enhances the pipeline. User input triggers mental health prediction by Random Forest, forwarded to a Google Gemini model via an API key, generating personalised insights, marking a significant advancement in mental health prediction.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICICI62254.2024.00040 },
  booktitle={ 2024 Second International Conference on Inventive Computing and Informatics (ICICI) },
  chapter={0}
}

@article{rayyan-352343839,
  title={ Developing a Website to Analyze and Validate Projects Using LangChain and Streamlit  -  2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT) },
  year={2024},
  author={Pillai, M. and Thakur, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467765 },
  abstract={This research study provides a new approach to project analysis and validation through the creation of a website using LangChain, a framework for building applications powered by Language Models, and Streamlit which is used to create LLM powered and Generative AI web applications quickly. In an era of rapid technological change, the necessity for effective project assessment tools has become increasingly crucial. The goal of this research is to overcome this obstacle by utilizing LangChain's natural language processing and understanding capabilities. The proposed website serves as a basic platform for project validation, making it easier to assess project feasibility, technical requirements, and work allocation. It serves as a starting point for developing a comprehensive system. The features of LangChain allow for the extraction of valuable insights from project data, technology, and team experience, resulting in a more automated and intelligent decision-making process. The developed website encompasses two main functionalities: individual and team project validation and task allocation. For individual projects, users can input project details and technologies, and their resume after which LangChain processes the information to determine feasibility and generate technical specifications based on the assessment of their resume. On the other hand, the team task allocation feature, utilizes LangChain to analyze frontend and backend specifications, and project requirements to intelligently allocate tasks based on team's experience level.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDCIoT59759.2024.10467765 },
  booktitle={ 2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT) },
  chapter={0}
}

@article{rayyan-352343840,
  title={ Natural Language Processing in Environmental Health Research  -  2024 IEEE MIT Undergraduate Research Technology Conference (URTC) },
  year={2024},
  author={Tiahi, M. and Kumar, M. and Feric, Z. and Kaeli, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937629 },
  abstract={Large Language Models (LLMs) are utilized across multiple disciplines for summarizing information and generating domain relevant responses. The Puerto Rico Testsite for Exploring Contamination Threats (PROTECT) Center at Northeastern University aims to address environmental health issues, particularly focusing on the impact of exposure to environmental contaminants on preterm birth rates in Puerto Rico. We explore the application of RAG in creating an AI assistant tailored to the needs of PROTECT for information dissemination and community engagement. The virtual assistant is designed to interact with community members, providing them with information about environmental health risks and preventive measures. We assess the performance our model and its efficacy in environmental health research compared to other Large Language Models (LLMs). Our findings suggest that equipping an LLM with a RAG model in the domain of environmental health studies can enhance outreach efforts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/URTC65039.2024.10937629 },
  booktitle={ 2024 IEEE MIT Undergraduate Research Technology Conference (URTC) },
  chapter={0}
}

@article{rayyan-352343841,
  title={ Assessing the Resilience of BFT-Raft Consensus Against Insider DoS Attacks in Blockchain  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Altarawneh, A. and Owusu-Tweneboah, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903681 },
  abstract={A significant amount of research has put forward various consensus mechanisms for blockchain technology, but many have not been implemented due to security and performance concerns. Consensus mechanisms are essential for ensuring the continued operation (liveness) and security of blockchain systems. The Byzantine Fault Tolerant-Raft (BFT-Raft) consensus algorithm combines the simplicity of Raft, developed by the Stanford group, with the resilience of Byzantine Fault Tolerance (BFT) mechanisms. However, the liveness and security of BFT-Raft as a consensus mechanism have not been thoroughly validated. This study addresses this gap by analyzing the availability of BFT-Raft, particularly focusing on the behavior of malicious miners who manipulate their timeout to influence the leader election process within the consensus mechanism. Using both simulation and theoretical models, the research assesses the vulnerability of BFT-Raft to insider denial of service (DoS) attacks. Additionally, the study evaluates BFT-Rafts' ability to maintain availability and effectively terminate the consensus and miner selection processes in the presence of malicious miners and clients. Using binomial distribution, queuing theory, and Markov chains, the resilience of BFT-Raft is systematically examined. The findings indicate that BFT-Raft has specific security vulnerabilities making it susceptible to insider DoS attacks. The paper also proposes potential approaches to mitigate these vulnerabilities, such as a game theory approach with incentives and penalties, a hardware-based approach, and an attack detection approach using AI and explainable AI to help make decisions for these complex attacks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903681 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343842,
  title={ NextG-GPT: Leveraging GenAI for Advancing Wireless Networks and Communication Research  -  2025 34th International Conference on Computer Communications and Networks (ICCCN) },
  year={2025},
  author={Nazar, A. M. and Selim, M. Y. and Qiao, D. and Zhang, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11133874 },
  abstract={Artificial intelligence (AI) and wireless networking advancements have created new opportunities to enhance network efficiency and performance. In this paper, we introduce Next-Generation GPT (NextG-GPT), an innovative framework that integrates retrieval-augmented generation (RAG) and large language models (LLMs) within the wireless systems’ domain. By leveraging state-of-the-art LLMs alongside a domain-specific knowledge base, NextG-GPT provides context-aware real-time support for researchers, optimizing wireless network operations. Through a comprehensive evaluation of LLMs—including Mistral-7B, Mixtral-8×7B, LLaMa3.1-8B, and LLaMa3.1-70B—we demonstrate significant improvements in answer relevance, contextual accuracy, and overall correctness. In particular, LLaMa3.1-70B achieves a correctness score of 86.2% and an answer relevancy rating of 90.6%. By incorporating diverse datasets such as ORAN-13K-Bench, TeleQnA, TSpecLLM, and Spec5G, we improve NextG-GPT’s knowledge base, generating precise and contextually aligned responses. This work establishes a new benchmark in AI-driven support for next-generation wireless network research, paving the way for future innovations in intelligent communication systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCN65249.2025.11133874 },
  booktitle={ 2025 34th International Conference on Computer Communications and Networks (ICCCN) },
  chapter={0}
}

@article{rayyan-352343843,
  title={ Generative Artificial Intelligence and Large Language Models: A Systematic Review of Architectures, Applications, and Future Directions  -  2025 25th International Conference on Control Systems and Computer Science (CSCS) },
  year={2025},
  author={Ciubotaru, B. -I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181683 },
  abstract={This review aims to identify the most significant practical applications, limitations, and future directions of generative AI (artificial intelligence) and LLMs (Large Language Models) to guide researchers, industry stakeholders, and policymakers. Through comprehensive analysis of scientific literature, it was traced the development of these technologies from early linguistic theories to modern transformer-based architectures. The findings presented in this review article reveal the transformative impact of LLMs across diverse domains including healthcare, education, software development, and creative industries. Significant technical limitations were identified, including hallucinations, context window constraints, and reasoning deficiencies, along-side ethical concerns regarding bias, privacy, and environmental impact. The review concludes by exploring emerging trends in model architecture, efficiency improvements, and ethical frameworks that will shape future development. This work provides researchers, practitioners, and policymakers with a comprehensive understanding of the current state and future trajectory of generative AI and LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCS66924.2025.00063 },
  booktitle={ 2025 25th International Conference on Control Systems and Computer Science (CSCS) },
  chapter={0}
}

@article{rayyan-352343844,
  title={ What Guides Our Choices? Modeling Developers' Trust and Behavioral Intentions Towards Genai  -  2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE) },
  year={2025},
  author={Choudhuri, R. and Trinkenreich, B. and Pandita, R. and Kalliamvakou, E. and Steinmacher, I. and Gerosa, M. and Sanchez, C. and Sarma, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029764 },
  abstract={Generative AI (genAI) tools, such as ChatGPT or Copilot, are advertised to improve developer productivity and are being integrated into software development. However, misaligned trust, skepticism, and usability concerns can impede the adoption of such tools. Research also indicates that AI can be exclusionary, failing to support diverse users adequately. One such aspect of diversity is cognitive diversity-variations in users' cognitive styles-that leads to divergence in perspectives and interaction styles. When an individual's cognitive style is unsupported, it creates barriers to technology adoption. Therefore, to understand how to effectively integrate genAI tools into software development, it is first important to model what factors affect developers' trust and intentions to adopt genAI tools in practice? We developed a theoretically grounded statistical model to (1) identify factors that influence developers' trust in genAI tools and (2) examine the relationship between developers' trust, cognitive styles, and their intentions to use these tools in their work. We surveyed software developers ($\mathrm{N}=238$) at two major global tech organizations: GitHub Inc. and Microsoft; and employed Partial Least Squares-Structural Equation Modeling (PLS-SEM) to evaluate our model. Our findings reveal that genAI's system/output quality, functional value, and goal maintenance significantly influence developers' trust in these tools. Furthermore, developers' trust and cognitive styles influence their intentions to use these tools in their work. We offer practical suggestions for designing genAI tools for effective use and inclusive user experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE55347.2025.00087 },
  booktitle={ 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE) },
  chapter={0}
}

@article{rayyan-352343845,
  title={ Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Li, H. and Yang, X. and Wang, Z. and Zhu, X. and Zhou, J. and Qiao, Y. and Wang, X. and Li, H. and Lu, L. and Dai, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10658032 },
  abstract={Many reinforcement learning environments (e.g., Minecraft) provide only sparse rewards that indicate task completion or failure with binary values. The challenge in exploration efficiency in such environments makes it difficult for reinforcement-learning-based agents to learn complex tasks. To address this, this paper introduces an advanced learning system, named Auto MC-Reward, that leverages Large Language Models (LLMs) to automatically design dense reward functions, thereby enhancing the learning efficiency. Auto MC-Reward consists of three important components: Reward Designer, Reward Critic, and Trajectory Analyzer. Given the environment information and task descriptions, the Reward Designer first design the reward function by coding an executable Python function with predefined observation inputs. Then, our Reward Critic will be responsible for verifying the code, checking whether the code is self-consistent and free of syntax and semantic errors. Further, the Trajectory Analyzer summarizes possible failure causes and provides refinement suggestions according to collected trajectories. In the next round, Reward Designer will further refine and iterate the dense reward function based on feedback. Experiments demonstrate a significant improvement in the success rate and learning efficiency of our agents in complex tasks in Minecraft, such as obtaining diamond with the efficient ability to avoid lava, and efficiently explore trees and animals that are sparse in the plains biome.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.01554 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343846,
  title={ THRONE: An Object-Based Hallucination Benchmark for the Free-Form Generations of Large Vision-Language Models  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Kaul, P. and Li, Z. and Yang, H. and Dukler, Y. and Swaminathan, A. and Taylor, C. J. and Soatto, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10657848 },
  abstract={Mitigating hallucinations in large vision-language models (LVLMs) remains an open problem. Recent benchmarks do not address hallucinations in open-ended free-form responses, which we term “Type I hallucinations”. Instead, they focus on hallucinations responding to very specific question formats-typically a multiple-choice response regarding a particular object or attribute-which we term “Type II hallucinations”. Additionally, such benchmarks often require external API calls to models which are subject to change. In practice, we observe that a reduction in Type II hallucinations does not lead to a reduction in Type I hallucinations but rather that the two forms of halluci-nations are often anti-correlated. To address this, we propose THRONE, a novel object-based automatic framework for quantitatively evaluating Type I hallucinations in LVLM free-form outputs. We use public language models (LMs) to identify hallucinations in LVLM responses and compute informative metrics. By evaluating a large selection of recent LVLMs using public datasets, we show that an improvement in existing metrics do not lead to a reduction in Type I hallucinations, and that established benchmarks for measuring Type I hallucinations are incomplete. Finally, we provide a simple and effective data augmentation method to reduce Type I and Type II hallucinations as a strong baseline.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.02571 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343847,
  title={ A Study on the Effectiveness of GPT-4V in Classifying Driver Behavior Captured on Video Using Just a Few Frames per Video  -  2024 International Joint Conference on Neural Networks (IJCNN) },
  year={2024},
  author={Calenzani, J. F. G. and Neves, V. N. and Ramos, L. T. and Junior, L. J. L. and Magnago, L. C. S. and Badue, C. and Oliveira-Santos, T. and Souza, A. F. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650751 },
  abstract={This paper introduces an innovative study that evaluates the effectiveness of GPT-4V vision processing technology in identifying risk events within driving scenarios. These scenarios are captured in a series of videos, with GPT-4V’s analysis focusing on only a few frames from each video. The study specifically targets risk behaviors such as yawning, smoking, phone usage, and distractions from the road. To achieve this, it utilizes a comprehensive collection of video recordings featuring drivers, which have been previously annotated by human evaluators to identify and tag instances of such risk behaviors. Our methodology involves a detailed analysis of GPT-4V’s performance, assessing its accuracy and consistency against human benchmarks across both private and public datasets. For the private dataset, GPT-4V demonstrated strong performance in identifying yawning events with a 98.9% accuracy, closely followed by a 98.4% accuracy in detecting smoking. In terms of recognizing driver distractions, it achieved a 91.7% accuracy, and for phone usage, it recorded a 95.7% accuracy. The "Face Not Visible" events achieved a 94.1% accuracy. For the public dataset, GPT-4V achieved an accuracy of 90.9% for the "Using Cellphone" category, with a recall of 76.6% and a precision of 92.1%. In identifying "Distraction" events, it achieved an accuracy of 91.0%, with a recall of 93.1% and a precision of 97.4%. For "Yawning" events, it achieved an accuracy of 98.2%, although its recall was lower at 43.7%, with a precision of 87.5%. These findings significantly enhance our understanding of how multimodal foundation models can be applied to improve road safety. Additionally, these results provide clear directions for future developments in autonomous monitoring systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IJCNN60899.2024.10650751 },
  booktitle={ 2024 International Joint Conference on Neural Networks (IJCNN) },
  chapter={0}
}

@article{rayyan-352343848,
  title={ Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Jang, Y. and Song, Y. and Sohn, S. and Logeswaran, L. and Luo, T. and Kim, D. -K. and Bae, K. and Lee, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093822 },
  abstract={Recent advancements in Large Language Models (LLMs) and Vision-Language Models (VLMs) have sparked significant interest in developing GUI visual agents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from YouTube), a large-scale dataset of 313K annotated frames from 20K instructional videos capturing diverse real-world mobile OS navigation across multiple platforms. Models that include MONDAY in their pretraining phases demonstrate robust cross-platform generalization capabilities, consistently outperforming models trained on existing single OS datasets while achieving an average performance gain of 18.11%p on an unseen mobile OS platform. To enable continuous dataset expansion as mobile platforms evolve, we present an automated framework that leverages publicly available video content to create comprehensive task datasets without manual annotation. Our framework comprises robust OCR-based scene detection (95.04% F1-score), near-perfect UI element detection (99.87% hit ratio), and novel multi-step action identification to extract reliable action sequences across diverse interface configurations. We contribute both the MONDAY dataset and our automated collection framework to facilitate future research in mobile OS navigation, available at https://github.com/runamu/monday.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.00804 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343849,
  title={ StarVector: Generating Scalable Vector Graphics Code from Images and Text  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Rodriguez, J. A. and Puri, A. and Agarwal, S. and Laradji, I. H. and Rodriguez, P. and Rajeswar, S. and Vazquez, D. and Pal, C. and Pedersoli, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11094387 },
  abstract={Scalable Vector Graphics (SVGs) are vital for modern image rendering due to their scalability and versatility. Previous SVG generation methods have focused on curve-based vectorization, lacking semantic understanding, often producing artifacts, and struggling with SVG primitives beyond path curves. To address these issues, we introduce StarVector, a multimodal large language model for SVG generation. It performs image vectorization by understanding image semantics and using SVG primitives for compact, precise outputs. Unlike traditional methods, StarVector works directly in the SVG code space, leveraging visual understanding to apply accurate SVG primitives. To train StarVector, we create SVG-Stack, a diverse dataset of 2M samples that enables generalization across vectorization tasks and precise use of primitives like ellipses, polygons, and text. We address challenges in SVG evaluation, showing that pixel-based metrics like MSE fail to capture the unique qualities of vector graphics. We introduce SVG-Bench, a benchmark across 10 datasets, and 3 tasks: Image-to-SVG, Text-to-SVG generation, and diagram generation. Using this setup, StarVector achieves state-of-the-art performance, producing more compact and semantically rich SVGs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.01508 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343850,
  title={ Multiknowledge and LLM-Inspired Heterogeneous Graph Neural Network for Fake News Detection  -  IEEE Transactions on Computational Social Systems },
  author={Xie, B. and Ma, X. and Shan, X. and Beheshti, A. and Yang, J. and Fan, H. and Wu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752733 },
  abstract={The widespread diffusion of fake news has become a critical problem on dynamic social media worldwide, which requires effective strategies for fake news detection to alleviate its hazardous consequences for society. However, most recent efforts only focus on the features of news content and social context without realizing the benefits of large language models (LLMs) and multiple knowledge graphs (KGs), thus failing to improve detection capabilities further. To tackle this issue, we present a multiknowledge and LLM-inspired heterogeneous graph neural network for fake news detection (MiLk-FD), by combining KGs, LLMs, and graph neural networks (GNNs). Specifically, we first model news content as a heterogeneous graph (HG) containing news, entity, and topic nodes and then fuse the knowledge from three KGs to augment the factual basis of news articles. Meanwhile, we leverage TransE to initialize the knowledge features and employ LLaMa2-7B to obtain the initial feature vectors of news articles. After that, we utilize the devised HG transformer to learn news embeddings with specific feature distribution in high-dimensional spaces by aggregating neighborhood information according to metapaths. Finally, a classifier based on multilayer perceptron (MLP) is trained to predict each news article as fake or true. Through experiments, we demonstrate that our proposed framework surpasses ten baselines according to accuracy, precision, F1-score, recall, and ROC in four public real-world benchmarks (i.e., COVID-19, FakeNewsNet, PAN2020, Liar).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCSS.2024.3488191 },
  booktitle={ IEEE Transactions on Computational Social Systems },
  chapter={0}
}

@article{rayyan-352343851,
  title={ LLMCov: A Methodology for LLM-Aided DfT Coverage Improvement in Open-Source Designs  -  2025 IEEE 9th International Test Conference India (ITC India) },
  year={2025},
  author={Kumari, M. and Roy, S. and Fujita, M. and Kumar, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141575 },
  abstract={Scan insertion is one of the important steps in the development of test infrastructure in modern designs. During the scan insertion step, it is very crucial to resolve all design rule violations as these violations may lead to significant drop in the test coverage. Because of nature of these violations, it becomes a tedious debugging exercise and requires lot of manual expertise. In this work, we propose AI-based solution for seeking solution for these design rule checks. The power of AI-based techniques (such as CNN-based models or LLM-based methods) is getting widely recognized in the area of EDA tools performance enhancement. Therefore, we develop a LLM-aided DRC debugging methodology to aid the scan synthesis tool that in turn assists the ATPG tool to obtain enhanced test coverage values. Experimental results indicate significant improvement in the test coverage with fixes obtained with assistance of LLM.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITCIndia66078.2025.11141575 },
  booktitle={ 2025 IEEE 9th International Test Conference India (ITC India) },
  chapter={0}
}

@article{rayyan-352343852,
  title={ Detecting LLM-Generated Text in Computing Education: Comparative Study for ChatGPT Cases  -  2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC) },
  year={2024},
  author={Orenstrakh, M. S. and Karnalim, O. and Suárez, C. A. and Liut, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633247 },
  abstract={Due to the recent improvements and wide availability of Large Language Models (LLMs), they have posed a serious threat to academic integrity in education. Modern LLM-generated text detectors attempt to combat the problem by offering educators with services to assess whether some text is LLM-generated. In this work, we have collected 124 submissions from computer science students before the creation of ChatGPT. We then generated 40 ChatGPT submissions. We used this data to evaluate eight publicly-available LLM-generated text detectors through the measures of accuracy, false positives, and resilience. Our results find that Copy Leaks is the most accurate LLM-generated text detector, G PTKit is the best LLM-generated text detector to reduce false positives, and GLTR is the most resilient LLM-generated text detector. We note that all LLM-generated text detectors are less accurate with code, other languages (aside from English), and after the use of paraphrasing tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COMPSAC61105.2024.00027 },
  booktitle={ 2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC) },
  chapter={0}
}

@article{rayyan-352343853,
  title={ Enhanced Voice Phishing Detection Using an LLM-Based Framework for Data Augmentation and Classification  -  IEEE Access },
  author={Park, H. and Lee, J. and Han, S. and Byun, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11142247 },
  abstract={Existing voice phishing detection models based on call transcripts often suffer from limited generalizability due to insufficient scenario diversity and the absence of ambiguous samples in data. To address these challenges, we propose an integrated framework that leverages GPT-4o, a large language model (LLM), to generate realistic call transcripts from actual fraud cases and to build an expert-guided phishing detection model. Using case reports from the Financial Supervisory Service (FSS) and Korean call transcripts from the KorCCVi dataset, we generate Korean phishing call transcripts that capture underrepresented fraud tactics. In addition, we generate non-phishing call transcripts that retain phishing-like linguistic patterns by removing or attenuating core fraudulent cues, thereby enabling training on ambiguous cases. The generated data are quantitatively evaluated for linguistic naturalness, scenario diversity, and detection difficulty. To assess the sample-level detection difficulty in semantic space, we introduce the metric Class Centroid Distance Variability (CCDV). We also propose the Domain Expert LLM, implemented using GPT-4o, a prompt-engineered detection model that incorporates six analytical criteria validated by a domain expert. The model not only improves detection performance but also produces structured analytical reports that enhance interpretability. In experiments, the Domain Expert LLM achieves an F1 score of 0.9686 on previously unseen and ambiguous transcripts, substantially outperforming conventional models such as RandomForest and KoBERT, which yield an average F1 score of approximately 0.70.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3603007 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343854,
  title={ Breaking the Silence: Whisper-Driven Emotion Recognition in AI Mental Support Models  -  2024 IEEE Conference on Artificial Intelligence (CAI) },
  year={2024},
  author={Qu, X. and Sun, Z. and Feng, S. and Chen, C. and Tian, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605509 },
  abstract={Most emotional support conversations (ESCs) currently rely on text-based interfaces, which may not be user-friendly, especially for individuals with visual impairments or those who struggle with reading and writing. Thus, we present a personalized voice-based ESC system powered by large language models (LLMs). It can analyze emotional status from vocal user inputs, which provides deep insights that text-based methods cannot, enabling the LLM-driven chatbot to offer more tailored and effective emotional support to its users. Our code is available at https://github.com/xinghua-qu/speech_emotion_recognition},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI59869.2024.00063 },
  booktitle={ 2024 IEEE Conference on Artificial Intelligence (CAI) },
  chapter={0}
}

@article{rayyan-352343855,
  title={ NAIA: A Multi-Technology Virtual Assistant for Boosting Academic Environments—A Case Study  -  IEEE Access },
  author={Mendoza, A. Pabón and Quiroga, K. J. Barrios and Celis, S. D. Solano and Quintero, C. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121858 },
  abstract={Virtual assistants have become essential tools for improving productivity and efficiency in various domains. This paper presents NAIA (Nimble Artificial Intelligence Assistant), an advanced multi-role and multi-task virtual assistant enhanced with artificial intelligence, designed to serve a university community case study. The system integrates AI technologies including Large Language Models (LLM), Computer Vision, and voice processing to create an immersive and efficient interaction through animated digital avatars. NAIA features five specialized roles: researcher, receptionist, personal skills trainer, personal assistant, and university guide, each equipped with specific capabilities to support different aspects of academic life. The system’s Computer Vision capabilities enable it to comment on users’ physical appearance and environment, enriching the interaction. Through natural language processing and voice interaction, NAIA aims to improve productivity and efficiency within the university environment while providing personalized assistance through a ubiquitous platform accessible across multiple devices. NAIA is evaluated through a user experience survey involving 30 participants with different demographic characteristics, this is the most accepted way by the community to evaluate this type of solution. Participants give their feedback after using one role of NAIA after using it for 30 minutes. The experiment showed that 90% of the participants considered NAIA-assisted tasks of higher quality and, on average, NAIA has a score of 4.27 out of 5 on user satisfaction. Participants particularly appreciated the assistant’s visual recognition, natural conversation flow, and user interaction capabilities. Results demonstrate NAIA’s capabilities and effectiveness across the five roles.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3597565 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343856,
  title={ Robotic Action Planning Using Large Language Models  -  2024 Latin American Robotics Symposium (LARS) },
  year={2024},
  author={Silva, C. B. Da and Ramírez, J. L. B. and Mastelari, N. and Lotufo, R. and Pereira, J. and Rohmer, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786412 },
  abstract={This study1 explores the integration of artificial intelligence (AI) and large language models (LLMs) in robotics, focusing on task planning and execution. We implemented a Reasoning and Acting (ReAct) system within a simulated environment, utilizing a humanoid robot equipped with various tools for searching, locomotion, vision, manipulation, and communication. The robot operates based on natural language prompts and utilizes the LangChain framework to facilitate interaction with the LLM. We conducted experiments to evaluate the robot’s performance on tasks requiring short-term, medium-term, and long-term memory. Short-term memory tasks involved single-step actions, medium-term memory tasks needed the completion of two-step sequences, and long-term memory tasks involved three or more steps. The results demonstrated a high success rate for short-term tasks, while performance for medium and long-term tasks varied depending on the number of steps involved. Our findings highlight both the challenges and potential of using AI and LLMs in robotic task planning. The results demonstrate the promise of enhancing robotic capabilities to perform complex tasks through natural language instructions.1The work is available on: https://github.com/cesarbds/LLM_Planner},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LARS64411.2024.10786412 },
  booktitle={ 2024 Latin American Robotics Symposium (LARS) },
  chapter={0}
}

@article{rayyan-352343857,
  title={ Did ChatGPT or Copilot Use Alter the Style of Internet News Headlines? A Time Series Regression Analysis  -  2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI) },
  year={2025},
  author={Brogly, C. and McElroy, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141113 },
  abstract={The release of advanced Large Language Models (LLMs) such as ChatGPT and Copilot is changing the way text is created and may influence the content that we find on the web. This study investigated whether the release of these two popular LLMs coincided with a change in writing style in headlines and links on worldwide news websites. 175 NLP features were obtained for each text in a dataset of 451 million headlines/links. An interrupted time series analysis was applied for each of the 175 NLP features to evaluate whether there were any statistically significant sustained changes after the release dates of ChatGPT and/or Copilot. There were a total of 44 features that did not appear to have any significant sustained change after the release of ChatGPT/Copilot. A total of 13 features did appear to have a significant sustained change after the release of ChatGPT and/or Copilot, when using GPT-3 and Gopher's introduction dates as controls that showed no sustained change. A total of 91 other features did show significant change with ChatGPT and/or Copilot although significance with earlier control LLM release dates (GPT-1/2/3, Gopher) removed them from consideration. This initial analysis suggests these language models may have had a limited impact on the style of individual news headlines/links, with respect to only some NLP measures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMI65310.2025.11141113 },
  booktitle={ 2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI) },
  chapter={0}
}

@article{rayyan-352343858,
  title={ Measuring the Summarization Capabilities of LLMs Using the ACT Score  -  2024 IEEE MIT Undergraduate Research Technology Conference (URTC) },
  year={2024},
  author={Balaji, A. and Greer, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937639 },
  abstract={Large Language Models (LLMs) have demonstrated significant capabilities in summarizing extensive textual content, yet their performance varies across different models. Evaluating the quality of these summaries is challenging due to the diverse aspects of summarization assessed by metrics such as ROUGE, BLEU, and BERTScore. This paper introduces an approach to measure summarization efficacy by examining the ability of LLM-generated summaries to answer questions from the ACT Reading section. We conducted experiments using GPT-4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet to generate summaries for ACT passages and assessed their accuracy in answering the associated questions. Our findings reveal that GPT-4o outperformed other models in most metrics and question-answering tasks, indicating its superior summarization capabilities. This method provides a novel perspective on evaluating summary quality, emphasizing practical application and comprehension.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/URTC65039.2024.10937639 },
  booktitle={ 2024 IEEE MIT Undergraduate Research Technology Conference (URTC) },
  chapter={0}
}

@article{rayyan-352343859,
  title={ GPT4ESG: Streamlining Environment, Society, and Governance Analysis with Custom AI Models  -  2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB) },
  year={2024},
  author={Lin, L. H. -M. and Ting, F. -K. and Chang, T. -J. and Wu, J. -W. and Tsai, R. T. -H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602567 },
  abstract={Many companies now prioritize Environment, Society, and Governance (ESG) and financial performance due to concerns about climate change. We created GPT4ESG, a quick method to analyze a company's ESG investment and influence. GPT4ESG is a model system architecture based on BERT and GPT with five parts:(1) Data cleaning: The data is cleaned and preprocessed to ensure it is in a suitable format for the model. (2) Tokenizer adaptation: A customized GPT assistant is used to assist in scoring, and results are given after expert review. (3) Model adjustment: A classification layer is added to the output. (4) Fine-tuning: The pre-trained model is fine-tuned according to the ESG field know-how. (5) Evaluation and Testing: The model was tested on a validation set during training and then on a testing set. We collected ESG reports of well-known listed companies in the technology industries in the United States as a data set. The experimental results showed that the customized GPT4ESG model was more effective than ESG-BERT in classifying ESG data. This model simplifies ESG reporting for stakeholders to make responsible decisions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIB61477.2024.10602567 },
  booktitle={ 2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB) },
  chapter={0}
}

@article{rayyan-352343860,
  title={ From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures  -  2024 IEEE/ACM International Workshop on Designing Software (Designing) },
  year={2024},
  author={Eisenreich, T. and Speth, S. and Wagner, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669862 },
  abstract={Designing domain models and software architectures represents a significant challenge in software development, as the resulting architectures play a vital role in fulfilling the system’s quality of service. Due to time pressure, architects often model only one architecture based on their known limited domain understanding, patterns, and experience instead of thoroughly analyzing the domain and evaluating multiple candidates, selecting the best fitting. Existing approaches try to generate domain models based on requirements, but still require time-consuming manual effort to achieve good results. Therefore, in this vision paper, we propose a method to generate software architecture candidates semi-automatically based on requirements using artificial intelligence techniques. We further envision an automatic evaluation and trade-off analysis of the generated architecture candidates using, e.g., the architecture trade-off analysis method combined with large language models and quantitative analyses. To evaluate this approach, we aim to analyze the quality of the generated architecture models and the efficiency and effectiveness of our proposed process by conducting qualitative studies.CCS CONCEPTS • Software and its engineering → Designing software; Software architectures; System description languages; • Computing methodologies → Artificial intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM International Workshop on Designing Software (Designing) },
  chapter={0}
}

@article{rayyan-352343861,
  title={ AI and Veterinary Medicine: Performance of Large Language Models on the North American Licensing Examination  -  2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS) },
  year={2023},
  author={Angel, M. and Patel, A. and Xing, H. and Balsz, D. and Arbuckle, C. and Bruyette, D. and Baldi, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10375414 },
  abstract={This study aimed to assess the performance of Large Language Models on the North American Veterinary Licensing Examination (NAVLE) and to analyze the impact of artificial intelligence in the domain of animal healthcare. For this study, a 200-question NAVLE self-assessment sourced from ICVA's website was used to evaluate the performance of three language models: GPT-3, GPT-4, and Bard. Questions involving images were omitted leaving a 164 text-only sample exam. Results were analyzed by comparing generated responses to the answer key, and scores were assigned to evaluate the models' veterinary medical reasoning capabilities. Our results showed that GPT-4 outperformed GPT-3 and Bard, passing the exam with 89 % of the text-only questions correctly. GPT-3 and Bard only achieved an accuracy of 63.4 % and 61 % respectively on the same set of questions. Language models hold promise for enhancing veterinary practices through expanded educational opportunities in the veterinary curriculum, improved diagnostic accuracy, treatment times, and efficiency. However, potential negatives include challenges in changing the current educational paradigm, reduced demand for professionals or paraprofessional concerns surrounding machine-generated decisions. Responsible and ethical integration of language models is crucial in veterinary medicine.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SNAMS60348.2023.10375414 },
  booktitle={ 2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS) },
  chapter={0}
}

@article{rayyan-352343862,
  title={ Design and Implementation of AI-Powered Plant Disease Detection & Remediation Using YOLOv5  -  2024 Second International Conference on Advances in Information Technology (ICAIT) },
  year={2024},
  author={B, K. S and Patil, N. and D'Souza, S. M. and Chandresh, K. and N, R. Reddy and Krishna, N. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10690741 },
  abstract={This research presents an automated solution for plant disease detection and remedies recommendation in agriculture. Leveraging YOLOv5 object detection architecture, the system accurately identifies diseased plant leaves across multiple plant species and disease types. Integration with the Gemini API enables the retrieval of customized remedies tailored to the identified diseases. A user-friendly web interface developed using Streamlit facilitates seamless interaction, allowing farmers to upload leaf images and receive instant diagnosis and treatment recommendations. With a mean Average Precision (mAP) of 0.85 and precision of 0.88 in disease diagnosis, this approach exhibits potential and outperforms current techniques. The successful execution of this project highlights its potential to revolutionize agricultural practices by harnessing technology for efficient disease management and promoting sustainable farming methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIT61638.2024.10690741 },
  booktitle={ 2024 Second International Conference on Advances in Information Technology (ICAIT) },
  chapter={0}
}

@article{rayyan-352343863,
  title={ HEALTH-OPS: An AI Driven Healthcare Application  -  2024 International Conference on Communication, Computing, Smart Materials and Devices (ICCCSMD) },
  year={2024},
  author={Ramakrishnan, A. and Kiruthika, S. and Athanesious, J. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015117 },
  abstract={In the realm of advancing healthcare and the ever-growing use of Artificial Intelligence, the medical chatbots are no less than a companion for medical professionals as well as common people. These chatbots are advanced enough to provide relevant and accurate medical information which helps people be more aware and health conscious and also aid in early detection and diagnosis of their ailments. In this work beyond the traditional question answering chatbots and we presented a smart healthbot capable of understanding context and generating text. With more features like supporting images and pdf file formats, the solution also incorporates a multi class chest X-Ray classification model which classifies an inputted chest X-Ray image into one of 14 thoracic conditions with an accuracy of 91% and a text summarization model specifically trained on biomedical text which can outline the input long format text file.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCSMD63546.2024.11015117 },
  booktitle={ 2024 International Conference on Communication, Computing, Smart Materials and Devices (ICCCSMD) },
  chapter={0}
}

@article{rayyan-352343864,
  title={ Interaction AI with Retrieval-enhanced Generation for Knowledge Retrieval in EAST  -  2024 3rd International Conference on Data Analytics, Computing and Artificial Intelligence (ICDACAI) },
  year={2024},
  author={Su, C. and Wan, C. and Hu, W. and Yuan, Q. and Xiao, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835634 },
  abstract={The tokamak is the most representative device for achieving magnetic confinement fusion and is one of the most promising pathways to realizing fusion energy. Among the many tokamak devices, China's first fully superconducting tokamak experiment device, the Experimental Advanced Superconducting Tokamak (EAST), has garnered significant attention due to its advanced technology and outstanding experimental achievements. Over the years, EAST has accumulated a wealth of experimental data and literature records. These documents provide profound background knowledge and professional insights. To enhance the efficiency of researchers in retrieving documents and gaining inspiration from historical documents, we have utilized EAST-related experimental documents, combined with Retrieval-Augmented Generation (RAG) technology and state-of-the-art Large Language Models (LLMs), to create an "operational copilots" model. The model leverages Intelligent Augmented Intelligence (IAI) to not only provide accurate answers but also draw on historical documents to explain specialized issues. Through practical examples, it has been demonstrated that for highly specialized tokamak-related questions, the RAG retrieval model offers more credible responses than a basic model.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDACAI65086.2024.00181 },
  booktitle={ 2024 3rd International Conference on Data Analytics, Computing and Artificial Intelligence (ICDACAI) },
  chapter={0}
}

@article{rayyan-352343865,
  title={ Comparative Analysis and Evaluation of Well-Being Activity-Infused Fine-Tuned Language Models with Benchmark Models  -  2025 IEEE Symposium on Computational Intelligence in Health and Medicine (CIHM) },
  year={2025},
  author={Mohammed, H. H. and Kiss, G. and Serrano, J. A. and Lindseth, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10969481 },
  abstract={Large language models (LLMs) have significantly impacted natural language processing (NLP), healthcare, and beyond fields. LLMs have demonstrated unprecedented abilities to understand and generate human-like text, making them highly valuable for various tasks, including information retrieval, question-answering, and conversational AI. However, as these models are integrated into real-world applications, especially in sensitive domains such as healthcare, it becomes essential to evaluate their performance comprehensively. We present a process for fine-tuning LLMs to incorporate cardiac exercise and corpus of well-being activity, aiming to promote activity health support through NLP-driven applications. Using QLoRA, you can ensure that the model size remains small and reduce overhead while maintaining the high performance of the fine-tuned model. Subsequently, this paper presents a comparative analysis benchmark pipeline to evaluate fine-tuned models with base models on standard benchmark datasets from the healthcare domain. The aim is to evaluate the performance, robustness and accuracy of these models, showing that the fine-tuning process does not degrade the model performance, but improves the performance to some extent in some benchmarks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIHM64979.2025.10969481 },
  booktitle={ 2025 IEEE Symposium on Computational Intelligence in Health and Medicine (CIHM) },
  chapter={0}
}

@article{rayyan-352343866,
  title={ World Models: The Safety Perspective  -  2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW) },
  year={2024},
  author={Zeng, Z. and Zhang, C. and Liu, F. and Sifakis, J. and Zhang, Q. and Liu, S. and Wang, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771431 },
  abstract={With the proliferation of the Large Language Model (LLM), the concept of World Models (WM) has recently attracted a great deal of attention in the AI research community, especially in the context of AI agents. It is arguably evolving into an essential foundation for building AI agent systems. A WM is intended to help the agent predict the future evolution of environmental states or help the agent fill in missing information so that it can plan its actions and behave safely. The safety property of WM plays a key role in their effective use in critical applications. In this work, we review and analyze the impacts of the current state-of-the-art in WM technology from the point of view of trustworthiness and safety based on a comprehensive survey and the fields of application envisaged. We provide an in-depth analysis of state-of-the-art WMs and derive technical research challenges and their impact in order to call on the research community to collaborate on improving the safety and trustworthiness of WM.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISSREW63542.2024.00104 },
  booktitle={ 2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW) },
  chapter={0}
}

@article{rayyan-352343867,
  title={ GenAI-Enabled Network Design: ABEP of SC Diversity Under the Combined Effects of Rician Fading and Rician Co-Channel Interference in WCN Case Study  -  2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST) },
  year={2025},
  author={Petrović, N. and Škrbić, S. and Jović, M. and Suljović, S. and Milašinović, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098387 },
  abstract={This paper analyzes a selection combining (SC) receiver with $L$ branches in wireless communication networks affected by Rician fading and co-channel interference (CCI). A closed-form expression for the moment generating function (MGF) is derived and used to calculate the average bit error probability (ABEP) for non-coherent Binary Frequency Shift Keying (BFSK) and Binary Differential Phase Shift Keying (BDPSK) modulation schemes. Numerical and graphical results are provided to evaluate ABEP performance for varying numbers of diversity branches and Rician κ values. Furthermore, we explore the adoption of Generative Artificial Intelligence (GenAI) techniques to simplify network experimentation and reduce cognitive load. A proof-of-concept implementation is demonstrated through ABEP case study based on the first part of the paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEST66328.2025.11098387 },
  booktitle={ 2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST) },
  chapter={0}
}

@article{rayyan-352343868,
  title={ MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Zhang, W. and Sun, S. and Wang, B. and Zou, X. and Liu, Z. and He, Y. and Lin, G. and Chen, N. F. and Aw, A. Ti},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888128 },
  abstract={The rapid advancements in large language models (LLMs) have significantly enhanced natural language processing capabilities, facilitating the development of AudioLLMs that process and understand speech and audio inputs alongside text. Existing AudioLLMs typically combine a pre-trained audio encoder with a pre-trained LLM, which are subsequently finetuned on specific audio tasks. However, the pre-trained audio encoder has constrained capacity to capture features for new tasks and datasets. To address this, we propose to incorporate mixtures of ‘weak’ encoders (MoWE) into the AudioLLM framework. MoWE supplements a base encoder with a pool of relatively lightweight encoders, selectively activated based on the audio input to enhance feature extraction without significantly increasing model size. Our empirical results demonstrate that MoWE effectively improves multi-task performance, broadening the applicability of AudioLLMs to more diverse audio tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888128 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343869,
  title={ Towards Trustworthy Agentic IoEV: AI Agents for Explainable Cyberthreat Mitigation and State Analytics  -  2025 IEEE 50th Conference on Local Computer Networks (LCN) },
  year={2025},
  author={Dif, M. M. and Bouchiha, M. A. and Korba, A. A. and Ghamri-Doudane, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11146357 },
  abstract={The Internet of Electric Vehicles (IoEV) envisions a tightly coupled ecosystem of electric vehicles (EVs), charging infrastructure, and grid services, yet remains vulnerable to cyberattacks, unreliable battery-state predictions, and opaque decision processes that erode trust and performance. To address these challenges, we introduce a novel Agentic Artificial Intelligence (AAI) framework tailored for IoEV, where specialized agents collaborate to deliver autonomous threat mitigation, robust analytics, and interpretable decision support. Specifically, we design an AAI architecture comprising dedicated agents for cyber-threat detection and response at charging stations, real-time State of Charge (SoC) estimation, and State of Health (SoH) anomaly detection, all coordinated through a shared, explainable reasoning layer; develop interpretable threat-mitigation mechanisms that proactively identify and neutralize attacks on both physical charging points and learning components; propose resilient SoC and SoH models that leverage continuous and adversarial-aware learning to produce accurate, uncertainty-aware forecasts with human-readable explanations; and implement a three-agent pipeline, where each agent uses LLM-driven reasoning and dynamic tool invocation to interpret intent, contextualize tasks, and execute formal optimizations for user-centric assistance. Finally, we validate our framework through comprehensive experiments across diverse IoEV scenarios, demonstrating significant improvements in security and prediction accuracy. All datasets, models, and code will be released publicly.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LCN65610.2025.11146357 },
  booktitle={ 2025 IEEE 50th Conference on Local Computer Networks (LCN) },
  chapter={0}
}

@article{rayyan-352343870,
  title={ QueryMintAI: Multipurpose Multimodal Large Language Models for Personal Data  -  IEEE Access },
  author={Ghosh, A. and Deepa, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10695061 },
  abstract={QueryMintAI, a versatile multimodal Language Learning Model (LLM) designed to address the complex challenges associated with processing various types of user inputs and generating corresponding outputs across different modalities. The proliferation of diverse data formats, including text, images, videos, documents, URLs, and audio recordings, necessitates an intelligent system capable of understanding and responding to user queries effectively. Existing models often exhibit limitations in handling multimodal inputs and generating coherent outputs across different modalities. The proposed QueryMintAI framework leverages state-of-the-art language models such as GPT-3.5 Turbo, DALL-E-2, TTS-1 and Whisper v2 among others, to enable seamless interaction with users across multiple modalities. By integrating advanced natural language processing (NLP) techniques with domain-specific models, QueryMintAI offers a comprehensive solution for text-to-text, text-to-image, text-to-video, and text-to-audio conversions. Additionally, the system supports document processing, URL analysis, image description, video summarization, audio transcription, and database querying, catering to diverse user needs and preferences. The proposed model addresses several limitations observed in existing approaches, including restricted modality support, lack of adaptability to various data formats, and limited response generation capabilities. QueryMintAI overcomes these challenges by employing a combination of advanced NLP algorithms, deep learning architectures, and multimodal fusion techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3468996 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343871,
  title={ Dialogue-Based XAI Approaches: Exploring the Continuum from Static Explanations to Free-Form Chat Interfaces  -  2025 19th International Conference on Semantic Computing (ICSC) },
  year={2025},
  author={Mindlin, D. and Cimiano, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036305 },
  abstract={It is increasingly recognized that end users have individual and specific explanation needs in the context of eXplainable Artificial Intelligence (XAI). The XAI field is thus shifting towards personalized and co-constructive explanations for non-technical stakeholders. Therefore, conversational XAI systems are proposed, aiming to provide a natural conversation between the user and the XAI system and promise to improve user understanding through the adaptive nature of bidirectional explanations. However, evidence on the effectiveness of such systems, particularly those utilizing large language models (LLMs), remains limited. In this study, we explore dialogue interfaces using a three-phase experiment capturing the user's objective and subjective understanding in conditions ranging from static explanation reports to guiding chatbots. Our findings demonstrate the effectiveness of a single- and two-prompt LLM mechanism for intent mapping and suggest that participants who engaged more frequently, especially with feature-specific questions, achieved higher understanding scores. We also uncover that participants prefer to select suggested explanations rather than type their own questions and argue that successful chat interfaces must extend beyond simple question-to-XAI method mapping to enhance model understanding.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC64641.2025.00015 },
  booktitle={ 2025 19th International Conference on Semantic Computing (ICSC) },
  chapter={0}
}

@article{rayyan-352343872,
  title={ Enhancing Retrieval Augmented Generation Systems Using AI Models and Graph Databases  -  2025 International Conference on Emerging Smart Computing and Informatics (ESCI) },
  year={2025},
  author={Mukherjee, S. and Shabnam, S. and Hasan, S. and Ajitha, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988015 },
  abstract={This paper outlines the process of generating a Neo4j graph database powered by Language Models (LLMs). The primary goal is to extract structured information from unstructured data, including user profiles, paper briefs, and Slack messages, and convert them into Cypher queries. The data is then ingested into Neo4j to build a graph database that captures relationships between users, paper, technologies, and messages. A pipeline was developed to automate the process, ensuring accurate entity and relationship extraction using predefined templates. This approach allows for efficient data representation and supports consultancy in managing large datasets by generating insightful visualizations and querying capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ESCI63694.2025.10988015 },
  booktitle={ 2025 International Conference on Emerging Smart Computing and Informatics (ESCI) },
  chapter={0}
}

@article{rayyan-352343873,
  title={ The Inadequacy of Reinforcement Learning From Human Feedback—Radicalizing Large Language Models via Semantic Vulnerabilities  -  IEEE Transactions on Cognitive and Developmental Systems },
  author={McIntosh, T. R. and Susnjak, T. and Liu, T. and Watters, P. and Halgamuge, M. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10474163 },
  abstract={This study is an empirical investigation into the semantic vulnerabilities of four popular pretrained commercial large language models (LLMs) to ideological manipulation. Using tactics reminiscent of human semantic conditioning in psychology, we have induced and assessed ideological misalignments and their retention in four commercial pretrained LLMs, in response to 30 controversial questions that spanned a broad ideological and social spectrum, encompassing both extreme left- and right-wing viewpoints. Such semantic vulnerabilities arise due to fundamental limitations in LLMs’ capability to comprehend detailed linguistic variations, making them susceptible to ideological manipulation through targeted semantic exploits. We observed reinforcement learning from human feedback (RLHF) in effect to LLM initial answers, but highlighted the limitations of RLHF in two aspects: 1) its inability to fully mitigate the impact of ideological conditioning prompts, leading to partial alleviation of LLM semantic vulnerabilities; and 2) its inadequacy in representing a diverse set of “human values,” often reflecting the predefined values of certain groups controlling the LLMs. Our findings have provided empirical evidence of semantic vulnerabilities inherent in current LLMs, challenged both the robustness and the adequacy of RLHF as a mainstream method for aligning LLMs with human values, and underscored the need for a multidisciplinary approach in developing ethical and resilient artificial intelligence (AI).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TCDS.2024.3377445 },
  booktitle={ IEEE Transactions on Cognitive and Developmental Systems },
  chapter={0}
}

@article{rayyan-352343874,
  title={ PE-GPT: A New Paradigm for Power Electronics Design  -  IEEE Transactions on Industrial Electronics },
  author={Lin, F. and Li, X. and Lei, W. and Rodriguez-Andina, J. J. and Guerrero, J. M. and Wen, C. and Zhang, X. and Ma, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10701612 },
  abstract={Large language models (LLMs) have shown exciting potential in powering the growth of many industries, yet their adoption in the power electronics (PE) sector is hindered by a lack of specialized PE technical expertise and challenges in processing PE-specific data. This study presents a pioneering approach to establish a multimodal LLM tailored for PE design applications, named PE-GPT. The methodology involves enhancing PE-GPT with retrieval augmented generation from a PE knowledge base, and proposes a hybrid framework that integrates an LLM agent with metaheuristic algorithms, Model Zoo, and Simulation Repository. This enhances its multimodal processing capabilities and enables integration into the existing design workflow. The PE-GPT methodology is demonstrated with two case studies: modulation design of the dual-active bridge (DAB) converter and circuit parameter design of the buck converter. PE-GPT demonstrates a 22.2% increase in correctness compared to human experts. Against other leading LLMs, PE-GPT shows a 35.6% improvement in correctness and a 15.4% enhancement in consistency, reducing hallucination. Hardware experiments validate PE-GPT’s multimodal capabilities in optimizing a five-degree-of-freedom modulation strategy for the DAB converter. The generalization of PE-GPT to other PE design applications and associated AI ethical considerations are also discussed. This research concludes by outlining inspiring future research directions, encouraging researchers to expand the boundaries of the PE industry and advance toward a more intelligent era.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIE.2024.3454408 },
  booktitle={ IEEE Transactions on Industrial Electronics },
  chapter={0}
}

@article{rayyan-352343875,
  title={ Enhancing Teaching Quality Through LLM: An Experimental Study on Prompt Engineering  -  2025 14th International Conference on Educational and Information Technology (ICEIT) },
  year={2025},
  author={Chen, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976127 },
  abstract={This study explores the application of Large Language Models Artificial Intelligence (LLM AI) in the assessment of course teaching quality, aiming to overcome the limitations of traditional teaching evaluation. Taking the experimental courses in School G as an example, we propose CORE, a framework to support generating feedback from student assessment during the course. Through the Solomon four-group design experiment, it validates the significant effectiveness of the teaching quality evaluation feedback generated by LLM in enhancing teachers' teaching quality. This feedback can help teachers improve teaching strategies, boost teaching effects, effectively make up for the limitations of traditional teaching assessment methods, and offer a new perspective and tool for teaching quality evaluation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIT64364.2025.10976127 },
  booktitle={ 2025 14th International Conference on Educational and Information Technology (ICEIT) },
  chapter={0}
}

@article{rayyan-352343876,
  title={ Towards LLM-Assisted HDL Generation and Verification  -  2025 14th Mediterranean Conference on Embedded Computing (MECO) },
  year={2025},
  author={Amin, R. Al and Lincoln, M. G. R. and Obermaisser, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11049176 },
  abstract={The rapid advancement of Large Language Models (LLMs) across various application domains has led to their increasing adoption in Electronic Design Automation (EDA). LLM-assisted hardware design, particularly in HDL (Hardware Description Language) generation and verification, is gaining significant traction in industry and academia. The hardware design process begins with generating and verifying HDL code, which remains a challenging and error-prone task. While recent research has made notable progress in leveraging LLMs for HDL generation (e.g., Verilog and VHDL), existing models still struggle with accuracy. Moreover, a lack of publicly available datasets and open-source evaluation frameworks, particularly for VHDL, limits further advancements in this domain. This paper presents an automated HDL generation and verification system utilizing CodeLlama-7B Instruct with Parameter-Efficient Fine-Tuning (PEFT) methods to address these challenges. Additionally, a multi-granularity VHDL dataset has been developed, incorporating a Pyramid of Thought (PoT) architecture to enhance the efficiency of HDL generation and verification. The proposed LLM model is evaluated using the VerilogEval framework for generated Verilog code and a human evaluation process for VHDL code. The results demonstrate promising performance, achieving up to 63% accuracy with Pass@10 for Verilog and 52% with Pass@10 for VHDL. These findings and the developed VHDL dataset contribute to advancing automatic HDL generation and verification, facilitating further research in EDA and AI-assisted hardware design.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MECO66322.2025.11049176 },
  booktitle={ 2025 14th Mediterranean Conference on Embedded Computing (MECO) },
  chapter={0}
}

@article{rayyan-352343877,
  title={ LLM-Based Persona-Driven Text Data Augmentation  -  IEEE Access },
  author={Jeong, H. Seong and Ko, H. Kyeong and Park, S. Yong and Kim, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11170443 },
  abstract={Illicit online communication, such as drug-dealing dialogues, is increasingly conducted through covert, context dependent language patterns that evade traditional detection techniques in South Korea. However, developing reliable AI based detection systems remains challenging due to the scarcity of real world training data in such sensitive domains. This paper proposes a novel persona-driven data augmentation framework using Large Language Model(LLM) to generate realistic synthetic drug-dealing dialogues. By encoding domain specific buyer and seller personas along with linguistic behaviour rules, the method produces contextually coherent and semantically diverse dialogues that reflect authentic communication styles. Evaluation results demonstrate that the augmented data preserves key stylistic features (high cosine similarity), maintains lexical diversity (TTR), improves fluency (perplexity), and enhances coherence and lexical richness (ROUGE-L), outperforming traditional augmentation method. Furthermore, statistical validation confirms the semantic consistency and stability of the generated data. These findings highlight the viability of LLM-based augmentation in low-resource, high-risk domains and suggest its potential transferability to other specialized NLP applications requiring context-preserving generation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3611636 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343878,
  title={ Resspar: AI-Driven Resume Parsing and Recruitment System using NLP and Generative AI  -  2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI) },
  year={2024},
  author={D, A. and S, K. and R, N. E. and K, K. and S, J. M. and R, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10696451 },
  abstract={Artificial Intelligence (AI) is a highly emerging domain in the current scenario. It has numerous applications in various fields and almost every domain started integrating with AI for better and efficient working. In today's scenario resumes playa vital role as it decides the candidate's future scope. The candidate's resume must clearly contain the skills and details expected by the recruiters. Resume parser is always a demanding field for both the applicants and the recruiters. The LLM model takes in prompts or instructions and generates text that corresponds to the relevant information extracted from the resume images. This text generation capability is crucial for parsing and understanding the content of resumes in a structured manner. Generative AI is utilized through the GenAl API provided by Google. The GenAl API is used for tasks such as generating text from images of resumes, where it interprets the visual information and produces structured text output containing relevant details like names, emails, phone numbers, and skills. Resspar aims to streamline the hiring process by developing a web-based Resume Parsing System using Natural Language Processing (NLP) like Language Model (LLM), then it also uses GenAl, and Prompt Engineering Techniques with Python and Flask as the backend Framework. It provides a user-friendly platform that automates the extraction of essential information such as personal information (name, email, phone number) and professional skills from uploaded resumes. Recruitment processes often involve sifting through a large number of resumes to identify suitable candidates for specific job roles or domains. Resspar's functionality includes a user interface for uploading resumes, parsing them using advanced algorithms, storing parsed data in a SQLite database, and offering a filtering mechanism to match candidates with specific job requirements. It identifies the candidates whose skills align with the given criteria. This functionality significantly reduces the time spent manually sifting through resumes, enabling recruiters to focus on assessing the most relevant applicants.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoICI62503.2024.10696451 },
  booktitle={ 2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI) },
  chapter={0}
}

@article{rayyan-352343879,
  title={ Semantic to Structure: Learning Structural Representations for Infringement Detection  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Huang, C. and Jia, Z. and Fei, H. and Zhu, Y. and Yuan, Z. and Zhang, J. and Zhou, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888100 },
  abstract={Structural information in images is crucial for aesthetic assessment, and it is widely recognized in the artistic field that imitating the structure of other works significantly infringes on creators’ rights. The advancement of diffusion models has led to AI-generated content imitating artists’ structural creations, yet effective detection methods are still lacking. In this paper, we define this phenomenon as "structural infringement" and propose a corresponding detection method. Additionally, we develop quantitative metrics and create manually annotated datasets for evaluation: the SIA dataset of synthesized data, and the SIR dataset of real data. Due to the current lack of datasets for structural infringement detection, we propose a new data synthesis strategy based on diffusion models and LLM, successfully training a structural infringement detection model. Experimental results show that our method can successfully detect structural infringements and achieve notable improvements on annotated test sets.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888100 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343880,
  title={ Deploying Language Model-Based Assessment Support Technology in a Computer Science Degree: How Do the Academics Feel About It?  -  2025 IEEE Global Engineering Education Conference (EDUCON) },
  year={2025},
  author={Yee-King, M. and Fiorucci, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016587 },
  abstract={We present two contrasting case studies wherein we used large language model (LLM) technology to support critical elements of our work in the context of a large scale online undergraduate computer science degree. Firstly we used semantic embeddings to identify student-student collusion in exam answers. Secondly we used LLMs to generate starter drafts for exam question papers. We gathered academic staff responses to the two systems through structured interviews. We describe and use a novel, LLM-powered inductive thematic analysis methodology to tag and identify themes in the interviews. All analysis was carried out on locally hosted language models. We identified 26 themes, some shared across the two systems, others unique. The academics were largely comfortable with the use of LLM technology in assessment, the exam generator system helped to kick-start exam writing and the collusion detection tool found otherwise invisible cases. Academics emphasised the need for human oversight of such systems, but were prepared to use them as they perceived that they improved the efficiency of exam processes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EDUCON62633.2025.11016587 },
  booktitle={ 2025 IEEE Global Engineering Education Conference (EDUCON) },
  chapter={0}
}

@article{rayyan-352343881,
  title={ Towards Floating Point-Based Attention-Free LLM: Hybrid PIM with Non-Uniform Data Format and Reduced Multiplications  -  2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD) },
  year={2024},
  author={Guo, L. and Zhu, Z. and Liu, T. and Ning, X. and Li, S. and Dai, G. and Yang, H. and Fu, W. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126347 },
  abstract={Attention-free large language models (LLMs), such as Mamba and RWKV, have emerged as promising architectures to address the quadratic attention complexity of Transformer models. The inference bottleneck of these models lies in memory-bound matrix-vector multiplications (MVMs) and element-wise multiplications (EWMs). The emerging RRAM/SRAM-based Processing-In-Memory (PIM) architectures have shown great potential to overcome the memory wall problem. However, constrained by the supported data format and operator type, directly adopting PIM architectures for attentionfree models faces three challenges: (1) RRAM-based analog PIM architectures perform integer (INT) MVMs using voltage, current, and conductance in the analog domain, limiting their application to the more accurate floating point (FP) data format; (2) SRAMbased digital PIM architectures require additional decoder circuits to support FP format, and the SRAM capacity cannot satisfy the storage requirement of LLMs; (3) When performing EWMs using PIM architectures, only one row/column or the diagonal memory cells are activated, resulting in severe device under-utilization. To tackle the above challenges, this paper proposes an RRAM and 3D-SRAM-based hybrid PIM architecture with non-uniform data format, achieving FP-based algorithm accuracy, high device utilization, and high energy efficiency. At the software level, we first analyze the impact of quantization errors on the accuracy of attention-free LLMs. For the quantization error-insensitive MVM operations, we propose the PIM-oriented exponent-free non-uniform (PN) data format. The proposed PN format can be flexibly adjusted to fit the data distribution and approach the accuracy of the FP format using bit-slicing-based full INT operations. For the quantization error-sensitive EWM operations, we introduce the multiplicationfree approximated FP multiplications to reduce the additional hardware overhead for PIM. At the hardware level, we propose a hybrid PIM architecture, including an RRAM analog PIM using shift-and-add for PN-based MVMs, and a 3D-SRAM digital PIM with high utilization for multiplication-free FP-based EWMs. Extensive experiments show that the proposed PIM architecture achieves up to $89 \times$ and $16 \times$ speedup with $2537 \times$ and $12 \times$ energy efficiency improvement compared with GPU and PIM-baseline, respectively, while achieving FP-based algorithm accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD) },
  chapter={0}
}

@article{rayyan-352343882,
  title={ Linguistically-Informed Dataset Curation for Efficient LLM Fine-Tuning: Balancing Performance and Efficiency  -  IEEE Transactions on Sustainable Computing },
  author={Alshamrani, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11150525 },
  abstract={The rapid growth of AI systems, particularly large language models, has raised significant concerns about their environmental impact due to excessive energy consumption and carbon emissions. Despite these concerns, the trend in AI development continues to prioritize performance gains through increasingly resource-intensive approaches, such as utilizing more powerful hardware and larger datasets, often at the expense of efficiency. This study contributes to the efforts towards more efficient AI by proposing and empirically evaluating two dataset curation strategies, DS-1 and DS-2, which are linguistically-informed by syntactic features like Part-of-Speech (POS) tags to prune lexical content, for fine-tuning LLMs. The focus of this work is the empirical demonstration of how these linguistically-motivated curation approaches can create a balance between computational efficiency gains and performance maintenance during the LLM fine-tuning process. This approach represents a promising step in addressing the critical issue of AI's environmental impact. The evaluation is conducted on sentiment analysis tasks, serving as a focused case study. We evaluate two curation approaches, DS-1 and DS-2, applied to sentiment analysis tasks across three datasets, achieving substantial dataset size reductions while preserving essential linguistic information. Our assessment of six state-of-the-art LLMs—RoBERTa, ALBERT, ERNIE, DeBERTa, BERT, and GPT-2—on both curated and original datasets reveals that curated datasets can yield comparable performance to uncurated ones, with efficiency gains of up to 70% in tokenization time and up to 80% in training energy. Notably, the study uncovers varying resilience of different model architectures to curation, with the GPT-based model demonstrating perfect performance adaptation, while other advanced models like ERNIE and DeBERTa also showed strong resilience. This research is crucial in promoting the development of more sustainable and resource-efficient NLP systems, challenging the prevailing notion that larger datasets invariably lead to better performance in fine-tuning LLMs, and paving the way for more environmentally conscious AI development practices. The generalizability of these specific curation strategies to other NLP tasks is an avenue for future investigation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TSUSC.2025.3605796 },
  booktitle={ IEEE Transactions on Sustainable Computing },
  chapter={0}
}

@article{rayyan-352343883,
  title={ Teach Me Sign: Stepwise Prompting LLM for Sign Language Production  -  2025 IEEE International Conference on Image Processing (ICIP) },
  year={2025},
  author={An, Z. and Kawakami, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084322 },
  abstract={Large language models, with their strong reasoning ability and rich knowledge, have brought revolution to many tasks of AI, but their impact on sign language generation remains limited due to its complexity and unique rules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign language as another natural language. By fine-tuning an LLM, we enable it to learn the correspondence between text and sign language, and facilitate generation. Considering the differences between sign and spoken language, we employ a stepwise prompting strategy to extract the inherent sign language knowledge within the LLM, thereby supporting the learning and generation process. Experimental results on How2Sign and Phoenix14T datasets demonstrate that our approach effectively leverages both the sign language knowledge and reasoning capabilities of LLM to align the different distribution and grammatical rules between sign and spoken language.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIP55913.2025.11084322 },
  booktitle={ 2025 IEEE International Conference on Image Processing (ICIP) },
  chapter={0}
}

@article{rayyan-352343884,
  title={ Wealth of Nations, Wealth of Data: How GDP Shapes Diverse Large Language Models like ChatGPT : Interviewing Assorted Open Source Generative AI Models  -  2023 IEEE International Conference on Big Data (BigData) },
  year={2023},
  author={Kaplunovich, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386329 },
  abstract={Generative large language models (such as ChatGPT) are increasingly influencing various aspects of our lives, partly due to their training on vast datasets that encompassing big data paradigms and range of topics. "Intervista," an award-winning Italian film by Federico Fellini, focuses on his interview with a Japanese TV crew. Inspired by this, we conducted interviews with a diverse set of open-source and OpenAI models to explore various political, economic, and cultural aspects of life, evaluating LLM performance. We also examined whether a correlation exists between a country’s GDP per capita and the quality of the model’s answers. To this end, we utilized a Huggingface model leaderboard to select appropriate models and deployed them in an AWS SageMaker GPU environment. The identical questions were posed about nearly 200 countries, and the responses were analyzed to verify their accuracy and correlation with Gross Domestic Product (GDP). We were amazed by the diversity, quantity, and quality of existing pretrained open-source LLMs. Our journey provided insights into model selection, inference pipeline automation, GPU configuration, generated texts benchmarking, and systematic evaluation of model quality. Overall, leading LLMs performed well, providing reasonable responses for many countries. However, we discovered that the depth and detail of the answers were influenced by a country’s GDP per capita, with higher-income nations receiving more accurate responses.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData59044.2023.10386329 },
  booktitle={ 2023 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343885,
  title={ Leveraging Large Language Models for Requirements Generation: An Evaluation Through Systems Engineering Guidelines  -  2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  year={2025},
  author={Stein, J. and Esho, T. and Gadewadikar, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114032 },
  abstract={Identifying business needs and system requirements is a crucial task in the systems engineering life cycle. With recent advancements in large language models (LLMs), there is growing interest in their potential to enhance the requirements engineering process. This study explores the capabilities of LLMs in generating and clustering requirements by developing a dedicated test platform. Our findings indicate that LLM-based tools can significantly aid in requirements engineering, achieving strong results in coverage and cluster relevance. Ongoing efforts focus on prototyping new applications and expanding the evaluation framework to further assess the impact of LLMs in this domain.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAD65464.2025.11114032 },
  booktitle={ 2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  chapter={0}
}

@article{rayyan-352343886,
  title={ Evolution of Data Center Design to Handle AI Workloads  -  2024 34th International Telecommunication Networks and Applications Conference (ITNAC) },
  year={2024},
  author={Gupta, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10815309 },
  abstract={Large Language Model (LLM) training differs significantly from traditional computing tasks, presenting unique challenges for data center design. This computationally intensive workload demands low latency, high throughput, and lossless network operations. We present an analysis of networking solutions designed to address these challenges in Artificial Intelligence (AI) focused data centers. Our approach leverages High Performance Computing tools and protocols, including Remote Direct Memory Access (RDMA), InfiniBand (IB), and Priority-based Flow Control (PFC). We examine high performance networking solutions such as RoCEv2, GPU Cluster Design, and Rail Optimized Design. These solutions effectively mitigate issues of packet loss and congestion, crucial for LLM training environments. Our analysis reveals potential challenges in implementing these solutions, providing valuable insights for optimizing data center operations in LLM training. This work contributes to the evolving field of AI infrastructure, offering a roadmap for researchers and practitioners developing next generation data centers for advanced AI applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITNAC62915.2024.10815309 },
  booktitle={ 2024 34th International Telecommunication Networks and Applications Conference (ITNAC) },
  chapter={0}
}

@article{rayyan-352343887,
  title={ Drive Like a Human: Rethinking Autonomous Driving with Large Language Models  -  2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW) },
  year={2024},
  author={Fu, D. and Li, X. and Wen, L. and Dou, M. and Cai, P. and Shi, B. and Qiao, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10495699 },
  abstract={In this paper, we explore the potential of using a large language model (LLM) to understand the driving environment in a human-like manner and analyze its ability to reason, interpret, and memorize when facing complex scenarios. We argue that traditional optimization-based and modular autonomous driving (AD) systems face inherent performance limitations when dealing with long-tail corner cases. To address this problem, we propose that an ideal AD system should drive like a human, accumulating experience through continuous driving and using common sense to solve problems. To achieve this goal, we identify three key abilities necessary for an AD system: reasoning, interpretation, and memorization. We demonstrate the feasibility of employing an LLM in driving scenarios by building a closed-loop system to showcase its comprehension and environment-interaction abilities. Our extensive experiments show that the LLM exhibits the impressive ability to reason and solve long-tailed cases, providing valuable insights for the development of human-like autonomous driving. The related code are available at https:/ithub.om/PJLab-ADG/DriveLikeAHuman.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WACVW60836.2024.00102 },
  booktitle={ 2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW) },
  chapter={0}
}

@article{rayyan-352343888,
  title={ Transducer-Llama: Integrating LLMs into Streamable Transducer-based Speech Recognition  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Deng, K. and Guo, J. and Ma, Y. and Moritz, N. and Woodland, P. C. and Kalinli, O. and Seltzer, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889530 },
  abstract={While large language models (LLMs) have been applied to automatic speech recognition (ASR), the task of making the model streamable remains a challenge. This paper proposes a novel model architecture, Transducer-Llama, that integrates LLMs into a Factorized Transducer (FT) model, naturally enabling streaming capabilities. Furthermore, given that the large vocabulary of LLMs can cause data sparsity issue and increased training costs for spoken language systems, this paper introduces an efficient vocabulary adaptation technique to align LLMs with speech system vocabularies. The results show that directly optimizing the FT model with a strong pre-trained LLM-based predictor using the RNN-T loss yields some but limited improvements over a smaller pre-trained LM predictor. Therefore, this paper proposes a weak-to-strong LM swap strategy, using a weak LM predictor during RNN-T loss training and then replacing it with a strong LLM. After LM replacement, the minimum word error rate (MWER) loss is employed to finetune the integration of the LLM predictor with the Transducer-Llama model. Experiments on the LibriSpeech and large-scale multi-lingual LibriSpeech corpora show that the proposed streaming Transducer-Llama approach gave a 17% relative WER reduction (WERR) over a strong FT baseline and a 32% WERR over an RNN-T baseline.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10889530 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343889,
  title={ A Student Emotions Recognition Based Online Texts with Large Language Models for Learning Prediction  -  2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) },
  year={2024},
  author={Fan, G. and Zhang, S. and Cheng, S. and Yang, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10822338 },
  abstract={with the rapid development of artificial intelligence (AI) and Large Language Models (LLM) technologies, it offers innovative approaches to model and analyze to predict student performance with educational behavior and learning data. But the challenges of data diversity, technical complex, and lack of semantic comprehension ability that limited the use of AI-based tools for learning performance prediction. In the paper, student emotions recognition based online learning data especially forum texts using LLMs is proposed, and an improved online learning performance prediction with online learning data, including student emotions using Signed Graph Neural Networks (SGNN) and LLMs, namely ER-SGNN-LLM, is constructed. In the model, the keywords are extracted from both forum texts and answers generated by students using LLM, and the keywords extracted from student’s forum texts are used for student emotions recognition, the keywords extracted from student’s answers, as well as the student emotions are used for student learning prediction. The relationships between each keyword extracted from texts and knowledge points of the course are encoded with SGNN. A graphic contrastive learning model is used to handle the noise in the dataset caused by students' subjective reasons. The combination of GNN and LLM is used to student emotions recognition and learning prediction. To verify the performances of the model, many experiments are conducted using the public dataset. The results demonstrate that, the model achieved better effectiveness in learning prediction, compared with other models. The values of F1 score of the proposed model is improved 0.032 compared that of the exist SGNN-LLM model.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BIBM62325.2024.10822338 },
  booktitle={ 2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) },
  chapter={0}
}

@article{rayyan-352343890,
  title={ Using Instruction-Following LLM Hidden States as Conditioning for Video Diffusion Model  -  2025 17th International Conference on Electronics, Computers and Artificial Intelligence (ECAI) },
  year={2025},
  author={Bhushan, R. H. and K, A. G. and Ambiga, P. and Malgikar, S. S. and V.R., B. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095434 },
  abstract={Video generation has applications in several fields. With the advent of Generative AI, we see extensive research being conducted on video generation using AI. Through this project, we experiment the usage of LLM Hidden states as conditioning to train a Video Latent Diffusion Model to study their ability of passing richer semantic information about the video samples. We performed a comparative study of context retention abilities of LLMs in case of embeddings and hidden states separately. We create a pipeline with three major components - the LLM, a custom Bridge Network and the Diffusion UNet. We conduct our study using two different datasets - the Captioned Moving MNIST and a subset of the Sakuga-42M dataset. We conclude by evaluating our model variants on standard benchmarks and metrics, and state our findings, which could serve as ground for future work.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECAI65401.2025.11095434 },
  booktitle={ 2025 17th International Conference on Electronics, Computers and Artificial Intelligence (ECAI) },
  chapter={0}
}

@article{rayyan-352343891,
  title={ Broken Access Control Detection Focused on Privilege Escalation Prevention Using a Llama 3 LLM-Based Assistant  -  2025 11th International Symposium on System Security, Safety, and Reliability (ISSSR) },
  year={2025},
  author={Saenz, E. and Marchesi, V. and Chen, Z. and Wong, W. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022644 },
  abstract={Broken Access Control (BAC) found itself atop the Open Worldwide Application Security Project (OWASP) top 10 risks of 2021. Cementing the importance and danger of this cyber threat. Access control enforces policies that ensure users are only able to access what they are permitted to. Failures within access control lead us to BAC, which introduces a variety of security hazards such as data breaches and leaks. In a society where data is becoming invaluable, having a cyber threat of this caliber is potentially detrimental to businesses and consumers alike. Utilizing the ever-evolving field of artificial intelligence (AI) to combat BAC can revolutionize the way security measures are created. Implementing an AI assistant to monitor and detect BAC during the developmental process to resolve potential BAC before an attack occurs allows for a proactive rather than a reactive approach. This study will specifically focus on privilege escalation, a key component and leading cause in BAC, and on the Llama 3 Large Language Model (LLM) from Meta. Llama was chosen due to its role as a pioneer within the open-source LLM community, rivaling the products of OpenAI's ChatGPT and Anthropic's Claude.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISSSR65654.2025.00074 },
  booktitle={ 2025 11th International Symposium on System Security, Safety, and Reliability (ISSSR) },
  chapter={0}
}

@article{rayyan-352343892,
  title={ Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation  -  2025 IEEE Conference on Software Testing, Verification and Validation (ICST) },
  year={2025},
  author={Tomic, S. and Alégroth, E. and Isaac, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989038 },
  abstract={Automated testing, particularly for GUI-based systems, remains a costly and labor-intensive process and prone to errors. Despite advancements in automation, manual testing still dominates in industrial practice, resulting in delays, higher costs, and increased error rates. Large Language Models (LLMs) have shown great potential to automate tasks traditionally requiring human intervention, leveraging their cognitive-like abilities for test generation and evaluation. In this study, we present PathFinder, a Multi-Agent LLM (MALLM) framework that incorporates four agents responsible for (a) perception and summarization, (b) decision-making, (c) input handling and extraction, and (d) validation, which work collaboratively to automate exploratory web-based GUI testing. The goal of this study is to assess how different LLMs, applied to different agents, affect the efficacy of automated exploratory GUI testing. We evaluate PathFinder with three models, Mistral-Nemo, Gemma2, and Llama3.1, on four e-commerce websites. Thus, 27 permutations of the LLMs, across three agents (excluding the validation agent), to test the hypothesis that a solution with multiple agents, each using different LLMs, is more efficacious (efficient and effective) than a multi-agent solution where all agents use the same LLM. The results indicate that the choice of LLM constellation (combination of LLMs) significantly impacts efficacy, suggesting that a single LLM across agents may yield the best balance of efficacy (measured by F1-score). Hypothesis to explain this result include, but are not limited to: improved decision-making consistency and reduced task coordination discrepancies. The contributions of this study are an architecture for MALLM-based GUI testing, empirical results on its performance, and novel insights into how LLM selection impacts the efficacy of automated testing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICST62969.2025.10989038 },
  booktitle={ 2025 IEEE Conference on Software Testing, Verification and Validation (ICST) },
  chapter={0}
}

@article{rayyan-352343893,
  title={ Sentiment Analysis for Better User Experience in Tourism Chatbot using LSTM and LLM  -  2023 9th International Conference on Signal Processing and Communication (ICSC) },
  year={2023},
  author={Balamurali, O. and Sai, A. M. Abhishek and Karthikeya, M. and Anand, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10441148 },
  abstract={Emotions of human plays a vital role in the usage of any technical solutions. AI now provide various opportunity to devise solutions that can understand human emotion from written and spoken words. In this research, we focus on the importance and application of sentiment analysis for an AI chatbot designed for tourism. The chatbot helps to act as a real-time information service system for tourists visiting a new city. Incorporating sentiment analysis to identify the user’s emotions and framing the response catering to the user’s emotions can enhance the chatbot’s user experience. By integrating Long Short-Term Memory (LSTM) networks and Large Language Models (LLM), this study aims to offer the components of a comprehensive system that understands and responds to user sentiments, enhancing the tourism experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC60394.2023.10441148 },
  booktitle={ 2023 9th International Conference on Signal Processing and Communication (ICSC) },
  chapter={0}
}

@article{rayyan-352343894,
  title={ PCCL: Energy-Efficient LLM Training with Power-Aware Collective Communication  -  2024 IEEE 42nd International Conference on Computer Design (ICCD) },
  year={2024},
  author={Jia, Z. and Bhuyan, L. N. and Wong, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818209 },
  abstract={The era of AI is witnessing a significant increase in energy consumption and carbon emissions from the execution of large language models (LLMs). Due to memory and compute requirements, it is necessary to distribute training and inference across many AI accelerators, such as GPUs. This paper focuses on distributed training that requires significant collective communication between accelerators; which often accounts for greater than half of training time. Besides LLMs, collective communication between GPUs is also common for many ML and HPC workloads. We first analyze the properties of collective communication operations in Nvidia Collective Communication Library (NCCL) and characterize the bandwidth, frequency, and energy properties of each collective communication operation. Then we propose PCCL, a Power-aware Collective Communication Library, based on NCCL, that can reduce power for communication kernels with dynamic voltage and frequency scaling (DVFS). PCCL identifies the optimal frequency for each collective communication call and precisely manages the GPU frequency accordingly in runtime. It can transparently lower the energy consumption of collective communication operations with negligible impact to throughput and performance. PCCL can reduce the energy of collective communication operations by ~27% and can reduce the end-to-end LLM training energy by 17.3%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCD63220.2024.00023 },
  booktitle={ 2024 IEEE 42nd International Conference on Computer Design (ICCD) },
  chapter={0}
}

@article{rayyan-352343895,
  title={ Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach  -  2025 20th Annual System of Systems Engineering Conference (SoSE) },
  year={2025},
  author={Sadik, A. R. and Ashfaq, M. and Mäkitalo, N. and Mikkonen, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11083807 },
  abstract={Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces challenges in system architecture, planning, task management, and execution. Traditional architectural approaches struggle with scalability, adaptability, and seamless resource integration within dynamic and complex environments. This paper presents an intelligent holonic architecture that incorporates Large Language Model (LLM) to manage the complexities of UAM. Holons function semi-autonomously, allowing for real-time coordination among air taxis, ground transport, and vertiports. LLMs process natural language inputs, generate adaptive plans, and manage disruptions such as weather changes or airspace closures. Through a case study of multimodal transportation with electric scooters and air taxis, we demonstrate how this architecture enables dynamic resource allocation, real-time replanning, and autonomous adaptation without centralized control, creating more resilient and efficient urban transportation networks. By advancing decentralized control and AI-driven adaptability, this work lays the groundwork for resilient, human-centric UAM ecosystems, with future efforts targeting hybrid AI integration and real-world validation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SoSE66311.2025.11083807 },
  booktitle={ 2025 20th Annual System of Systems Engineering Conference (SoSE) },
  chapter={0}
}

@article{rayyan-352343896,
  title={ Large Language Model in Suburban Transport Data Management  -  2024 Systems of Signals Generating and Processing in the Field of on Board Communications },
  year={2024},
  author={Kuftinova, N. G. and Ostroukh, A. V. and Maksimychev, O. I. and Podberezkin, A. A. and Volkov, A. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496733 },
  abstract={This article explores the new reality of using Large Language Models (LLM) to manage digital data of transport infrastructure based on the concept of artificial intelligence and deep learning of the transport network model as a digital twin of agglomeration. Innovations in the field of artificial intelligence based on data make it possible to make reliable predictions and make optimal decisions to solve scientific problems in this study, but it faces a number of critical problems, including high system complexity, large search space, incomplete knowledge and small amounts of data, and all this requires new strategies to effectively solve these problems. In combination with Artificial General Intelligence (AGI), vehicles can use this data to make more complex decisions, for example, choosing the optimal route depending on the current traffic situation and predicting its changes. LLM's artificial intelligence technology can also be used to create safer vehicles. For example, the system can automatically respond to changes in the traffic situation, preventing traffic accidents and minimizing risks to passengers and others.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEECONF60226.2024.10496733 },
  booktitle={ 2024 Systems of Signals Generating and Processing in the Field of on Board Communications },
  chapter={0}
}

@article{rayyan-352343897,
  title={ Neuro-Symbolic Program Synthesis for Multi-Hop Natural Language Navigation  -  2024 International Conference on Assured Autonomy (ICAA) },
  year={2024},
  author={English, W. and Simon, D. and Ahmed, R. and Jha, S. and Ewetz, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765960 },
  abstract={Solving navigation problems from natural language descriptions is essential for advancing humanrobot interaction and enhancing the usability of autonomous systems. Symbolic approaches to path planning excel in well defined environments but cannot cope with the ambiguity of natural language inputs. On the other hand, neural solutions centered on large language models (LLMs) can parse free-form natural language but lack the reasoning capabilities for solving complex multihop path planning problems. In this paper, we propose a neuro-symbolic framework based on program synthesis for multi-hop natural language navigation called NSPS. The framework uses an LLM to parse the problem definition in natural language, a graph of the environment, and an API of a graph library. Next, the code generation capabilities of the LLM are used to synthesize a program for path planning and verification. The path planning program is executed to generate a solution path that is checked by the verification program. A selfcorrection loop is used to fix both syntax and value errors. The framework is evaluated using 600 multihop navigation tasks with 1 to 10 hops. Compared with neural approaches, the NSPS framework improves the success rate and path efficiency by an average of 64.3% and 19.4% across all tasks, respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAA64256.2024.00027 },
  booktitle={ 2024 International Conference on Assured Autonomy (ICAA) },
  chapter={0}
}

@article{rayyan-352343898,
  title={ Context-Driven Chatbot Development: Leveraging Zephyr-7b with RAG for Improved Response Accuracy  -  2025 Emerging Technologies for Intelligent Systems (ETIS) },
  year={2025},
  author={Jervas, S. and Jacob, C. and Sundar, S. and P, D. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10960935 },
  abstract={In recent years, the demand for AI-driven conversational agents has increased significantly across various industries. Traditional generative models, while capable of producing human-like responses, often struggle with factual accuracy and context retention. Retrieval Augmented Generation (RAG) presents a novel approach to enhance the performance of AI chatbots by combining the strengths of both retrieval-based and generative models. The paper focuses on the development of an AI-driven chatbot using a RAG framework, integrating the Zephyr-7b model, to serve the needs of the ICT Academy of Kerala (ICTAK). The chatbot is engineered to deliver precise and contextually relevant responses to user queries by integrating advanced language models with structured data extracted from the ICTAK website. The data, which was meticulously scraped and processed, ensures that the chatbot's knowledge base remains current and accurately reflects the ICTAK's services and operations. A critical challenge addressed by this work is the issue of hallucinations in large language models (LLMs), where models may generate seemingly plausible yet incorrect or irrelevant information. To counteract this, the paper employs various chunking methods that enhance the chatbot's capability to retrieve and generate accurate responses. This AI Chatbot incorporates cutting-edge techniques in natural language processing, including document retrieval, context compression, and re-ranking. This multi-faceted approach ensures that the chatbot not only provides accurate responses but also delivers them in a contextually relevant manner.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ETIS64005.2025.10960935 },
  booktitle={ 2025 Emerging Technologies for Intelligent Systems (ETIS) },
  chapter={0}
}

@article{rayyan-352343899,
  title={ Intern VL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Chen, Z. and Wu, J. and Wang, W. and Su, W. and Chen, G. and Xing, S. and Zhong, M. and Zhang, Q. and Zhu, X. and Lu, L. and Li, B. and Luo, P. and Lu, T. and Qiao, Y. and Dai, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656429 },
  abstract={The exponential growth of large language models (LLMs) has opened up numerous possibilities for multi-modal AGI systems. However, the progress in vision and vision-language foundation models, which are also critical elements of multi-modal AGI, has not kept pace with LLMs. In this work, we design a large-scale vision-language foun-dation model (Intern VL), which scales up the vision foun-dation model to 6 billion parameters and progressively aligns it with the LLM, using web-scale image-text data from various sources. This model can be broadly applied to and achieve state-of-the-art performance on 32 generic visual-linguistic benchmarks including visual perception tasks such as image-level or pixel-level recognition, vision-language tasks such as zero-shot image/video classification, zero-shot image/video-text retrieval, and link with LLMs to create multi-modal dialogue systems. It has powerful visual capabilities and can be a good alternative to the ViT-22B. We hope that our research could contribute to the development of multi-modal large models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.02283 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343900,
  title={ Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Lin, G. -T. and Shivakumar, P. G. and Gandhe, A. and Yang, C. -H. H. and Gu, Y. and Ghosh, S. and Stolcke, A. and Lee, H. -Y. and Bulyko, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446933 },
  abstract={Large Language Models (LLMs) have demonstrated superior abilities in tasks such as chatting, reasoning, and question-answering. However, standard LLMs may ignore crucial paralinguistic information, such as sentiment, emotion, and speaking style, which are essential for achieving natural, human-like spoken conversation, especially when such information is conveyed by acoustic cues. We therefore propose Paralinguistics-enhanced Generative Pretrained Transformer (ParalinGPT), an LLM that utilizes text and speech modalities to better model the linguistic content and paralinguistic attributes of spoken dialogue. The model takes the conversational context of text, speech embeddings, and paralinguistic attributes as input prompts within a serialized multitasking multimodal framework. Specifically, our framework serializes tasks in the order of current paralinguistic attribute prediction, response paralinguistic attribute prediction, and response text generation with autoregressive conditioning. We utilize the Switchboard-1 corpus, including its sentiment labels as the paralinguistic attribute, as our spoken dialogue dataset. Experimental results indicate the proposed serialized multitasking method outperforms typical sequence classification techniques on current and response sentiment classification. Furthermore, leveraging conversational context and speech embeddings significantly improves both response text generation and sentiment prediction. Our proposed framework achieves relative improvements of 6.7%, 12.0%, and 3.5% in current sentiment accuracy, response sentiment accuracy, and response text BLEU score, respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10446933 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343901,
  title={ Socratic Planner: Self-QA-Based Zero-Shot Planning for Embodied Instruction Following  -  2025 IEEE International Conference on Robotics and Automation (ICRA) },
  year={2025},
  author={Shin, S. and Jeon, S. and Kim, J. and Kang, G. -C. and Zhang, B. -T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11128677 },
  abstract={Embodied Instruction Following (EIF) is the task of executing natural language instructions by navigating and interacting with objects in interactive environments. A key challenge in EIF is compositional task planning, typically addressed through supervised learning or few-shot in-context learning with labeled data. To this end, we introduce the Socratic Planner, a self-QA-based zero-shot planning method that infers an appropriate plan without any further training. The Socratic Planner first facilitates self-questioning and answering by the Large Language Model (LLM), which in turn helps generate a sequence of subgoals. While executing the subgoals, an embodied agent may encounter unexpected situations, such as unforeseen obstacles. The Socratic Planner then adjusts plans based on dense visual feedback through a visuallygrounded re-planning mechanism. Experiments demonstrate the effectiveness of the Socratic Planner, outperforming current state-of-the-art planning models on the ALFRED benchmark across all metrics, particularly excelling in long-horizon tasks that demand complex inference. We further demonstrate its real-world applicability through deployment on a physical robot for long-horizon tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRA55743.2025.11128677 },
  booktitle={ 2025 IEEE International Conference on Robotics and Automation (ICRA) },
  chapter={0}
}

@article{rayyan-352343902,
  title={ AeroQuery RAG and LLM for Aerospace Query in Designs, Development, Standards, Certifications  -  2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT) },
  year={2024},
  author={Yadav, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677028 },
  abstract={In the realm of avionics and aerospace, the demand for swift access to critical data is hindered by vast documentation, causing hallucinations, delays, and inefficiencies.To address this issue, our approach leverages the concepts of Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs).Our approach aims to overcome the limitations of LLMs by incorporating real-time data retrieval capabilities through RAG, enabling seamless access to current information. This envisioned chatbot utilizes advanced natural language processing and proactive pattern identification to streamline information retrieval and communication across various aerospace domains.By leveraging advancements in text summarization and utilizing models like Google’s PaLM2, Facebook’s LLaMA, or OpenAI’s GPT-4, we aim to enhance the performance of chatbots in information retrieval. This involves generating training examples and improving text summarization to efficiently address general inquiries related to standards and communication protocols within the aerospace sector but not limited to this.For instance, an aerospace engineer can quickly obtain relevant information on industry standards or communication protocols through the chatbot equipped with RAG, effortlessly taps into external sources to provide up-to-date and relevant information, reducing the need for exhaustive explanations and improving efficiency in information retrieval and communication processes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONECCT62155.2024.10677028 },
  booktitle={ 2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT) },
  chapter={0}
}

@article{rayyan-352343903,
  title={ LLM-Powered Diagnostic Decision Support System Integrated with Electronic Health Records  -  2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI) },
  year={2025},
  author={Khan, F. A. and Hajiarbabi, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135130 },
  abstract={To address the dual challenges of extensive clinical documentation and diagnostic complexity in healthcare, we developed a Diagnostic Decision Support System (DDSS) built atop an automated Electronic Health Record (EHR) pipeline. Our system combines intelligent language understanding with automated transcription to capture clinical dialogues between doctors and patients. It then fills in relevant sections of the electronic health record on its own, cutting down the time needed for documentation by more than 90% while maintaining a classification accuracy about 98.97%. At its core, the DDSS employs LLama3-8B, a large language model fine-tuned on domain-specific medical datasets, to provide intelligent diagnostic suggestions. Evaluation results show that LLama3-8B consistently outperforms other models when tested on tasks requiring deep understanding of medical information, achieving 96.98% on MMLU Clinical Knowledge, 99.31% on MMLU College Biology and 72.56% on MedMCQA. By integrating transcription, classification, and context-aware reasoning, the system significantly alleviates clinician cognitive burden, improves documentation efficiency, and enhances diagnostic accuracy—ultimately streamlining clinical workflows and improving patient outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDICI66477.2025.11135130 },
  booktitle={ 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI) },
  chapter={0}
}

@article{rayyan-352343904,
  title={ Large Language Models in Human-Robot Collaboration With Cognitive Validation Against Context-Induced Hallucinations  -  IEEE Access },
  author={Ranasinghe, N. and Mohammed, W. M. and Stefanidis, K. and Lastra, J. L. Martinez},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10980279 },
  abstract={The recent leap in Large Language Models (LLMs) has paved the way for several research ideas. LLMs are employed not only for personal use but also in professional contexts to enhance human productivity at work. A significant area of research is human-robot collaboration (HRC), which focuses on developing methodologies for effective interaction between humans and AI-enabled machines. In this regard, exploitation of LLMs appears to be a practical approach. However, these models are susceptible to several limitations, including context-induced errors, the propagation of misleading information, and hallucinations. Such deficiencies impede the seamless application of LLMs in scenarios where a high degree of accuracy is essential. To address this issue, this study introduces a dual-agent system designed to validate the responses generated by LLMs. This novel system is integrated into a framework called “CogniVera”, which facilitates collaborative tasks involving a collaborative robot (cobot) through vocal interactions. This initiative represents a significant advancement in HRC, enabling robots to communicate vocally with human operators during assembly tasks. To evaluate the feasibility of this approach, a focused case study will be conducted, concentrating on the human-robot collaborative task of box assembly utilizing vocal communication. The outcomes of this study are anticipated to yield valuable insights into the efficacy of the proposed dual-agent system in enhancing the reliability and performance of LLMs in practical applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3565918 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343905,
  title={ Research Report: AI Security is a LangSec Problem  -  2025 IEEE Security and Privacy Workshops (SPW) },
  year={2025},
  author={Hippel, M. Von and Miyazono, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050820 },
  abstract={The rapid development of Artificial Intelligence (AI) systems, and particularly Large Language Models (LLMs), has already started changing how software is written in industry. In this work, we categorize two important features of modern AI systems - structured outputs and tool-use - and explain how the security of each is, inherently, a LangSec problem. We provide anecdotal evidence from the San Francisco startup ecosystem to illustrate how companies are currently using, deploying, and securing AI systems with these features. Based on these observations and our analysis of current practices, we identify three concrete research directions where the LangSec community can contribute to securing both the parsing of LLM outputs and the safe deployment of LLM-powered tools. This work should be read as a call-to-action for the LangSec community to tackle outstanding, and growing, security problems catalyzed by AI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPW67851.2025.00011 },
  booktitle={ 2025 IEEE Security and Privacy Workshops (SPW) },
  chapter={0}
}

@article{rayyan-352343906,
  title={ Toward a Holistic Performance Evaluation of Large Language Models Across Diverse AI Accelerators  -  2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) },
  year={2024},
  author={Emani, M. and Foreman, S. and Sastry, V. and Xie, Z. and Raskar, S. and Arnold, W. and Thakur, R. and Vishwanath, V. and Papka, M. E. and Shanmugavelu, S. and Gandhi, D. and Zhao, H. and Ma, D. and Ranganath, K. and Weisner, R. and -y. Chen, J. and Yang, Y. and Vassilieva, N. and Zhang, B. C. and Howland, S. and Tsyplikhin, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10596441 },
  abstract={Artificial intelligence (AI) methods have become critical in scientific applications to help accelerate scientific discovery. Large language models (LLMs) are being considered a promising approach to address some challenging problems because of their superior generalization capabilities across domains. The effectiveness of the models and the accuracy of the applications are contingent upon their efficient execution on the underlying hardware infrastructure. Specialized AI accelerator hardware systems have recently become available for accelerating AI applications. However, the comparative performance of these AI accelerators on large language models has not been previously studied. In this paper, we systematically study LLMs on multiple AI accelerators and GPU s and evaluate their performance characteristics for these models. We evaluate these systems with (i) a micro-benchmark using a core transformer block, (ii) a GPT-2 model, and (iii) an LLM-driven science use case, GenSLM. We present our findings and analyses of the models' performance to better understand the intrinsic capabilities of AI accelerators. Furthermore, our analysis takes into account key factors such as sequence lengths, scaling behavior, and sensitivity to gradient accumulation steps.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPDPSW63119.2024.00016 },
  booktitle={ 2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) },
  chapter={0}
}

@article{rayyan-352343907,
  title={ Retrieval Augmented Generation for Relational Mapping of Resume Data for Improved Analysis  -  2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS) },
  year={2025},
  author={Manish, V. and Manchala, Y. and Chopra, S. B. and Siddartha, M. and Reddy, K. Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10968921 },
  abstract={Analysis of resume data is often a critical and time-intensive process that requires extensive metadata. However, a lack of consistency and scalability often leads to inefficiencies and errors in the recruitment process. Tools like Applicant Tracking Systems (ATS) often struggle with the contextual understanding of resume data, as they evaluate each resume in isolation without considering its relations to other similar resumes. We proposes the implementation of a Retrieval-Augmented Generation (RAG) architecture to create a vector relational mapping of resume data based on several curated parameters, such as skills, experiences, and education. This approach enables the system to understand the contextual relations between different resumes, helping the system evaluate them more effectively within a broader context, and improve recruitment outcomes by reducing biases and increasing efficiency.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLAS64557.2025.10968921 },
  booktitle={ 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS) },
  chapter={0}
}

@article{rayyan-352343908,
  title={ Contextual ASR with Retrieval Augmented Large Language Model  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Xiao, C. and Hou, Z. and Garcia-Romero, D. and Han, K. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890057 },
  abstract={Automatic speech recognition (ASR) systems can benefit from incorporating contextual information to improve recognition accuracy, especially for uncommon words or phrases. Current approaches like custom vocabularies or prompting with previous transcript segments provide limited contextual control. Compared to existing context biasing methods, RAG promises more flexible and scalable contextual control by leveraging LLMs’ broad knowledge. To this end, we propose leveraging large language models (LLMs) and retrieval-augmented generation (RAG) to enhance the contextual capabilities of ASR systems. Specifically, we propose systems based on text and audio LLMs to perform contextual error correction with context retrieved by querying a text-based retriever using the ASR module’s firstpass ASR hypotheses and a frequency-based custom vocabulary (CV) list. Our experiments reveal that the fine-tuned system has effectively learned to extract the relevant context to perform error correction while maintaining robustness against noise.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10890057 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343909,
  title={ VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework  -  2024 IEEE International Conference on Web Services (ICWS) },
  year={2024},
  author={Yao, Z. and Tang, Z. and Lou, J. and Shen, P. and Jia, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707432 },
  abstract={The Large Language Model (LLM) has gained significant popularity and is extensively utilized across various domains. Most LLM deployments occur within cloud data centers, where they encounter substantial response delays and incur high costs, thereby impacting the Quality of Services (QoS) at the network edge. Leveraging vector database caching to store LLM request results at the edge can substantially mitigate response delays and cost associated with similar requests, which has been overlooked by previous research. Addressing these gaps, this paper introduces a novel Vector database-assisted cloud-Edge collaborative LLM QoS Optimization (VELO) framework. Firstly, we propose the VELO framework, which ingeniously employs vector database to cache the results of some LLM requests at the edge to reduce the response time of subsequent similar requests. Diverging from direct optimization of the LLM, our VELO framework does not necessitate altering the internal structure of LLM and is broadly applicable to diverse LLMs. Subsequently, building upon the VELO framework, we formulate the QoS optimization problem as a Markov Decision Process (MDP) and devise an algorithm grounded in Multi-Agent Reinforcement Learning (MARL) to decide whether to request the LLM in the cloud or directly return the results from the vector database at the edge. Moreover, to enhance request feature extraction and expedite training, we refine the policy network of MARL and integrate expert demonstrations. Finally, we implement the proposed algorithm within a real edge system. Experimental findings confirm that our VELO framework substantially enhances user satisfaction by concurrently diminishing delay and resource consumption for edge users utilizing LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS62655.2024.00105 },
  booktitle={ 2024 IEEE International Conference on Web Services (ICWS) },
  chapter={0}
}

@article{rayyan-352343910,
  title={ Exploring the Potential of DeepSeek-R1 Model in Transforming Healthcare Solutions: An Overview  -  2025 13th International Symposium on Digital Forensics and Security (ISDFS) },
  year={2025},
  author={Raza, M. R. and Ahmed, S. and Khokhar, F. A. and Varol, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012057 },
  abstract={Over the past few decades, artificial intelligence (AI) has become more integrated into healthcare, with Large Language Models (LLMs) being a key component in improving healthcare decision-making. These LLMs' capacity to produce and interpret human-like texts has the potential to revolutionize healthcare procedures, where efficient data processing and communication are crucial. DeepSeek-Rl, created by DeepSeek AI, has drawn notice globally for its reasoning-based design that uses reinforcement learning (RL) to enhance problem-solving skills. Keeping this in view, the paper emphasizes the significance of the DeepSeek- Rl model and its application in the healthcare industry. Highlighting some hypothetical potential scenarios, we believe that DeepSeek models can playa crucial role in transforming existing medical approaches and revolutionizing the future of AI in health care.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISDFS65363.2025.11012057 },
  booktitle={ 2025 13th International Symposium on Digital Forensics and Security (ISDFS) },
  chapter={0}
}

@article{rayyan-352343911,
  title={ Leveraging RAG for Effective Prompt Engineering in Job Portals  -  2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN) },
  year={2025},
  author={Haneef, F. and M, V. and U, P. M. P},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932524 },
  abstract={Traditional recruitment methods are time-consuming and heavily reliant on manual processes, leading to inefficiencies. This paper explores the integration of AI technologies into a job portal to streamline the hiring process, focusing on AI’s ability to automatically parse and extract information from resumes and job descriptions to match candidates with relevant job opportunities. The platform leverages Large Language Models (LLMs) to extract key information, such as skills, education, and work experience, from both resumes and job descriptions. Fine-tuning through prompt engineering ensures accurate extraction, even when data fields are incomplete or missing. To further enhance matching accuracy, Retrieval-Augmented Generation (RAG) techniques are employed. These mechanisms retrieve relevant information from a structured skills database to provide context, which, combined with the generative capabilities of LLMs, enables more contextually accurate matches. Candidates receive personalized job recommendations based on the information extracted from their resumes, while employers can post job descriptions and use AI-driven tools to match candidates. This approach of using contextual prompts not only improves matching accuracy but also reduces computational time, eliminating the need for custom models tailored specifically to resumes or job descriptions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CICTN64563.2025.10932524 },
  booktitle={ 2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN) },
  chapter={0}
}

@article{rayyan-352343912,
  title={ Walk-the-Talk: LLM driven pedestrian motion generation  -  2024 IEEE Intelligent Vehicles Symposium (IV) },
  year={2024},
  author={Ramesh, M. and Flohr, F. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10588860 },
  abstract={In the field of autonomous driving, a key challenge is the "reality gap": transferring knowledge gained in simulation to real-world settings. Despite various approaches to mitigate this gap, there’s a notable absence of solutions targeting agent behavior generation which are crucial for mimicking spontaneous, erratic, and realistic actions of traffic participants. Recent advancements in Generative AI have enabled the representation of human activities in semantic space and generate real human motion from textual descriptions. Despite current limitations such as modality constraints, motion sequence length, resource demands, and data specificity, there’s an opportunity to innovate and use these techniques in the intelligent vehicles domain. We propose Walk-the-Talk, a motion generator utilizing Large Language Models (LLMs) to produce reliable pedestrian motions for high-fidelity simulators like CARLA. Thus, we contribute to autonomous driving simulations by aiming to scale realistic, diverse long-tail agent motion data - currently a gap in training datasets. We employ Motion Capture (MoCap) techniques to develop the Walk-the-Talk dataset, which illustrates a broad spectrum of pedestrian behaviors in street-crossing scenarios, ranging from standard walking patterns to extreme behaviors such as drunk walking and near-crash incidents. By utilizing this new dataset within a LLM, we facilitate the creation of realistic pedestrian motion sequences, a capability previously unattainable (cf. Figure 1). Additionally, our findings demonstrate that leveraging the Walk-the-Talk dataset enhances cross-domain generalization and significantly improves the Fréchet Inception Distance (FID) score by approximately 15% on the HumanML3D dataset. https://iv.ee.hm.edu/publications/w-the-t/},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IV55156.2024.10588860 },
  booktitle={ 2024 IEEE Intelligent Vehicles Symposium (IV) },
  chapter={0}
}

@article{rayyan-352343913,
  title={ AVERT (Authorship Verification and Evaluation Through Responsive Testing): an LLM-Based Procedure that Interactively Verifies Code Authorship and Evaluates Student Understanding  -  2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET) },
  year={2024},
  author={Vintila, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837675 },
  abstract={The rapid development of generative artificial intelligence challenges traditional plagiarism detection systems. Classic methods, based primarily on similarity, are more and more ineffective against content that is AI-generated, and which resembles authentic student submissions. This requires the use of detection methods that not only establish authorship but also augment student engagement and motivation, thus discouraging future plagiarism attempts. In this work-in-progress paper, we present AVERT (Authorship Verification and Evaluation through Responsive Testing), a proof-of-concept approach for establishing the authorship of programming assignments. Integrated in an LLM-based chatbot, it proactively assesses students' understanding of programming assignments by interactively questioning them about the process of developing their own code. This way the reasons for which students may be dishonest, such as motivation and lack of subject comprehension, are addressed. Using advanced prompting techniques and formulating questions that employ the Socratic method, AVERT dynamically generates questions to verify the students' understanding of the coding process. By asking students to explain the logic behind their solutions, it also improves analytical skills and engages students in the learning process. By automating the assessment of authorship, AVERT alleviates the logistical problems encountered by educators in large classroom environments where individualized assessment demands large resources. It also helps instructors in grading students by making the details of each conversation available for evaluation. AVERT provides a scalable and efficient method for establishing authorship, overcoming the shortcomings of other techniques by directly addressing the primary goal of programming assignments: assessing students' abilities to write functional code.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITHET61869.2024.10837675 },
  booktitle={ 2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET) },
  chapter={0}
}

@article{rayyan-352343914,
  title={ “Thanks for the Practice!”: LLM-Powered Social Robot as Tandem Language Partner at University  -  2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  year={2025},
  author={Ashok, A. and Bruno, B. and Helf, T. and Berns, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973837 },
  abstract={Large language models (LLMs), when integrated into social robots, have the potential to transform robot-assisted language learning by offering personalized, interactive communication. However, there is limited research exploring their potential to simultaneously reduce anxiety and enhance language-speaking skills among international university students, who often feel anxious when speaking a foreign language. This study addresses this gap by evaluating the impact of a humanoid robot powered by the OpenChat-3.5 LLM as a tandem partner for German language learning. Using a between-subjects design with 22 multilingual participants, two interaction conditions were tested: immersive (German-only) and bilingual (German-English). Our findings indicate that participants in the immersive mode reported experiencing significantly reduced perceived judgment by the robot compared to the bilingual mode. Although female participants showed a trend of greater improvement in learning gain, no significant gender differences were found. Open-ended feedback highlighted the need for enhanced contextual responses, slower speech rate, faster response times, and error corrections to enhance language speaking support. This study aims to advance social robots for learning by demonstrating the usage of generative AI in creating non-judgmental language practice scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HRI61500.2025.10973837 },
  booktitle={ 2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI) },
  chapter={0}
}

@article{rayyan-352343915,
  title={ AI-Integrated Traffic Information System: A Synergistic Approach of Physics Informed Neural Network and GPT-4 for Traffic Estimation and Real-Time Assistance  -  IEEE Access },
  author={Gebre, T. Syum and Beni, L. and Wasehun, E. Tsehaye and Dorbu, F. Elikem},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10526250 },
  abstract={Traffic management systems have primarily relied on live traffic sensors for real-time traffic guidance. However, this dependence often results in uneven service delivery due to the limited scope of sensor coverage or potential sensor failures. This research introduces a novel approach to overcome this limitation by synergistically integrating a Physics-Informed Neural Network-based Traffic State Estimator (PINN-TSE) with a powerful Natural Language Processing model, GPT-4. The purpose of this integration is to provide a seamless and personalized user experience, while ensuring accurate traffic density prediction even in areas with limited data availability. The innovative PINN-TSE model was developed and tested, demonstrating a promising level of precision with a Mean Absolute Error of less than four vehicles per mile in traffic density estimation. This performance underlines the model’s ability to provide dependable traffic information, even in regions where conventional traffic sensors may be sparsely distributed or data communication is likely to be interrupted. Furthermore, the incorporation of GPT-4 enhances user interactions by understanding and responding to inquiries in a manner akin to human conversation. This not only provides precise traffic updates but also interprets user intentions for a tailored experience. The results of this research showcase an AI-integrated traffic guidance system that outperforms traditional methods in terms of traffic estimation, personalization, and reliability. While the study primarily focuses on a single road segment, the methodology shows promising potential for expansion to network-level traffic guidance, offering even greater accuracy and usability. This paves the way for a smarter and more efficient approach to traffic management in the future.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3399094 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343916,
  title={ Generative AI for Intelligent Manufacturing Virtual Assistants in the Semiconductor Industry  -  IEEE Robotics and Automation Letters },
  author={Lin, C. -Y. and Tsai, T. -H. and Tseng, T. -L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10897746 },
  abstract={As semiconductor manufacturing complexity escalates, the intricacy of corresponding manufacturing systems intensifies. These extensive systems necessitate diverse engineering expertise for effective operation and analysis. For instance, yield engineers analyze yield systems, process engineers interpret FDC parameters, and equipment engineers monitor device equipment health. Traditional manufacturing systems, reliant on manual data analysis and fixed algorithms, suffer from slow decision-making and limited adaptability. They are susceptible to human error, reactive maintenance, and restricted user interaction confined to technical interfaces and business hours. Additionally, scalability and integration pose significant challenges, inflating operational costs and hampering resource efficiency. This letter introduces an Intelligent Manufacturing Virtual Assistant (IMVA) specifically designed for the semiconductor industry. By harnessing the power of Large Language Models (LLMs) and AI Agents, IMVA enhances yield analysis and seamlessly integrates with existing systems and tools. It exhibits high accuracy in defect detection through advanced data analysis and report generation. Furthermore, IMVA facilitates natural language interaction, rendering it user-friendly and accessible to non-technical personnel. Consequently, IMVA markedly improve operational efficiency and cost-effectiveness compared to traditional manufacturing systems. The efficacy of IMVA is demonstrated through the Wide-bandgap (WBG) process, showcasing its capability to simplify root cause analysis and provide comprehensive yield reports.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LRA.2025.3544506 },
  booktitle={ IEEE Robotics and Automation Letters },
  chapter={0}
}

@article{rayyan-352343917,
  title={ Interface on demand: Towards AI native Control interfaces for 6G  -  2025 IEEE International Conference on Communications Workshops (ICC Workshops) },
  year={2025},
  author={Dandekar, A. and Thapa, P. D. and Rahman, A. and Schulz-Zander, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11162406 },
  abstract={Traditional standardized network interfaces face significant limitations, including vendor-specific incompatibilities, rigid design assumptions, and lack of adaptability for new functionalities. We propose a multi-agent framework leveraging large language models (LLMs) to generate control interfaces on demand between network functions (NFs). This includes a matching agent, which aligns required control functionalities with NF capabilities, and a code-generation agent, which generates the necessary API server for interface realization. We validate our approach using simulated multi-vendor gNB and WLAN AP environments. The performance evaluations highlight the trade-offs between cost and latency across LLMs for interface generation tasks. Our work sets the foundation for AI-native dynamic control interface generation, paving the way for enhanced interoperability and adaptability in future mobile networks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCWorkshops67674.2025.11162406 },
  booktitle={ 2025 IEEE International Conference on Communications Workshops (ICC Workshops) },
  chapter={0}
}

@article{rayyan-352343918,
  title={ CircularPSP: AI-Powered Platform for Advancing Urban Circular Economy Transitions  -  2025 21st International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT) },
  year={2025},
  author={Vogt, G. and Schmidt, N. and Vanacore, E. and Vilier, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096334 },
  abstract={The CircularPSP project is developing an AI-powered Public Service Platform (PSP) to support municipalities in their transition to a circular economy (CE). Municipalities, which are responsible for significant resource consumption, face systemic barriers to adopting CE practices. Eight municipalities identified four main challenge areas: access to information, operations, organisation and change. A joint pre-commercial procurement (PCP) was initiated to stimulate the development of CE-solutions. These solutions integrate large language models (LLMs) trained on a curated CE Taxonomy with multilingual and contextual support. The core objective is to provide local government staff - regardless of their level of expertise - with useful workflows to enable day-to-day implementation of CE strategies, complemented by critical functionality for decision makers, CE experts and procurement officers. Testing will include real-world deployment across 20 local government organisations from 2025, with evaluation focused on user satisfaction and ability to achieve circular impact. The approach aims to produce scalable, transferable tools to support CE adoption in diverse local contexts across the EU.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DCOSS-IoT65416.2025.00081 },
  booktitle={ 2025 21st International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT) },
  chapter={0}
}

@article{rayyan-352343919,
  title={ SPADE: Enhancing Adaptive Cyber Deception Strategies with Generative AI and Structured Prompt Engineering  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Ahmed, S. and Rahman, A. B. M Mohaimenur and Alam, M. M. and Sajid, M. S. Islam},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903748 },
  abstract={The rapid evolution of modern malware presents significant challenges to the development of effective defense mechanisms. Traditional cyber deception techniques often rely on static or manually configured parameters, limiting their adaptability to dynamic and sophisticated threats. This study leverages Generative AI (GenAI) models to automate the creation of adaptive cyber deception ploys, focusing on structured prompt engineering (PE) to enhance relevance, actionability, and deploy-ability. We introduce a systematic framework (SPADE) to address inherent challenges large language models (LLMs) pose to adaptive deceptions, including generalized outputs, ambiguity, under-utilization of contextual information, and scalability constraints. Evaluations across diverse malware scenarios using metrics such as Recall, Exact Match (EM), BLEU Score, and expert quality assessments identified ChatGPT-4o as the top performer. Additionally, it achieved high engagement (93%) and accuracy (96%) with minimal refinements. Gemini and ChatGPT-4o Mini demonstrated competitive performance, with Llama3.2 showing promise despite requiring further optimization. These findings highlight the transformative potential of GenAI in automating scalable, adaptive deception strategies and underscore the critical role of structured PE in advancing real-world cybersecurity applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903748 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343920,
  title={ AI-Based Assistant: LLMs for Effective Robotics Education and Research  -  2024 International Conference on Emerging eLearning Technologies and Applications (ICETA) },
  year={2024},
  author={Krupáš, M. and Antonets, L. and Vaščák, J. and Zolotová, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850835 },
  abstract={Large language models (LLMs) offer new educational and research opportunities by enabling personalized learning, providing tutoring and assistance and enhancing accessibility. This paper examines the current application solutions of LLMs in education and their usability, benefits, and challenges. Through our use case and experimental data on Turtlebot3 education robots, we discuss the potential of different transformer-based LLMs and their limitations to improve educational and research outcomes for students working with robotic systems in laboratory conditions. We also evaluated selected models based on quantitative and qualitative metrics to choose one which was best suited for our AI-based education and research assistant use case.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICETA63795.2024.10850835 },
  booktitle={ 2024 International Conference on Emerging eLearning Technologies and Applications (ICETA) },
  chapter={0}
}

@article{rayyan-352343921,
  title={ Generative AI-Based Adaptation in Microservices Architectures: A Systematic Mapping Study  -  2025 IEEE International Conference on Web Services (ICWS) },
  year={2025},
  author={Sanwouo, B. and Temple, P. and Quinton, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169686 },
  abstract={Microservices have seen widespread adoption in academia and industry. Despite their benefits, challenges persist in resilience, performance, scalability, and adaptation to dynamic contexts. Generative AI (GenAI) has emerged as a promising approach to address these issues, though concerns remain about the suitability of various models and potential drawbacks. To assess the state of the art, we conducted a systematic mapping study analyzing 22 primary studies. Results reveal significant potential of GenAI in enhancing microservice adaptation, with emphasis on Large Language Models and optimization techniques. Applications primarily target maintenance and monitoring, especially anomaly management. This study also highlights research gaps and outlines future directions to advance GenAI integration for more resilient and autonomous microservices architectures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS67624.2025.00072 },
  booktitle={ 2025 IEEE International Conference on Web Services (ICWS) },
  chapter={0}
}

@article{rayyan-352343922,
  title={ MediGuard: Protecting Sensitive Healthcare Data with Privacy-Preserving Language Models  -  IEEE Journal of Biomedical and Health Informatics },
  author={Javed, H. and Ali, F. and Shah, B. and Dilshad, N. and Kwak, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11142715 },
  abstract={The integration of large language models (LLMs) into digital healthcare has the potential to significantly improve access to accurate and timely medical advice, especially in underserved areas. However, serious privacy concerns hinder the widespread adoption of LLM-based medical consultation systems, as they often require users to disclose private health information, risking unauthorized exposure and non-compliance with regulations. To address these issues, we introduce MediGuard, a new privacy-preserving LLM framework that dynamically protects sensitive healthcare data throughout the consultation process. MediGuard employs adaptive information obfuscation, combined with secure access protocols and robust auditing mechanisms, to process only non-sensitive information while preserving the necessary semantic integrity for precise medical inference and decision-making. Extensive testing across multiple medical question-answering datasets demonstrates that MediGuard consistently outperforms existing methods in both privacy protection and clinical accuracy, even under stringent privacy constraints. Our findings suggest that MediGuard provides safe, trustworthy, and clinically reliable medical consultations, setting a new standard for privacy-aware healthcare AI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JBHI.2025.3602983 },
  booktitle={ IEEE Journal of Biomedical and Health Informatics },
  chapter={0}
}

@article{rayyan-352343923,
  title={ VVF-AI: A Vulnerability Verification Framework Based on AI-Agent  -  2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) },
  year={2025},
  author={Liu, C. and Liu, T. and Tang, Y. and Lin, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11035850 },
  abstract={With the continuous deepening of research on big language models in LLM4Cybersecurity, LLM has shown great potential in applications such as vulnerability detection, code repair, and threat intelligence. This study innovatively proposes an AI agent based PoC verification framework (VVF-AI) to address the technical challenge of high false positive rates in vulnerability detection. We manually validate and evaluate four types of vulnerabilities based on the benchmark we constructed. The experimental results demonstrate that LLM can automatically filter false positives and achieve an accuracy rate of 93.1 % in information leakage vulnerabilities. The proposed framework is applicable to ASAT tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AINIT65432.2025.11035850 },
  booktitle={ 2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) },
  chapter={0}
}

@article{rayyan-352343924,
  title={ Generative AI for Low-Carbon Artificial Intelligence of Things with Large Language Models  -  IEEE Internet of Things Magazine },
  author={Wen, J. and Zhang, R. and Niyato, D. and Kang, J. and Du, H. and Zhang, Y. and Han, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10815045 },
  abstract={By integrating Artificial Intelligence (AI) with the Internet of Things (IoT), Artificial Intelligence of Things (AIoT) has revolutionized many fields. However, AIoT is facing the challenges of energy consumption and carbon emissions due to the continuous advancement of mobile technology. Fortunately, Generative AI (GAI) holds immense potential to reduce carbon emissions of AIoT due to its excellent reasoning and generation capabilities. In this article, we explore the potential of GAI for carbon emissions reduction and propose a novel GAI-enabled solution for low-carbon AIoT. Specifically, we first study the main impacts that cause carbon emissions in AIoT, and then introduce GAI techniques and their relations to carbon emissions. We then explore the application prospects of GAI in low-carbon AIoT, focusing on how GAI can reduce carbon emissions of network components. Subsequently, we propose a Large Language Model (LLM)-enabled carbon emission optimization framework, in which we design pluggable LLM and Retrieval Augmented Generation (RAG) modules to generate more accurate and reliable optimization problems. Furthermore, we utilize Generative Diffusion Models (GDMs) to identify optimal strategies for carbon emission reduction. Numerical results demonstrate the effectiveness of the proposed framework. Finally, we insightfully provide open research directions for low-carbon AIoT.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IOTM.001.2400074 },
  booktitle={ IEEE Internet of Things Magazine },
  chapter={0}
}

@article{rayyan-352343925,
  title={ LLM Agents as 6G Orchestrator: A Paradigm for Task-Oriented Physical-Layer Automation  -  2024 IEEE Globecom Workshops (GC Wkshps) },
  year={2024},
  author={Xiao, Z. and Ye, C. and Hu, Y. and Yuan, H. and Huang, Y. and Cai, L. and Chang, J. and Feng, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101226 },
  abstract={The rapid advancement in generative pre-training models is propelling a paradigm shift in technological progression from basic applications such as chatbots towards more sophisticated agent-based systems. It is with huge potential and necessity that the 6G system be combined with the copilot of large language model (LLM) agents and digital twins (DT) to manage the highly complicated communication system with new emerging features such as native AI service and sensing. With the 6G-oriented agent, the base station could understand the transmission requirements of various dynamic upper-layer tasks, automatically orchestrate the optimal system workflow. Through continuously get feedback from the 6G DT for reinforcement, the agents can finally raise the performance of practical system accordingly. Differing from existing LLM agents designed for general application, the 6G-oriented agent aims to make highly rigorous and precise planning with a vast amount of extra expert knowledge, which inevitably requires a specific system design from model training to implementation. This paper proposes a novel comprehensive approach for building task-oriented 6G LLM agents. We first propose a two-stage continual pre-training and fine-tuning scheme to build the field basic model and diversities of specialized expert models for meeting the requirements of various application scenarios. Further, a novel inference framework based on semantic retrieval for leveraging the existing communication-related functions is proposed. Experiment results of exemplary tasks, such as physical-layer task decomposition, show the proposed paradigm’s feasibility and effectiveness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GCWkshp64532.2024.11101226 },
  booktitle={ 2024 IEEE Globecom Workshops (GC Wkshps) },
  chapter={0}
}

@article{rayyan-352343926,
  title={ Thinking and Moving: An Efficient Computing Approach for Integrated Task and Motion Planning in Cooperative Embodied AI Systems (Invited Paper)  -  2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD) },
  year={2024},
  author={Wan, Z. and Du, Y. and Ibrahim, M. and Zhao, Y. and Krishna, T. and Raychowdhury, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126322 },
  abstract={Cooperative embodied AI systems, where multiple agents collaborate to accomplish complex, long-horizon tasks, show significant promise for real-world applications. These systems integrate perception, cognition, and action through integrated task and motion planning (TAMP), leveraging the advanced reasoning and communication capabilities of large language models (LLMs). However, their efficiency is often hindered by challenges such as high computational latency and redundant communication, largely due to the reliance on LLMs for sequential planning decisions. In this paper, we aim to identify the inherent characteristics and optimization opportunities in cooperative embodied AI systems. We first present a cognitive-inspired modular framework encompassing perception, memory, communication, planning, and execution. We then conduct a detailed profiling analysis of two state-of-the-art cooperative embodied systems, revealing the significance of each module and identifying critical bottlenecks such as redundant message pre-generation and excessive LLM usage in decision-making processes. Based on these insights, we propose several model- and system-level optimizations, including a planning-first communication strategy, selective multi-agent communication, and planning-guided multi-step execution. Evaluated across long-horizon cooperative tasks, these optimizations reduce the frequency of LLM inference runs, achieving an average 3.93× speedup in end-to-end task execution. Finally, we discuss the challenges and potential directions for embodied AI computing, to enhance system flexibility, efficiency, and scalability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676536.3698389 },
  booktitle={ 2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD) },
  chapter={0}
}

@article{rayyan-352343927,
  title={ GG-LLM: Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning  -  2024 IEEE International Conference on Robotics and Automation (ICRA) },
  year={2024},
  author={Graule, M. A. and Isler, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10611090 },
  abstract={A robot in a human-centric environment needs to account for the human’s intent and future motion in its task and motion planning to ensure safe and effective operation. This requires symbolic reasoning about probable future actions and the ability to tie these actions to specific locations in the physical environment. While one can train behavioral models capable of predicting human motion from past activities, this approach requires large amounts of data to achieve acceptable long-horizon predictions. More importantly, the resulting models are constrained to specific data formats and modalities. Moreover, connecting predictions from such models to the environment at hand to ensure the applicability of these predictions is an unsolved problem. We present a system that utilizes a Large Language Model (LLM) to infer a human’s next actions from a range of modalities without fine-tuning. A novel aspect of our system that is critical to robotics applications is that it links the predicted actions to specific locations in a semantic map of the environment. Our method leverages the fact that LLMs, trained on a vast corpus of text describing typical human behaviors, encode substantial world knowledge, including probable sequences of human actions and activities. We demonstrate how these localized activity predictions can be incorporated in a human-aware task planner for an assistive robot to reduce the occurrences of undesirable human-robot interactions by 29.2% on average.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRA57147.2024.10611090 },
  booktitle={ 2024 IEEE International Conference on Robotics and Automation (ICRA) },
  chapter={0}
}

@article{rayyan-352343928,
  title={ LLM-driven Multimodal and Multi-Identity Listening Head Generation  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Lai, P. and Zhong, W. and Qin, Y. and Ren, X. and Wang, B. and Li, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093213 },
  abstract={Generating natural listener responses in conversational scenarios is crucial for creating engaging digital humans and avatars. Recent work has shown that large language models (LLMs) can be effectively leveraged for this task, demonstrating remarkable capabilities in generating contextually appropriate listener behaviors. However, current LLM-based methods face two critical limitations: they rely solely on speech content, overlooking other crucial communication signals, and they entangle listener identity with response generation, compromising output fidelity and generalization. In this work, we present a novel framework that addresses these limitations while maintaining the advantages of LLMs. Our approach introduces a Multimodal-LM architecture that jointly processes speech content, acoustics, and speaker emotion, capturing the full spectrum of communication cues. Additionally, we propose an identity disentanglement strategy using instance normalization and adaptive instance normalization in a VQ-VAE framework, enabling high-fidelity listening head synthesis with flexible identity control. Extensive experiments demonstrate that our method significantly outperforms existing approaches in terms of response naturalness and fidelity, while enabling effective identity control without retraining.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.00996 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343929,
  title={ The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models  -  2024 2nd International Conference on Foundation and Large Language Models (FLLM) },
  year={2024},
  author={Renze, M. and Guven, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852493 },
  abstract={In this paper, we introduce Concise Chain-of-Thought (CCoT) prompting. We compared standard CoT and CCoT prompts to see how conciseness impacts response length and correct-answer accuracy. We evaluated this using GPT-3.5 and GPT-4 with a multiple-choice question-and-answer (MCQA) benchmark. CCoT reduced average response length by 48.70% for both GPT-3.5 and GPT-4 while having a negligible impact on problem-solving performance. However, on math problems, GPT-3.5 with CCoT incurred a performance penalty of 27.69%. Overall, CCoT leads to an average per-token cost reduction of 22.67%. All code, data, and supplemental materials are available on GitHub at https://github.com/matthewrenze/jhu-concise-cot},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FLLM63129.2024.10852493 },
  booktitle={ 2024 2nd International Conference on Foundation and Large Language Models (FLLM) },
  chapter={0}
}

@article{rayyan-352343930,
  title={ MilChat: A Large Language Model and Application for Military Equipment  -  2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP) },
  year={2024},
  author={Xue, L. and Jie, L. and Peipei, Z. and Tao, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10800008 },
  abstract={To offer the military personnel a good service of assisting them to get information about enemy's equipment outside Internet, we build a system named MilChat which includes a large language model that has the ability to generate texts and an application which is easy to use. The model of MilChat is fine-tuned by the method of LoRA with military datasets from the basic model, Qwen-7B-Chat which is opensource and has good performance. After fine-tuning, the new model has higher scores than the basic one. Besides, we use the method of Prompt Learning to limit the answers into a standard format. Therefore, it is more accurate and professional than the basic model. This study has also a value of industrial application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MLNLP63328.2024.10800008 },
  booktitle={ 2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP) },
  chapter={0}
}

@article{rayyan-352343931,
  title={ Automated Synthesis of Hardware Designs using Symbolic Feedback and Grammar-Constrained Decoding in Large Language Models  -  NAECON 2024 - IEEE National Aerospace and Electronics Conference },
  year={2024},
  author={Jha, S. Kumar and Jha, S. and Rashed, M. R. Haq and Ewetz, R. and Velasquez, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670630 },
  abstract={Large language models (LLMs) are capable of creating small programs including those in hardware description languages. However, there are no guarantees on the correctness of such generated programs. Our approach seeks to create correct-by-construction hardware designs using LLMs by employing formal verification to verify the designs and by using counterex-amples to guide the synthesis of such hardware designs in a counterexample-guided refinement loop. Grammar-constrained decoding is used to ensure that the generated code always satisfies the grammar of the hardware description language. We demonstrate the capability of our automated synthesis approach by generating a multiplier using LLMs and their assurance artifacts using model checking. Our approach provides a step in the direction of high-assurance synthesis of hardware artifacts using LLMs and formal methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NAECON61878.2024.10670630 },
  booktitle={ NAECON 2024 - IEEE National Aerospace and Electronics Conference },
  chapter={0}
}

@article{rayyan-352343932,
  title={ Automated Analysis of Short Answers Using Text Vectorization  -  2025 XXVIII International Conference on Soft Computing and Measurements (SCM) },
  year={2025},
  author={Minnegalieva, C. and Ziyatdinova, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060299 },
  abstract={Open-ended questions are used to test knowledge, and automated assessment of answers to them is currently widely studied. The paper analyzes student's answers formulated in free form. At first, language models were used and assessments were obtained using cosine similarity. To clarify the assessments, it is proposed to use binary classification. The capabilities of explainable artificial intelligence tools and modern chatbots based on large language models were also studied.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCM66446.2025.11060299 },
  booktitle={ 2025 XXVIII International Conference on Soft Computing and Measurements (SCM) },
  chapter={0}
}

@article{rayyan-352343933,
  title={ Navigating the Roadblocks: Lessons Learned from a Gardening Society Conversational RAG Bot  -  2024 IEEE 3rd World Conference on Applied Intelligence and Computing (AIC) },
  year={2024},
  author={Tamanna and Rana, S. and Choudhary, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10731053 },
  abstract={Large Language Model (LLM) Retrieval-Augmented Generation (RAG) chatbots hold immense potential for enhancing user engagement and information access. However, bringing such a system to life on a real-world platform presents unique challenges. This article explores the design of the chatbot, and the hurdles encountered in productionizing an LLM-RAG chatbot for a gardening society website. We delve into specific roadblocks faced during development, including•Domain-Specific Knowledge Acquisition: Training the LLM on a comprehensive gardening knowledge base proved crucial to ensure accurate and relevant responses.•Balancing Open-Endedness with Focus: While LLMs excel at open-ended conversation, enabling the chatbot to answer gardening queries effectively required focused training strategies.•Integration with Website Infrastructure: Seamless integration of the chatbot into the society's website involved addressing technical considerations and ensuring a user-friendly experience.We present the solutions implemented to overcome these challenges, offering valuable insights for those considering deploying similar LLM-RAG chatbots for niche online communities. The article concludes by discussing the lessons learned and the potential impact of such chatbots on the future of online user interactions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIC61668.2024.10731053 },
  booktitle={ 2024 IEEE 3rd World Conference on Applied Intelligence and Computing (AIC) },
  chapter={0}
}

@article{rayyan-352343934,
  title={ Estimating the Impact of Classroom Speech Using a Large Language Model  -  2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI) },
  year={2024},
  author={Onishi, S. and Kojima, S. and Shiina, H. and Yasumori, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707873 },
  abstract={Teachers in elementary and junior high schools in Japan have little time for reflection and other training, and there is an urgent need to develop a system for analyzing lessons. If the impact of the teacher's and children's speech in class could be numerically determined, this would lead to class improvements. In this study, fine tuning of a large language model was performed using LoRA to imitate teachers and children, and the Attention Weight and the variation of the generation probability obtained from the generation of utterances by the model are used to estimate the impact received and given by teachers' and children's utterances.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IIAI-AAI63651.2024.00081 },
  booktitle={ 2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI) },
  chapter={0}
}

@article{rayyan-352343935,
  title={ ClearFlow: Empowering Fluent Communication Through RAG-Based Text Generation for People Who Stutter  -  2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA) },
  year={2025},
  author={Al-Banna, A. -K. and Arafah, M. and Al-habahbeh, M. and Abu-Arqoub, M. and AlShaikh-Hasan, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11013690 },
  abstract={This paper introduces ClearFlow, an AI-driven text generation tool designed specifically for People Who Stutter (PWS) leveraging Retrieval Augmented Generation (RAG) technology to enhance communication fluency. The tool combines pre-trained models to generate real-time stutter-friendly text alternatives based on a private knowledge base. ClearFlow's architecture integrates ada-2 for text embedding and GPT-4 as the Large Language Model (LLM), employing a refined retrieval mechanism that uses cosine similarity to identify and suggest alternative document chunks that minimize stuttering events. The tool was evaluated using the Stuttering Severity Instrument 4 (SSI-4), a standardized assessment tool for mea-suring stuttering severity. The framework's effectiveness was tested through a comprehensive study involving six subjects, comparing their speech text fluency before and after using ClearFlow. Our implementation, built on Django 5.1 and utilizing the LangChain framework, demonstrates significant potential in reducing stuttering events while maintaining the semantic integrity of the intended communication. Results indicate that ClearFlow successfully assists PWS in generating alternative speech patterns that reduce core stuttering behaviors, such as blocks, repetitions, and prolongations, while preserving the intended message's meaning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCIAA65327.2025.11013690 },
  booktitle={ 2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA) },
  chapter={0}
}

@article{rayyan-352343936,
  title={ Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Keluskar, A. and Bhattacharjee, A. and Liu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825265 },
  abstract={Ambiguity in natural language poses significant challenges to Large Language Models (LLMs) used for open-domain question answering. LLMs often struggle with the inherent uncertainties of human communication, leading to misinterpretations, miscommunications, hallucinations, and biased responses. This significantly weakens their ability to be used for tasks like fact-checking, question answering, feature extraction, and sentiment analysis. Using open-domain question answering as a test case, we compare off-the-shelf and few-shot LLM performance, focusing on measuring the impact of explicit disambiguation strategies. We demonstrate how simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks. We empirically show our findings and discuss best practices and broader impacts regarding ambiguity in LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825265 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343937,
  title={ The Rise of Generative Artificial Intelligence in Healthcare  -  2023 12th Mediterranean Conference on Embedded Computing (MECO) },
  year={2023},
  author={Kuzlu, M. and Xiao, Z. and Sarp, S. and Catak, F. O. and Gurler, N. and Guler, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155107 },
  abstract={Generative Artificial Intelligence (GAI) is transforming various fields, including finance, education, marketing, and healthcare. Especially in healthcare, GAI has the potential to revolutionize various aspects, such as medical imaging, drug development, patient care, and treatment planning. Key stakeholders who stand to benefit from these advancements include hospitals, clinics, pharmaceutical companies, medical device manufacturers, and research institutions. However, the implementation of GAI in healthcare presents several challenges, such as ensuring data privacy and security, addressing ethical considerations, maintaining quality and accuracy, adhering to regulatory compliance, and integrating with existing systems. This paper examines the current state of GAI in healthcare, discusses its potential benefits and challenges, and highlights future directions that must be addressed to fully harness the power of GAI in improving patient outcomes and healthcare systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MECO58584.2023.10155107 },
  booktitle={ 2023 12th Mediterranean Conference on Embedded Computing (MECO) },
  chapter={0}
}

@article{rayyan-352343938,
  title={ Integrating LLM with CNN-RNN for Optimizing Crop Production  -  2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM) },
  year={2024},
  author={Gupta, K. and Rani, K. and Ajmani, P. and Sharma, V. and Alkhayyat, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10925778 },
  abstract={This study establishes a hybrid methodology combining LLM, CNN, and RNN for predicting crop yield, and detailed coverage of each area of the hybrid is set as follows-. In general, traditional methods have great difficulties with analyzing agricultural data presented as complex non-linear data. Our suggested approach utilizes the extraction capabilities of CNN, the temporal sequence modeling of RNN, and the sophisticated data processing of LLM, and this hybrid approach produced high accuracy levels for tested crops including wheat, maize, millet, rice, and barley, as well as significantly better precision, recall and f-score cutoff levels than traditional methods. This research contributes to ongoing developments toward improved food security and agriculture output through the implementation of sophisticated machine learning models. This paper presents a novel hybrid model for predicting crops yields by combining Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) with Large Language Models (LLMs). Because agricultural data is challenging to model as traditional algorithms typically struggle with complex, inherently non-linear data, our modeling approach leverages the capabilities of sophisticated LLMs for processing data, temporal sequence modeling capabilities of RNNs, and data extraction capabilities of CNNs. Our hybrid model can produce high accuracy outcomes from the model experimentation using standard measures of output accuracy from a number of crop species, including barley, rice, millet, maize and wheat, and the model also produced significant and meaningful improvements over previous studies with traditional methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IIPEM62726.2024.10925778 },
  booktitle={ 2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM) },
  chapter={0}
}

@article{rayyan-352343939,
  title={ LightRot: A Light-Weighted Rotation Scheme and Architecture for Accurate Low-Bit Large Language Model Inference  -  IEEE Journal on Emerging and Selected Topics in Circuits and Systems },
  author={Kim, S. and Choi, Y. and Oh, J. and Kim, B. and Yoo, H. -J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10950449 },
  abstract={As large language models (LLMs) continue to demonstrate exceptional capabilities across various domains, the challenge of achieving energy-efficient and accurate inference becomes increasingly critical. This work presents LightRot, a lightweight rotation scheme and dedicated hardware accelerator designed for low-bit LLM inference. The proposed architecture integrates Grouped Local Rotation (GLR) and Outlier Direction Aligning (ODA) algorithms with a hierarchical Fast Hadamard Transform (FHT)-based rotation unit to address key challenges in low-bit quantization, including the energy overhead of rotation operations. The proposed accelerator, implemented in a 28nm CMOS process, achieves a peak energy efficiency of 27.4TOPS/W for 4-bit inference, surpassing prior state-of-the-art designs. Unlike conventional approaches that rely on higher-precision inference or evaluate on basic language modeling tasks like GPT-2, LightRot is optimized for advanced models such as LLaMA2-13B and LLaMA3-8B. Its performance is further validated on MT-Bench, demonstrating robust applicability to real-world conversational scenarios and redefining benchmarks for chat-based AI systems. By synergizing algorithmic innovations and hardware efficiency, this work sets a new paradigm for scalable, low-bit LLM inference, paving the way for sustainable AI advancements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JETCAS.2025.3558300 },
  booktitle={ IEEE Journal on Emerging and Selected Topics in Circuits and Systems },
  chapter={0}
}

@article{rayyan-352343940,
  title={ AI-Enhanced Honeypots: Leveraging LLM for Adaptive Cybersecurity Responses  -  2024 16th International Conference on Information Technology and Electrical Engineering (ICITEE) },
  year={2024},
  author={Christli, J. A. and Lim, C. and Andrew, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10808265 },
  abstract={Honeypots have long been used as decoy systems to lure and study attackers, providing valuable intelligence on emerging cybersecurity threats. However, with the increasing sophistication of cyberattacks, static honeypots have become less effective against advanced adversaries. This paper presents an innovative solution: AI-driven honeypots powered by Large Language Models (LLMs), specifically the LLaMA-3 model. Unlike traditional honeypots, these AI-enhanced systems can dynamically generate contextually appropriate, human-like responses in real-time, greatly improving their ability to deceive and engage attackers. By leveraging the LLaMA-3 model, the proposed system enhances the realism of interactions, making it significantly more difficult for attackers to identify the decoy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICITEE62483.2024.10808265 },
  booktitle={ 2024 16th International Conference on Information Technology and Electrical Engineering (ICITEE) },
  chapter={0}
}

@article{rayyan-352343941,
  title={ Cost-Effective LLM Accelerator Using Processing in Memory Technology  -  2024 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits) },
  year={2024},
  author={Lee, H. and Kim, G. and Yun, D. and Kim, I. and Kwon, Y. and Lim, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10631397 },
  abstract={Large language model (LLM)-based services continue to improve their performance requires the system with both large memory capacity and high memory bandwidth. For the GPT-3 [1] [5] 175 billion model to operate at a minimum, it requires 800GB of storage. In addition, from frequent memory access and limited data reuse also affects memory bandwidth. More powerful memory performance requirements, however, comes with significant costs increase. The expenses associated with operating the necessary equipment and services to handle these capacity and bandwidth requirements are considerable. SK hynix aims to solve this issue by introducing a processing in memory (PIM) device and PIM based accelerator called AiM [2] and AiMX, respectively. By exploiting true bank-level parallelism, AiM and AiMX are expected to enhance the performance of LLM-based services as a core component of disaggregated system and multi-head attention acceleration. Additionally, AiM also has a potential in on-device AI, in direction of both performance and energy consumption with low batch size and reducing off-chip data movement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VLSITechnologyandCir46783.2024.10631397 },
  booktitle={ 2024 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits) },
  chapter={0}
}

@article{rayyan-352343942,
  title={ Controlled Chain of Thought: Eliciting Role-Play Understanding in LLM Through Prompts  -  2024 IEEE Conference on Games (CoG) },
  year={2024},
  author={Carlander, D. and Okada, K. and Engström, H. and Kurabayashi, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645667 },
  abstract={Tabletop Role Playing Games (TRPG) are games that require players to become the characters they play through engaging in role-play. The challenge of training AI lies in the requirement of it not only understanding the explicitly stated game rules, but also the implicit ones that come with role-playing. Previous studies endeavouring said challenge allude to aspects of role-play, but do not emphasise its role in their methods, indicating that the definition of role-play and how it is to be employed remains unclear. This short paper aims to investigate a proposed definition of role-play based on previous research and employ its use on Large Language Model LLM, eliciting an understanding thereof through a novel prompting method dubbed Controlled Chain of Thought (CCoT). CCoT allows for the LLM to highlight absence of information in inputs given to it by generating questions, which become the template for its chain of thoughts when answered. This paper presents an initial pilot testing of CCoT as well as opens up the discussion of how a definition of role-play can be beneficial for future studies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG60054.2024.10645667 },
  booktitle={ 2024 IEEE Conference on Games (CoG) },
  chapter={0}
}

@article{rayyan-352343943,
  title={ LLM for NVIDIA SDKs  -  2023 International Conference on Emerging Techniques in Computational Intelligence (ICETCI) },
  year={2023},
  author={Sreevaatsav, B. and Srikanth, C. and Vamshi, B. K. and Deepesh, G. V. and Sai, K. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10331012 },
  abstract={This paper introduces an AI-driven language model (LLM) designed to facilitate users' comprehension and adept usage of different NVIDIA SDKs (Software Development Kits) and toolkits. The central goal is to provide a LLM which establishes an interactive and intuitive platform that offers inclusive insights, practical illustrations, and expert direction on NVIDIA's diverse SDKs and toolkits. Harnessing the capabilities of language models and NVIDIA's toolkits, this study strives to streamline developers' learning process, enabling them to harness NVIDIA's technological advancements with enhanced proficiency.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICETCI58599.2023.10331012 },
  booktitle={ 2023 International Conference on Emerging Techniques in Computational Intelligence (ICETCI) },
  chapter={0}
}

@article{rayyan-352343944,
  title={ BNS Mitra: RAG-Optimized LLM Based AI-Powered Legal Virtual Assistant  -  2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI) },
  year={2025},
  author={Patil, B. and Alam, R. and Kalal, T. V. and Porwal, P. and Kushwaha, N. S. and Sharma, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11063757 },
  abstract={This paper presents BNS Mitra, a Virtual legal assistant for Bharatiya Nyaya Sanhita (BNS), which is powered by Artificial intelligence and is designed with RAG (Retrieval Augmented Generation) framework. Since many stakeholders exist: law enforcement, advocates, judiciary members and common people, BNS Mitra assisted by Meta's LLAMA 2 model is helpful in translating user-described incidents into legal sentences to determine the most relevant sections of BNS. BNS Mitra incorporated FAISS (Facebook AI Similarity Search) that provides the encoded BNS database for encoding vectors to use as a database suitable for user queries, thus allowing contextual legal advice to be provided in due time. Due to its simple design, the general public is able to obtain legal information. On the other hand, the time spent carrying out manual research is reduced since professionals are able to quickly obtain relevant sections. In tests BNS Mitra managed to achieve 87% accuracy regarding which BNS sections were most closely related to user input. The software performed well enough in simple cases, but some issues were identified in more complex cases. This paper presents the capacity of AI as a tool to diminish the knowledge gap in the Indian legal system and recommends the idea of expanding the scope of BNS Mitra to other legal areas/fields and language models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCSAI64074.2025.11063757 },
  booktitle={ 2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI) },
  chapter={0}
}

@article{rayyan-352343946,
  title={ Automatic Generation of OpenCL Code through Polyhedral Compilation with LLM  -  2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS) },
  year={2024},
  author={Palkowski, M. and Gruzewski, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736100 },
  abstract={In recent years, a multitude of AI solutions has emerged to facilitate code generation, commonly known as Language Model-based Programming (LLM). These tools empower programmers to automate their work. Automatic programming also falls within the domain of optimizing compilers, primarily based on the polyhedral model, which processes loop nests concentrating most computations. This article focuses on harnessing LLM tools to generate OpenCL code for non-serial polyadic dynamic programming kernels. [1] We have chosen the Nussinov RNA folding computational task, previously employed to test polyhedral compilers in optimizing kernels with non-uniform dependences. The code generated in OpenMP by polyhedral optimizers is limited to CPU computations. We automatically convert it into the OpenCL standard using ChatGPT-3.5 through its source-to-source queries to extend the number of possible platforms. The validity and efficiency of the generated code were verified on various CPUs and GPUs from different manufacturers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.15439/2024F6469 },
  booktitle={ 2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS) },
  chapter={0}
}

@article{rayyan-352343947,
  title={ Data Space and LLM Enabled Decision-Making Support System: An Application in Drug Development  -  2025 2nd International Conference on Electronic Engineering and Information Systems (EEISS) },
  year={2025},
  author={Wang, C. and Ming, X. and Zhang, X. and Xu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11085518 },
  abstract={In this study, we analyzed the demand and pain points of multi-business pipelines integrated decision-making scenarios (such as drug development), including the subjectivity, non-interpretability and low efficiency of traditional expert experience-driven decision-making, and the inability to handle a large amount of data. Then, we designed a framework for the Data Space and Large Language Model (LLM) enabled decision-making support system. By integrating Data Space, the framework helps enterprises to achieve multilateral data-driven evaluation and analysis; By integrating LLM and Ai-Agent, collaborative decisionmaking of multi-business pipelines can be realized. This framework can provide quantitative analysis for experts and improve the accuracy and efficiency of decision-making. The effectiveness of this study has been verified in the decisionmaking scenario of drug development. The follow-up studies will further explore the autonomous decision-making of multi-business pipelines and the intelligent conflict resolution mechanism to reduce the dependence on expert experience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEISS65394.2025.11085518 },
  booktitle={ 2025 2nd International Conference on Electronic Engineering and Information Systems (EEISS) },
  chapter={0}
}

@article{rayyan-352343948,
  title={ Development of an RAG-Based LLM Chatbot for Enhancing Technical Support Service  -  TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  year={2024},
  author={Lee, H. -C. and Hung, K. and Man, G. M. -T. and Ho, R. and Leung, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10902801 },
  abstract={The global shortage of manpower for technical support is a critical issue in the digital transformation era. Recently, Large Language Models (LLMs) have made significant strides in natural language processing, leading to the development of AI chatbots to address this problem. However, LLMs have notable limitations in handling domain-specific information, often generating incorrect responses when queries go beyond the coverage of the training data or require the most up-to-date information. A promising solution is the Retrieval-Augmented Generation (RAG) approach, which incorporates domain-specific data retrieval into the generative process. Our team has developed a domain-specific and RAG-based LLM chatbot to enhance the software house technical support of an IT consultant in Canada. The chatbot was implemented and evaluated in real-world production environments. Preliminary results show that the system has achieved high scores of 38%, 188%, and 40% in the ROUGE-I, ROUGE-2, and ROUGE-L measures, respectively, compared to using only a general LLM model. End-user feedback also reflected that the enhanced system produced more accurate and efficient replies, thereby enhancing overall customer satisfaction.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TENCON61640.2024.10902801 },
  booktitle={ TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  chapter={0}
}

@article{rayyan-352343949,
  title={ An Open Framework for Smart Retrofitting of Legacy Industrial Machines Towards Industry 4.0  -  TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  year={2024},
  author={Patel, D. and Muthuswamy, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10902873 },
  abstract={This paper presents a six-layer framework for smart retrofitting of legacy industrial machines to align with Industry 4.0 standards, using open-source technologies for cost-effectiveness and scalability. The layers include edge data acquisition, data preprocessing, Digital Twin technology, long-term data storage, AI-based data analysis, and real-time visual-ization. Implemented and evaluated through a case study on a legacy CNC lathe, the framework demonstrated reliable communication and effective performance across various layers. The results validate the framework's feasibility and highlight the need for further fine-tuning of open large language models with manufacturing domain knowledge.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TENCON61640.2024.10902873 },
  booktitle={ TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON) },
  chapter={0}
}

@article{rayyan-352343950,
  title={ Finetuning Large Language Models for Vulnerability Detection  -  IEEE Access },
  author={Shestov, A. and Levichev, R. and Mussabayev, R. and Maslov, E. and Zadorozhny, P. and Cheshkov, A. and Mussabayev, R. and Toleu, A. and Tolegen, G. and Krassovitskiy, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908394 },
  abstract={This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in Java source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder’s training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, handling class imbalance, and improving performance on difficult vulnerability detection datasets. This demonstrates the potential for transfer learning by finetuning large pretrained language models for specialized source code analysis tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3546700 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343951,
  title={ End-to-End Speech Recognition Contextualization with Large Language Models  -  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2024},
  author={Lakomkin, E. and Wu, C. and Fathullah, Y. and Kalinli, O. and Seltzer, M. L. and Fuegen, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446898 },
  abstract={In recent years, Large Language Models (LLMs) have garnered significant attention from the research community due to their exceptional performance and generalization capabilities. In this paper, we introduce a novel method for contextualizing speech recognition models incorporating LLMs. Our approach casts speech recognition as a mixed-modal language modeling task based on a pretrained LLM. We use audio features, along with optional text tokens for context, to train the system to complete transcriptions in a decoder-only fashion. As a result, the system implicitly learns how to leverage unstructured contextual information during training. Our empirical results demonstrate a significant improvement in performance, with a 6% WER reduction when additional textual context is provided. Moreover, we find that our method performs competitively, improving by 7.5% WER overall and 17% WER on rare words, compared to a baseline contextualized RNN-T system that has been trained on a speech dataset more than twenty-five times larger. Overall, we demonstrate that by adding only a handful of trainable parameters via adapters, we can unlock the contextualized speech recognition capability of the pretrained LLM while maintaining the same text-only input functionality.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP48485.2024.10446898 },
  booktitle={ ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343952,
  title={ Lifelong Robot Learning with Human Assisted Language Planners  -  2024 IEEE International Conference on Robotics and Automation (ICRA) },
  year={2024},
  author={Parakh, M. and Fong, A. and Simeonov, A. and Chen, T. and Gupta, A. and Agrawal, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10610225 },
  abstract={Large Language Models (LLMs) have been shown to act like planners that can decompose high-level instructions into a sequence of executable instructions. However, current LLM-based planners are only able to operate with a fixed set of skills. We overcome this critical limitation and present a method for using LLM-based planners to query new skills and teach robots these skills in a data and time-efficient manner for rigid object manipulation. Our system can re-use newly acquired skills for future tasks, demonstrating the potential of open world and lifelong learning. We evaluate the proposed framework on multiple tasks in simulation and the real world. Videos are available at: https://sites.google.com/mit.edu/halp-robot-learning},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRA57147.2024.10610225 },
  booktitle={ 2024 IEEE International Conference on Robotics and Automation (ICRA) },
  chapter={0}
}

@article{rayyan-352343953,
  title={ Painter: Teaching Auto-regressive Language Models to Draw Sketches  -  2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW) },
  year={2023},
  author={Pourreza, R. and Bhattacharyya, A. and Panchal, S. and Lee, M. and Madan, P. and Memisevic, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350894 },
  abstract={Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc. In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image. We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way. We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities. We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks. Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches. Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCVW60793.2023.00038 },
  booktitle={ 2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW) },
  chapter={0}
}

@article{rayyan-352343954,
  title={ All-Rounder: A Flexible AI Accelerator With Diverse Data Format Support and Morphable Structure for Multi-DNN Processing  -  IEEE Transactions on Very Large Scale Integration (VLSI) Systems },
  author={Noh, S. -H. and Lee, S. and Shin, B. and Park, S. and Jang, Y. and Kung, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908423 },
  abstract={Recognizing the explosive increase in the use of artificial intelligence (AI)-based applications, several industrial companies developed custom application-specific integrated circuits (ASICs) (e.g., Google TPU, IBM RaPiD, and Intel NNP-I/NNP-T) and constructed a hyperscale cloud infrastructure with them. These ASICs perform operations of the inference or training process of AI models which are requested by users. Since the AI models have different data formats and types of operations, the ASICs need to support diverse data formats and various operation shapes. However, the previous ASIC solutions do not or less fulfill these requirements. To overcome these limitations, we first present an area-efficient multiplier, named all-in-one multiplier, which supports multiple bit-widths for both integer (INT) and floating-point (FP) data types. Then, we build a multiply-and-accumulation (MAC) array equipped with these multipliers with multiformat support. In addition, the MAC array can be partitioned into multiple blocks that can be flexibly fused to support various deep neural network (DNN) operation types. We evaluate the practical effectiveness of the proposed MAC array by making an accelerator out of it, named All-rounder. According to our evaluation, the proposed all-in-one multiplier occupies  $1.49\times $  smaller area compared to the baselines with dedicated multipliers for each data format. Then, we compare the performance and energy efficiency of the proposed All-rounder with three different accelerators showing consistent speedup and higher efficiency across various AI benchmarks from vision to large language model (LLM)-based language tasks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TVLSI.2025.3540346 },
  booktitle={ IEEE Transactions on Very Large Scale Integration (VLSI) Systems },
  chapter={0}
}

@article{rayyan-352343955,
  title={ Adaptive Learning Revolution with AI-Driven Personalization and Gamified Real-Time Interaction  -  2025 International Conference on Knowledge Engineering and Communication Systems (ICKECS) },
  year={2025},
  author={Shukla, V. K. and Merikapudi, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034830 },
  abstract={As cutting-edge technologies like artificial intelligence, machine learning, cloud computing, OpenAI, LLM, generative AI, augmented reality (AR), virtual reality (VR), mixed reality (MR), extended reality (XR), and big data become more prevalent, it is helpful from an educational point of view to analyze the AI-enabled Adaptive Learning Platform with Gamified Personalized System and Real-Time Recommendations. This will allow learners to take full advantage of these new technologies. The literature review and their research on the Adaptive Learning Model are conducted from this point of view. This study assesses the potential of cutting-edge technologies for adaptive learning platforms, addressing the proliferation of personalized with recommendations & gamified educational approaches. Since 2012, numerous studies have been conducted to this extent. Also, the perspective of current going on studies is crucial to provide advanced and accurate solutions in the realm of education which can transform the complete educational & research field. This paper synthesizes the guide for future research and studies on how to better platforms design AI-Based Adaptive Learning Platform with Dynamic Content Delivery, Real-Time Feedback, Student Engagement, Competency-Based Education, Supervised Association Rules, Dynamic System Models, Open Educational Resources (OERs), Reinforcement Learning, Advanced Analytics & Visualization, Scalability, Low Latency. These advancements highlight the potential for AI and machine learning to strengthen personalized learning & gamification, improve student engagement and optimize educational results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICKECS65700.2025.11034830 },
  booktitle={ 2025 International Conference on Knowledge Engineering and Communication Systems (ICKECS) },
  chapter={0}
}

@article{rayyan-352343956,
  title={ Accelerating Model-Based Systems Engineering by Harnessing Generative AI  -  2024 19th Annual System of Systems Engineering Conference (SoSE) },
  year={2024},
  author={Crabb, E. S. and Jones, M. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620975 },
  abstract={With the rise of artificial intelligence (AI) tools to support the work of numerous disciplines, we describe a preliminary investigation into the benefits and drawbacks of large language model (LLM) use as part of a traditional systems engineering and design workflow. To explore this, we tasked a group of systems engineers to each create a list of requirements and use case diagram to satisfy a systems of systems user scenario presented in a proposal document. Participants created models of a healthcare setting in which clinicians resolved discrepancies with patient care by consulting additional sources of record, demonstrating the importance of integrating new systems within the larger healthcare system of systems. The first group were provided open access to an LLM, the second group were provided draft materials generated by an LLM, and the third followed their normal workflow. A subject matter expert (SME) evaluator then scored each model according to its completeness, consistency, correctness, simplicity, and traceability. Through this, we show that although LLMs are not a replacement for a trained systems engineer, they can contribute in two primary ways to the modeling process: first, they can generate a significant portion of the information necessary to create a minimum viable product (MVP) model within a fraction of the time, offering a promising way to accelerate the overall model development process. Second, they can answer detailed, domain-specific questions and reduce the time spent on external research.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SOSE62659.2024.10620975 },
  booktitle={ 2024 19th Annual System of Systems Engineering Conference (SoSE) },
  chapter={0}
}

@article{rayyan-352343957,
  title={ Natural Language Interface for Queries on Databases with Sensitive Information  -  2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  year={2025},
  author={Adeniye, S. and Al-Atawi, F. and Sen, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114052 },
  abstract={The analysis of large datasets poses significant challenges for users unfamiliar with structured query languages such as SQL or Cypher. These users, often from fields like social sciences or law enforcement, require intuitive and secure access to complex databases. Additionally, datasets in domains such as criminal justice, healthcare, and education often contain sensitive information, necessitating robust privacy protections. To address these challenges, we propose a privacy-preserving natural language interface for querying graph databases. Our framework integrates Optical Character Recognition (OCR) techniques to extract structured data from scanned and unstructured documents, storing it in a Neo4j graph database to efficiently model entity relationships. To facilitate user interaction, we leverage a Large Language Model (LLM)-powered query translation module that converts natural language queries into Cypher, eliminating the need for technical expertise. To enhance privacy, our framework pseudonymizes sensitive entities using entity masking before query translation, ensuring that personally identifiable information within the user queries is never exposed to the LLM. Additionally, the Neo4j database is entirely separated from the LLM, meaning that the LLM only has access to the database schema and not any stored data. This ensures that query processing occurs in a controlled, authenticated environment, mitigating risks of data leakage. We also enforce schema-aware query translation, which significantly improves accuracy by guiding the LLM with structured database constraints. We evaluate our system using real-world criminal records and the publicly available Text2Cypher dataset, demonstrating high logical and execution accuracy. Computational performance analysis shows that our privacy mechanisms introduce only minimal latency overhead ($\sim 5-8 \%$), making them suitable for real-time applications. Our results confirm that this framework effectively balances accessibility, accuracy, and privacy, making it applicable to sensitive domains where secure, user-friendly data retrieval is essential.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAD65464.2025.11114052 },
  booktitle={ 2025 IEEE International Conference on AI and Data Analytics (ICAD) },
  chapter={0}
}

@article{rayyan-352343958,
  title={ Enhancing the LLM-Based Robot Manipulation Through Human-Robot Collaboration  -  IEEE Robotics and Automation Letters },
  author={Liu, H. and Zhu, Y. and Kato, K. and Tsukahara, A. and Kondo, I. and Aoyama, T. and Hasegawa, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10561501 },
  abstract={Large Language Models (LLMs) are gaining popularity in the field of robotics. However, LLM-based robots are limited to simple, repetitive motions due to the poor integration between language models, robots, and the environment. This letter proposes a novel approach to enhance the performance of LLM-based autonomous manipulation through Human-Robot Collaboration (HRC). The approach involves using a prompted GPT-4 language model to decompose high-level language commands into sequences of motions that can be executed by the robot. The system also employs a YOLO-based perception algorithm, providing visual cues to the LLM, which aids in planning feasible motions within the specific environment. Additionally, an HRC method is proposed by combining teleoperation and Dynamic Movement Primitives (DMP), allowing the LLM-based robot to learn from human guidance. Real-world experiments have been conducted using the Toyota Human Support Robot for manipulation tasks. The outcomes indicate that tasks requiring complex trajectory planning and reasoning over environments can be efficiently accomplished through the incorporation of human demonstrations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LRA.2024.3415931 },
  booktitle={ IEEE Robotics and Automation Letters },
  chapter={0}
}

@article{rayyan-352343959,
  title={ Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={Yang, Y. and Zhou, T. and Li, K. and Tao, D. and Li, L. and Shen, L. and He, X. and Jiang, J. and Shi, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10657391 },
  abstract={While large language models (LLMs) excel in a simulated world of texts, they struggle to interact with the more realistic world without perceptions of other modalities such as visual or audio signals. Although vision-language models (VLMs) integrate LLM modules (1) aligned with static image features, and (2) may possess prior knowledge of world dynamics (as demonstrated in the text world), they have not been trained in an embodied visual world and thus cannot align with its dynamics. On the other hand, training an embodied agent in a noisy visual world without expert guidance is often chal-lenging and inefficient. In this paper, we train a VLM agent living in a visual world using an LLM agent excelling in a parallel text world. Specifically, we distill LLM's reflection outcomes (improved actions by analyzing mistakes) in a text world's tasks to finetune the VLM on the same tasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA) quickly adapting to the visual world dy-namics. Such cross-modality imitation learning between the two parallel worlds is achieved by a novel DAgger-DPO algorithm, enabling EMMA to generalize to a broad scope of new tasks without any further guidance from the LLM expert. Extensive evaluations on the ALFWorld benchmark's diverse tasks highlight EMMA's superior performance to SOTA VLM-based agents, e.g., 20%-70% improvement in the success rate.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.02482 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343960,
  title={ HITS: High-coverage LLM-based Unit Test Generation via Method Slicing  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Wang, Z. and Liu, K. and Li, G. and Jin, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765010 },
  abstract={Large language models (LLMs) have behaved well in generating unit tests for Java projects. However, the performance for covering the complex focal methods within the projects is poor. Complex methods comprise many conditions and loops, requiring the test cases to be various enough to cover all lines and branches. However, existing test generation methods with LLMs provide the whole method-to-test to the LLM without assistance on input analysis. The LLM has difficulty inferring the test inputs to cover all conditions, resulting in missing lines and branches. To tackle the problem, we propose decomposing the focal methods into slices and asking the LLM to generate test cases slice by slice. Our method simplifies the analysis scope, making it easier for the LLM to cover more lines and branches in each slice. We build a dataset comprising complex focal methods collected from the projects used by existing state-of-the-art approaches. Our experiment results show that our method significantly outperforms current test case generation methods with LLMs and the typical SBST method Evosuite regarding both line and branch coverage scores.CCS CONCEPTS• Software and its engineering → Software testing and debugging; • Computing methodologies → Natural language processing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352343961,
  title={ LLM-Craft: Robotic Crafting of Elasto-Plastic Objects With Large Language Models  -  IEEE Robotics and Automation Letters },
  author={Bartsch, A. and Farimani, A. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11122568 },
  abstract={When humans create sculptures, we are able to reason about how geometrically we need to alter the clay state to reach our target goal. We are not computing point-wise similarity metrics, or reasoning about low-level positioning of our tools, but instead determining the higher-level changes that need to be made. In this work, we propose LLM-Craft, a novel pipeline that leverages large language models (LLMs) to iteratively reason about and generate deformation-based crafting action sequences. We simplify and couple the state and action representations to further encourage shape-based reasoning. To the best of our knowledge, LLM-Craft is the first system successfully leveraging LLMs for complex deformable object interactions. Through our experiments, we demonstrate that with the LLM-Craft framework, LLMs are able to successfully create a set of simple letter shapes. We explore a variety of reasoning strategies, and compare performances of LLM-Craft variants with and without an explicit goal shape images.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LRA.2025.3597835 },
  booktitle={ IEEE Robotics and Automation Letters },
  chapter={0}
}

@article{rayyan-352343962,
  title={ RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms  -  IEEE Open Journal of Vehicular Technology },
  author={Wang, Z. and Li, R. and Li, S. and Xiang, Y. and Wang, H. and Zhao, Z. and Zhang, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168174 },
  abstract={Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as a critical research focus, and it typically requires the swarm to navigate effectively while avoiding obstacles and achieving continuous coverage over multiple mission targets. Although traditional Multi-Agent Reinforcement Learning (MARL) approaches offer dynamic adaptability, they are hindered by the semantic gap in black-boxed communication and the rigidity of homogeneous role structures, resulting in poor generalization and limited task scalability. Recent advances in Large Language Model (LLM)-based control frameworks demonstrate strong semantic reasoning capabilities by leveraging extensive prior knowledge. However, due to the lack of online learning and over-reliance on static priors, these works often struggle with effective exploration, leading to reduced individual potential and overall system performance. To address these limitations, we propose a Role-Adaptive LLM-Driven Yoked navigation algorithm RALLY. Specifically, we first develop an LLM-driven semantic decision framework that uses structured natural language for efficient semantic communication and collaborative reasoning. Afterward, we introduce a dynamic role-heterogeneity mechanism for adaptive role switching and personalized decision-making. Furthermore, we propose a Role-value Mixing Network (RMIX)-based assignment strategy that integrates LLM offline priors with MARL online policies to enable offline training of role selection strategies. Experiments in the Multi-Agent Particle Environment (MPE) and a Software-In-The-Loop (SITL) platform demonstrate that RALLY outperforms conventional approaches in terms of task coverage, convergence speed, and generalization, highlighting its strong potential for collaborative navigation in agentic multi-UAV systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/OJVT.2025.3610852 },
  booktitle={ IEEE Open Journal of Vehicular Technology },
  chapter={0}
}

@article{rayyan-352343963,
  title={ MeanCache: User-Centric Semantic Caching for LLM Web Services  -  2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS) },
  year={2025},
  author={Gill, W. and Elidrisi, M. and Kalapatapu, P. and Ahmed, A. and Anwar, A. and Gulzar, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11078558 },
  abstract={Large Language Models (LLMs) like ChatGPT and Llama have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters, where inference demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries nor do they operate effectively on contextual queries, leading to unacceptable false hit-and-miss rates. This paper introduces MeanCache, a user-centric semantic cache for LLM-based services that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user's semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCache leverages Federated Learning (FL) to collaboratively train a query similarity model without violating user privacy. By placing a local cache in each user's device and using FL, MeanCache reduces the latency, costs, and enhances model performance, resulting in lower false-hit rates. MeanCache also encodes context chains for every cached query, offering a simple yet highly effective mechanism to discern contextual query responses from standalone queries. Our experiments benchmarked against the state-of-the-art caching method reveal that MeanCache attains an approximately 17 % higher F -score and a 20 % increase in precision during semantic cache hit-and-miss decisions while performing even better on contextual queries. It also reduces the storage requirement by 83 % and accelerates semantic cache hit-and-miss decisions by 11 %.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPDPS64566.2025.00117 },
  booktitle={ 2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS) },
  chapter={0}
}

@article{rayyan-352343964,
  title={ LLM-NPU: Towards Efficient Foundation Model Inference on Low-Power Neural Processing Units  -  2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS) },
  year={2025},
  author={Raha, A. and Kundu, S. and Sridhar, S. N. and Kundu, S. and Ghosh, S. K. and Palla, A. and Das, A. and Crews, D. and Mathaikutty, D. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11125797 },
  abstract={Neural processing units (NPUs) have become essential in modern client and edge platforms, offering unparalleled efficiency by delivering high throughput at low power. This is critical to improve the TOPS/W of the NPU, leading to longer battery life. While NPUs were initially designed to efficiently execute computer vision (CV) workloads such as CNNs, the rising demand to run transformer-based large language models (LLMs) locally now calls for significant architectural and software adaptation. This paper presents LLM-NPU, a comprehensive software-hardware co-optimization framework that enables scalable, power-efficient LLM deployment on NPUs under tight compute and memory budgets. We present software solutions such as vertical and horizontal operator fusion, quantization-aware weight compression, hybrid key-value (KV) quantization, eviction strategies, and static-shape inference that target memory bottlenecks and compute inefficiencies in LLM execution. On the hardware side, we explore domain-specialized NPU enhancements, including processing-in-memory architectures, extended input channel accumulation, structured sparsity acceleration, GEMM engine optimizations, mixed precision, microscaling format support, and fusion-aware execution pipelines. These co-designed innovations can collectively improve the energy, throughput, and latency of NPUs for LLM workloads.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COINS65080.2025.11125797 },
  booktitle={ 2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS) },
  chapter={0}
}

@article{rayyan-352343965,
  title={ Security, Privacy, and Ethical Challenges of Artificial Intelligence in Large Language Model Scope: A Comprehensive Survey  -  2024 1st International Conference On Cryptography And Information Security (VCRIS) },
  year={2024},
  author={Nguyen, T. T. and Vu, H. T. T. and Nguyen, H. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10813382 },
  abstract={Artificial intelligence (AI) models like ChatGPT and LLama have changed how we understand and create human-like language. They understand language well, can generate text like a person, know the context, and solve problems effectively. This makes them useful in many areas like search engines, customer service, and translation. Recently, these models have also caught the attention of the security field, uncovering weaknesses in security and proving useful for security tasks. This paper offers an extensive review of the security, privacy, and ethical issues associated with AI, focusing on LLMs and their impact on various domains. We explore the vulnerabilities of LLMs, propose poten-tial defense mechanisms, and highlight the broader implications of AI on human society. This survey intends to offer a clear perspective for researchers and practitioners, and policymakers on responsibly developing and deploying AI technologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VCRIS63677.2024.10813382 },
  booktitle={ 2024 1st International Conference On Cryptography And Information Security (VCRIS) },
  chapter={0}
}

@article{rayyan-352343966,
  title={ On Combining XAI and LLMs for Trustworthy Zero-Touch Network and Service Management in 6G  -  IEEE Communications Magazine },
  author={Mekrache, A. and Mekki, M. and Ksentini, A. and Brik, B. and Verikoukis, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10742571 },
  abstract={Zero-touch network and service management (ZSM) is a key pillar of 6G networks. It allows the 6G management and orchestration framework to operate the networks without external (e.g., human) intervention. To effectively achieve ZSM, advanced network management procedures are required to detect and resolve anomalies within the 6G network autonomously, which usually requires artificial intelligence (AI) and machine learning (ML) models. However, relying solely on AI can raise concerns about trust due to their lack of explainability. Indeed, as these models are not explainable, it is difficult to understand and trust their decisions. To overcome this limitation, this article introduces a novel pipeline for ensuring trustworthy ZSM in 6G networks by combining AI for detecting anomalies; eXplainable AI (XAI) to identify the root causes of anomalies using feature importance analysis; and large language models (LLMs) to generate user-friendly explanations and suggest/apply corrective actions to resolve anomalies. A use case is presented using XGBoost as AI, SHAP as XAI, and Llama2 as LLM to address service level agreement (SLA) latency violations within cloud-native 6G microservices. Evaluation results obtained through real experiments demonstrate the framework's efficiency in scaling cloud resources to prevent SLA violations while providing understandable explanations to users, thereby enhancing trust in the system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MCOM.002.2400276 },
  booktitle={ IEEE Communications Magazine },
  chapter={0}
}

@article{rayyan-352343967,
  title={ Privacy and Security Challenges in Large Language Models  -  2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  year={2025},
  author={Rathod, V. and Nabavirazavi, S. and Zad, S. and Iyengar, S. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903912 },
  abstract={Large Language Models (LLMs) are at the forefront of artificial intelligence advancements, demonstrating exceptional capabilities in natural language understanding and generation across diverse domains such as healthcare, finance, and customer service. However, their deployment introduces substantial secu-rity and privacy risks, including prompt injection, data leakage, and unauthorized data disclosures. These vulnerabilities highlight the need for robust frameworks to safeguard sensitive data and prevent misuse. This paper provides a comprehensive analysis of the security and privacy challenges in LLMs, examines existing mitigation strategies such as intelligent LLM firewalls, differen-tial privacy, and OW ASP-based security principles, and discusses future directions for ethical and secure LLM deployment. By addressing these challenges in detail, we identify gaps in current practices and propose a roadmap for the secure and responsible deployment of LLMs in high-stakes applications. Our findings underscore the importance of tailored security frameworks and privacy-preserving techniques to ensure the ethical and reliable use of LLMs in sensitive environments. Additionally, this pa-per emphasizes the significance of a human-in-the-loop (HITL) approach to ensure accountability and accuracy, particularly in critical domains. The discussion extends to emerging technologies such as retrieval-augmented generation (RAG) and adaptive threat detection systems, which hold promise for enhancing the security and ethical deployment of LLMs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCWC62904.2025.10903912 },
  booktitle={ 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC) },
  chapter={0}
}

@article{rayyan-352343968,
  title={ Generating Phishing Attacks and Novel Detection Algorithms in the Era of Large Language Models  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Fairbanks, J. and Serra, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825007 },
  abstract={Phishing is a significant cybersecurity threat, with the financial impact of email security breaches and lack of awareness estimated to be between $50-100 billion in 2022. The advent of Large Language Models (LLMs) has further automated and intensified phishing attacks, posing greater challenges for defenders, especially large organizations being targeted by Advanced Persistent Threats (APT) at scale, such as Department of Energy National Labs. This study presents the development of two innovative algorithms. The first algorithm improves the efficacy of phishing attacks, while the second algorithm counteracts and defends against phishing attacks that leverage LLMs. The attack method takes detectable malicious phishing emails and rewrites them using an innovative LLM-based automatic output optimization technique, which includes Reflection and Beam Search, while preserving the original semantic meaning and Indicators Of Compromise (IOC). This approach bypasses most-commonly used institutional security tools, NLP and other LLM phishing detection systems. The results indicate that this attack algorithm increases the success rate of phishing attacks by up to 98%. The defensive algorithm presented in this research is also employed for defensive measures. When the proposed defensive algorithm is applied, it identifies malicious emails with 97% greater accuracy. The research detailed in this paper demonstrates that these algorithm serve dual purposes: one is utilized as an attack mechanism by altering the output, and the other as a defensive measure against phishing attacks by modifying the defensive prompt. Taking these algorithms and implementing them in the Department of Energy Laboratory (DOE) has demonstrated the effectiveness of applying these approaches to real world applications, and has been implemented into large-scale production environments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10825007 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352343969,
  title={ Planning to Guide LLM for Code Coverage Prediction  -  2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym: },
  year={2024},
  author={Dhulipala, H. and Yadavally, A. and Nguyen, T. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599551 },
  abstract={Code coverage serves as a crucial metric to assess testing effectiveness, measuring the degree to which a test suite exercises different facets of the code, such as statements, branches, or paths. Despite its significance, coverage profilers necessitate access to the entire codebase, constraining their usefulness in situations where the code is incomplete or execution is not feasible, and even cost-prohibitive. In this paper, we present Codepilot, a plan-based prompting approach grounded in program semantics, which collaborates with a Large Language Model (LLM) to enhance code coverage prediction. To address the intricacies of predicting code coverage, Codepilot employs planning by discerning various types of statements in an execution flow. Planning empowers GPT to autonomously generate plans based on guided examples, and then Codepilot prompts the GPT model to predict code coverage (Action) based on the plan it generated (Reasoning). Our experiments evaluating Codepilot demonstrate high accuracy, achieving up to 55% in exact-match and 89% in statement-match. It performs relatively better than the base-lines, achieving up to 33% and 19% relatively higher in those metrics. We also showed that due to highly accurate plans (90%), GPT model predicts better code coverage. Moreover, we show Codepilot's utility in correctly predicting the least covered statements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3650105.3652292 },
  booktitle={ 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym: },
  chapter={0}
}

@article{rayyan-352343970,
  title={ Luna: A Benchmark Project in the Convergence of Artificial Intelligence and Internet of Things for Home Automation  -  2024 IEEE International Conference on Advanced Telecommunication and Networking Technologies (ATNT) },
  year={2024},
  author={Al-Shateri, A. A. H. and Rashid, R. A. and Aburaya, A. and Muhammad, N. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10719226 },
  abstract={The fast growth of technology has increased the popularity and existence of Internet of Things (IoT) devices in modern households. These devices include fans, lighting systems, door locks, and home appliances, all of which are intended to improve convenience, efficiency, and security. However, the sheer quantity of diverse devices and platforms introduces complexity, making it difficult for users to attain a genuinely integrated smart home experience. This paper investigates the integration of Artificial Intelligence (AI) and the Internet of Things (IoT) in the building of a home automation system. The proposed system runs on a Raspberry Pi 4 and uses a Node-RED server to manage multiple IoT devices and speech-to-text (STT) functionality. This results in a centralized and streamlined experience where the user does not have to deal with multiple individual systems but can instead relay the request to the AI assistant and have it interpret the correct response to that query. The system will be compared to a benchmarked system that uses a locally executed STT algorithm. The proposed system utilized the CPU 6.78 times more than the benchmark system and responded twice as fast for appliance control and 1.66 times faster for voice output making it both faster and more power efficient.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ATNT61688.2024.10719226 },
  booktitle={ 2024 IEEE International Conference on Advanced Telecommunication and Networking Technologies (ATNT) },
  chapter={0}
}

@article{rayyan-352343971,
  title={ Hallucination Mitigation in LLM-Based Video Captioning via Multi-Scale Feature Fusion  -  2024 5th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI) },
  year={2024},
  author={Zhou, J. and Wang, Y. and Liu, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10933619 },
  abstract={With the development of visual representation methods and pre-trained language models, video captioning technology has made significant progress. However, when describing objects and actions in videos, models are still prone to generating hallucinations, which introduce information that is irrelevant to the actual video content. These hallucinations greatly limit the practical applications of video captioning.A major issue is that the visual encoders widely adopted in vision-language models are derived from CLIP. Although CLIP has demonstrated outstanding performance in various visual understanding tasks, it still faces limitations in effectively capturing comprehensive visual information, such as fine-grained visual semantics. Additionally, given that CLIP is trained using pairs of images and text, directly using CLIP as a video encoding module can also lead to the model’s inability to effectively capture the spatial-temporal information of videos. To overcome these difficulties, we introduce a multi-scale feature modeling network that utilizes visual feature fusion for video captioning. First, we compensate for the lack of fine-grained visual semantics caused by relying solely on a single pre-trained model by incorporating additional salient region features. Next, we conduct both local and global spatialtemporal modeling across consecutive frames to capture global dependencies and local action information within the video. Finally, a multi-scale feature fusion approach is employed to achieve unified semantic modeling of the video, facilitating the sentence decoding process in LLM. We conducted both quantitative and qualitative evaluations of our approach, demonstrating the significant potential of this novel method. Compared with the baseline method, the text description we generates more effective at mitigating hallucinations related to objects and action descriptions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCBD-AI65562.2024.00067 },
  booktitle={ 2024 5th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI) },
  chapter={0}
}

@article{rayyan-352343972,
  title={ Testing Refactoring Engine via Historical Bug Report driven LLM  -  2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  year={2025},
  author={Wang, H. and Xu, Z. and Tan, S. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052804 },
  abstract={Refactoring is the process of restructuring existing code without changing its external behavior while improving its internal structure. Refactoring engines are integral components of modern Integrated Development Environments (IDEs) and can automate or semi-automate this process to enhance code readability, reduce complexity, and improve the maintainability of software products. Similar to traditional software systems such as compilers, refactoring engines may also contain bugs that can lead to unexpected behaviors. In this paper, we propose a novel approach called RETester, a LLM-based framework for automated refactoring engine testing. Specifically, by using input program structure templates extracted from historical bug reports and input program characteristics that are error-prone, we design chain-of-thought (CoT) prompts to perform refactoring-preserving transformations. The generated variants are then tested on the latest version of refactoring engines using differential testing. We evaluate RETester on two most popular modern refactoring engines (i.e., Eclipse, and IntelliJ IDEA). It successfully revealed 18 previously unknown bugs in the latest version of those refactoring engines, seven of them have been confirmed by their developers, and three have been fixed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Forge66646.2025.00020 },
  booktitle={ 2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge) },
  chapter={0}
}

@article{rayyan-352343973,
  title={ GPT Based Malware: Unveiling Vulnerabilities and Creating a Way Forward in Digital Space  -  2023 International Conference on Data Security and Privacy Protection (DSPP) },
  year={2023},
  author={Shandilya, S. K. and Prharsha, G. and Datta, A. and Choudhary, G. and Park, H. and You, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404552 },
  abstract={The rise and development of AI-based solutions like ChatGPT have significantly changed the functioning of many enterprises, organizations, and domains including cybersecurity. The public’s open access to ChatGPT and its resources does, however, present significant security challenges. This review study aims to shed light on the emergence of GPT-based malware. As traditional malware detection systems, have advanced to mitigate many sophisticated malware attacks, threat actors are now aiming to utilize GPT and other Large Language Models (LLMs) to create sophisticated tactics to infect systems with new malware. Furthermore, this study seeks to present a select number of methods that may be utilized to reduce the hazards posed by malware developed with ChatGPT and other LLM-based tools.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSPP58763.2023.10404552 },
  booktitle={ 2023 International Conference on Data Security and Privacy Protection (DSPP) },
  chapter={0}
}

@article{rayyan-352343974,
  title={ On the Difficulties of Conducting and Replicating Systematic Literature Reviews Studies Using LLMs in Software Engineering  -  2025 IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE) },
  year={2025},
  author={Felizardo, K. R. and Deizepe, A. and Coutinho, D. and Gomes, G. and Meireles, M. and Gerosa, M. and Steinmacher, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071430 },
  abstract={The Software Engineering (SE) community has adopted Systematic Literature Reviews (SLRs) to summarize the state-of-the-art in specific research topics. SLRs offer benefits such as synthesizing evidence from diverse studies to generate auditable results following a reproducible approach, and identifying research gaps for future exploration. However, the process is effort-intensive, prone to errors, and lays various challenges during their conduction. To overcome some of these issues, there is a growing belief that Large Language Models (LLMs) can support systematic literature reviews. While the literature has shown promising results in social sciences, more evidence of its accuracy is needed in technical fields like SE. In this context, studies and replications are essential in verifying the benefits and drawbacks of applying LLMs in systematic literature reviews. This paper discusses the difficulties in conducting and replicating studies that adopt LLMs to support systematic literature in SE. As an implication, we identified the challenges of adopting LLM in SLRs and offered a list of open issues for future research.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WSESE66602.2025.00010 },
  booktitle={ 2025 IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE) },
  chapter={0}
}

@article{rayyan-352343975,
  title={ Benchmarking Large Language Models for Ethereum Smart Contract Development  -  2024 6th Conference on Blockchain Research & Applications for Innovative Networks and Services (BRAINS) },
  year={2024},
  author={Daspe, E. and Durand, M. and Hatin, J. and Bradai, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10732686 },
  abstract={The integration of blockchain technology, particularly Ethereum and its smart contract, has revolutionized software programming. Solidity, Ethereum’s main language, is crucial due to its features for blockchain applications. However, the immutable nature of Smart Contract (SC) presents significant security issues, with vulnerabilities leading to financial risks. Meanwhile, Large language models (LLMS ) have transformed software development by enhancing coding efficiency and error detection. Despite their potential, current benchmarks often overlook niche languages like Solidity. This paper introduces the first benchmark to evaluate LLMs in Solidity smart contract generation, aiming to improve automated SC development and blockchain deployment reliability using a Test-Driven Development inspired methodology and pass@k metric. This work not only addresses a significant gap in LLM evaluation for blockchain applications but also extends the capabilities of LLMs in this specialized and critical area of software development.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BRAINS63024.2024.10732686 },
  booktitle={ 2024 6th Conference on Blockchain Research & Applications for Innovative Networks and Services (BRAINS) },
  chapter={0}
}

@article{rayyan-352343976,
  title={ Comparative Analysis of Mobile-Friendly Large Language Models: Performance, Efficiency, and Accuracy  -  2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T) },
  year={2025},
  author={Joshi, R. and Selvakumar, S. and Pillai, V. and Bambras, V. and Boyanapalli, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132208 },
  abstract={This research presents a comparative analysis of various mobile-friendly LLMs, evaluating their performance in terms of inference speed (tokens per second) and response accuracy. The study benchmarks models such as Llama 3:2.1B, Gemma 2:2B, Deepseek R1:1.5B , and Qwen 2.5, testing them in an offline environment to determine their suitability for mobile deployment. The results highlight the trade-offs between model size, inference speed, accuracy, BERTScore, BLEU, and ROUGE-L, showing that smaller models achieve higher throughput but often compromise response quality. The findings provide valuable guidance for developers and enterprises seeking to implement LLM-based solutions on mobile devices while balancing computational efficiency and accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICETI4T63625.2025.11132208 },
  booktitle={ 2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T) },
  chapter={0}
}

@article{rayyan-352343977,
  title={ Approach to Evaluating AI-Generated Educational Content: A Case Study on AI-Generated Tests  -  2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT) },
  year={2025},
  author={Maiatskaia, E. and Zabokritskaya, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11054236 },
  abstract={Evaluating texts generated by large language models (LLMs) remains a critical challenge due to their high linguistic quality, susceptibility to hallucinations, and potential lack of depth. Existing evaluation methods, including lexical analysis, hallucination detection, and LLM-based assessments, often fail to comprehensively assess the substantive meaning of texts in educational contexts. This study focuses on the evaluation of LLM-generated educational materials, particularly test questions, identifying key limitations in conventional assessment approaches. To address these challenges, we propose a novel evaluation framework based on knowledge graphs automatically constructed by LLMs using contextual information from lecture materials and course syllabi. This graph-based approach, aligned with Bloom’s taxonomy, enables a structured and automated assessment of AI-generated educational content, improving its reliability and pedagogical validity. While the primary goal of this method is to evaluate the quality of educational materials, it also has the potential to be applied in the future for their refinement and improvement, ensuring better alignment with learning objectives.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/USBEREIT65494.2025.11054236 },
  booktitle={ 2025 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT) },
  chapter={0}
}

@article{rayyan-352343978,
  title={ Explaining Transformer-based Code Models: What Do They Learn? When They Do Not Work?  -  2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation (SCAM) },
  year={2023},
  author={Mohammadkhani, A. H. and Tantithamthavorn, C. and Hemmatif, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356671 },
  abstract={In recent years, there has been a wide interest in designing deep neural network-based models that automate downstream software engineering tasks on source code, such as code document generation, code search, and program repair. Although the main objective of these studies is to improve the effectiveness of the downstream task, many studies only attempt to employ the next best neural network model, without a proper in-depth analysis of why a particular solution works or does not, on particular tasks or scenarios. In this paper, using an example eXplainable AI (XAI) method (attention mechanism), we study two recent large language models (LLMs) for code (CodeBERT and GraphCodeBERT) on a set of software engineering downstream tasks: code document generation (CDG), code refinement (CR), and code translation (CT). Through quantitative and qualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the highest attention on, in terms of source code token types), on these tasks. We also show some of the common patterns when the model does not work as expected (performs poorly even on easy problems) and suggest recommendations that may alleviate the observed challenges.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCAM59687.2023.00020 },
  booktitle={ 2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation (SCAM) },
  chapter={0}
}

@article{rayyan-352343979,
  title={ Technical Debt Prediction  -  2024 26th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC) },
  year={2024},
  author={Patcas, R. -D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10896415 },
  abstract={Technical debt prediction involves anticipating prob-lems and challenges in software projects. Because of lousy coding choices, these projects are often far from the optimal design. These issues can accumulate over time and affect long-term maintainability and stability. Numerous studies are available for predicting technical debt. For instance, some studies utilize static analysis tools like Pylint11https://pypi.org/project/pylint/, and others use dynamic code analysis tools like SZZ [1]. This study addresses AI predictions using data obtained from static analysis tools. This paper presents technical debt prediction using static code analysis data generated with SonarQube22https://docs.sonarsource.com!sonarqube/latest/ and Radon33https://pypi.org/project/radon/. It covers both short-term and long-term predictions by analyzing code quality metrics such as complexity, duplication, and adherence to standards. The study also integrates git commit classification to analyze commit history, providing valuable insights into the evolution and management of technical debt within the project.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SYNASC65383.2024.00028 },
  booktitle={ 2024 26th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC) },
  chapter={0}
}

@article{rayyan-352343980,
  title={ Design of an Autonomous Cyber Defence Agent using Hybrid AI models  -  2024 International Conference on Military Communication and Information Systems (ICMCIS) },
  year={2024},
  author={Loevenich, J. F. and Adler, E. and Mercier, R. and Velazquez, A. and Lopes, R. R. F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10540988 },
  abstract={This paper extends the design of an autonomous cyber defence (ACD) agent to monitor and actuate within a protected core network segment. The goal is to take advantage of recent developments in AI models to define a hybrid architecture that combines deep reinforcement learning (DRL), large language models (LLMs), and rule-based models. The motivation comes from the fact that modern network segments within colored clouds are using software-defined controllers with the means to host ACD agents and other cybersecurity tools implementing hybrid AI models. For example, our ACD agent uses a DRL model and the chatbot uses an LLM to create an interface with human cybersecurity experts. The ACD agent was evaluated against two red agent strategies in a gym environment using a set of actions to defend services in the network (monitor, analyse, decoy, remove, and restore). Our chatbot was developed using retrieval augmented generation and a prompting agent to augment a pre-trained LLM with data from cybersecurity knowledge graphs. We performed a comparative analysis between a baseline implementation and our chatbot using generation/retrieval metrics. The results suggest that both ACD agent and chatbot can potentially enhance the defence of critical networks connected to untrusted infrastructure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMCIS61231.2024.10540988 },
  booktitle={ 2024 International Conference on Military Communication and Information Systems (ICMCIS) },
  chapter={0}
}

@article{rayyan-352343981,
  title={ A Framework for LLM-Assisted Smart Policing System  -  IEEE Access },
  author={Sarzaeim, P. and Mahmoud, Q. H. and Azim, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538107 },
  abstract={In the face of rapidly increasing crime rates, the evolving complexity of crime data processing, and public safety challenges, the need for more advanced policing solutions has increased leading to the emergence of smart policing systems and predictive policing techniques. This urgency and shift toward smart policing incorporates artificial intelligence (AI), with a specific focus on machine learning (ML) as an essential tool for data analysis, pattern recognition, and proactive crime forecasting. Among these, the flexibility and power of AI techniques including large language models (LLMs), as a subset of generative AI, have increased the interest in applying them in real-world applications, such as financial, medical, legal, and agricultural applications. However, the abilities and possibilities of adopting LLMs in applications including crime prediction remain unexplored. This paper focuses on bridging this gap by developing a framework based on the transformative potential of BART, GPT-3, and GPT-4, three state-of-the-art LLMs, in the domain of smart policing, specifically, crime prediction. As a prototype, diverse methods such as zero-shot prompting, few-shot prompting, and fine-tuning are used to comprehensively assess the performance of these models in crime prediction based on state-of-the-art datasets from two major cities: San Francisco and Los Angeles. The main objective is to illuminate the adaptability of LLMs and their capacity to revolutionize crime analysis practices. Additionally, a comparative analysis of the aforementioned methods on the GPT series model and BART with ML techniques is provided which shows that the GPT models are more suitable than the traditional ML models for crime classification in most experimental scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3404862 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352343982,
  title={ Zero Trust Architectures Empowered by AI: A Paradigm Shift in Cloud and Edge Cybersecurity  -  2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS) },
  year={2025},
  author={N, P. S and Pimpalkar, A. and Shelke, N. and Saini, D. K. J. Bahadur},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166875 },
  abstract={The cloud-edge computing phenomenon and distributed digital infrastructure have exposed inherent limitations within perimeter-based security paradigms. Zero Trust Architecture (ZTA) on the "never trust, always verify" tenet has emerged as the underlying paradigm to combat advanced cyber threats. In this paper, we propose a new AI-based Zero Trust framework (AI-ZTA) that combines Transformer-based deep anomaly detection, Graph Neural Network (GNN)-based trust propagation, and Large Language Model (LLM)-assisted policy adaptation to deliver continuous, contextual, and intelligent access control in dynamic cloud-edge environments. We also incorporate Federated Learning (FL) for facilitating collaborative and privacy-preserving model training across heterogeneous edge nodes. Experimental performance on three benchmarking datasets—CICIDS2017, NSL-KDD, and an industrial cloud-edge log dataset—demonstrates that AI-ZTA identifies threats with 98.7% accuracy, a false positive rate (FPR) of merely 1.2%, and a 42% reduction in access policy violation events in comparison to traditional ZTA models. The Transformer-based behavioral engine outperforms LSTM and CNN baselines by +6.4% in precision and +8.1% in recall, and GNN-based trust modeling enhances threat context explainability by 35%. Our incorporation of LLM also enables 90% accurate auto-generation of fine-grained access policies, reducing administrative overhead by 60%. These results make AI-ZTA a scalable, resilient, and intelligent security model superior to comparable architectures and a new benchmark of Zero Trust deployment in cloud and edge computing. The proposed framework is a paradigm shift towards AI-native Industry 4.0, next-generation digital services, and critical infrastructure cybersecurity.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSCDS65426.2025.11166875 },
  booktitle={ 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS) },
  chapter={0}
}

@article{rayyan-352343983,
  title={ Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled Architectures  -  2025 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) },
  year={2025},
  author={Vellaisamy, P. and Labonte, T. and Chakraborty, S. and Turner, M. and Sury, S. and Shen, J. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11096369 },
  abstract={Large language model (LLM)-based inference workloads increasingly dominate data center costs and resource utilization. Therefore, understanding the inference workload characteristics on evolving CPU-GPU coupled architectures is crucial for optimization. This paper presents an in-depth analysis of LLM inference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled (GH200) systems. We analyze performance dynamics using fine-grained operator-to-kernel trace analysis, facilitated by our novel profiler SKIP and metrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that closely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC) systems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for Llama-3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound up to 4x larger batch sizes than LC systems. In this extended CPU-bound region, we identify the performance characteristics of the Grace CPU as a key factor contributing to higher inference latency at low batch sizes on GH200. We demonstrate that TKLQT accurately identifies this CPU/GPU-bound transition point. Based on this analysis, we further show that kernel fusion offers significant potential to mitigate GH200's low-batch latency bottleneck by reducing kernel launch overhead. This detailed kernel-level characterization provides critical insights for optimizing diverse CPU-GPU coupling strategies. This work is an initial effort, and we plan to explore other major AI/DL workloads that demand different degrees of CPU-GPU heterogeneous architectures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISPASS64960.2025.00015 },
  booktitle={ 2025 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) },
  chapter={0}
}

@article{rayyan-352343984,
  title={ Insights and Current Gaps in Open-Source LLM Vulnerability Scanners: A Comparative Analysis  -  2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE) },
  year={2025},
  author={Brokman, J. and Hofman, O. and Rachmil, O. and Singh, I. and Pahuja, V. and Sabapathy, R. and Priya, A. and Giloni, A. and Vainshtein, R. and Kojima, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029414 },
  abstract={We present a comparative analysis of open-source tools that scan conversational large language models (LLMs) for vulnerabilities, in short - scanners. As LLMs become integral to various applications, they also present potential attack surfaces, exposed to security risks such as information leakage and jail-break attacks. AI red-teaming, adapted from traditional cyberse-curity, is recognized by governments and companies as essential - often emphasizing the challenge of continuously evolving threats. Our study evaluates prominent, cutting-edge scanners - Garak, Giskard, PyRIT, and CyberSecEval - that address this challenge by automating red-teaming processes. We detail the distinctive features and practical use of these scanners, outline unifying principles of their design and perform quantitative evaluations to compare them. These evaluations uncover significant reliability issues in detecting successful attacks, highlighting a fundamental gap for future development. Additionally, we contribute a foundational labeled dataset, which serves as an initial step to bridge this gap. Based on the above, we provide suggestions for future regulations and standardization, as well as strategic recommendations to assist organizations in scanner selection, considering customizability, test-suite comprehensiveness and industry-specific use cases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAIE66699.2025.00005 },
  booktitle={ 2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE) },
  chapter={0}
}

@article{rayyan-352343985,
  title={ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification  -  2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI) },
  year={2024},
  author={Akyash, M. and Kamali, H. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10682659 },
  abstract={The rise of instruction-tuned Large Language Models (LLMs) marks a significant advancement in artificial intelligence (AI) (tailored to respond to specific prompts). Despite their popularity, applying such models to debug security vulnerabilities in hardware designs, i.e., register transfer language (RTL) modules, particularly at system-on-chip (SoC) level, presents considerable challenges. One of the main issues lies in the need for precisely designed instructions for pinpointing and mitigating the vulnerabilities, which requires substantial time and expertise from human experts. In response to this challenge, this paper proposes Self-HWDebug, an innovative framework that leverages LLMs to automatically create required debugging instructions. In Self-HWDebug, a set of already identified bugs from the most critical hardware common weakness enumeration (CWE) listings, along with mitigation resolutions, is provided to the framework, followed by prompting the LLMs to generate targeted instructions for such mitigation. The LLM-generated instructions are subsequently used as references to address vulnerabilities within the same CWE category but in totally different designs, effectively demonstrating the framework's ability to extend solutions across related security issues. Self-HWDebug significantly reduces human intervention by using the model's own output to guide debugging. Through comprehensive testing, Self-HWDebug proves not only to reduce experts' effort/time but also to even improve the Quality of the debugging process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISVLSI61997.2024.00077 },
  booktitle={ 2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI) },
  chapter={0}
}

@article{rayyan-352343986,
  title={ Test-Driven Development and LLM-based Code Generation  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Mathews, N. S. and Nagappan, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764936 },
  abstract={Recent Large Language Models (LLMs) have demonstrated significant capabilities in generating code snippets directly from problem statements. This increasingly automated process mirrors traditional human-led software development, where code is often written in response to a requirement. Historically, Test-Driven Development (TDD) has proven its merit, requiring developers to write tests before the functional code, ensuring alignment with the initial problem statements. Applying TDD principles to LLM-based code generation offers one distinct benefit: it enables developers to verify the correctness of generated code against predefined tests. This paper investigates if and how TDD can be incorporated into AI-assisted code-generation processes. We experimentally evaluate our hypothesis that providing LLMs like GPT-4 and Llama 3 with tests in addition to the problem statements enhances code generation outcomes. We experimented with established function-level code generation benchmarks such as MBPP and HumanEval. Our results consistently demonstrate that including test cases leads to higher success in solving programming challenges. We assert that TDD is a promising paradigm for helping ensure that the code generated by LLMs effectively captures the requirements.CCS CONCEPTS• Software and its engineering → Software development techniques; • Computing methodologies → Artificial intelligence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352343987,
  title={ LLM-Powered Multi-Actor System for Intelligent Analysis and Visualization of IEC 61499 Control Systems  -  IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society },
  year={2024},
  author={Xavier, M. and Laikh, T. and Patil, S. and Vyatkin, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10905502 },
  abstract={This paper introduces an innovative multiactor framework that harnesses the potential of LLMs to augment the functionalities of ICS. By integrating conversational AI technologies, this framework significantly improves human-machine interactions, enabling sophisticated analysis and visualization of intricate data sets. The core of the system comprises specialized LLM actors that interact through a LangGraph-based multiactor framework, addressing various aspects of IEC 61499 control systems including PLC code analysis, SQL query execution, and data visualization. This integration enables operators to interact with the control system using natural language, significantly reducing technical barriers and enhancing the accessibility and usability of complex industrial systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IECON55916.2024.10905502 },
  booktitle={ IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society },
  chapter={0}
}

@article{rayyan-352343988,
  title={ slAIces: an LLM Chatbot for Simplifying Experiments with the SLICES-RI  -  2024 IFIP Networking Conference (IFIP Networking) },
  year={2024},
  author={Kefalas, D. and Christakis, S. and Fdida, S. and Makris, N. and Syrigos, I. and Passas, V. and Korakis, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10619821 },
  abstract={SLICES-RI is the outcome of several years of evolution of the concept of a networking test platform, that has recently transformed into a scientific instrument for the assessment of new research challenges in the Digital Infrastructures domain. Making large-scale scientific instruments easily accessible has always been challenging, often hindered by the complexity of the underlying platforms, the size and diversity of resources and the low-level settings that experimenters need to configure. Emerging technologies such as artificial intelligence(AI) have ignited a wave of innovation, inspiring companies, professionals, and researchers to incorporate chatbot assistants into their projects. These assistants revolutionize user experience by simplifying access to information and resources, significantly increasing productivity and presenting a familiar interface. In this work, we introduce slAIces, an LLM-based chatbot specifically designed to ease access to the SLICES-RI. slAIces utilizes the Generative Pre-trained Transformer(GPT) GPT-4 model to create a sophisticated Retrieval Augmented Generation(RAG) system. This system provides external knowledge by leveraging a properly preprocessed dataset, which includes documentation from SLICES-RI and all integrated testbeds. The contribution of this study lies in its methodology and recommendations for enriching the information on the test platform to enhance the quality of the service provided. We demonstrate that this chatbot significantly reduces the learning curve for new experimenters to become acquainted with the infrastructure. It exposes the appropriate level of abstraction, enabling experimenters to conduct complex experiments mobilizing the extensive and diverse resources available within a large-scale infrastructure like SLICES-RI.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/IFIPNetworking62109.2024.10619821 },
  booktitle={ 2024 IFIP Networking Conference (IFIP Networking) },
  chapter={0}
}

@article{rayyan-352343989,
  title={ Integrating Blockchain with LLM for Real-Time Insight into Transactions in an E-Auction System  -  2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA) },
  year={2025},
  author={Sharma, S. and Koirala, R. and Matalonga, S. and Dahal, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11155428 },
  abstract={Real-time data retrieval and analytics play a crucial role in digital systems, requiring efficient, secure, and automated mechanisms for extracting insights from structured and unstructured data. Traditional methods rely on centralized databases and SQL (Structure Query Language) queries, which may lack security, transparency, adaptability and automation. Blockchain (BC) technology introduces a decentralized and tamper-proof ledger that enhances data integrity, while large language models (LLMs) leverage natural language processing (NLP) and excel in contextual understanding to facilitate more intuitive and flexible querying mechanisms. Implementing these technologies brings promising solutions, but some challenges remain, particularly in retrieving contextual information and data analysis. Hence, this research paper explores the integration of BC with LLM in an e-auction system using three different integration alternatives: the Pandas Query Engine (PQE), Retrieval-Augmented Generation (RAG) and Custom Query Pipeline (CQP). We compare the accuracy, and the time elapsed on querying of these methods in extracting relevant information from online auction event logs. Among three integration alternatives, RAG provides better result in terms of accuracy and PQE provides quicker result in terms of response time. Our results provide guidance on selecting retrieval strategies for AI-driven blockchain analytics, with implications for bid monitoring, regulatory compliance, fraud detection and recommendations to users of e-auction systems about efficient bidding. Further, we have discussed about cost of using these techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SKIMA66621.2025.11155428 },
  booktitle={ 2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA) },
  chapter={0}
}

@article{rayyan-352343990,
  title={ Application Scenario Analysis of Large Language Models Education Based on Activity Theory  -  2024 IEEE/ACIS 24th International Conference on Computer and Information Science (ICIS) },
  year={2024},
  author={Zhang, Z. and Hu, M. and Zhang, B. and Jin, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778383 },
  abstract={With the continuous development of large languaege models (LLM), LLM technology is having a profound impact on the field of education. This paper takes activity theory as the methodological tool, and aims to explore the internal relationship between LLM and educational activities through scene analysis. Firstly, this paper reviewed the development process of LLM and the related concept connotation of activity theory. Then, a conceptual model of LLM in education application based on activity theory was established. In this model, the application scenarios were analyzed from the aspects of teaching, learning, evaluation and research, and the application characteristics were analyzed by examining the elements of subject, community and object. From the perspective of four subsystems of teaching, learning, evaluation and research, this paper analyzes the impact of the application of LLM on educational activities in detail. This paper provided theoretical support and empirical analysis for the application of LLM in the field of education, further deepened the understanding of the relationship between technology and education, and provided useful reference and guidance for the development of education in the future.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIS61260.2024.10778383 },
  booktitle={ 2024 IEEE/ACIS 24th International Conference on Computer and Information Science (ICIS) },
  chapter={0}
}

@article{rayyan-352343991,
  title={ The Breakthrough Memory Solutions for Improved Performance on LLM Inference  -  IEEE Micro },
  author={Kim, B. and Cha, S. and Park, S. and Lee, J. and Lee, S. and -h. Kang, S. and So, J. and Kim, K. and Jung, J. and Lee, J. -G. and Lee, S. and Paik, Y. and Kim, H. and Kim, J. -S. and Lee, W. -J. and Ro, Y. and Cho, Y. and Kim, J. H. and Song, J. and Yu, J. and Lee, S. and Cho, J. and Sohn, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10477465 },
  abstract={Large language models (LLMs) have changed our lives, but they require unprecedented computing resources—especially large memory capacity and high bandwidth to process weights. However, while the logic process was developing, the speed of development of the memory process could not keep up, causing problems that resulted in the performance of LLMs being hindered by memory. Samsung has introduced breakthrough processing-in-memory/processing-near-memory (PIM/PNM) solutions that enhance the main memory bandwidth. With the high bandwidth memory PIM-based GPU-cluster system and LPDDR5-PIM-based system, the performance of transformer-based LLMs improved by up to 1.9$ \times $× and 2.7$ \times $×, respectively. The Compute eXpress Link (CXL)-based PNM solution serves memory-centric computing systems by implementing logic inside the CXL memory controller. This results in a performance gain of more than 4.4$ \times $× with an energy reduction of about 53% with PNM. Furthermore, we provide PIM/PNM software stacks, including an AI compiler targeting the acceleration of AI models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MM.2024.3375352 },
  booktitle={ IEEE Micro },
  chapter={0}
}

@article{rayyan-352343992,
  title={ MimicAI: An LLM based system that mimics and explains  -  2024 IEEE 6th International Conference on Cognitive Machine Intelligence (CogMI) },
  year={2024},
  author={Sharma, U. and Ayachitula, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10835506 },
  abstract={Large Language Models (LLMs) have demonstrated significant proficiency across various tasks, showcasing emergent abilities in in-context learning, instruction following, and multi-step reasoning. However, their operation as “black boxes” poses a challenge regarding explainability, affecting stakeholders’ trust in these models. In contrast, simpler AI models such as linear classifiers, decision trees, and random forests offer greater explainability. They are easier to train but typically require intricate tuning and do not generalize well across different objectives. These simpler models also demand extensive data engineering and machine learning expertise to optimize performance. To address these limitations, we introduce MimicAI, a novel system designed to replicate the functionality of simpler AI models while enhancing their interpretability and ease of use. MimicAI generates outputs that are easily understandable regarding input contributions and simplifies the model extension process for domain experts without the need for deep machine learning knowledge. By integrating the principles of in-context learning (ICL), MimicAI achieves superior generalizability without requiring extensive fine-tuning, making it a robust tool for applications seeking the dual benefits of simplicity and deep learning prowess.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CogMI62246.2024.00022 },
  booktitle={ 2024 IEEE 6th International Conference on Cognitive Machine Intelligence (CogMI) },
  chapter={0}
}

@article{rayyan-352343993,
  title={ LLM-based Cyber Security Testing for Consumer Internet of Things  -  2025 27th International Conference on Advanced Communications Technology (ICACT) },
  year={2025},
  author={Wang, Y. -C. and Hsu, C. -F. and Shen, Y. -P. and Lu, Y. -T. and Chen, J. -L. and Hsu, H. -H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936653 },
  abstract={With the increasing prevalence of handheld devices in daily life, routers have become essential for connecting devices to the Internet while also becoming prime targets for hacker attacks. Currently, the cybersecurity testing of these devices primarily relies on manual processes. Testing engineers are required to thoroughly understand various regulations, such as EN 303 645 and TS 103 701, and to develop specific testing procedures for different devices. This paper proposes a semi-automated AI system for testing Internet of Things (IoT) devices. The system uses standardized procedures and AI-driven regulatory interpretation to rapidly generate test reports, significantly reducing engineers' time searching for relevant regulations and improving testing efficiency and accuracy. This study evaluates multiple open-source embedding models and the Llama 3.1 70B large language model to develop an Advanced Retrieval-Augmented Generation (Advance-RAG) framework. This framework automatically retrieves test items from cybersecurity regulations and generates preliminary assessments based on self-declarations provided by device manufacturers. It quickly determines whether a device's functionalities comply with specified testing standards. Testing engineers can then upload supporting evidence through the report generation system, providing a comprehensive test report.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/ICACT63878.2025.10936653 },
  booktitle={ 2025 27th International Conference on Advanced Communications Technology (ICACT) },
  chapter={0}
}

@article{rayyan-352343994,
  title={ OpenBias: Open-Set Bias Detection in Text-to-Image Generative Models  -  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2024},
  author={D'Incà, M. and Peruzzo, E. and Mancini, M. and Xu, D. and Goe, V. and Xu, X. and Wang, Z. and Shi, H. and Sebe, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10655395 },
  abstract={Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previously proposed biases. We study the behavior of Stable Diffusion 1.5, 2, and XL emphasizing new biases, never investigated before. Via quantitative experiments, we demonstrate that OpenBias agrees with current closed-set bias detection methods and human judgement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52733.2024.01162 },
  booktitle={ 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352343995,
  title={ BPE: Exploring the Prompt Framework of Physics Exercises Generated from Bloom's Taxonomy in LLM  -  2024 5th International Conference on Machine Learning and Computer Application (ICMLCA) },
  year={2024},
  author={Luo, H. and Weng, J. and Lu, X. and Yu, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754020 },
  abstract={This study explores the application of large language models (LLMs) in automating the generation of physics exercises. By integrating principles from Bloom's Taxonomy, the research develops a prompt framework named BPE (Bloom's Physics Exercises) to enhance the quality and relevance of automatically generated questions. The BPE framework addresses challenges such as controlling question difficulty, assessing cognitive depth, and managing computational aspects. Key components of the framework include ‘Action’, ‘Purpose’, ‘Example’, ‘Role’, and ‘Excluded Content’, which together guide the LLM to produce exercises that are pedagogically sound and tailored to educational needs. This approach aims to reduce teacher workload, diversify student learning experiences, and improve the overall educational efficacy of AI-assisted learning environments. Our contributions are available at https://github.com/yuzengyi/BPE.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLCA63499.2024.10754020 },
  booktitle={ 2024 5th International Conference on Machine Learning and Computer Application (ICMLCA) },
  chapter={0}
}

@article{rayyan-352343996,
  title={ OPS: Outlier-Aware Precision-Slice Framework for LLM Acceleration  -  2025 Design, Automation & Test in Europe Conference (DATE) },
  year={2025},
  author={Liu, F. and Yang, N. and Wang, Z. and Zhu, X. and Yao, H. and Xiong, X. and Sun, Q. and Jiang, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993106 },
  abstract={Large language models (LLMs) have transformed numerous AI applications, with on-device deployment becoming increasingly important for reducing cloud computing costs and protecting user privacy. However, the astronomical model size and limited hardware resources pose significant deployment challenges. Model quantization is a promising approach to mitigate this gap, but the presence of outliers in LLMs reduces its effectiveness. Previous efforts addressed this issue by employing compression-based encoding for mixed-precision quantization. These approaches struggle to balance model accuracy with hard-ware efficiency due to their value-wise outlier granularity and complex encoding/decoding hardware logic. To address this, we propose OPS (Outlier-aware Precision-Slicing), an acceleration framework that exploits massive sparsity in the higher-order part of LLMs by splitting 16-bit values into a 4-bit/12-bit format. Crucially, OPS introduces an early bird mechanism that leverages the high-order 4-bit computation to predict the importance of the full calculation result. This mechanism enables efficient computational skips by continuing execution only for important computations and using preset values for less significant ones. This scheme can be efficiently integrated with existing hardware accelerators like systolic arrays without complex encoding/decoding. As a result, OPS outperforms state-of-the-art outlier-aware accelerators, achieving a 1.3 − 4.3× performance boost with minimal model accuracy loss. This approach enables more efficient on-device LLM deployment, effectively balancing computational efficiency and model accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/DATE64628.2025.10993106 },
  booktitle={ 2025 Design, Automation & Test in Europe Conference (DATE) },
  chapter={0}
}

@article{rayyan-352343997,
  title={ Quality Assurance for LLM-Generated Test Cases: A Systematic Literature Review  -  2024 8th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI) },
  year={2024},
  author={Edirisinghe, H. and Wickramaarachchi, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10844968 },
  abstract={The rapid advancements in artificial intelligence have transformed software testing, with Large Language Models (LLMs) emerging as powerful tools for automating test case generation. This paper explores Quality Assurance (QA) for LLM-generated test cases in black-box testing through a systematic literature review. Though LLMs are increasingly used for test case generation, challenges in ensuring their quality remain. Following PRISMA guidelines, relevant studies were selected from databases focusing on critical quality attributes, QA frameworks, metrics, and challenges. LLMs demonstrate high efficiency but face numerous issues. A recommendation for future research is given on addressing standardized metrics and improving human-AI collaboration for enhanced testing outcomes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SLAAI-ICAI63667.2024.10844968 },
  booktitle={ 2024 8th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI) },
  chapter={0}
}

@article{rayyan-352343998,
  title={ KARLM: Enhancing LLM-based Recommendation Systems with Knowledge Bases  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Song, Z. and Chen, D. and Shen, X. and Zhou, X. and Qi, J. and Zhou, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888867 },
  abstract={Large language models signify a pivotal advancement in general artificial intelligence, exhibiting capabilities that exceed human performance in diverse tasks. Nevertheless, these models often lack expertise in specialized knowledge areas. To augment the performance of LLMs in downstream applications, enhancing their knowledge acquisition and comprehension is imperative. In this paper, we introduce a knowledge-enhanced large language model, named "KARLM", which integrates symbolic AI into the training of LLM through a knowledge base derived from logic extracted from datasets and external resources. By incorporating this KB in conjunction with training corpora, "KARLM" is adeptly enabled to acquire and understand domain-specific knowledge. We validated the effectiveness of this method on recommendation tasks. Extensive experiments on multiple datasets indicate that "KARLM" successfully learns item knowledge and outperforms state-of-the-art baselines.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888867 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352343999,
  title={ LLM-based Automated Facilitator for Building Effective Consensus on Mission and Vision Definition  -  2024 IEEE International Conference on Agents (ICA) },
  year={2024},
  author={Liu, Q. and Shiramatsu, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10807423 },
  abstract={Mission and Vision are crucial for enterprises and organizations. But the traditional methods often consume significant human resources and time. Moreover, participants’ understanding level of Mission and Vision varies, and these tasks are often considered primarily the responsibility of senior management, all making the definition process even more challenging. This study addresses these challenges by introducing a novel automated meeting facilitator system based on LLM (Large Language Model). The study designs five steps for the meeting based on divergent and convergent strategies, specifically for the definition of Mission and Vision, and incorporates step transition strategies that enable the facilitator to automatically switch steps and apply different facilitation strategies according to each step to guide discussions. Experiments with three versions of the system demonstrate its effectiveness in facilitating discussions and building consensus, with improvements made across different versions. This study advances the development of AI-assisted collaboration tools and provides an innovative solution to enhance the process of defining Mission and Vision.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICA63002.2024.00034 },
  booktitle={ 2024 IEEE International Conference on Agents (ICA) },
  chapter={0}
}

@article{rayyan-352344000,
  title={ Optimized Story Generation using DeepSeek LLM with Supervised Fine-Tuning  -  2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE) },
  year={2025},
  author={P, M. and Velvizhy, P. and Sherly, P. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042725 },
  abstract={Automated story generation using Large Language Models (LLMs) has gained significant attention due to its applications in creative writing, education, and interactive systems. Despite advancements, existing LLMs often generate narratives that lack coherence, contextual alignment, and semantic accuracy, limiting their effectiveness in real-world applications. Addressing these challenges requires systematic model adaptation and optimization. This study focuses on enhancing the story generation capabilities of the DeepSeek-7B model through Supervised Fine-Tuning (SFT) and content moderation. The objective is to improve lexical overlap, contextual relevance, and narrative fluency by training the model on a curated dataset of structured narratives. The proposed methodology involves fine-tuning DeepSeek-7B using high-quality training data, optimizing for linguistic coherence and semantic alignment followed by content filtering. The model's performance is evaluated using ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and BERT Score to quantify improvements over zero-shot generation. Experimental results demonstrate a 15% improvement in ROUGE-1, a 31% increase in ROUGE-2, and notable gains in METEOR and BERT scores, indicating superior content generation capabilities. These enhancements validate the effectiveness of SFT in refining narrative consistency and linguistic diversity. The findings contribute to advancing AI-driven storytelling by improving the structural and semantic integrity of generated content. This research underscores the potential of supervised adaptation in enhancing LLM performance for real-world generative applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RMKMATE64874.2025.11042725 },
  booktitle={ 2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE) },
  chapter={0}
}

@article{rayyan-352344001,
  title={ Large Language Models are Strong Audio-Visual Speech Recognition Learners  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Cappellazzo, U. and Kim, M. and Chen, H. and Ma, P. and Petridis, S. and Falavigna, D. and Brutti, A. and Pantic, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889251 },
  abstract={Multimodal large language models (MLLMs) have recently become a focal point of research due to their formidable multimodal understanding capabilities. For example, in the audio and speech domains, an LLM can be equipped with (automatic) speech recognition (ASR) abilities by just concatenating the audio tokens, computed with an audio encoder, and the text tokens to achieve state-of-the-art results. On the contrary, tasks like visual and audio-visual speech recognition (VSR/AVSR), which also exploit noise-invariant lip movement information, have received little or no attention. To bridge this gap, we propose Llama-AVSR, a new MLLM with strong audio-visual speech recognition capabilities. It leverages pre-trained audio and video encoders to produce modality-specific tokens which, together with the text tokens, are processed by a pre-trained LLM (e.g., Llama3.1-8B) to yield the resulting response in an auto-regressive fashion. Llama-AVSR requires a small number of trainable parameters as only modality-specific projectors and LoRA modules are trained whereas the multi-modal encoders and LLM are kept frozen. We evaluate our proposed approach on LRS3, the largest public AVSR benchmark, and we achieve new state-of-the-art results for the tasks of ASR and AVSR with a WER of 0.79% and 0.77%, respectively. To bolster our results, we investigate the key factors that underpin the effectiveness of Llama-AVSR: the choice of the pre-trained encoders and LLM, the efficient integration of LoRA modules, and the optimal performance-efficiency trade-off obtained via modality-aware compression rates.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10889251 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352344002,
  title={ ViUniT: Visual Unit Tests for More Robust Visual Programming  -  2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  year={2025},
  author={Panagopoulou, A. and Zhou, H. and Savarese, S. and Xiong, C. and Callison-Burch, C. and Yatskar, M. and Niebles, J. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11092353 },
  abstract={Programming based approaches to reasoning tasks have substantially expanded the types of questions models can answer about visual scenes. Yet on benchmark visual reasoning data, when models answer correctly, they produce incorrect programs 33% of the time. These models are often right for the wrong reasons and risk unexpected failures on new data. Unit tests play a foundational role in ensuring code correctness and could be used to repair such failures. We propose Visual Unit Testing (ViUniT), a framework to improve the reliability of visual programs by automatically generating unit tests. In our framework, a unit test is represented as a novel image and answer pair meant to verify the logical correctness of a program produced for a given query. Our method leverages a language model to create unit tests in the form of image descriptions and expected answers, followed by image synthesis to produce corresponding images. We conduct a comprehensive analysis of what constitutes an effective visual unit test suite, exploring unit test generation, sampling strategies, image generation methods, and varying the number of programs and unit tests. Additionally, we introduce four applications of visual unit tests: best program selection, answer refusal, re-prompting, and unsupervised reward formulations for reinforcement learning. Experiments with two models across three datasets in visual question answering and image-text matching demonstrate that ViUniT improves model performance by 11.4 points in accuracy. Notably, it enables 7B open-source language models to outperform gpt-4o-mini in visual program generation by an average of 7.7 points and reduces the occurrence of programs that are correct for the wrong reasons by 40%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52734.2025.02295 },
  booktitle={ 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
  chapter={0}
}

@article{rayyan-352344003,
  title={ From Zero to Sixty at the Speed of RAG: Improving YAML Recipe Generation via Retrieval  -  2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code) },
  year={2025},
  author={Farmahinifarahani, F. and Babkin, P. and Alamir, S. and Liu, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028329 },
  abstract={LLMs have been shown to match or even exceed the performance of specialized Deep Learning models on code generation tasks for general purpose imperative languages, such as Python, Java, C++, and Rust. Conversely, there is only limited work investigating whether such impressive out of the box generalization transfers onto less ubiquitous domain-specific languages, which are often declarative, based on XML, JSON, or YAML. To bridge this gap, we explore the capabilities of LLMs for composing code automation recipes without resorting to any form of task-specific finetuning. We experiment with two GPT versions and CodeLlama-13b-Instruct, and in our experiments, we find that after extensive prompt engineering and chain-of-thought prompting, these models’ accuracy in recipe selection does not go beyond ≈ 30%. For parameter filling of YAML recipes, the accuracy of these models remains below 50%. However, by decomposing the task into two stages: dense retrieval and generative slot filling, and while still keeping our setup training-free, the models are able to attain an accuracy in a range of ≈ 50% to ≈ 67% in recipe selection, and ≈ 60% to ≈ 76% in parameter filling. Our study sheds light on the capabilities of LLMs in generating scripts for less widespread languages and opens up avenues for future research.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LLM4Code66737.2025.00011 },
  booktitle={ 2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code) },
  chapter={0}
}

@article{rayyan-352344546,
  title={ HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference  -  nan },
  year={2025},
  author={Z and Zhang and Zeyu and H and Shen and Haiying and S and Vargaftik and Shay and R.B and Basat and Ben, Ran and M.D and Mitzenmacher and D, Michael and M and Yu and Minlan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016240155&doi=10.1145%2F3718958.3750481&partnerID=40&md5=b0cf92ae1e5f36ff1855e265fadd6893 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3718958.3750481 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344547,
  title={ Towards LLM-Based Failure Localization in Production-Scale Networks  -  nan },
  year={2025},
  author={C and Wang and Chenxu and X and Zhang and Xumiao and R and Lu and Runwei and X and Lin and Xianshang and X and Zeng and Xuan and X and Zhang and Xinlei and Z and An and Zhe and G and Wu and Gongwei and J and Gao and Jiaqi and C and Tian and Chen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016225074&doi=10.1145%2F3718958.3750505&partnerID=40&md5=828c4c4194ecf545b0f513dba8354806 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3718958.3750505 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344548,
  title={ Forewarned is Forearmed: Joint Prediction and Classification of Optical Transceiver Failures in Large-Scale LLM Training Clusters  -  nan },
  year={2025},
  author={S and Xia and Sibo and L and Ma and Long and J and Kuang and Junhua and S and Zhang and Shenglin and Q and Xie and Qitong and Y and Sun and Yongqian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013083898&doi=10.1145%2F3735358.3737815&partnerID=40&md5=1ee285ade84e20effeb80862a617a631 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3735358.3737815 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344549,
  title={ EARN: Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2025},
  author={C and Yang and Chaoqun and X and Lin and Xinyu and W and Wang and Wenjie and Y and Li and Yongqi and T and Sun and Teng and X and Han and Xianjing and T and Chua and Tatseng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014360480&doi=10.1145%2F3711896.3736919&partnerID=40&md5=472fa80c11dc21bbeac94951c0f78f25 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3711896.3736919 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352344550,
  title={ L4: Diagnosing Large-scale LLM Training Failures via Automated Log Analysis  -  Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  year={2025},
  author={Z and Jiang and Zhihan and J and Huang and Junjie and G and Yu and Guangba and Z and Chen and Zhuangbin and Y and Li and Yichen and R and Zhong and Renyi and C and Feng and Cong and Y and Yang and Yongqiang and Z and Yang and Zengyin and M.R.T and Lyu and Tsong, Michael Rung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013970916&doi=10.1145%2F3696630.3728531&partnerID=40&md5=3071265ef238e4b4e678d0ed08f3dfd5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696630.3728531 },
  booktitle={ Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  chapter={0}
}

@article{rayyan-352344551,
  title={ AgentFM: Role-Aware Failure Management for Distributed Databases with LLM-Driven Multi-Agents  -  Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  year={2025},
  author={L and Zhang and Lingzhe and Y and Zhai and Yunpeng and T and Jia and Tong and X and Huang and Xiaosong and C and Duan and Chiming and Y and Li and Ying},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013966973&doi=10.1145%2F3696630.3728492&partnerID=40&md5=658505176e78d183d552bfc340b7dd15 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696630.3728492 },
  booktitle={ Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  chapter={0}
}

@article{rayyan-352344552,
  title={ ACE: Automated Technical Debt Remediation with Validated Large Language Model Refactorings  -  Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  year={2025},
  author={A and Tornhill and Adam and M and Borg and Markus and N and Hagatulah and Nadim and E., Söderberg and Emma},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013963759&doi=10.1145%2F3696630.3730565&partnerID=40&md5=0bd4a1121fc39f96059bed20d4bdfae0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696630.3730565 },
  booktitle={ Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  chapter={0}
}

@article{rayyan-352344553,
  title={ The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines  -  Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  year={2025},
  author={M and Martinez and Matias},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013958950&doi=10.1145%2F3696630.3728704&partnerID=40&md5=2c096386ede105f294434c853faab707 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696630.3728704 },
  booktitle={ Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering },
  chapter={0}
}

@article{rayyan-352344554,
  title={ Efficiency Unleashed: Inference Acceleration for LLM-based Recommender Systems with Speculative Decoding  -  nan },
  year={2025},
  author={Y and Xi and Yunjia and H and Wang and Hangyu and B and Chen and Bo and J and Lin and Jianghao and M and Zhu and Menghui and W and Liu and Weiwen and R and Tang and Ruiming and Z and Wei and Zhewei and W and Zhang and Weinan and Y and Yu and Yong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011819920&doi=10.1145%2F3726302.3729961&partnerID=40&md5=6d2da4033fe9be8e9c4fce1fd96123f7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3726302.3729961 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344555,
  title={ AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference  -  Proceedings of the ACM SIGMOD International Conference on Management of Data },
  year={2025},
  author={Y and Deng and Yangshen and Z and You and Zhengxin and L and Xiang and Long and Q and Li and Qilong and P and Yuan and Peiqi and Z and Hong and Zhaoyang and Y and Zheng and Yitao and W and Li and Wanting and R and Li and Runzhong and H and Liu and Haotian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010205352&doi=10.1145%2F3722212.3724428&partnerID=40&md5=0d7dca4d176aeb1e7469db587cf63881 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3722212.3724428 },
  booktitle={ Proceedings of the ACM SIGMOD International Conference on Management of Data },
  chapter={0}
}

@article{rayyan-352344556,
  title={ LIA: A Single-GPU LLM Inference Acceleration with Cooperative AMX-Enabled CPU-GPU Computation and CXL Offloading  -  nan },
  year={2025},
  author={H and Kim and Hyungyo and N and Wang and Nachuan and Q and Xia and Qirong and J and Huang and Jinghan and A and Yazdanbakhsh and Amir and N and Kim and Namsung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009603399&doi=10.1145%2F3695053.3731092&partnerID=40&md5=b4864353348015998f7af847c0b6cd0e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3731092 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344557,
  title={ AiF: Accelerating On-Device LLM Inference Using In-Flash Processing  -  nan },
  year={2025},
  author={J and Lee and Jaeyong and H and Kim and Hyeunjoo and S and Oh and Sanghun and M and Chun and Myoungjun and M and Kim and Myungsunk and J and Kim and Jihong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009603288&doi=10.1145%2F3695053.3731073&partnerID=40&md5=e0a02e92e0975237ae55c1f2a99840d0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3731073 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344558,
  title={ SpecEE: Accelerating Large Language Model Inference with Speculative Early Exiting  -  nan },
  year={2025},
  author={J and Xu and Jiaming and J and Pan and Jiayi and Y and Zhou and Yongkang and S and Chen and Siming and J and Li and Jinhao and Y and Lian and Yaoxiu and J and Wu and Junyi and G and Dai and Guohao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009601193&doi=10.1145%2F3695053.3730996&partnerID=40&md5=11d2d55bc1afb966e70d90c2d7b258e2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3730996 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344559,
  title={ Hybe: GPU-NPU Hybrid System for Efficient LLM Inference with Million-Token Context Window  -  nan },
  year={2025},
  author={S and Moon and Seungjae and J and Cha and Junseo and H and Park and Hyunjun and J and Kim and Joo-young},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009590277&doi=10.1145%2F3695053.3731051&partnerID=40&md5=b47f777081036dce27d6c76cb2ebfc8c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3731051 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344560,
  title={ AMALI: An Analytical Model for Accurately Modeling LLM Inference on Modern GPUs  -  nan },
  year={2025},
  author={S and Cao and Shiheng and J and Wu and Junmin and J and Chen and Junshi and H and An and Hong and Z and Yu and Zhibin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009588893&doi=10.1145%2F3695053.3731064&partnerID=40&md5=4303bf42e5d4b5162c1d1d73ccd97c14 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3731064 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344561,
  title={ H2-LLM: Hardware-Dataflow Co-Exploration for Heterogeneous Hybrid-Bonding-based Low-Batch LLM Inference  -  nan },
  year={2025},
  author={C and Li and Cong and Y and Yin and Yihan and X and Wu and Xintong and J and Zhu and Jingchen and Z and Gao and Zhutianya and D and Niu and Dimin and Q and Wu and Qiang and X and Si and Xin and Y and Xie and Yuanyuan and C and Zhang and Chen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009587557&doi=10.1145%2F3695053.3731008&partnerID=40&md5=daff02e5b2289ce9ed96196a9cadeaab },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3731008 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344562,
  title={ LUT Tensor Core: A Software-Hardware Co-Design for LUT-Based Low-Bit LLM Inference  -  nan },
  year={2025},
  author={Z and Mo and Zhiwen and L and Wang and Lei and J and Wei and Jianyu and Z and Zeng and Zhichen and S and Cao and Shijie and L and Ma and Lingxiao and N and Jing and Naifeng and T and Cao and Ting and J and Xue and Jilong and F and Yang and Fan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009585830&doi=10.1145%2F3695053.3731057&partnerID=40&md5=c7e614fa4b8e55d569e6126823b81f60 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3695053.3731057 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344563,
  title={ PPQformer: Privacy-Preserving Quantized Transformer for Efficient and Secure Inference  -  nan },
  year={2025},
  author={B and Dong and Benchang and Z and Chen and Zhili},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015572425&doi=10.1145%2F3728725.3728743&partnerID=40&md5=8db2e0ba7cedfa67754278a73551c89a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3728725.3728743 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344564,
  title={ The Application of Membership Inference in Privacy Auditing of Large Language Models Based on Fine-Tuning Method  -  nan },
  year={2025},
  author={C and Wen and Chengjiang and Y and Yue and Yang and Z and Wang and Zhixiang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015556338&doi=10.1145%2F3728725.3728799&partnerID=40&md5=0496c56431b0e3e90e6e5dc761719cad },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3728725.3728799 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344565,
  title={ Enhancing Room Occupancy Inference from Sparse PIR Sensor Data Using Transformer Models  -  nan },
  year={2025},
  author={Y and Sheng and Yu and A.D., Özbakir and Deǧer, Ali and C and Maathuis and Clara and D and Iren and Deniz and S and Bromuri and Stefano},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006448910&doi=10.1145%2F3672608.3707755&partnerID=40&md5=c7858952a5fec7d344db5e4ead24f54e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3672608.3707755 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344566,
  title={ SCOOT: SLO-Oriented Performance Tuning for LLM Inference Engines  -  nan },
  year={2025},
  author={K and Cheng and Ke and Z and Wang and Zhi and W and Hu and Wen and T and Yang and Tiannuo and J and Li and Jianguo and S and Zhang and Sheng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005162023&doi=10.1145%2F3696410.3714930&partnerID=40&md5=60b9b9c0a2b81336def45cb55ab61555 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696410.3714930 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344567,
  title={ WeInfer: Unleashing the Power of WebGPU on LLM Inference in Web Browsers  -  nan },
  year={2025},
  author={Z and Chen and Zhiyang and Y and Ma and Yun and H and Shen and Haiyang and M and Liu and Mugeng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005157335&doi=10.1145%2F3696410.3714553&partnerID=40&md5=5cb811ff5a3a12d0ebba9653d036cfef },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696410.3714553 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344568,
  title={ Baton: Enhancing Batch-wise Inference Efficiency for Large Language Models via Dynamic Re-batching  -  nan },
  year={2025},
  author={P and Cong and Peizhuang and Q and Chen and Qizhi and H and Zhao and Haochen and T and Yang and Tong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005138198&doi=10.1145%2F3696410.3714950&partnerID=40&md5=e460ecfae4376a490f62b5f80ff6640e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3696410.3714950 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344569,
  title={ Dynamic-Width Speculative Beam Decoding for LLM Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={Z and Qin and Zongyue and Z and He and Zifan and N.B and Prakriya and Bhairavi, Neha and J.J and Cong and Jason, Jingsheng and Y and Sun and Yizhou},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004169631&doi=10.1609%2Faaai.v39i23.34690&partnerID=40&md5=1a66d1b68be8da644cba039f14deeeca },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i23.34690 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344570,
  title={ Prompt Compression with Context-Aware Sentence Encoding for Fast and Improved LLM Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={B and Liskavets and Barys and M and Ushakov and Maxim and S and Roy and Shuvendu and M and Klibanov and Mark and S.A and Etemad, S. Ali and S.K and Luke and K, Shane},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004169610&doi=10.1609%2Faaai.v39i23.34639&partnerID=40&md5=1e196a8c37892033f1aebc34cde81146 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i23.34639 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344571,
  title={ Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={H and Zhao and Han and M and Zhang and Min and W and Zhao and Wei and P and Ding and Pengxiang and S and Huang and Siteng and D and Wang and Donglin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004168417&doi=10.1609%2Faaai.v39i10.33131&partnerID=40&md5=32b7f51e289c5b92857f168790f1b779 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i10.33131 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344572,
  title={ AdaSkip: Adaptive Sublayer Skipping for Accelerating Long-Context LLM Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={Z and He and Zhuomin and Y and Yao and Yizhen and P and Zuo and Pengfei and B and Gao and Bin and Q and Li and Qinya and Z and Zheng and Zhenzhe and J and Lei and Jiale},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004004478&doi=10.1609%2Faaai.v39i22.34579&partnerID=40&md5=ef09dce3e43c7a7ea63cc345676d17ba },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i22.34579 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344573,
  title={ Falcon: Faster and Parallel Inference of Large Language Models Through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={X and Gao and Xiangxiang and W and Xie and Weisheng and Y and Xiang and Yiwei and F and Ji and Feng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004002642&doi=10.1609%2Faaai.v39i22.34566&partnerID=40&md5=12c8f70ee361eb240537d6dc12eafa86 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i22.34566 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344574,
  title={ Pushing the Limits of BFP on Narrow Precision LLM Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={H and Wang and Hui and Y and Cheng and Yuan and X and Han and Xiaomeng and Z and Zhao and Zhengpeng and D and Yang and Dawei and Z and Jiang and Zhe},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003999300&doi=10.1609%2Faaai.v39i20.35407&partnerID=40&md5=dfacb5112f624b6342efe33346dd6a22 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i20.35407 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344575,
  title={ Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge Editing for Large Language Models  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={C and Hu and Chenhui and P and Cao and Pengfei and Y and Chen and Yubo and K and Liu and Kang and J and Zhao and Jun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003998967&doi=10.1609%2Faaai.v39i22.34583&partnerID=40&md5=519477d2e95d300c4ffb07e853595498 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i22.34583 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344576,
  title={ Multi-Branch Self-Drafting for LLM Inference Acceleration  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={Z and Gao and Zipeng and Q and Xia and Qingrong and T and Xu and Tong and X and Duan and Xinyu and Z and Zheng and Zhi and Z and Wang and Zhefeng and E and Chen and Enhong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003995706&doi=10.1609%2Faaai.v39i22.34567&partnerID=40&md5=8ceeccb3924e8d2d7f4b2f29193c18ea },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i22.34567 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344577,
  title={ ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={C and Zeng and Chao and S and Liu and Songwei and Y and Xie and Yusheng and H and Liu and Hong and X and Wang and Xiaojian and M and Wei and Miao and S and Yang and Shu and F and Chen and Fangmin and X and Mei and Xing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003995649&doi=10.1609%2Faaai.v39i21.34385&partnerID=40&md5=59317a15907c8a4d7002ee1d757f7dca },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i21.34385 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344578,
  title={ Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={Z and Lin and Zhihang and M and Lin and Mingbao and L and Lin and Luxi and R and Ji and Rongrong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003995322&doi=10.1609%2Faaai.v39i5.32567&partnerID=40&md5=5b726747397cfe18963f6c1b0c5ba187 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i5.32567 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344579,
  title={ Extracting Interpretable Task-Specific Circuits from Large Language Models for Faster Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={J and García-Carrasco and Jorge and A and Maté and Alejandro and J.C and Trujillo and Carlos, Juan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003967436&doi=10.1609%2Faaai.v39i16.33843&partnerID=40&md5=b7856960c09fb54c32ca2e1af83521a4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i16.33843 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344580,
  title={ DF-MIA: A Distribution-Free Membership Inference Attack on Fine-Tuned Large Language Models  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={Z and Huang and Zhiheng and Y and Liu and Yannan and D and He and Daojing and Y and Li and Yu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003909443&doi=10.1609%2Faaai.v39i1.32012&partnerID=40&md5=2b23603bc5b94d9f0ab3b7a2150b7ca3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i1.32012 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344581,
  title={ Portcullis: A Scalable and Verifiable Privacy Gateway for Third-Party LLM Inference  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2025},
  author={J and Zhan and Jiangou and W and Zhang and Wenhui and Z and Zhang and Zheng and H and Xue and Huanran and Y and Zhang and Yao and Y and Wu and Ye},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003908780&doi=10.1609%2Faaai.v39i1.32088&partnerID=40&md5=3550ec726596077478a8d7f289745c60 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v39i1.32088 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344582,
  title={ APINT: A Full-Stack Framework for Acceleration of Privacy-Preserving Inference of Transformers based on Garbled Circuits  -  IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  year={2025},
  author={H and Cho and Hyunjun and J and Jeon and Jaeho and J and Heo and Jaehoon and J and Kim and Joo-young},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003642143&doi=10.1145%2F3676536.3676786&partnerID=40&md5=f6d2578c7507a5737cb4eeef01d5dc26 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676536.3676786 },
  booktitle={ IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  chapter={0}
}

@article{rayyan-352344584,
  title={ Edge-BiT: Software-Hardware Co-design for Optimizing Binarized Transformer Networks Inference on Edge FPGA  -  IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  year={2025},
  author={S and Zhou and Shuai and S and Meng and Sisi and H and Tian and Huinan and J and Yu and Jun and K and Wang and Kun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003633328&doi=10.1145%2F3676536.3676667&partnerID=40&md5=eec680d2f5bf7e2b79ec6577f5ca67db },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676536.3676667 },
  booktitle={ IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  chapter={0}
}

@article{rayyan-352344585,
  title={ An Agile Framework for Efficient LLM Accelerator Development and Model Inference  -  IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  year={2025},
  author={L and Chen and Lvcheng and Y and Wu and Ying and C and Wen and Chenyi and S and Wang and Shizhang and L and Zhang and Li and B and Yu and Bei and Q and Sun and Qi and C and Zhuo and Cheng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003632542&doi=10.1145%2F3676536.3676753&partnerID=40&md5=0007521a389a71138e373e5a0d52e76c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676536.3676753 },
  booktitle={ IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  chapter={0}
}

@article{rayyan-352344586,
  title={ Deferred prefill for throughput maximization in LLM inference  -  nan },
  year={2025},
  author={M and Mohanty and Moonmoon and G and Bolar and Gautham and P and Patil and Preetam and U.M.C and Devi and C, Umamaheswari Maheswari and F and George and Felix and P and Moogi and Pratibha and P and Parag and Parimal},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003626349&doi=10.1145%2F3721146.3721962&partnerID=40&md5=2be279f5b991401b85c2a327bfad06c7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3721146.3721962 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344587,
  title={ Beyond Test-Time Compute Strategies: Advocating Energy-per-Token in LLM Inference  -  nan },
  year={2025},
  author={P and Wilhelm and Patrick and T and Wittkopp and Thorsten and O and Kao and Odej},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003623360&doi=10.1145%2F3721146.3721953&partnerID=40&md5=33a08803fb5a37425227667ad61b2ee1 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3721146.3721953 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344588,
  title={ FlexInfer: Breaking Memory Constraint via Flexible and Efficient Offloading for On-Device LLM Inference  -  nan },
  year={2025},
  author={H and Du and Hongchao and S and Wu and Shangyu and A and Kharlamova and Arina and N and Guan and Nan and C.J and Xue and Jason, Chun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003622298&doi=10.1145%2F3721146.3721961&partnerID=40&md5=210f52431e68ca22c18df44a873cbb44 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3721146.3721961 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344589,
  title={ TAPAS: Thermal- and Power-Aware Scheduling for LLM Inference in Cloud Platforms  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2025},
  author={J and Stojkovic and Jovan and C and Zhang and Chaojie and Í and Goiri, Íñigo and E and Choukse and Esha and H and Qiu and Haoran and R and Fonseca and Rodrigo and J and Torrellas and Josep and R and Bianchini and Ricardo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002564863&doi=10.1145%2F3676641.3716025&partnerID=40&md5=89e98d1fcdf8c045540b91b2d92b5a57 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676641.3716025 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344590,
  title={ POD-Attention: Unlocking Full Prefill-Decode Overlap for Faster LLM Inference  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2025},
  author={A.K and Kamath and K, Aditya and R and Prabhu and Ramya and J and Mohan and Jayashree and S and Peter and Simon and R and Ramjee and Ramachandran and A and Panwar and Ashish},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002564340&doi=10.1145%2F3676641.3715996&partnerID=40&md5=82bf68bd2eff174e22b9768a562c4a35 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676641.3715996 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344591,
  title={ PIM Is All You Need: A CXL-Enabled GPU-Free System for Large Language Model Inference  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2025},
  author={Y and Gu and Yufeng and A and Khadem and Alireza and S and Umesh and Sumanth and N and Liang and Ning and X and Servot and Xavier and O.C and Mutlu and Cezmi, Onur and R.R and Iyer and R, Ravi and R and Das and Reetuparna},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002559445&doi=10.1145%2F3676641.3716267&partnerID=40&md5=e759b948ffc734e0cb9b818607ef3eef },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3676641.3716267 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344592,
  title={ Fast On-device LLM Inference with NPUs  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2025},
  author={D and Xu and Daliang and H and Zhang and Hao and L and Yang and Liming and R and Liu and Ruiqi and G and Huang and Gang and M and Xu and Mengwei and X and Liu and Xuanzhe},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002399367&doi=10.1145%2F3669940.3707239&partnerID=40&md5=911f866b43250786486ddd8ea2ac9111 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3669940.3707239 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344593,
  title={ Medusa: Accelerating Serverless LLM Inference with Materialization  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2025},
  author={S and Zeng and Shaoxun and M and Xie and Minhui and S and Gao and Shiwei and Y and Chen and Youmin and Y and Lu and Youyou},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002392331&doi=10.1145%2F3669940.3707285&partnerID=40&md5=630ef329dd8b66a16eebeea9b26d19ad },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3669940.3707285 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344594,
  title={ SpInfer: Leveraging Low-Level Sparsity for Efficient Large Language Model Inference on GPUs  -  nan },
  year={2025},
  author={R and Fan and Ruibo and X and Yu and Xiangrui and P and Dong and Peijie and Z and Li and Zeyu and G and Gong and Gu and Q and Wang and Qiang and W and Wang and Wei and X and Chu and Xiaowen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002214895&doi=10.1145%2F3689031.3717481&partnerID=40&md5=b562d76a0b9a4aae540916444f90a8f3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3689031.3717481 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344595,
  title={ Lightning IR: Straightforward Fine-tuning and Inference of Transformer-based Language Models for Information Retrieval  -  nan },
  year={2025},
  author={F and Schlatt and Ferdinand and M and Fröbe and Maik and M and Hagen and Matthias},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001669168&doi=10.1145%2F3701551.3704118&partnerID=40&md5=912838a5709a001de464da71345baacb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3701551.3704118 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344596,
  title={ MARLIN: Mixed-Precision Auto-Regressive Parallel Inference on Large Language Models  -  Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPOPP },
  year={2025},
  author={E and Frantar and Elias and R.L and Castro and L, Roberto and J and Chen and Jiale and T and Hoefler and Torsten and D and Alistarh and Dan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000427565&doi=10.1145%2F3710848.3710871&partnerID=40&md5=fe2b1aeb48a5dbf0c28c88ab73a5a110 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3710848.3710871 },
  booktitle={ Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPOPP },
  chapter={0}
}

@article{rayyan-352344597,
  title={ A Vision Transformer Inference Accelerator for KR260  -  nan },
  year={2025},
  author={Z and Bao and Zhenshan and H and Li and Han and W and Zhang and Wenbo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219607554&doi=10.1145%2F3709026.3709107&partnerID=40&md5=6fe1a90a7a4b6fcbc843c42d73e97672 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3709026.3709107 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344598,
  title={ On LLM-generated Logic Programs and their Inference Execution Methods  -  Electronic Proceedings in Theoretical Computer Science, EPTCS },
  year={2025},
  author={P and Tarau and Paul},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218633611&doi=10.4204%2FEPTCS.416.1&partnerID=40&md5=6db991673e4a6c38097bc6f94281fb94 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.4204/EPTCS.416.1 },
  booktitle={ Electronic Proceedings in Theoretical Computer Science, EPTCS },
  chapter={0}
}

@article{rayyan-352344599,
  title={ Analysis of Transformer Decoder Architecture and KV Cache Behavior During LLM Inference  -  nan },
  year={2025},
  author={K and Jung and Kyudan and J and Kwon and Jeongyoun and Y and Mun and Young-dae and B and Kang and Byeong-geun and J and Song and Joon-seok and M and Kim and Minji and N and Kim and Nam-joon and H and Ryu and Hyungon and H and Lee and Hyukjae},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000013228&doi=10.1109%2FICEIC64972.2025.10879650&partnerID=40&md5=06fdd4a782443736f7671cac6f139ebc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIC64972.2025.10879650 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344600,
  title={ Enhancing Inference Performance of a Personalized Driver Assistance System through LLM Fine-Tuning and Quantization  -  nan },
  year={2025},
  author={G and Song and Gihoon and J and Lim and Jihun and C and Jeong and Cheolmin and C.M and Kang and Mook, Chang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000005819&doi=10.1109%2FICEIC64972.2025.10879617&partnerID=40&md5=ef290d2a44e9c658e18f25719988c54a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIC64972.2025.10879617 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344601,
  title={ Dynamic Layer-Wise Token Pruning for Sequence-to-Sequence Transformer Inference  -  Lecture Notes in Computer Science },
  year={2025},
  author={J.H and Keom and Hun, Ji and Y and Kim and Yeachan and S and Lee and Sungju and S and Lee and Sangkeun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219210135&doi=10.1007%2F978-981-97-8705-0_23&partnerID=40&md5=a4d9af6675aa8b67c0892466c2099bcc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-97-8705-0_23 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344602,
  title={ Few-Shot N-Ary Knowledge Inference Using Large Language Models  -  Lecture Notes in Computer Science },
  year={2025},
  author={F and Lang and Fang and W and Song and Wei and Q and Zhu and Qiuguo and S and Zhu and Shiqiang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218638454&doi=10.1007%2F978-981-96-0792-1_22&partnerID=40&md5=c6e5830e7ad4a9e1a9de4fb96a182735 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-96-0792-1_22 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344603,
  title={ QuickLLaMA: Query-aware Inference Acceleration for Large Language Models  -  Proceedings - International Conference on Computational Linguistics, COLING },
  year={2025},
  author={J and Li and Jingyao and H and Shi and Han and S and Wu and Sitong and C and Zheng and Chuanyang and P and Chen and Pengguang and Z and Li and Zhenguo and X and Jiang and Xin and H and Xu and Hong and J and Jia and Jiaya},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218503638&partnerID=40&md5=7b239d287b770f33671e3374102cd3be },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings - International Conference on Computational Linguistics, COLING },
  chapter={0}
}

@article{rayyan-352344604,
  title={ Sibyl: Empowering Empathetic Dialogue Generation in Large Language Models via Sensible and Visionary Commonsense Inference  -  Proceedings - International Conference on Computational Linguistics, COLING },
  year={2025},
  author={L and Wang and Lanrui and J and Li and Jiangnan and C and Yang and Chenxu and Z and Lin and Zheng and H and Tang and Hongyin and H and Liu and Huan and Y and Cao and Yanan and J and Wang and Jingang and W.P and Wang and Ping, Weipinng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218498695&partnerID=40&md5=c2f1fea76f4b502fdf5e31e8cf050eea },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings - International Conference on Computational Linguistics, COLING },
  chapter={0}
}

@article{rayyan-352344605,
  title={ Biases in Large Language Model-Elicited Text: A Case Study in Natural Language Inference  -  Proceedings - International Conference on Computational Linguistics, COLING },
  year={2025},
  author={G and Proebsting and Grace and A and Poliak and Adam},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218498610&partnerID=40&md5=843559f8a6a3de57d46efb73d8028f27 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings - International Conference on Computational Linguistics, COLING },
  chapter={0}
}

@article{rayyan-352344606,
  title={ Enhancing Software Defect Prediction in Ansible Scripts Using Code-Smell-Guided Prompting with Large Language Models in Edge-Cloud Infrastructures  -  Communications in Computer and Information Science },
  year={2025},
  author={H and Hong and Hyunsun and S and Lee and Sungu and D and Ryu and Duksan and J and Baik and Jongmoon},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218458418&doi=10.1007%2F978-3-031-75110-3_3&partnerID=40&md5=cfbcbcb25ba2ee972ca24d7083f1a244 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-75110-3_3 },
  booktitle={ Communications in Computer and Information Science },
  chapter={0}
}

@article{rayyan-352344607,
  title={ UELLM: A Unified and Efficient Approach for Large Language Model Inference Serving  -  Lecture Notes in Computer Science },
  year={2025},
  author={Y and He and Yiyuan and M and Xu and Minxian and J and Wu and Jingfeng and W and Zheng and Wanyi and K and Ye and Kejiang and C and Xu and Chengzhong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212921991&doi=10.1007%2F978-981-96-0805-8_16&partnerID=40&md5=d297320b03e02330759d106691b631d5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-96-0805-8_16 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344608,
  title={ TADIL: Task-Agnostic Domain-Incremental Learning Through Task-ID Inference Using Transformer Nearest-Centroid Embeddings  -  Lecture Notes in Computer Science },
  year={2025},
  author={G and Bravo-Rocca and Gusseppe and P and Liu and Peini and J and Guitart and Jordi and A and Dholakia and Ajay and D and Ellison and David},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211947993&doi=10.1007%2F978-3-031-78110-0_22&partnerID=40&md5=37d4599e34260f70c81520efcad52384 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-78110-0_22 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344609,
  title={ Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction  -  Lecture Notes in Computer Science },
  year={2025},
  author={C and Eichler, Cédric and N and Champeil and Nathan and N and Anciaux and Nicolas and A and Bensamoun and Alexandra and H.H and Arcolezi and Hwang, Heber and J.M., de Fuentes and María, José},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211338156&doi=10.1007%2F978-981-96-0570-5_32&partnerID=40&md5=aded61025985e6531eaa2994439e4469 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-96-0570-5_32 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344610,
  title={ TransCAD: A Hierarchical Transformer for CAD Sequence Inference from Point Clouds  -  Lecture Notes in Computer Science },
  year={2025},
  author={E and Dupont and Elona and K and Cherenkova and Kseniya and D and Mallis and Dimitrios and G and Gusev and Gleb and A and Kacem and Anis and D and Aouada and Djamila},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210892241&doi=10.1007%2F978-3-031-73030-6_2&partnerID=40&md5=13caf88de27cc263e82c2bf4a99df110 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-73030-6_2 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344611,
  title={ FIRP: Faster LLM Inference via Future Intermediate Representation Prediction  -  Lecture Notes in Computer Science },
  year={2025},
  author={P and Wu and Pengfei and J and Liu and Jiahao and Z and Gong and Zhuocheng and Q and Wang and Qifan and J and Li and Jinpeng and J and Wang and Jingang and X and Cai and Xunliang and D and Zhao and Dong-Yan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210087768&doi=10.1007%2F978-981-97-9437-9_13&partnerID=40&md5=6fe4291d5153f4d7843e5d0f47329b71 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-97-9437-9_13 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344612,
  title={ Improving Causal Inference of Large Language Models with SCM Tools  -  Lecture Notes in Computer Science },
  year={2025},
  author={Z and Hua and Zhenyang and S and Xing and Shuyue and H and Jiang and Huixing and W and Chen and Wei and X and Wang and Xiaojie},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210085899&doi=10.1007%2F978-981-97-9437-9_1&partnerID=40&md5=6fd9217f0d768b70a2a04aa3d675a004 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-97-9437-9_1 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344613,
  title={ Token Compensator: Altering Inference Cost of Vision Transformer Without Re-tuning  -  Lecture Notes in Computer Science },
  year={2025},
  author={S and Jie and Shibo and Y and Tang and Yehui and J and Guo and Jianyuan and Z and Deng and Zhihong and K and Han and Kai and Y and Wang and Yunhe},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209784738&doi=10.1007%2F978-3-031-72640-8_5&partnerID=40&md5=9300a83e563e14b55864781bb73e99b1 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-72640-8_5 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344614,
  title={ DECIDER: Leveraging Foundation Model Priors for Improved Model Failure Detection and Explanation  -  Lecture Notes in Computer Science },
  year={2025},
  author={R and Subramanyam and Rakshith and K and Thopalli and Kowshik and V.S and Narayanaswamy and Sivaraman, Vivek and J.J and Thiagarajan and Jayaraman, Jayaraman},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208597411&doi=10.1007%2F978-3-031-72986-7_27&partnerID=40&md5=0b979a3d3b9850ed8c5a60af5a93a224 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-72986-7_27 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344615,
  title={ Global-Local Collaborative Inference with LLM for Lidar-Based Open-Vocabulary Detection  -  Lecture Notes in Computer Science },
  year={2025},
  author={X and Peng and Xingyu and Y and Bai and Yan and C and Gao and Chen and L and Yang and Lirong and F and Xia and Fei and B and Mu and Beipeng and X and Wang and Xiaofei and S and Liu and Si},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206383440&doi=10.1007%2F978-3-031-72761-0_21&partnerID=40&md5=7aac0c5bee7ff02b6a12b5bd8a8944e2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-72761-0_21 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344616,
  title={ Embedding-Free Transformer with Inference Spatial Reduction for Efficient Semantic Segmentation  -  Lecture Notes in Computer Science },
  year={2025},
  author={H and Yu and Hyunwoo and Y and Cho and Yubin and B and Kang and Beoungwoo and S and Moon and Seunghun and K and Kong and Kyeongbo and S and Kang and Sukju},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206220045&doi=10.1007%2F978-3-031-72946-1_6&partnerID=40&md5=e9a82e733a2017d0fe413cf745cfa07d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-72946-1_6 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344617,
  title={ Joint Communication and Inference User Allocation in LLM Native Networks  -  nan },
  year={2025},
  author={B and Picano and Benedetta and A and Buratto and Alessandro and L and Badia and Leonardo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016789008&doi=10.1109%2FICMLCN64995.2025.11139994&partnerID=40&md5=7826e7ab89960f962b37f89ff1241a63 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLCN64995.2025.11139994 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344618,
  title={ Uncertainty-Aware Hybrid Inference with On-Device Small and Remote Large Language Models  -  nan },
  year={2025},
  author={S and Oh and Seungeun and J and Kim and Jinhyuk and J and Park and Jihong and S and Ko and Seung-woo and T.Q and Quek and Q.S, Tony and S and Kim and Seonglyun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016781379&doi=10.1109%2FICMLCN64995.2025.11140540&partnerID=40&md5=deed7be0aaca5f8ed96928157d3d3109 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLCN64995.2025.11140540 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344619,
  title={ Transformer-Based Multi-Label Classification for Code Smell Detection in Software Engineering  -  nan },
  year={2025},
  author={M and Habib, Bin and Muhaimin and A.T and Jannat and Tul, Aklima and T and Azhar and Tanvir},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016778982&doi=10.1109%2FINCET64471.2025.11140264&partnerID=40&md5=a08b0eb5952293e0f794fd6829ee6a2a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INCET64471.2025.11140264 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344620,
  title={ Database Perspective on LLM Inference Systems  -  Proceedings of the VLDB Endowment },
  year={2025},
  author={J.J and Pan and Jie, James and G and Li and Guoliang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016682422&doi=10.14778%2F3750601.3750703&partnerID=40&md5=4ba063eeaa0d03acb7eb8885bf826bbe },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.14778/3750601.3750703 },
  booktitle={ Proceedings of the VLDB Endowment },
  chapter={0}
}

@article{rayyan-352344621,
  title={ CPP: Clustered NPU-PIM Heterogeneous Computing Topology for LLM Inference  -  nan },
  year={2025},
  author={D and Kim and Dongwook and D and Kim and Dohyun and E and Chung and Euiyoung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016384491&doi=10.1109%2FITC-CSCC66376.2025.11137596&partnerID=40&md5=a7d06f925460e3d1a3f569b0afa3e431 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITC-CSCC66376.2025.11137596 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344622,
  title={ EMMFormer: Secure Transformer Inference with Efficient Matrix Multiplication  -  nan },
  year={2025},
  author={nan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016381510&doi=10.1109%2FBDPC63545.2025.11135711&partnerID=40&md5=935bb36e3795bcb711bba0535f4487a3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BDPC63545.2025.11135711 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344625,
  title={ CIM for Transformer Models: Enhancing Large Language Model Inference Efficiency  -  Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI },
  year={2025},
  author={M.S and Li and Syuan, Meng and J and Ke and Jungfang and E and Huang and Enming and Z and Liu and Zhiwei and Y and Chen and Yuguang and C and Lee and Chunyi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016105253&doi=10.1109%2FISVLSI65124.2025.11130222&partnerID=40&md5=f06586bee864375c42015579cee72a8c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISVLSI65124.2025.11130222 },
  booktitle={ Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI },
  chapter={0}
}

@article{rayyan-352344626,
  title={ Disk-Based Shared KV Cache Management for Fast Inference in Multi-Instance LLM RAG Systems  -  IEEE International Conference on Cloud Computing, CLOUD },
  year={2025},
  author={H and Lee and Hyungwoo and K and Kim and Kihyun and J and Kim and Jinwoo and J and So and Jungmin and M and Cha and Myung-hoon and H and Kim and Hong-yeon and J.J and Kim and J, James and Y and Kim and Youngjae},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016000439&doi=10.1109%2FCLOUD67622.2025.00029&partnerID=40&md5=50bc928aebfec1449cd457b3d71477de },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CLOUD67622.2025.00029 },
  booktitle={ IEEE International Conference on Cloud Computing, CLOUD },
  chapter={0}
}

@article{rayyan-352344627,
  title={ Cost-Efficient VM Selection for Cloud-Based LLM Inference with KV Cache Offloading  -  IEEE International Conference on Cloud Computing, CLOUD },
  year={2025},
  author={K and Kim and Kihyun and J and Kim and Jinwoo and H and Chung and Hyunsun and M and Cha and Myung-hoon and H and Kim and Hongyeon and Y and Kim and Youngjae},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015973850&doi=10.1109%2FCLOUD67622.2025.00027&partnerID=40&md5=ba983be87098acf975a7726b3ca36d2c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CLOUD67622.2025.00027 },
  booktitle={ IEEE International Conference on Cloud Computing, CLOUD },
  chapter={0}
}

@article{rayyan-352344628,
  title={ Mind the Memory Gap: Unveiling GPU Bottlenecks in Large-Batch LLM Inference  -  IEEE International Conference on Cloud Computing, CLOUD },
  year={2025},
  author={P.G and Recasens and G, Pol and F and Agullo and Ferran and Y and Zhu and Yue and C and Wang and Chen and E and Lee and Eun-kyung and O and Tardieu and Olivier and J and Torres and Jordi and J.L and Garcia, Berral and Lluís, Josep},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015972178&doi=10.1109%2FCLOUD67622.2025.00036&partnerID=40&md5=49b2530508fe014dab398fe02d3ea376 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CLOUD67622.2025.00036 },
  booktitle={ IEEE International Conference on Cloud Computing, CLOUD },
  chapter={0}
}

@article{rayyan-352344629,
  title={ Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference  -  IEEE International Conference on Cloud Computing, CLOUD },
  year={2025},
  author={Y and Zhu and Yue and H and Yu and Hao and C and Wang and Chen and Z and Liu and Zhuoran and E and Lee and Eun-kyung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015959841&doi=10.1109%2FCLOUD67622.2025.00052&partnerID=40&md5=61ef9be1496fbc9e30a3025ec2229286 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CLOUD67622.2025.00052 },
  booktitle={ IEEE International Conference on Cloud Computing, CLOUD },
  chapter={0}
}

@article{rayyan-352344630,
  title={ Large Language Model Partitioning for Low-Latency Inference at the Edge  -  Proceedings of the International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks, WiOpt },
  year={2025},
  author={D and Kafetzis and Dimitrios and R and Khalili and Ramin and I and Koutsopoulos and Iordanis},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015948390&doi=10.23919%2FWiOpt66569.2025.11123401&partnerID=40&md5=c0beb0dbdbec324f0ea67728d389f8d8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/WiOpt66569.2025.11123401 },
  booktitle={ Proceedings of the International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks, WiOpt },
  chapter={0}
}

@article{rayyan-352344631,
  title={ Modeling Interaction between Large Language Models and Humans in Co-Creative Decision-Making as Distributed Bayesian Inference  -  Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO },
  year={2025},
  author={M and Hirose and Momoha and M and Nagano and Masatoshi and T and Taniguchi and Tadahiro},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015851377&doi=10.1109%2FARSO64737.2025.11124961&partnerID=40&md5=34ed61ba6d87ee2ab1e6c0bf7e00ac7d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ARSO64737.2025.11124961 },
  booktitle={ Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO },
  chapter={0}
}

@article{rayyan-352344632,
  title={ ReaLLM: A Trace-Driven Framework for Rapid Simulation of Large-Scale LLM Inference  -  Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors },
  year={2025},
  author={H and Peng and Huwan and S and Davidson and Scott and C.J.R and Shi, C. J.Richard and M.B and Taylor and Bedford, Michael},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015669648&doi=10.1109%2FASAP65064.2025.00022&partnerID=40&md5=f797313062d05833cff5b8cb0907ad20 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASAP65064.2025.00022 },
  booktitle={ Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors },
  chapter={0}
}

@article{rayyan-352344633,
  title={ METAL: A Memory-Efficient Transformer Architecture for Long-Context Inference on FPGA  -  Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors },
  year={2025},
  author={Z and He and Zicheng and S and Lu and Shaoqiang and T and Zhao and Tiandong and J and Yan and Jinlong and C and Wu and Chen and L and He and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015640492&doi=10.1109%2FASAP65064.2025.00023&partnerID=40&md5=9c030059819e714e630c53c21b56d8d7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASAP65064.2025.00023 },
  booktitle={ Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors },
  chapter={0}
}

@article{rayyan-352344635,
  title={ Breaking Down LLM Inference: A preliminary performance analysis of sparsified transformers  -  nan },
  year={2025},
  author={I and Tasou and Ioanna and P and Anastasiadis and Petros and P and Mpakos and Panagiotis and D and Galanopoulos and Dimitrios and N and Koziris and Nectarios and G.I and Goumas and I, Georgios},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015432095&doi=10.1109%2FIPDPSW66978.2025.00154&partnerID=40&md5=ef2cd020c978ac7d868f00cab33fb017 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPDPSW66978.2025.00154 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344636,
  title={ LM-Offload: Performance Model-Guided Generative Inference of Large Language Models with Parallelism Control  -  nan },
  year={2025},
  author={J and Wu and Jianbo and J and Ren and Jie and S and Yang and Shuangyan and K and Parasyris and Konstantinos and G and Georgakoudis and Giorgis and I and Laguna and Ignacio and D and Li and Dong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015408107&doi=10.1109%2FIPDPSW66978.2025.00134&partnerID=40&md5=436732578d690681c430cf42131e93f7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPDPSW66978.2025.00134 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344637,
  title={ How private are your chat adapters? Evaluating the privacy of LoRA fine-Tuned large language models with membership inference attacks  -  Proceedings of SPIE - The International Society for Optical Engineering },
  year={2025},
  author={N and Manzonelli and Nico and S.M and Coffey and M, Sean and N.D and Bastian and Drew, Nathaniel},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015304381&doi=10.1117%2F12.3053265&partnerID=40&md5=cd4a5f3fd8039596482528ba02c58499 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1117/12.3053265 },
  booktitle={ Proceedings of SPIE - The International Society for Optical Engineering },
  chapter={0}
}

@article{rayyan-352344638,
  title={ Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference  -  Proceedings of Machine Learning Research },
  year={2025},
  author={C and Samplawski and Colin and A.D and Cobb and D, Adam and M and Acharya and Manoj and R and Kaur and Ramneet and S and Jha and Susmit},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014749864&partnerID=40&md5=bab2bd96249e24267f11156714577c25 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344639,
  title={ Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment  -  Proceedings of Machine Learning Research },
  year={2025},
  author={Q and Feng and Qizhang and S.R and Kasa and Rajesh, Siva and S.K and Kasa and Kumar, Santhosh and H and Yun and Hyokun and C.H and Teo and Hui, Choon and S.B and Bodapati and Babu, Sravan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014323142&partnerID=40&md5=8f50ee1d1c7a32ebff9ed1bba4937b81 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344640,
  title={ Enabling High-Throughput Inference of Transformers on Near-Data Processing Architectures  -  nan },
  year={2025},
  author={Y and Zhong and Yingjian and Q and Xu and Qin and M and Ge and Mengke and S and Chen and Song},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014239026&doi=10.1109%2FISEDA65950.2025.11101057&partnerID=40&md5=43fbfc00476a18dd2bfd66ee1549147f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISEDA65950.2025.11101057 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344641,
  title={ BTDT: Membership Inference Attacks Against Large Language Models  -  Lecture Notes in Computer Science },
  year={2025},
  author={S and Farokhghate and Shadi and A and Abbasi-Tadi and Ali and D and Alhadidi and Dima},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013741560&doi=10.1007%2F978-3-032-00624-0_21&partnerID=40&md5=487e483238ca66723dccc8e5b1775973 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-032-00624-0_21 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344642,
  title={ ETDH: Efficient Transformer Inference with Dynamic Head Selection in Collaborative Edge Environments  -  nan },
  year={2025},
  author={H and Chen and Haokun and X and Wang and Xiaogang and J and Li and Jiayi and Y and Du and Yuze},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013458777&doi=10.1109%2FECIE65947.2025.11086814&partnerID=40&md5=20bb3463b78e06a8e2dab893c813b33e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECIE65947.2025.11086814 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344643,
  title={ Accelerating LLM Inference on RISC-V Edge Devices via Vector Extension Optimization  -  Lecture Notes in Computer Science },
  year={2025},
  author={Z and Liu and Zhilong and L and Peng and Long and W and Wang and Wenzhu and K and Li and Ke and B and Zeng and Binrui and J and Yu and Jie and X and Liu and Xiaodong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013060244&doi=10.1007%2F978-981-96-9869-1_43&partnerID=40&md5=f21e859d0787181df7e2cb7ba0f5e1c6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-96-9869-1_43 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344644,
  title={ Bayesian Inference for Transformer Degradation Prediction: A Comparative Analysis with Traditional and Machine Learning Models  -  nan },
  year={2025},
  author={A and Jarosz and Anna and J and Baranowski and Jerzy},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012240395&doi=10.1109%2FEUROCON64445.2025.11073497&partnerID=40&md5=385fa1ba9d090457d7f2e4d75c6961fc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EUROCON64445.2025.11073497 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344645,
  title={ Scaling LLM Inference Architectures: A Performance Analysis for Chatbot Applications  -  nan },
  year={2025},
  author={A.M and Jain and M, Aditi and A and Jain and Ayush},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012182372&doi=10.1109%2FAIRC64931.2025.11077484&partnerID=40&md5=530fa9c964e19590d59d3017f2a868ce },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIRC64931.2025.11077484 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344646,
  title={ JointCloud LLM Inference Deployment Framework: A Cost-Aware Optimization Approach Based on Hybrid Genetic Reinforcement Learning  -  nan },
  year={2025},
  author={S and Cheng and Shuen and J and Zheng and Jiali and Y and Li and Yuxian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012107684&doi=10.1109%2FAIITA65135.2025.11047742&partnerID=40&md5=d79b59e6b401b6efefbfd78b0aece0d9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIITA65135.2025.11047742 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344647,
  title={ Meta-Learning and ReFT (Reasoning with Reinforced Fine-Tuning) are Used to Improve the Inference Accuracy of Large Language Models  -  nan },
  year={2025},
  author={M and Xi and Mingku and H and Yu and Hongzhi and F and Wan and Fucheng and M and Chen and Min and B and Lu and Baoqing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012106979&doi=10.1109%2FAIITA65135.2025.11047841&partnerID=40&md5=0b532a05d4718dc1ea40fd56b3d89e24 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIITA65135.2025.11047841 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344648,
  title={ AS-LLM: An LLM-based Framework for Industrial Autonomous System Relationship Inference  -  nan },
  year={2025},
  author={X and Hu and Xinyu and J and Zhang and Jierui and W and Liu and Wenhao and Z and Ma and Zihui},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012102041&doi=10.1109%2FICAISISAS64483.2025.11052174&partnerID=40&md5=a5ee7c1e0673ec815f8a71805397f3dd },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAISISAS64483.2025.11052174 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344649,
  title={ Research on efficient inference of large language model based on routing policy  -  nan },
  year={2025},
  author={P and Shan and Penghui and W and Xi and Wei and Y and Zhang and Yizhong and D and Liu and Dong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011981124&doi=10.1109%2FCISCE65916.2025.11065479&partnerID=40&md5=64a3a43f2a8a6580d5b8b5086d986ac3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CISCE65916.2025.11065479 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344650,
  title={ Accelerating LLM Inference for Multi-Round Medical Q&A  -  nan },
  year={2025},
  author={Z and Wang and Ziyu and A and Xiong and Anping and J and Shen and Jingcheng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011977591&doi=10.1109%2FISCTIS65944.2025.11065656&partnerID=40&md5=d990c0b4f3c49fb26965ac246a78991a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCTIS65944.2025.11065656 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344651,
  title={ TOPPINGS: CPU-Assisted, Rank-Aware Adapter Serving for LLM Inference  -  nan },
  year={2025},
  author={S and Li and Suyi and H and Lu and Hanfeng and T and Wu and Tianyuan and M and Yu and Minchen and Q and Weng and Qizhen and X and Chen and Xusheng and Y and Shan and Yizhou and B and Yuan and Binhang and W and Wang and Wei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011616278&partnerID=40&md5=9c09e769bcbbb2681c5be3c7cc2a970c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344652,
  title={ GeneralSparse: Bridging the Gap in SpMM for Pruned Large Language Model Inference on GPUs  -  nan },
  year={2025},
  author={Y and Wang and Yaoyu and X and Guo and Xiao and J and Xiao and Junmin and D and Chen and De and G and Tan and Guangming},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011601785&partnerID=40&md5=4adb6ee6efca598ceb6e6aff75beb425 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344653,
  title={ WaferLLM: Large Language Model Inference at Wafer Scale  -  nan },
  year={2025},
  author={C and He and Congjie and Y and Huang and Yeqi and P and Mu and Pei and Z and Miao and Ziming and J and Xue and Jilong and L and Ma and Lingxiao and F and Yang and Fan and L and Mai and Luo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011593902&partnerID=40&md5=c1ea557cdb8ee36d6b898b87577cadae },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344654,
  title={ Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements  -  nan },
  year={2025},
  author={S.M and Abtahi and Moein, Seyed and A and Azim and Akramul},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011348339&doi=10.1109%2FForge66646.2025.00017&partnerID=40&md5=bbbc92d38543dda9d378df2b8dd67f5d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Forge66646.2025.00017 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344655,
  title={ Development of a Transformer-based Framework for Deep Causal Inference and Prospective Forecasting in Financial Time Series  -  nan },
  year={2025},
  author={C and Qiu and Chen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011065496&doi=10.1109%2FICAID65275.2025.11034532&partnerID=40&md5=269269d477d30c7d91ddc3096185c61f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAID65275.2025.11034532 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344656,
  title={ SPIN: Accelerating Large Language Model Inference with Heterogeneous Speculative Models  -  Proceedings - IEEE INFOCOM },
  year={2025},
  author={F and Chen and Fahao and P and Li and Peng and T.H and Luan and H, Tom and Z and Su and Zhou and J and Deng and Jing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011062356&doi=10.1109%2FINFOCOM55648.2025.11044522&partnerID=40&md5=8c3c067f82849084cf20eb0132df42c4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOM55648.2025.11044522 },
  booktitle={ Proceedings - IEEE INFOCOM },
  chapter={0}
}

@article{rayyan-352344657,
  title={ C2F: Enabling Context-Aware Edge-Cloud Collaborative Inference for Foundation Models  -  Proceedings - IEEE INFOCOM },
  year={2025},
  author={M and Zhao and Mingyue and J and Shi and Jiayi and Z and Zhang and Zhengyuan and Y and Ling and Yue and G and Zhu and Guanzhou and D and Zhao and Dong and H and Ma and Huadong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011053260&doi=10.1109%2FINFOCOM55648.2025.11044700&partnerID=40&md5=63beb8245bd65fe944ff4821ce741a1f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOM55648.2025.11044700 },
  booktitle={ Proceedings - IEEE INFOCOM },
  chapter={0}
}

@article{rayyan-352344658,
  title={ Blind Baselines Beat Membership Inference Attacks for Foundation Models  -  nan },
  year={2025},
  author={D and Das and Debeshee and J and Zhang and Jie and F and Tranter and Florian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010813416&doi=10.1109%2FSPW67851.2025.00016&partnerID=40&md5=89f5f9af16d70821089194414e442be6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPW67851.2025.00016 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344659,
  title={ Boosting Static Resource Leak Detection via LLM-based Resource-Oriented Intention Inference  -  Proceedings - International Conference on Software Engineering },
  year={2025},
  author={C and Wang and Chong and J and Liu and Jianan and X and Peng and Xin and Y and Liu and Yang and Y and Lou and Yiling},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010330625&doi=10.1109%2FICSE55347.2025.00131&partnerID=40&md5=510ad9587d5c647be19e63315e98f8c6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE55347.2025.00131 },
  booktitle={ Proceedings - International Conference on Software Engineering },
  chapter={0}
}

@article{rayyan-352344660,
  title={ PROGRESSIVE MIXED-PRECISION DECODING FOR EFFICIENT LLM INFERENCE  -  nan },
  year={2025},
  author={H and Chen and Hao and F and Tan and Fuwen and A and Kouris and Alexandros and R and Lee and Royson and H and Fan and Hongxiang and S.I and Venieris and I, Stylianos},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010273356&partnerID=40&md5=592d3d19238cf944200c1992197cc96a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344661,
  title={ TRAINING NONLINEAR TRANSFORMERS FOR CHAIN-OF-THOUGHT INFERENCE: A THEORETICAL GENERALIZATION ANALYSIS  -  nan },
  year={2025},
  author={H and Li and Hongkang and S and Lu and Songtao and P and Chen and Pinyu and X and Cui and Xiaodong and M and Wang and Meng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010267756&partnerID=40&md5=18b02ab2780a9b20c3e3569d2940e1f8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344662,
  title={ REVISITING IN-CONTEXT LEARNING INFERENCE CIRCUIT IN LARGE LANGUAGE MODELS  -  nan },
  year={2025},
  author={H and Cho and Hakaze and M and Kato and Mariko and Y and Sakai and Yoshihiro and N and Inoue and Naoya},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010261304&partnerID=40&md5=a049f83274ade31196cfe29ecf2d964d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344663,
  title={ SFS: SMARTER CODE SPACE SEARCH IMPROVES LLM INFERENCE SCALING  -  nan },
  year={2025},
  author={J and Light and Jonathan and Y and Wu and Yue and Y and Sun and Yiyou and W and Yu and Wenchao and Y and Liu and Yanchi and X and Zhao and Xujiang and Z and Hu and Ziniu and H and Chen and Haifeng and W and Cheng and Wei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010260181&partnerID=40&md5=e7ede47026c9df2fa4c500517e4722c8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344664,
  title={ CIPHERPRUNE: EFFICIENT AND SCALABLE PRIVATE TRANSFORMER INFERENCE  -  nan },
  year={2025},
  author={Y and Zhang and Yancheng and J and Xue and Jiaqi and M and Zheng and Mengxin and M and Xie and Mimi and M and Zhang and Mingzhe and L and Jiang and Lei and Q and Lou and Qian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010254800&partnerID=40&md5=48b5e6ebe05b146405758ba65db55863 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344665,
  title={ INFERENCE SCALING LAWS: AN EMPIRICAL ANALYSIS OF COMPUTE-OPTIMAL INFERENCE FOR LLM PROBLEM-SOLVING  -  nan },
  year={2025},
  author={Y and Wu and Yangzhen and Z and Sun and Zhiqing and S and Li and Shanda and S.J and Welleck and J, Sean and Y and Yang and Yiming},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010254534&partnerID=40&md5=67e8954de50a442bfac60efad774ef23 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344666,
  title={ CATASTROPHIC FAILURE OF LLM UNLEARNING VIA QUANTIZATION  -  nan },
  year={2025},
  author={Z and Zhang and Zhiwei and F and Wang and Fali and X and Li and Xiaomin and Z and Wu and Zongyu and X and Tang and Xianfeng and H and Liu and Hui and Q and He and Qi and W and Yin and Wenpeng and S and Wang and Suhang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010240727&partnerID=40&md5=2024fc9cd54b5fbab83eb05f262f9047 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344667,
  title={ OPTIMIZED MULTI-TOKEN JOINT DECODING WITH AUXILIARY MODEL FOR LLM INFERENCE  -  nan },
  year={2025},
  author={Z and Qin and Zongyue and Z and Hu and Ziniu and Z and He and Zifan and N.B and Prakriya and Bhairavi, Neha and J.J and Cong and Jason, Jingsheng and Y and Sun and Yizhou},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010240668&partnerID=40&md5=9acaf59cfc91492ae42441518e87fffa },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344668,
  title={ SWIFT: ON-THE-FLY SELF-SPECULATIVE DECODING FOR LLM INFERENCE ACCELERATION  -  nan },
  year={2025},
  author={H and Xia and Heming and Y and Li and Yongqi and J and Zhang and Jun and C and Du and Cunxiao and W and Li and Wenjie},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010230700&partnerID=40&md5=b2e9dd7ea79f40e8f14d673e7502218d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344669,
  title={ DEFT: DECODING WITH FLASH TREE-ATTENTION FOR EFFICIENT TREE-STRUCTURED LLM INFERENCE  -  nan },
  year={2025},
  author={J and Yao and Jinwei and K and Chen and Kaiqi and K and Zhang and Kexun and J and You and Jiaxuan and B and Yuan and Binhang and Z and Wang and Zeke and T and Lin and Tao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010228897&partnerID=40&md5=200f875fac9bad5e2da449dfd46dbafb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344670,
  title={ R-SPARSE: RANK-AWARE ACTIVATION SPARSITY FOR EFFICIENT LLM INFERENCE  -  nan },
  year={2025},
  author={Z and Zhang and Zhenyu and Z and Liu and Zechun and Y and Tian and Yuandong and H and Khaitan and Harshit and Z and Wang and Zhangyang and S and Li and Steven},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010221513&partnerID=40&md5=140b93af60a8fc20afe7d7ccc0d6cd7f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344671,
  title={ DUOATTENTION: EFFICIENT LONG-CONTEXT LLM INFERENCE WITH RETRIEVAL AND STREAMING HEADS  -  nan },
  year={2025},
  author={G and Xiao and Guangxuan and J and Tang and Jiaming and J and Zuo and Jingwei and J and Guo and Junxian and S and Yang and Shang and H and Tang and Haotian and Y and Fu and Yao and S and Han and Song},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010221020&partnerID=40&md5=4c68e048492e5f8741a8f15c5cec93ba },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344672,
  title={ MOTHERNET: FAST TRAINING AND INFERENCE VIA HYPER-NETWORK TRANSFORMERS  -  nan },
  year={2025},
  author={A.C., Müller and C, Andreas and C.A and Curino and A, Carlo and R and Ramakrishnan and Raghu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010219885&partnerID=40&md5=18a7041757c14486bb66a91d159953a8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344673,
  title={ BIRD: A TRUSTWORTHY BAYESIAN INFERENCE FRAMEWORK FOR LARGE LANGUAGE MODELS  -  nan },
  year={2025},
  author={Y and Feng and Yu and B and Zhou and Ben and W and Lin and Weidong and D and Roth and Dan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010217363&partnerID=40&md5=9ea2b80993b3727295a7b51e09cb294a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344674,
  title={ SQUEEZEATTENTION: 2D MANAGEMENT OF KV-CACHE IN LLM INFERENCE VIA LAYER-WISE OPTIMAL BUDGET  -  nan },
  year={2025},
  author={Z and Wang and Zihao and B and Cui and Bin and S and Gan and Shaoduo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010211828&partnerID=40&md5=cf477b18e5582fb60a3b55346d3b83fd },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344675,
  title={ EFFICIENT INFERENCE FOR LARGE LANGUAGE MODEL-BASED GENERATIVE RECOMMENDATION  -  nan },
  year={2025},
  author={X and Lin and Xinyu and C and Yang and Chaoqun and W and Wang and Wenjie and Y and Li and Yongqi and C and Du and Cunxiao and F and Feng and Fuli and S.K and Ng and Kiong, See and T and Chua and Tatseng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010209231&partnerID=40&md5=d49ff42a913a05330b8c49b13b7afd3a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344676,
  title={ STYLE OUTWEIGHS SUBSTANCE: FAILURE MODES OF LLM JUDGES IN ALIGNMENT BENCHMARKING  -  nan },
  year={2025},
  author={B and Feuer and Benjamin and M and Goldblum and Micah and T and Datta and Teresa and S and Nambiar and Sanjana and R and Besaleli and Raz and S and Dooley and Samuel and M and Cembalest and Max and J.P and Dickerson and P, John},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010200795&partnerID=40&md5=43e93851219c35e5a39e1bd351ef764b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344677,
  title={ D2O: DYNAMIC DISCRIMINATIVE OPERATIONS FOR EFFICIENT LONG-CONTEXT INFERENCE OF LARGE LANGUAGE MODELS  -  nan },
  year={2025},
  author={Z and Wan and Zhongwei and X and Wu and Xinjian and Y and Zhang and Yu and Y and Xin and Yi and C and Tao and Chaofan and Z and Zhu and Zhihong and X and Wang and Xin and S and Luo and Siqi and J and Xiong and Jing and L and Wang and Longyue},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010199826&partnerID=40&md5=1397e8f2c64ca85387d030fe9e7e33b7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344678,
  title={ DS-LLM: LEVERAGING DYNAMICAL SYSTEMS TO ENHANCE BOTH TRAINING AND INFERENCE OF LARGE LANGUAGE MODELS  -  nan },
  year={2025},
  author={R and Song and Ruibing and C and Liu and Chuan and C and Wu and Chunshu and A and Li and Ang and D and Liu and Dongfang and Y and Wu and Yingnian and T and Geng and Tony},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010199778&partnerID=40&md5=ae71f85622cf6a58f747cf8af606f4e0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344679,
  title={ WARD: PROVABLE RAG DATASET INFERENCE VIA LLM WATERMARKS  -  nan },
  year={2025},
  author={N and Jovanovic and Nikola and R and Staab and Robin and M and Baader and Maximilian and M.T and Vechev and T, Martin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010193288&partnerID=40&md5=cd34b41de9b64e90de96acaad175b72f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344680,
  title={ INFERENCE-AWARE FINE-TUNING FOR BEST-OF-N SAMPLING IN LARGE LANGUAGE MODELS  -  nan },
  year={2025},
  author={Y and Chow and Yinlam and G and Tennenholtz and Guy and I., Gür and Izzeddin and V and Zhuang and Vincent and B and Dai and Bo and S and Thiagarajan and Sridhar and C.E and Boutilier and E, Craig and R and Agarwal and Rishabh and A and Kumar and Aviral and A and Faust and Aleksandra},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010187530&partnerID=40&md5=aa5c05dd6fcd4b6bf5505cc002a9427b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344681,
  title={ OPENRCA: CAN LARGE LANGUAGE MODELS LOCATE THE ROOT CAUSE OF SOFTWARE FAILURES?  -  nan },
  year={2025},
  author={J and Xu and Junjielong and Q and Zhang and Qinan and Z and Zhong and Zhiqing and S and He and Shilin and C and Zhang and Chaoyun and Q and Lin and Qingwei and D and Pei and Dan and P and He and Pinjia and D and Zhang and Dongmei and Q and Zhang and Qi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010186300&partnerID=40&md5=3494550a9166d6db3e6ad094321467c1 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344682,
  title={ Multi-Node Inference Architectures for Low-Latency LLM Serving  -  nan },
  year={2025},
  author={N.K and Gundla and Kumar, Naresh and S.H and Atthuluri and Harsha, Sri},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010172638&doi=10.1109%2FICoACT63339.2025.11004706&partnerID=40&md5=12efbcc7a242871645dc5de15fd5dbf2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoACT63339.2025.11004706 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344683,
  title={ Parallelization Techniques for Large Language Models: A Review from Training to Inference  -  Lecture Notes in Computer Science },
  year={2025},
  author={S and Liu and Shanwen and X and Tao and Xi and W and Cao and Weipeng and Z and Ming and Zhong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009869106&doi=10.1007%2F978-981-96-8725-1_25&partnerID=40&md5=5d7c2fb544b0046d9378fb93d79bf269 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-96-8725-1_25 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344684,
  title={ Context Adaptive Memory-Efficient LLM Inference for Edge Multi-Agent Systems  -  Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS },
  year={2025},
  author={H and Mohammed and Hamza and H and Yin and Hang and S and Boyapati and Sai},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009822872&partnerID=40&md5=7bc2f3fb51ed1c7e527defb18b1d8b74 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS },
  chapter={0}
}

@article{rayyan-352344685,
  title={ DynamicAttention: Dynamic KV Cache for Disaggregate LLM Inference  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={Z and Ding and Zhiqiang and T and Yang and Tongkai},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009603723&doi=10.1109%2FICASSP49660.2025.10890367&partnerID=40&md5=3eec6484431b120445d280381674421e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10890367 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344687,
  title={ Transitive Inference in Large Language Models and Prompting Intervention  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={W and Wu and Wenya and W and Deng and Weihong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009585766&doi=10.1109%2FICASSP49660.2025.10889585&partnerID=40&md5=ef0001004aa83a1796281a7f8e11e5e7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10889585 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344688,
  title={ StrucFormer: Structural Prior Guided Transformer for Mobile Crowdsensing Data Inference  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={X and Kang and Xu and S and Tian and Shouceng and F and Kou and Feifei and L and Shi and Lei and J and Ren and Jiadong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009584385&doi=10.1109%2FICASSP49660.2025.10890429&partnerID=40&md5=a35a8b91c2aa0694a46843d495e86b42 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10890429 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344689,
  title={ Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity  -  Proceedings - IEEE Symposium on Security and Privacy },
  year={2025},
  author={G and Yan and Guang and Y and Zhang and Yuhui and Z and Guo and Zimu and L and Zhao and Lutan and X and Chen and Xiaojun and C and Wang and Chen and W and Wang and Wenhao and D and Meng and Dan and R and Hou and Rui},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009323097&doi=10.1109%2FSP61157.2025.00182&partnerID=40&md5=fb9de45c4b28bf699325b2b6bb843121 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SP61157.2025.00182 },
  booktitle={ Proceedings - IEEE Symposium on Security and Privacy },
  chapter={0}
}

@article{rayyan-352344690,
  title={ Prompt Inversion Attack Against Collaborative Inference of Large Language Models  -  Proceedings - IEEE Symposium on Security and Privacy },
  year={2025},
  author={W and Qu and Wenjie and Y and Zhou and Yuguang and Y and Wu and Yongji and T and Xiao and Tingsong and B and Yuan and Binhang and Y and Li and Yiming and J and Zhang and Jiaheng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009321468&doi=10.1109%2FSP61157.2025.00160&partnerID=40&md5=f6ff6ecceced9b9373dea8f58b7ecb55 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SP61157.2025.00160 },
  booktitle={ Proceedings - IEEE Symposium on Security and Privacy },
  chapter={0}
}

@article{rayyan-352344691,
  title={ Lachesis: Predicting LLM Inference Accuracy using Structural Properties of Reasoning Paths  -  nan },
  year={2025},
  author={N and Kim and Naryeong and S and Kang and Sungmin and G and An and Gabin and S and Yoo and Shin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009156506&doi=10.1109%2FDeepTest66595.2025.00008&partnerID=40&md5=2c32c4e28557222a7b8bdd654f91dd3f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DeepTest66595.2025.00008 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344692,
  title={ Optimizing Attention for Efficient LLM Inference: A Review  -  nan },
  year={2025},
  author={S and Sun and Siyuan and J and Yu and Jinling and H and Liu and Hanshuo and H and Guo and Hanyun and Y and Cao and Yang and S and Zhang and Shouhua and J and Zhou and Jiehan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009154000&doi=10.1109%2FWCCCT65447.2025.11027973&partnerID=40&md5=2ecd3c51fd9cf41e9a2c3214f808b7a6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WCCCT65447.2025.11027973 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344693,
  title={ Explaining GitHub Actions Failures with Large Language Models: Challenges, Insights, and Limitations  -  IEEE International Conference on Program Comprehension },
  year={2025},
  author={P and Valenzuela-Toledo and Pablo and C and Wu and Chuyue and S and Hernandez and Sandro and A and Boll and Alexander and R and Machacek and Roman and S and Panichella and Sebastiano and T and Kehrer and Timo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009152139&doi=10.1109%2FICPC66645.2025.00037&partnerID=40&md5=5d6b589554824db09ea742fed6c23a6d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPC66645.2025.00037 },
  booktitle={ IEEE International Conference on Program Comprehension },
  chapter={0}
}

@article{rayyan-352344694,
  title={ Improving the Efficiency of LLM Inference Serving Systems  -  Lecture Notes in Computer Science },
  year={2025},
  author={K and Papaioannou and Konstantinos and T and Doudali, Dimitra and Thaleia},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008645828&doi=10.1007%2F978-3-031-90203-1_39&partnerID=40&md5=a1e28d3c7b68c4b807b4bf3cb1cdb4ab },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1007/978-3-031-90203-1_39 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344695,
  title={ How Propense Are Large Language Models at Producing Code Smells? A Benchmarking Study  -  Proceedings - International Conference on Software Engineering },
  year={2025},
  author={A and Velasco and Alejandro and D and Rodríguez-Cárdenas and Daniel and L.R and Alif and Rahman, Luftar and D and Nader-Palacio and David and D and Poshyvanyk and Denys},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008497880&doi=10.1109%2FICSE-NIER66352.2025.00025&partnerID=40&md5=3346d85c7aaf42478e32696332fb9c21 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSE-NIER66352.2025.00025 },
  booktitle={ Proceedings - International Conference on Software Engineering },
  chapter={0}
}

@article{rayyan-352344696,
  title={ Protecting Privacy against Membership Inference Attack with LLM Fine-tuning through Flatness  -  nan },
  year={2025},
  author={T and Chen and Tiejin and L and Da and Longchao and H and Zhou and Huixue and P and Li and Pingzhi and K and Zhou and Kaixiong and T and Chen and Tianlong and W and Hua and Wei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008424755&doi=10.1137%2F1.9781611978520.41&partnerID=40&md5=b19c25bdb2865612a784ec56469ae2c9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1137/1.9781611978520.41 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344697,
  title={ Taxonomy Inference for Tabular Data Using Large Language Models  -  Lecture Notes in Computer Science },
  year={2025},
  author={Z and Wu and Zhenyu and J and Chen and Jiaoyan and N.W and Paton and W, Norman},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008012410&doi=10.1007%2F978-3-031-94575-5_22&partnerID=40&md5=59fb679fd3a86e06b779edbbdc66d3bd },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-94575-5_22 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344698,
  title={ ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition  -  nan },
  year={2025},
  author={Y and Huang and Yinting and K and Zheng and Keran and Z and Yu and Zhewen and C.S and Bouganis and Savvas, Christos},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007975744&doi=10.1109%2FFCCM62733.2025.00046&partnerID=40&md5=71c49873f057947382c37cd6cff25464 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FCCM62733.2025.00046 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344699,
  title={ Piecewise-Linear Approximation of Self-Attention and Its Accuracy-Aware Training for Area-Efficient Vision Transformer Inference Accelerator  -  Proceedings - International Symposium on Quality Electronic Design, ISQED },
  year={2025},
  author={T and Kawamura and Teppei and Y and Masuda and Yukata and T and Ishihara and Tohru},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007554630&doi=10.1109%2FISQED65160.2025.11014475&partnerID=40&md5=eeb99d8c7bba9854d76a2b5b779cfc2a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISQED65160.2025.11014475 },
  booktitle={ Proceedings - International Symposium on Quality Electronic Design, ISQED },
  chapter={0}
}

@article{rayyan-352344700,
  title={ A Reproducibility Study on Consistent LLM Reasoning for Natural Language Inference over Clinical Trials  -  Lecture Notes in Computer Science },
  year={2025},
  author={A and Guimarães and Artur and J and Magalhães and João and B and Martins and Bruno},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006632120&doi=10.1007%2F978-3-031-88717-8_5&partnerID=40&md5=63435038106dedafa532d4591d39fc97 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-88717-8_5 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344701,
  title={ Research on LLM speculative inference in training-inference integrated computing infrastructure scenarios  -  Proceedings of SPIE - The International Society for Optical Engineering },
  year={2025},
  author={Z and Zhu and Zeya and M and Sun and Mengyu and E and Zheng and Enrong and M and Cai and Mengru},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005139458&doi=10.1117%2F12.3061241&partnerID=40&md5=d4edfde4bc290372e5631a67f1906dcd },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1117/12.3061241 },
  booktitle={ Proceedings of SPIE - The International Society for Optical Engineering },
  chapter={0}
}

@article{rayyan-352344702,
  title={ Diagnosing demagnetization failures in mining permanent magnet motors using residual neural network and transformer on cyclic spectrum images  -  Proceedings of SPIE - The International Society for Optical Engineering },
  year={2025},
  author={Y and Fu and Yangyi and W and Wang and Wenshuo and D and An and Di and J and Deng and Jinyu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004641294&doi=10.1117%2F12.3065078&partnerID=40&md5=ca3747087c3c0d42af3b1c54133fdd90 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1117/12.3065078 },
  booktitle={ Proceedings of SPIE - The International Society for Optical Engineering },
  chapter={0}
}

@article{rayyan-352344703,
  title={ Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={E and Casanova and Edresson and R and Langman and Ryan and P and Neekhara and Paarth and S.S and Hussain and Samarah, Shehzeen and J and Li and Jason and S and Ghosh and Subhankar and A and Jukić and Ante and S and Lee and Sang-gil},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003891310&doi=10.1109%2FICASSP49660.2025.10888202&partnerID=40&md5=452f96753b0f399678351b2c602fcf67 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888202 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344704,
  title={ EM-MIAs: Enhancing Membership Inference Attacks in Large Language Models through Ensemble Modeling  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={Z and Song and Zichen and S and Huang and Sitan and Z and Kang and Zhongfeng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003884857&doi=10.1109%2FICASSP49660.2025.10888320&partnerID=40&md5=c1e67ba010e1da1f04f9cd2abbacde5d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888320 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344705,
  title={ Enhancing Large Language Model Inference Efficiency via Lookahead Cache Filtering  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={J and Ou and Jie and Y and Chen and Yueming and S and Jiang and Shuaihong and W and Tian and Wenhong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003877642&doi=10.1109%2FICASSP49660.2025.10888646&partnerID=40&md5=928ea4b2e4bc7dfb9f171a75d694e92d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888646 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344706,
  title={ ScalaLog: Scalable Log-Based Failure Diagnosis Using LLM  -  Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  year={2025},
  author={L and Zhang and Lingzhe and T and Jia and Tong and M and Jia and Mengxi and Y and Wu and Yifan and H and Liu and Hongyi and Y and Li and Ying},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003863980&doi=10.1109%2FICASSP49660.2025.10888670&partnerID=40&md5=6e1a3a264340b8fe6302457f8af3a70f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888670 },
  booktitle={ Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing },
  chapter={0}
}

@article{rayyan-352344707,
  title={ throttLL'eM: Predictive GPU Throttling for Energy Efficient LLM Inference Serving  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={A.K and Kakolyris and Kosmas, Andreas and D and Masouros and Dimosthenis and P and Vavaroutsos and Petros and S and Xydis and Sotirios and D.J and Soudris and J, Dimitrios},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003417849&doi=10.1109%2FHPCA61900.2025.00103&partnerID=40&md5=c9a4af4d708c5e08c16f3f556e0308bf },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00103 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344708,
  title={ PAISE: PIM-Accelerated Inference Scheduling Engine for Transformer-based LLM  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={H and Lee and Hyojung and D and Baek and Daehyeon and J and Son and Jimyoung and J and Choi and Jieun and K and Moon and Kihyo and M and Jang and Minsung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003415728&doi=10.1109%2FHPCA61900.2025.00126&partnerID=40&md5=9858ac17a1da89ced15f952304d049f3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00126 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344710,
  title={ Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={C and Fang and Chao and M and Shi and Man and R and Geens and Robin and A and Symons and Arne and Z and Wang and Zhongfeng and M and Verhelst and Marian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003408949&doi=10.1109%2FHPCA61900.2025.00110&partnerID=40&md5=0bb41857e5ce136092fcb962b58abe5e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00110 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344711,
  title={ Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={L and Liu and Lian and S and Zhao and Shixin and B and Li and Bing and H and Ren and Haimeng and Z and Xu and Zhaohui and M and Wang and Mengdi and X and Li and Xiaowei and Y and Han and Yinhe and Y and Wang and Ying},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003404102&doi=10.1109%2FHPCA61900.2025.00129&partnerID=40&md5=4bd31c1e821a384bdd78da60eb124abe },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00129 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344712,
  title={ DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={J and Stojkovic and Jovan and C and Zhang and Chaojie and Í and Goiri, Íñigo and J and Torrellas and Josep and E and Choukse and Esha},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003402139&doi=10.1109%2FHPCA61900.2025.00102&partnerID=40&md5=170e4dd95fc10d19f1dffa29e9d15e64 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00102 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344713,
  title={ FACIL: Flexible DRAM Address Mapping for SoC-PIM Cooperative On-device LLM Inference  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={S and Seo and Seong-hoon and J and Kim and Junghoon and D and Lee and Donghyun and S and Yoo and Seonah and S and Moon and Seokwon and Y and Park and Yeonhong and J.W and Lee and W, Jae},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003395614&doi=10.1109%2FHPCA61900.2025.00127&partnerID=40&md5=d2befd32ecdbac31558e74ecb2bd6213 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00127 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344714,
  title={ VQ-LLM: High-performance Code Generation for Vector Quantization Augmented LLM Inference  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={Z and Liu and Zihan and X and Luo and Xinhao and J and Guo and Junxian and W and Ni and Wentao and Y and Zhou and Yangjie and Y and Guan and Yue and C and Guo and Cong and W and Cui and Weihao and Y and Feng and Yu and M and Guo and Minyi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003394516&doi=10.1109%2FHPCA61900.2025.00112&partnerID=40&md5=8c6c1d5c058f0c4670e649d609a3c1b0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00112 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344715,
  title={ LAD: Efficient Accelerator for Generative Inference of LLM with Locality Aware Decoding  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={H and Wang and Haoran and Y and Li and Yuming and H and Xu and Haobo and Y and Wang and Ying and L and Liu and Liqi and J and Yang and Jun and Y and Han and Yinhe},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003382205&doi=10.1109%2FHPCA61900.2025.00111&partnerID=40&md5=010d3d23e0ebebc8010f91f10b45c8f5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00111 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344716,
  title={ Lincoln: Real-Time 50∼100B LLM Inference on Consumer Devices with LPDDR-Interfaced, Compute-Enabled Flash Memory  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2025},
  author={W and Sun and Weiyi and M and Gao and Mingyu and Z and Li and Zhaoshi and A and Zhang and Aoyang and I.Y and Chou and Ying, Iris and J and Zhu and Jianfeng and S and Wei and Shaojun and L and Liu and Leibo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003373081&doi=10.1109%2FHPCA61900.2025.00128&partnerID=40&md5=90df5f95e66f2f790f419582f4f901a7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA61900.2025.00128 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344717,
  title={ Understanding the Inference Performance of Spatial Temporal Diffusion Transformer  -  Lecture Notes in Computer Science },
  year={2025},
  author={Y and Li and Yu and Y and Wei and Yuanxin and J and Du and Jiangsu and D and Huang and Dan and N and Xiao and Nong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002372025&doi=10.1007%2F978-981-96-2830-8_37&partnerID=40&md5=b28e1def7dd2b16598bd44cd562c4f72 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-96-2830-8_37 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344718,
  title={ Framework for Identifying Failure Mechanisms in Consumer Electronics Using Large Language Models  -  Proceedings - Annual Reliability and Maintainability Symposium },
  year={2025},
  author={E and So and Eunseo and M.H and Modarres and H, Mo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002273992&doi=10.1109%2FRAMS48127.2025.10935274&partnerID=40&md5=d0eb0e8fb2be575c71a15f0d371fc4a3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAMS48127.2025.10935274 },
  booktitle={ Proceedings - Annual Reliability and Maintainability Symposium },
  chapter={0}
}

@article{rayyan-352344719,
  title={ IMPRESS: An Importance-Informed Multi-Tier Prefix KV Storage System for Large Language Model Inference  -  nan },
  year={2025},
  author={W and Chen and Weijian and S and He and Shuibing and H and Qu and Haoyang and R and Zhang and Ruidong and S and Yang and Siling and P and Chen and Ping and Y and Zheng and Yi and B and Huai and Baoxing and G and Chen and Gang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002240838&partnerID=40&md5=2f7d5838ff59aed186458fae49d505f5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344720,
  title={ Best Practices for Distilling Large Language Models into BERT for Web Search Ranking  -  Proceedings - International Conference on Computational Linguistics, COLING },
  year={2025},
  author={D and Ye and Dezhi and J and Hu and Junwei and J and Fan and Jiabin and B and Tian and Bowen and J and Liu and Jie and H and Liang and Haijin and J and Ma and Jin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000152550&partnerID=40&md5=0fc45660f609f548a99f40d9bd31fb77 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings - International Conference on Computational Linguistics, COLING },
  chapter={0}
}

@article{rayyan-352344721,
  title={ Research on Inference and Training Acceleration of Large Language Model  -  nan },
  year={2024},
  author={Q and Chen and Qianyu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216086341&doi=10.1145%2F3703187.3703238&partnerID=40&md5=838cc7ecdde085c7372d729b6de41822 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3703187.3703238 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344722,
  title={ MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices  -  nan },
  year={2024},
  author={Z and Wang and Zhaode and J and Yang and Jingbang and X and Qian and Xinyu and S and Xing and Shiwen and X and Jiang and Xiaotang and C and Lv and Chengfei and S and Zhang and Shengyu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216519752&doi=10.1145%2F3700410.3702126&partnerID=40&md5=d9c97c8f1ecb8259c367d07a98ee826b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3700410.3702126 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344723,
  title={ Membership Inference Attacks against Vision Transformers: Mosaic MixUp Training to the Defense  -  nan },
  year={2024},
  author={Q and Zhang and Qiankun and D and Yuan and Di and B and Zhang and Boyu and B and Yuan and Bin and B and Du and Bingqian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215532105&doi=10.1145%2F3658644.3690268&partnerID=40&md5=419fa38886d65d8549215e35dbbb58c5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3658644.3690268 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344724,
  title={ A First Look At Efficient And Secure On-Device LLM Inference Against KV Leakage  -  nan },
  year={2024},
  author={H and Yang and Huan and D and Zhang and Deyu and Y and Zhao and Yudong and Y and Li and Yuanchun and Y and Liu and Yunxin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214946292&doi=10.1145%2F3691555.3696827&partnerID=40&md5=56cfde73c140fa5896484c4113c94d8c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3691555.3696827 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344725,
  title={ QUQ: Quadruplet Uniform Quantization for Efficient Vision Transformer Inference  -  nan },
  year={2024},
  author={X and Geng and Xinkuang and S and Liu and Siting and L and Liu and Leibo and J and Han and Jie and H and Jiang and Honglan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211117553&doi=10.1145%2F3649329.3656516&partnerID=40&md5=659d1038218ef415e9aff8931ea84dbf },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3649329.3656516 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344726,
  title={ Leveraging Prompt Tuning-Based Cognitive Attention to Enhance Logical Inference in Large Language Models  -  nan },
  year={2024},
  author={X and Li and Xiaoyan and C and Jiang and Cuicui},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212496614&doi=10.1145%2F3698383.3699622&partnerID=40&md5=366d0b8fded6ea6854555a8beaaf0052 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3698383.3699622 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344727,
  title={ LLM Meets Bounded Model Checking: Neuro-symbolic Loop Invariant Inference  -  nan },
  year={2024},
  author={G and Wu and Guangyuan and W and Cao and Weining and Y and Yao and Yuan and H and Wei and Hengfeng and T and Chen and Taolue and X and Ma and Xiaoxing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212418622&doi=10.1145%2F3691620.3695014&partnerID=40&md5=d231f289e0d62c0b67d7458e582683b7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3691620.3695014 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344729,
  title={ Foreseer: Knowledge-Driven Acceleration of Memory-Bound Matrix Multiplications for Large Language Model Inference  -  nan },
  year={2024},
  author={C and Li and Cong and Y and Xu and Yutao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206848613&doi=10.1145%2F3688351.3689153&partnerID=40&md5=24a280ea7c58c22b13b65f68210de7ac },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3688351.3689153 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344730,
  title={ TwinPilots: A New Computing Paradigm for GPU-CPU Parallel LLM Inference  -  nan },
  year={2024},
  author={C and Yu and Chengye and T and Wang and Tianyu and Z and Shao and Zili and L and Zhu and Linjie and X and Zhou and Xu and S and Jiang and Song},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206839866&doi=10.1145%2F3688351.3689164&partnerID=40&md5=9a67f9ca541072ba2868099ae5a8c0ad },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3688351.3689164 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344732,
  title={ Enhancing On-Device LLM Inference with Historical Cloud-Based LLM Interactions  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2024},
  author={Y and Ding and Yucheng and C and Niu and Chaoyue and J and Lei and Jiale and S and Tang and Shaojie and C and Lyu and Chengfei and G and Chen and Guihai},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203712551&doi=10.1145%2F3637528.3671679&partnerID=40&md5=b8510391f59d63d2bfd66e44752d40f7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3637528.3671679 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352344733,
  title={ Inference Optimization of Foundation Models on AI Accelerators  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2024},
  author={Y and Park and Youngsuk and K and Budhathoki and Kailash and L and Chen and Liangfu and J.M., Kübler and M, Jonas and J and Huang and Jiaji and M and Kleindessner and Matthaus and J and Huan and Jun and V and Cevher and Volkan and Y and Wang and Yida and G and Karypis and George},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203686341&doi=10.1145%2F3637528.3671465&partnerID=40&md5=99b0ba72c812a7e2db01bd3e2fd6a4dc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3637528.3671465 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352344734,
  title={ Time-Aware Attention-Based Transformer (TAAT) for Cloud Computing System Failure Prediction  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2024},
  author={L and Deng and Lingfei and Y and Wang and Yunong and H and Wang and Haoran and X and Ma and Xuhua and X and Du and Xiaoming and X and Zheng and Xudong and D and Wu and Dongrui},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203673911&doi=10.1145%2F3637528.3671547&partnerID=40&md5=a0aa00ee381f9e5afd600e9ab7cee7e9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3637528.3671547 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352344735,
  title={ Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2024},
  author={Y and Zhao and Yao and Z and Xie and Zhitian and C and Liang and Chen and C and Zhuang and Chenyi and J and Gu and Jinjie},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203666888&doi=10.1145%2F3637528.3671614&partnerID=40&md5=734812fda31f00bf949baa08c37baadb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3637528.3671614 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352344736,
  title={ IMI: In-memory Multi-job Inference Acceleration for Large Language Models  -  nan },
  year={2024},
  author={B and Gao and Bin and Z and Wang and Zhehui and Z and He and Zhuomin and T and Luo and Tao and W and Weng-Fai and Wong and Z and Zhou and Zhi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202442657&doi=10.1145%2F3673038.3673053&partnerID=40&md5=b4160a9969c8c0dc4326b23ed92dfab5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3673038.3673053 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344737,
  title={ Large Language Models Based Stemming for Information Retrieval: Promises, Pitfalls and Failures  -  nan },
  year={2024},
  author={S and Wang and Shuai and S and Zhuang and Shengyao and G and Zuccon and Guido},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200540005&doi=10.1145%2F3626772.3657949&partnerID=40&md5=0e45e756cf122e5783eaa80dcdec1215 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3626772.3657949 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344738,
  title={ Hybrid SLM and LLM for Edge-Cloud Collaborative Inference  -  nan },
  year={2024},
  author={Z and Hao and Zixu and H and Jiang and Huiqiang and S and Jiang and Shiqi and J and Ren and Ju and T and Cao and Ting},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197317985&doi=10.1145%2F3662006.3662067&partnerID=40&md5=07091cfc5ab118d81adc182838879f9d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3662006.3662067 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344740,
  title={ An Autonomous Parallelization of Transformer Model Inference on Heterogeneous Edge Devices  -  nan },
  year={2024},
  author={J and Lee and Juhyeon and I and Bahk and Insung and H and Kim and Hoseung and S and Jeong and Sinjin and S and Lee and Suyeon and D and Min and Donghyun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196295588&doi=10.1145%2F3650200.3656628&partnerID=40&md5=5cc3625b06cae36d105d0867923213c3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3650200.3656628 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344741,
  title={ EchoSwift: An Inference Benchmarking and Configuration Discovery Tool for Large Language Models (LLMs)  -  nan },
  year={2024},
  author={K and Krishna and Karthik and R and Bandili and Ramana},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193918193&doi=10.1145%2F3629527.3652273&partnerID=40&md5=2c8b60d6732067425d3a4da2b7ce70dc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3629527.3652273 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344742,
  title={ 8-bit Transformer Inference and Fine-tuning for Edge Accelerators  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2024},
  author={J and Yu and Jeffrey and K and Prabhu and Kartik and Y and Urman and Yonatan and R.M and Radway and M, Robert and E and Han and Eric and P and Raina and Priyanka},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192218455&doi=10.1145%2F3620666.3651368&partnerID=40&md5=a2e8545d0c03f8df8673b98aae08eeec },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3620666.3651368 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344743,
  title={ AttAcc! Unleashing the Power of PIM for Batched Transformer-based Generative Model Inference  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2024},
  author={J and Park and Jaehyun and J and Choi and Jaewan and K and Kyung and Kwanhee and M.J and Kim and Jaemin, Michael and Y and Kwon and Yongsuk and N and Kim and Namsung and J.H and Ahn and Ho, Jung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192177035&doi=10.1145%2F3620665.3640422&partnerID=40&md5=09e9dac5d8ee1b269988ee122073a5b8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3620665.3640422 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344744,
  title={ SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2024},
  author={X and Miao and Xupeng and G and Oliaro and Gabriele and Z and Zhang and Zhihao and X and Cheng and Xinhao and Z and Wang and Zeyu and Z and Zhang and Zhengxin and R.Y.Y and Wong and Yee, Rae Ying and A and Zhu and Alan and L and Yang and Lijie and X and Shi and Xiaoxiang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192163386&doi=10.1145%2F3620666.3651335&partnerID=40&md5=c9c877e2214075185da081aefaf0adb7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3620666.3651335 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344745,
  title={ ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference  -  International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  year={2024},
  author={H and Oh and Hyungjun and K and Kim and Kihong and J and Kim and Jaemin and S and Kim and Sungkyun and J and Lee and Junyeol and D and Chang and Duseong and J and Seo and Jiwon},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192157479&doi=10.1145%2F3620665.3640383&partnerID=40&md5=6f87976c93a9d838630347b3b558765d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3620665.3640383 },
  booktitle={ International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS },
  chapter={0}
}

@article{rayyan-352344746,
  title={ The Importance of Workload Choice in Evaluating LLM Inference Systems  -  nan },
  year={2024},
  author={K and Papaioannou and Konstantinos and T.D and Doudali and Dimitra, Thaleia},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192271316&doi=10.1145%2F3642970.3655823&partnerID=40&md5=62785d8738f8a9d9854252d278e7c24d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"} | USER-NOTES: {"Brahim"=>["UMM"]}},
  doi={ 10.1145/3642970.3655823 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344748,
  title={ Combining Ontology and Large Language Models to Identify Recurring Machine Failures in Free-Text Fields  -  Advances in Transdisciplinary Engineering },
  year={2024},
  author={M and Bengtsson and Marcus and R.S., D’Cruze and Stanley, Ricky and M.U and Ahmed and Uddin, Mobyen and T and Sakao and Tomohiko and P.J and Funk and J, Peter and R and Sohlberg and Rickard},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191305248&doi=10.3233%2FATDE240151&partnerID=40&md5=da0ede59df41ae4bd71be8b685a65793 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.3233/ATDE240151 },
  booktitle={ Advances in Transdisciplinary Engineering },
  chapter={0}
}

@article{rayyan-352344749,
  title={ FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs  -  nan },
  year={2024},
  author={S and Zeng and Shulin and J and Liu and Jun and G and Dai and Guohao and X and Yang and Xinhao and T and Fu and Tianyu and H and Wang and Hongyi and W and Ma and Wenheng and H and Sun and Hanbo and S and Li and Shiyao and Z and Huang and Zixiao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190797845&doi=10.1145%2F3626202.3637562&partnerID=40&md5=c1a0f0d410cedb2099f6a615731ed408 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3626202.3637562 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344750,
  title={ OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models  -  Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2024},
  author={C and Lee and Changhun and J and Jin and Jungyu and T and Kim and Taesu and H and Kim and Hyungjun and E and Park and Eunhyeok},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189558813&doi=10.1609%2Faaai.v38i12.29237&partnerID=40&md5=0ae026545af3f553a7095cdd14dce2dc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v38i12.29237 },
  booktitle={ Proceedings of the AAAI Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344751,
  title={ A Generalizable Architecture for Explaining Robot Failures Using Behavior Trees and Large Language Models  -  ACM/IEEE International Conference on Human-Robot Interaction },
  year={2024},
  author={C and Tagliamonte and Christian and D and MacCaline and Daniel and G and LeMasurier and Gregory and H.A and Yanco and A, Holly},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188053925&doi=10.1145%2F3610978.3640551&partnerID=40&md5=634ab0a296b1c83dbccc7d7238762572 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3610978.3640551 },
  booktitle={ ACM/IEEE International Conference on Human-Robot Interaction },
  chapter={0}
}

@article{rayyan-352344752,
  title={ Integrating Knowledge Graph Data with Large Language Models for Explainable Inference  -  nan },
  year={2024},
  author={C.E and Quintero-Narvaez and Efrain, Carlos and R and Monroy and Raúl},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191738394&doi=10.1145%2F3616855.3636507&partnerID=40&md5=3337c3d9b60471a0e370bc587c8bbf5f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3616855.3636507 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344754,
  title={ Performance Characterization of Expert Router for Scalable LLM Inference  -  nan },
  year={2024},
  author={J and Pichlmeier and Josef and P and Ross and Philipp and A and Luckow and André},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218027915&doi=10.1109%2FBigData62323.2024.10826121&partnerID=40&md5=dead1b95021f6015d5edd47a6c3bc939 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10826121 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344755,
  title={ Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters  -  nan },
  year={2024},
  author={E and Yi and Euiin and T and Kim and Taehyeon and H and Jeung and Hongseok and D and Chang and Duseong and S and Yun and Seyoung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217820339&doi=10.18653%2Fv1%2F2024.emnlp-main.602&partnerID=40&md5=a433192bb5b576ef03d394c2d3dfbc70 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.602 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344756,
  title={ Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models  -  nan },
  year={2024},
  author={J and Huang and Jerry and P and Parthasarathi and Prasanna and M and Rezagholizadeh and Mehdi and S and Chandar and Sarath},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217811155&doi=10.18653%2Fv1%2F2024.emnlp-main.332&partnerID=40&md5=93abe050b93c26fa7c7013e5561e8aa7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.332 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344757,
  title={ Order of Magnitude Speedups for LLM Membership Inference  -  nan },
  year={2024},
  author={R and Zhang and Rongting and M.A and Bertrán and A, Mart´In and A.L and Roth and L, Aaron},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217804240&doi=10.18653%2Fv1%2F2024.emnlp-main.253&partnerID=40&md5=7472aa22504632c9ec665a364ff3f951 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.253 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344758,
  title={ A Systematic Analysis of Large Language Models as Soft Reasoners: The Case of Syllogistic Inferences  -  nan },
  year={2024},
  author={L and Bertolazzi and Leonardo and A and Gatt and Albert and R and Bernardi and Raffaella},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217804120&doi=10.18653%2Fv1%2F2024.emnlp-main.769&partnerID=40&md5=2913ffe56607c5c5d982a9a1088b5975 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.769 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344759,
  title={ Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model  -  nan },
  year={2024},
  author={C and Yuan and Chenhan and F and Huang and Fei and R and Peng and Ru and K and Lu and Keming and B and Yu and Bowen and C and Zhou and Chang and J and Zhou and Jingren},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217794361&doi=10.18653%2Fv1%2F2024.emnlp-main.316&partnerID=40&md5=dbec98d801b4c996553fe407a5965e62 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.316 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344760,
  title={ Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks  -  nan },
  year={2024},
  author={Y and Zhou and Yue and H.P and Zou and Peng, Henry and B and Eugenio, Di and Barbara and Y and Zhang and Yang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217778144&doi=10.18653%2Fv1%2F2024.emnlp-main.738&partnerID=40&md5=1f2a78098e304fc814f83d760de27049 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.738 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344761,
  title={ RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference  -  nan },
  year={2024},
  author={Y and Xu and Yige and X and Guo and Xu and Z and Zeng and Zhiwei and C and Miao and Chunyan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217755189&doi=10.18653%2Fv1%2F2024.emnlp-main.1232&partnerID=40&md5=b9f5a5b790462cbded68ca713c30eef7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.1232 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344762,
  title={ QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models  -  nan },
  year={2024},
  author={S and Ashkboos and Saleh and I and Markov and Ilia and E and Frantar and Elias and T and Zhong and Tingxuan and X and Wang and Xingchen and J and Ren and Jie and T and Hoefler and Torsten and D and Alistarh and Dan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217745543&doi=10.18653%2Fv1%2F2024.emnlp-main.197&partnerID=40&md5=cbcdb2508160b7cd5180a8f80bf4380a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.197 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344763,
  title={ CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification  -  nan },
  year={2024},
  author={J and He and Junhui and S and Wu and Shangyu and W and Wen and Weidong and C.J and Xue and Jason, Chun and Q and Li and Qing-An},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217733429&doi=10.18653%2Fv1%2F2024.emnlp-main.1038&partnerID=40&md5=2b4121da8191b9834a1f311572fcfb31 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.18653/v1/2024.emnlp-main.1038 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344764,
  title={ Contextual Health State Inference from Lifelog Data Using LLM  -  International Conference on ICT Convergence },
  year={2024},
  author={J and Park and Joohye and Y and Kim and Yeongkyo and J and Song and Jihyuk and H and Lee and Hangil},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217695311&doi=10.1109%2FICTC62082.2024.10827013&partnerID=40&md5=9227f2cf5767c3856517fbba2a8b192d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICTC62082.2024.10827013 },
  booktitle={ International Conference on ICT Convergence },
  chapter={0}
}

@article{rayyan-352344765,
  title={ Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation  -  nan },
  year={2024},
  author={Q and Zhu and Qin and Q and Cheng and Qinyuan and R and Peng and Runyu and X and Li and Xiaonan and T and Liu and Tengxiao and R and Peng and Ru and X and Qiu and Xipeng and X and Huang and Xuanjing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217621898&doi=10.18653%2Fv1%2F2024.findings-emnlp.532&partnerID=40&md5=9cbf82ecf115c4f83451f5ee0410265e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.532 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344766,
  title={ Identifying Factual Inconsistencies in Summaries: Grounding LLM Inference via Task Taxonomy  -  nan },
  year={2024},
  author={L and Xu and Liyan and Z and Su and Zhenlin and M and Yu and Mo and J and Xu and Jin and J.D and Choi and D, Jinho and J and Zhou and Jie and F and Liu and Fei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217621216&doi=10.18653%2Fv1%2F2024.findings-emnlp.857&partnerID=40&md5=07386d102d418a64d26f01f3cdf16b18 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.857 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344767,
  title={ Pruning Multilingual Large Language Models for Multilingual Inference  -  nan },
  year={2024},
  author={H and Kim and Hwichan and J and Suzuki and Jun and T and Hirasawa and Tosho and M and Komachi and Mamoru},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217621167&doi=10.18653%2Fv1%2F2024.findings-emnlp.580&partnerID=40&md5=cf7fe9ab5e353db61b407e74c1326107 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.580 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344768,
  title={ Explicit Inductive Inference using Large Language Models  -  nan },
  year={2024},
  author={T and Liu and Tianyang and T and Li and Tianyi and L and Cheng and Liang and M.J and Steedman and J, Mark},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217620055&doi=10.18653%2Fv1%2F2024.findings-emnlp.926&partnerID=40&md5=de82d61e961f472eaf16c9c536c0a60f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.926 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344769,
  title={ Exploring the Best Practices of Query Expansion with Large Language Models  -  nan },
  year={2024},
  author={L and Zhang and Le and Y and Wu and Yihong and Q and Yang and Qian and J and Nie and Jianyun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217619459&doi=10.18653%2Fv1%2F2024.findings-emnlp.103&partnerID=40&md5=7a8251528648fa6ce5240573fed000f7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.103 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344770,
  title={ Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions  -  nan },
  year={2024},
  author={J and Meadows and Jordan and T and James and Tamsin and A and Freitas and André},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217616838&doi=10.18653%2Fv1%2F2024.findings-emnlp.378&partnerID=40&md5=1c8391658279a18e657af9e53ba42a3b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.378 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344771,
  title={ Improving the Inference Efficiency of Transformer Models in Machine Translation Tasks by Low-rank Decomposition Methods  -  nan },
  year={2024},
  author={Z and Liu and Zhijia},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217391477&doi=10.1109%2FICEDCS64328.2024.00173&partnerID=40&md5=0771c14cb92481900c4f355f1942ddab },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEDCS64328.2024.00173 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344772,
  title={ SpaChat: Integrating Single-Cell Foundation Model with Cell Graph Network for Spatially Resolved Cell-Cell Communication Inference  -  nan },
  year={2024},
  author={D and Qiao and Debin and B and Ji and Boya and H and Xia and Hong and S and Peng and Shaoliang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217277949&doi=10.1109%2FBIBM62325.2024.10822648&partnerID=40&md5=ce2f5fdb7414b17a40a60406f171f2c2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BIBM62325.2024.10822648 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344774,
  title={ SPROUT: Green Generative AI with Carbon-Efficient LLM Inference  -  nan },
  year={2024},
  author={B and Li and Baolin and V.N and Gadepally and N, Vijay and Y and Jiang and Yankai and D and Tiwari and Devesh},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217146672&doi=10.18653%2Fv1%2F2024.emnlp-main.1215&partnerID=40&md5=9f63b330cb6c72d88ce3d22579d9c85b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.1215 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344775,
  title={ Vision Transformer Inference on a CNN Accelerator  -  Proceedings - IEEE International Conference on Computer Design: VLSI in Computers and Processors },
  year={2024},
  author={C and Yi and Changjae and H and Moh and Hyunsu and S and Hat and Soonhoi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217065062&doi=10.1109%2FICCD63220.2024.00101&partnerID=40&md5=1bbfca75ad018a63672c900678bf248f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCD63220.2024.00101 },
  booktitle={ Proceedings - IEEE International Conference on Computer Design: VLSI in Computers and Processors },
  chapter={0}
}

@article{rayyan-352344776,
  title={ Best Practices of Successive Halving on Neural Machine Translation and Large Language Models  -  nan },
  year={2024},
  author={X and Zhang and Xuan and K and Duh and Kevin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217063378&partnerID=40&md5=a54c01a5b9ec8cbc43ad0e77884c0b07 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344777,
  title={ Speculative Streaming: Fast LLM Inference without Auxiliary Models  -  Proceedings of Machine Learning Research },
  year={2024},
  author={N and Bhendawade and Nikhil and I and Belousova and Irina and Q and Fu and Qichen and H and Mason and Henry and M and Rastegari and Mohammad and M and Najibi and Mahyar},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216814538&partnerID=40&md5=0280ceed12f5dd960f4805e5d4e53074 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344778,
  title={ Distributed Speculative Inference of Large Language Models  -  Proceedings of Machine Learning Research },
  year={2024},
  author={N and Timor and Nadav and J and Mamou and Jonathan and D and Korat and Daniel and M and Berchansky and Moshe and O and Pereg and Oren and M and Wasserblat and Moshe and T and Galanti and Tomer and M and Gordon and Michal and D and Harel and David},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216768822&partnerID=40&md5=5a75b68992fd970ef8600a67a065ad12 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344779,
  title={ TensorOpera Router: A Multi-Model Router for Efficient LLM Inference  -  nan },
  year={2024},
  author={D and Stripelis and Dimitris and Z and Hu and Zijian and J and Zhang and Jipeng and Z and Xu and Zhaozhuo and A.D and Shah and Dilipbhai, Alay and H and Jin and Han and Y and Yao and Yuhang and T and Zhang and Tong and A.S and Avestimehr, A. Salman and C and He and Chaoyang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216763709&doi=10.18653%2Fv1%2F2024.emnlp-industry.34&partnerID=40&md5=ace7c8c6590722d5551642947d4ed21c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-industry.34 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344780,
  title={ GEAR: An Efficient Error Reduction Framework for KV Cache Compression in LLM Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={H and Kang and Hao and Q and Zhang and Qingru and S and Kundu and Souvik and G and Jeong and Geonhwa and Z and Liu and Zaoxing and T and Krishna and Tushar and T and Zhao and Tuo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216747892&partnerID=40&md5=ca159c16afffbe2bb8343b6b8f820177 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344781,
  title={ Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization  -  nan },
  year={2024},
  author={M.T.R and Laskar and Rahman, Md Tahmid and E and Khasanova and Elena and X and Fu and Xueyong and C and Chen and Cheng and S.T.N and Bhushan and T.N, Shashi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216745499&doi=10.18653%2Fv1%2F2024.emnlp-industry.86&partnerID=40&md5=f50266b9cb283c0ba748a220308fcd53 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-industry.86 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344784,
  title={ Transformer-Based Relationship Inference Model for Household Object Organization by Integrating Graph Topology and Ontology  -  IEEE International Conference on Intelligent Robots and Systems },
  year={2024},
  author={X and Li and Xiaodong and G and Tian and Guohui and Y and Cui and Yongcheng and Y and Gu and Yu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216453259&doi=10.1109%2FIROS58592.2024.10802781&partnerID=40&md5=bf5dcafaa0b38aea0f34bc9fa37c48f7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IROS58592.2024.10802781 },
  booktitle={ IEEE International Conference on Intelligent Robots and Systems },
  chapter={0}
}

@article{rayyan-352344785,
  title={ Knowledge Graph-Enhanced Semantic Cache for Low-Latency and Cost-Effective Inference in Large Language Models  -  nan },
  year={2024},
  author={N and Dominic and Nicholas and B and Pardamean and Bens},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216034299&doi=10.1109%2FICIMTech63123.2024.10780864&partnerID=40&md5=365af1832fbe2c1165997665b4a10cfe },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIMTech63123.2024.10780864 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344788,
  title={ Improving Throughput-Oriented LLM Inference with CPU Computations  -  Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT },
  year={2024},
  author={D and Park and Daon and B and Egger and Bernhard},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215527824&doi=10.1145%2F3656019.3676949&partnerID=40&md5=1ce62565cecb71d6a11db5b7c3ede4e1 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3656019.3676949 },
  booktitle={ Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT },
  chapter={0}
}

@article{rayyan-352344789,
  title={ D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models  -  nan },
  year={2024},
  author={D and Altinok and Duygu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215523564&doi=10.18653%2Fv1%2F2024.semeval-1.91&partnerID=40&md5=f3582f45e0847eebdfed63d2fac1099c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.semeval-1.91 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344790,
  title={ Adaptive Batch Budget for LLM Inference  -  nan },
  year={2024},
  author={Ç and Yeşil, Çağrı and B.T and Ay and Türkü, Berhan and F.A and Ak and Ay, Funda and Ö.B and Mercan, Öykü Berfin and O and Nefesoǧlu, Oǧuzhan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215516293&doi=10.1109%2FUBMK63289.2024.10773573&partnerID=40&md5=365b998b221e1cbc83f0b6dcba950a4a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UBMK63289.2024.10773573 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344791,
  title={ A Queueing Theoretic Perspective on Low-Latency LLM Inference with Variable Token Length  -  Proceedings of the International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks, WiOpt },
  year={2024},
  author={Y and Yang and Yuqing and L and Jiao and Lei and Y and Xu and Yuedong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215510507&partnerID=40&md5=8303d6dd528b3f7c553620d9fe0d1094 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of the International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks, WiOpt },
  chapter={0}
}

@article{rayyan-352344793,
  title={ PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation  -  International Conference for High Performance Computing, Networking, Storage and Analysis, SC },
  year={2024},
  author={B and Butler and Branden and S and Yu and Sixing and A and Mazaheri and Arya and A and Jannesari and Ali},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214984522&doi=10.1109%2FSC41406.2024.00046&partnerID=40&md5=f9f6d8bb4e8ba9088b2d10a4517f1025 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SC41406.2024.00046 },
  booktitle={ International Conference for High Performance Computing, Networking, Storage and Analysis, SC },
  chapter={0}
}

@article{rayyan-352344794,
  title={ LLM-Pilot: Characterize and Optimize Performance of your LLM Inference Services  -  International Conference for High Performance Computing, Networking, Storage and Analysis, SC },
  year={2024},
  author={M and Lazuka and Malgorzata and A.S and Anghel and S, Andreea and T.P and Parnell and P, Thomas},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214974705&doi=10.1109%2FSC41406.2024.00022&partnerID=40&md5=8024f66d08ce692c834750dd41cea59e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SC41406.2024.00022 },
  booktitle={ International Conference for High Performance Computing, Networking, Storage and Analysis, SC },
  chapter={0}
}

@article{rayyan-352344795,
  title={ A Low Power Attention and Softmax Accelerator for Large Language Models Inference  -  nan },
  year={2024},
  author={J and Kim and Jeong-hyun and C and Kim and Chanhoon and S and Rho and Soomin and K and Chung and Ki-seok},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214868470&doi=10.1109%2FICCE-Asia63397.2024.10773935&partnerID=40&md5=7c7dc73fe778a6be4277e56fadb2ec76 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCE-Asia63397.2024.10773935 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344796,
  title={ Non-Linear Inference Time Intervention: Improving LLM Truthfulness  -  Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH },
  year={2024},
  author={J and Hosciłowicz and Jakub and A and Wiącek and Adam and J and Chojnacki and Jan and A and Cieślak and Adam and L and Michon and Leszek and A and Janicki and Artur},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214800919&doi=10.21437%2FInterspeech.2024-819&partnerID=40&md5=6bdef7c98435f4ae3767cfedb0d4d800 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.21437/Interspeech.2024-819 },
  booktitle={ Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH },
  chapter={0}
}

@article{rayyan-352344797,
  title={ Inference acceleration for large language models using "stairs" assisted greedy generation  -  CEUR Workshop Proceedings },
  year={2024},
  author={D and Grigaliunas and Domas and M and Lukoševičius and Mantas},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214795215&partnerID=40&md5=c5b5540801960796b37ada98ac24e5d9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344798,
  title={ PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning  -  nan },
  year={2024},
  author={J and Zou and Jiaru and M and Zhou and Mengyu and T and Li and Tao and S and Han and Shi and D and Zhang and Dongmei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214742231&doi=10.18653%2Fv1%2F2024.findings-emnlp.602&partnerID=40&md5=1b08c7650af103ccd2b84e74d241e002 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.602 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344799,
  title={ XC-CACHE: Cross-Attending to Cached Context for Efficient LLM Inference  -  nan },
  year={2024},
  author={J and Monteiro and João and É and Marcotte, Étienne and P.A and Noël and André, Pierre and V and Zantedeschi and Valentina and D., Vázquez and David and N and Chapados and Nicolas and C.J and Pal and J, Christopher and P and Taslakian and Perouz},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214725547&doi=10.18653%2Fv1%2F2024.findings-emnlp.896&partnerID=40&md5=306c0d4f097d0448de57856e414c83e6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.896 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344801,
  title={ Leveraging Knowledge Graphs inference for Semi-Explainable Systems based on Large Language Models  -  CEUR Workshop Proceedings },
  year={2024},
  author={C.F and Longo and Fabio, Carmelo and D.F and Santamaria and Francesco, Daniele and M and Mongiovì and Misael and L and Bulla and Luana and E.M and Sanfilippo and M, Emilio},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214569139&partnerID=40&md5=825ad4c881d7d9dcade59aed9d11a5b4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344802,
  title={ LLMServingSim: A HW/SW Co-Simulation Infrastructure for LLM Inference Serving at Scale  -  nan },
  year={2024},
  author={J and Cho and Jaehong and M and Kim and Minsu and H and Choi and Hyunmin and G and Heo and Guseul and J and Park and Jongse},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214556480&doi=10.1109%2FIISWC63097.2024.00012&partnerID=40&md5=f79ef7937117812bb777cc929a412153 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IISWC63097.2024.00012 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344803,
  title={ Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models  -  nan },
  year={2024},
  author={C and Jung and Chani and D and Kim and Dongkwan and J and Jin and Jiho and J and Kim and Jiseon and Y and Seonwoo and Yeon and Y and Choi and Yejin and A.H.Y and Oh and Yun, Alice Hae and H and Kim and Hyunwoo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213736061&doi=10.18653%2Fv1%2F2024.emnlp-main.1105&partnerID=40&md5=4356e94a906bce2b1153bfa43715ae94 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.1105 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344804,
  title={ Cambricon-LLM: A Chiplet-Based Hybrid Architecture for On-Device Inference of 70B LLM  -  Proceedings of the Annual International Symposium on Microarchitecture, MICRO },
  year={2024},
  author={Z and Yu and Zhongkai and S and Liang and Shengwen and T and Ma and Tianyun and Y and Cai and Yunke and Z and Nan and Ziyuan and D and Huang and Di and X and Song and Xinkai and Y and Hao and Yifan and J and Zhang and Jie and T and Zhi and Tian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213407212&doi=10.1109%2FMICRO61859.2024.00108&partnerID=40&md5=cce8a319f4dfe2a60e257f47832f594b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MICRO61859.2024.00108 },
  booktitle={ Proceedings of the Annual International Symposium on Microarchitecture, MICRO },
  chapter={0}
}

@article{rayyan-352344806,
  title={ Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell  -  nan },
  year={2024},
  author={M and Gao and Muhan and T and Lu and Taiming and K and Yu and Kuai and A.B and Byerly and B, Adam and D and Khashabi and Daniel},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211775533&doi=10.18653%2Fv1%2F2024.findings-emnlp.447&partnerID=40&md5=a3a83296234c37135c49cbb6206aa730 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-emnlp.447 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344808,
  title={ Scaling Up the Transformers: A Survey of Training and Inference Optimization Techniques  -  nan },
  year={2024},
  author={H and Jahangir and Hadya and S.K and Goel and Kumar, Shobhit and S and Khurana and Shiraz},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211122153&doi=10.1109%2FICEECT61758.2024.10739061&partnerID=40&md5=74c8cff134d7a32ec86e85125eb78d05 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEECT61758.2024.10739061 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344809,
  title={ Performance Modeling and Workload Analysis of Distributed Large Language Model Training and Inference  -  nan },
  year={2024},
  author={J and Kundu and Joyjit and W and Guo and Wenzhe and A and BanaGozar and Ali and U., de Alwis and Udari and S and Sengupta and Sourav and P and Gupta and Puneet and A and Mallik and Arindam},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210616117&doi=10.1109%2FIISWC63097.2024.00015&partnerID=40&md5=339c62fe4d5f18cb7eae558dab128524 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IISWC63097.2024.00015 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344810,
  title={ Energy Cost Modelling for Optimizing Large Language Model Inference on Hardware Accelerators  -  International System on Chip Conference },
  year={2024},
  author={R and Geens and Robin and M and Shi and Man and A and Symons and Arne and C and Fang and Chao and M and Verhelst and Marian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210589021&doi=10.1109%2FSOCC62300.2024.10737844&partnerID=40&md5=25138f37dee48793b6e4130844aa18ed },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SOCC62300.2024.10737844 },
  booktitle={ International System on Chip Conference },
  chapter={0}
}

@article{rayyan-352344811,
  title={ Exploring Approximation and Dataflow Co-Optimization for Scalable Transformer Inference Architecture on the Edge  -  International System on Chip Conference },
  year={2024},
  author={L and He and Liu and Y and Wang and Yu and Z and Huang and Zongle and S and Fan and Shupei and C and Tang and Chen and S and Zhang and Shuyuan and L and Lei and Luchang and H and Yang and Huanzhong and Y and Liu and Yongpan and H and Jia and Hongyang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210565287&doi=10.1109%2FSOCC62300.2024.10737793&partnerID=40&md5=b3f5ca6cfeffebb837c2082aa4f074ef },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SOCC62300.2024.10737793 },
  booktitle={ International System on Chip Conference },
  chapter={0}
}

@article{rayyan-352344812,
  title={ Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference  -  nan },
  year={2024},
  author={Q and Zhu and Qihao and L.M and Chong and M, Leah and M.C and Yang and C, Maria and J and Luo and Jianxi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210263643&doi=10.1115%2FDETC2024-143961&partnerID=40&md5=13414b314250bd1175ec1ad86818120e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1115/DETC2024-143961 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344813,
  title={ Decompositional Semantic Analysis for LLM-based Code Quality Evaluation  -  CEUR Workshop Proceedings },
  year={2024},
  author={F and Xu and Fangzhou and S and Zhang and Sai and X and Zhang and Xiaowang and Y and Han and Yahong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210256475&partnerID=40&md5=46e41c469460a33a188eee3effe7411b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344814,
  title={ Planck: Optimizing LLM Inference Performance in Pipeline Parallelism with Fine-Grained SLO Constraint  -  Proceedings of the IEEE International Conference on Web Services, ICWS },
  year={2024},
  author={Y and Lin and Yanying and S and Peng and Shijie and S and Wu and Shuaipeng and Y and Li and Yanbo and C and Lu and Chengzhi and C and Xu and Chengzhong and K and Ye and Kejiang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210239739&doi=10.1109%2FICWS62655.2024.00157&partnerID=40&md5=92093456691ced7d2498c5da8686fb54 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS62655.2024.00157 },
  booktitle={ Proceedings of the IEEE International Conference on Web Services, ICWS },
  chapter={0}
}

@article{rayyan-352344815,
  title={ Towards LLM-driven Automated Verification of Best Practices in Digital Public Infrastructures  -  CEUR Workshop Proceedings },
  year={2024},
  author={M and Markovic and Milan and S.G and Sripada and Gowri, Somayajulu and S.K and Chakrabarti and Kumar, Sujit and R.B and Diddigi and Bharadwaj, Raghuram},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210045900&partnerID=40&md5=15c82999568e9dad5065575c6856cd2f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344816,
  title={ Analysis of the Effectiveness of Large Language Model Feature in Source Code Defect Detection  -  nan },
  year={2024},
  author={T and He and Tao and M and Yang and Meini and W and Hu and Wei and Y and Chen and Yun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209787768&doi=10.1109%2FAICIT62434.2024.10730232&partnerID=40&md5=80fa0c5619b11a3067bb80b9c7656e89 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICIT62434.2024.10730232 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344817,
  title={ All-in-one Approach for Large Language Models Inference  -  Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS },
  year={2024},
  author={S and Zhou and Shan and P and He and Pujiang and W and Huang and Wenhuan and C and Li and Changqing and Y and Xie and Yi and W and Yu and Weifei and D and Wang and Duyi and C and Meng and Chen and S and Gui and Sheng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208183322&doi=10.1109%2FICSESS62520.2024.10719375&partnerID=40&md5=18c06ccfcf9a3bd0c5e8af5a9ac325b1 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSESS62520.2024.10719375 },
  booktitle={ Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS },
  chapter={0}
}

@article{rayyan-352344818,
  title={ User Inference Attacks on Large Language Models  -  nan },
  year={2024},
  author={N and Kandpal and Nikhil and K and Pillutla and Krishna and A and Oprea and Alina and P and Kairouz and Peter and C.A and Choquette-Choo and A, Christopher and Z and Xu and Zheng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207848598&doi=10.18653%2Fv1%2F2024.emnlp-main.1014&partnerID=40&md5=a9a488dca08acdd5000b7534f6418e61 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.emnlp-main.1014 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344819,
  title={ Assessing Large Language Models Inference Performance on a 64-core RISC-V CPU with Silicon-Enabled Vectors  -  CEUR Workshop Proceedings },
  year={2024},
  author={A.M and Garcia, Marques and Marques, Adriano and G and Malenza and Giulio and R and Birke and Robert and M and Aldinucci and Marco},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207519040&partnerID=40&md5=f836fb157adee1fd419e0e23e2bb29b5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344820,
  title={ A retrieval-enhanced generative inference method based on large language models  -  Proceedings of SPIE - The International Society for Optical Engineering },
  year={2024},
  author={B and Shanjin and Bai and Q and Cheng and Qiu and Z and Zhu and Zhongke and Y and Zhang and Yongjin and C and Wang and Cunyi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207079528&doi=10.1117%2F12.3044973&partnerID=40&md5=69987d982b69716a1e72250f568dfbe8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1117/12.3044973 },
  booktitle={ Proceedings of SPIE - The International Society for Optical Engineering },
  chapter={0}
}

@article{rayyan-352344821,
  title={ RTiL: Real-Time Inference of Large Language Models on Memory-Constrained GPU Devices  -  nan },
  year={2024},
  author={J and Niu and Juxin and W and Zhang and Wei and C.J and Xue and Jason, Chun and N and Guan and Nan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207059041&doi=10.1109%2FRTCSA62462.2024.00013&partnerID=40&md5=0066403b45fe98d19bc20d94fd6be3d3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RTCSA62462.2024.00013 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344822,
  title={ CoLLM: A Collaborative LLM Inference Framework for Resource-Constrained Devices  -  nan },
  year={2024},
  author={J and Li and Jinrong and B and Han and Biao and S and Li and Sudan and X and Wang and Xiaoyan and J and Li and Jie},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206484279&doi=10.1109%2FICCC62479.2024.10681712&partnerID=40&md5=b2b7f127a6c6c21e208fc1137b340d6e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCC62479.2024.10681712 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344823,
  title={ Learning from Failures: Translation of Natural Language Requirements into Linear Temporal Logic with Large Language Models  -  IEEE International Conference on Software Quality, Reliability and Security, QRS },
  year={2024},
  author={Y and Xu and Yilongfei and J and Feng and Jincao and W and Miao and Weikai},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206388437&doi=10.1109%2FQRS62785.2024.00029&partnerID=40&md5=f1283a414518b24b03cdfb56599025b0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/QRS62785.2024.00029 },
  booktitle={ IEEE International Conference on Software Quality, Reliability and Security, QRS },
  chapter={0}
}

@article{rayyan-352344824,
  title={ Efficient Inference of Transformers on Bare-Metal Devices with RISC-V Vector Processors  -  nan },
  year={2024},
  author={Y and Huang and Yixuan and P and Huang and Pohan and J and Lu and Juinming and T.J and Lin and Jyi, Tay and T.F and Chen and Fu, Tien},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205707977&doi=10.1109%2FNewCAS58973.2024.10666304&partnerID=40&md5=f9b5dc2c53966cb4154e87e625d5f2a7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NewCAS58973.2024.10666304 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344825,
  title={ Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={H and Xia and Heming and Z and Yang and Zhe and Q and Dong and Qingxiu and P and Wang and Peiyi and Y and Li and Yongqi and T and Ge and Tao and T and Liu and Tianyu and W and Li and Wenjie and Z and Sui and Zhifang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205325424&doi=10.18653%2Fv1%2F2024.findings-acl.456&partnerID=40&md5=7aa7ef68008cfd5906ef5bcfcaeb5a00 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-acl.456 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344827,
  title={ Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={J and Liu and Jiahao and Q and Wang and Qifan and J and Wang and Jingang and X and Cai and Xunliang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205304369&doi=10.18653%2Fv1%2F2024.findings-acl.179&partnerID=40&md5=5738a73bebf95ba1c34f5b2a0007e3f4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-acl.179 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344828,
  title={ Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={H and Yi and Hanling and F and Lin and Feng and H and Li and Hongbin and P and Ning and Peiyang and X and Yu and Xiaotian and R and Xiao and Rong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205299211&doi=10.18653%2Fv1%2F2024.findings-acl.313&partnerID=40&md5=bff0582fd64075d5902b8e51d84cc4f2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-acl.313 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344829,
  title={ SecFormer: Fast and Accurate Privacy-Preserving Inference for Transformer Models via SMPC  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={J and Luo and Jinglong and Y and Zhang and Yehong and Z and Zhang and Zhuo and J and Zhang and Jiaqi and X and Mu and Xin and H and Wang and Hui and Y and Yu and Yue and Z and Xu and Zenglin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205288077&doi=10.18653%2Fv1%2F2024.findings-acl.790&partnerID=40&md5=9576b617eb6784a2edda52c60373d1d3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-acl.790 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344830,
  title={ PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={D and Yang and Dongjie and X and Han and Xiaodong and Y and Gao and Yan and Y and Hu and Yao and S and Zhang and Shilin and H and Zhao and Hai},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205285498&doi=10.18653%2Fv1%2F2024.findings-acl.195&partnerID=40&md5=753ed54b418c75634d0a36d757ca45c6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.findings-acl.195 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344831,
  title={ Turiya at DialAM-2024: Inference Anchoring Theory Based LLM Parsers  -  nan },
  year={2024},
  author={S and Saha and Sougata and R.K., Śrihari and K, Rohini},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204901977&partnerID=40&md5=4afc538c0c4add7cf337f25672f42c99 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344832,
  title={ LLM in a flash: Efficient Large Language Model Inference with Limited Memory  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={K and Alizadeh and Keivan and S.I and Mirzadeh and Iman, Seyed and D and Belenko and Dmitriy and S and Karen Khatamifard, S and M and Cho and Minsik and C.C., del Mundo and C, Carlo and M and Rastegari and Mohammad and M and Farajtabar and Mehrdad},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204499853&doi=10.18653%2Fv1%2F2024.acl-long.678&partnerID=40&md5=dafd43f3ba3355f28a2765f65e979f66 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.acl-long.678 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344833,
  title={ Inference to the Best Explanation in Large Language Models  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={D and Dalal and Dhairya and M and Valentino and Marco and A and Freitas and André and P and Buitelaar and Paul},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204498358&doi=10.18653%2Fv1%2F2024.acl-long.14&partnerID=40&md5=5431789c9cdefe1e112511e51324b4e3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.18653/v1/2024.acl-long.14 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344834,
  title={ Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={J and Bang and Jihwan and J and Lee and Juntae and K and Shim and Kyuhong and S and Yang and Seunghan and S and Chang and Simyung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204481195&doi=10.18653%2Fv1%2F2024.acl-long.204&partnerID=40&md5=abdad7c11076ec8014b3157990366e2e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.acl-long.204 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344835,
  title={ MULTI-TASK INFERENCE: Can Large Language Models Follow Multiple Instructions at Once?  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={G and Son and Guijin and S and Baek and Sangwon and S and Nam and Sangdae and I and Jeong and Ilgyun and S and Kim and Seungone},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204476206&doi=10.18653%2Fv1%2F2024.acl-long.304&partnerID=40&md5=9e600342e0118dbc01dfb65c5bbede0d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.acl-long.304 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344836,
  title={ Layer-Condensed KV Cache for Efficient Inference of Large Language Models  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={W and Haoyi and Wu and K and Tu and Kewei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204469115&doi=10.18653%2Fv1%2F2024.acl-long.602&partnerID=40&md5=e56f291d6c5ef1c72fbc4b0cde50c9ed },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.acl-long.602 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344837,
  title={ Do large language models and humans have similar behaviors in causal inference with script knowledge?  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={X and Hong and Xudong and M and Ryzhova and Margarita and D.A and Biondi and Adrian, Daniel and V and Demberg and Vera},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204312094&doi=10.18653%2Fv1%2F2024.starsem-1.34&partnerID=40&md5=aeec8100973cf1b9f4e947137901716e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.starsem-1.34 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344838,
  title={ Large language models fail to derive atypicality inferences in a human-like manner  -  nan },
  year={2024},
  author={C and Kurch and Charlotte and M and Ryzhova and Margarita and V and Demberg and Vera},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204295352&partnerID=40&md5=6a60f928be30cdd03c24f6572947589a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344839,
  title={ Model Inference Using TVM on AMD GPU: Image Classification and LLM Case Studies  -  nan },
  year={2024},
  author={A and Malbaša and Andrija and N.N and Petrović and N, Nenad and B and Arsić and Branko},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204050541&doi=10.1109%2FIcETRAN62308.2024.10645084&partnerID=40&md5=7f2998fc6147c656388a11767381fa3f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IcETRAN62308.2024.10645084 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344840,
  title={ BOLT: Privacy-Preserving, Accurate and Efficient Inference for Transformers  -  Proceedings - IEEE Symposium on Security and Privacy },
  year={2024},
  author={Q and Pang and Qi and J and Zhu and Jinhao and H., Möllering and Helen and W and Zheng and Wenting and T and Schneider and Thomas},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204048424&doi=10.1109%2FSP54263.2024.00130&partnerID=40&md5=7c95af1b0af5e0edeb1f9c4d61460e31 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SP54263.2024.00130 },
  booktitle={ Proceedings - IEEE Symposium on Security and Privacy },
  chapter={0}
}

@article{rayyan-352344841,
  title={ Break the Sequential Dependency of LLM Inference Using LOOKAHEAD DECODING  -  Proceedings of Machine Learning Research },
  year={2024},
  author={Y and Fu and Yichao and P.D and Bailis and D, Peter and I and Stoica and Ion and H and Zhang and Hao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203838630&partnerID=40&md5=546a16b8d17a2e528333a83916520277 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344842,
  title={ Towards Efficient Spiking Transformer: a Token Sparsification Framework for Training and Inference Acceleration  -  Proceedings of Machine Learning Research },
  year={2024},
  author={Z and Zhuge and Zhengyang and P and Wang and Peisong and X and Yao and Xingting and J and Cheng and Jian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203836031&partnerID=40&md5=371e44c61a33ba0b3bb26c4432e38269 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344843,
  title={ MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads  -  Proceedings of Machine Learning Research },
  year={2024},
  author={T and Cai and Tianle and Y and Li and Yuhong and Z and Geng and Zhengyang and H and Peng and Hongwu and J.D and Lee and D, Jason and D and Chen and Deming and T and Dao and Tri},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203829925&partnerID=40&md5=b7da9702160df3534c82a32cc8b6723f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344844,
  title={ Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={H and Dong and Harry and X and Yang and Xinyu and Z and Zhang and Zhenyu and Z and Wang and Zhangyang and Y and Chi and Yuejie and B and Chen and Beidi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203826024&partnerID=40&md5=06e6c899b6fdf8f68c9534db8e7b6e73 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344845,
  title={ QUEST: Query-Aware Sparsity for Efficient Long-Context LLM Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={J and Tang and Jiaming and Y and Zhao and Yilong and K and Zhu and Kan and G and Xiao and Guangxuan and B and Kasikci and Baris and S and Han and Song},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203825101&partnerID=40&md5=736466347299b72aa22aca94fd8cf0f9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344846,
  title={ ScalaLog: Scalable Log-Based Failure Diagnosis Using LLM  -  ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  year={2025},
  author={Zhang, L. and Jia, T. and Jia, M. and Wu, Y. and Liu, H. and Li, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888670 },
  abstract={As Industrial Internet of Things (IIoT) software systems become increasingly complex, precise failure diagnosis has become both essential and challenging. Current log-based failure diagnosis methods lack scalability for different failure types. In IIoT software systems, the number of failure types is constantly growing, and retraining the model each time a new failure type is introduced is highly resource-intensive. Additionally, traditional log-based failure diagnosis models often require log parsing as a preliminary step, which can also be resource-consuming. To address these challenges, we propose a scalable log-based failure diagnosis method named ScalaLog. ScalaLog builds on RAG by utilizing LLM-based summarization to extract key log information, applying sample augmentation to increase the number of samples, and using CoT prompts to guide the LLM in failure diagnosis. Experiments on various public and real-world datasets demonstrate that ScalaLog significantly enhances failure diagnosis accuracy without the need for training or log parsing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSP49660.2025.10888670 },
  booktitle={ ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) },
  chapter={0}
}

@article{rayyan-352344847,
  title={ Large Language Model-Informed ECG Dual Attention Network for Heart Failure Risk Prediction  -  IEEE Transactions on Big Data },
  year={2025},
  author={Chen, C. and Li, L. and Beetz, M. and Banerjee, A. and Gupta, R. and Grau, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10858425 },
  abstract={Heart failure (HF) poses a significant public health challenge, with a rising global mortality rate. Early detection and prevention of HF could significantly reduce its impact. We introduce a novel methodology for predicting HF risk using 12-lead electrocardiograms (ECGs). We present a novel, lightweight dual attention ECG network designed to capture complex ECG features essential for early HF risk prediction, despite the notable imbalance between low and high-risk groups. This network incorporates a cross-lead attention module and 12 lead-specific temporal attention modules, focusing on cross-lead interactions and each lead's local dynamics. To further alleviate model overfitting, we leverage a large language model (LLM) with a public ECG-Report dataset for pretraining on an ECG-Report alignment task. The network is then fine-tuned for HF risk prediction using two specific cohorts from the U.K. Biobank study, focusing on patients with hypertension (UKB-HYP) and those who have had a myocardial infarction (UKB-MI). The results reveal that LLM-informed pre-training substantially enhances HF risk prediction in these cohorts. The dual attention design not only improves interpretability but also predictive accuracy, outperforming existing competitive methods with C-index scores of 0.6349 for UKB-HYP and 0.5805 for UKB-MI. This demonstrates our method's potential in advancing HF risk assessment with clinical complex ECG data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TBDATA.2025.3536922 },
  booktitle={ IEEE Transactions on Big Data },
  chapter={0}
}

@article{rayyan-352344848,
  title={ A Probabilistic Methodology for Inclusion of Transformer End-of-life Failure in Power System Cascading Failure Simulations  -  2022 17th International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  year={2022},
  author={Awadallah, S. K. E. and Milanović, J. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9810587 },
  abstract={The paper proposes a probabilistic methodology to include end-of-life failure of power transformers into cascading failure simulation. To this end, the paper has adopted Arrhenius-Weibull distribution to characterise end-of-life failure of transformers under different loading conditions. In order to simulate different system states, Non-sequential Monte Carlo simulation method has been used. The simulation of cascading failure of transformer is achieved by comparing the unavailability of individual transformers under different loading condition to a random number. The method is applied to a realistic transmission network containing 154 transformers. The method can be used to feed into decision-making process to replace ageing transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PMAPS53380.2022.9810587 },
  booktitle={ 2022 17th International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  chapter={0}
}

@article{rayyan-352344849,
  title={ Investigation of the electrical and chemical processes causing the failure event in a copper sulfide related transformer failure  -  2015 IEEE Electrical Insulation Conference (EIC) },
  year={2015},
  author={Amaro, P. S. and Facciotti, M. and Lewin, P. L. and Pilgrim, J. A. and Brown, R. C. D. and Wilson, G. and Jarman, P. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223493 },
  abstract={Copper sulfide related failures of oil-filled plants have become more common around most parts of the world over the last couple of decades, which has led the industry to re-evaluate their asset risk analysis policy for mineral oil insulated power assets. Two main theories for the failure event suggested by the current state-of-the-art are thermal runaway and turn-to-turn disk electrical breakdown. This paper provides an over view of two possible failure scenarios, electrical breakdown and low degree of polymerization, and the likelihood of corrosive oil causing each scenario. Empirical DP studies have demonstrated that the corrosion process degrades the chemical cellulose chain bonds, where DP-life expectancy models demonstrated that the corrosion process reduces 33 % of the transformer life expectancy. The electrical breakdown strength experiments demonstrated that the CuxS deposits reduced the electrical breakdown strength of each Kraft paper layer. Finally the results are considered in the larger context of the transformer insulation life-expectancy and its probability of causing the failure event.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICACACT.2014.7223493 },
  booktitle={ 2015 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352344850,
  title={ Statistical analysis of transformer failures for PGE Warsaw  -  2022 Progress in Applied Electrical Engineering (PAEE) },
  year={2022},
  author={Daszczyński, T. and Kaczmarska, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9966569 },
  abstract={The main objective of this work is to understand how the transformer failure trend in PGE Dystrybucja Sp. z o.o. can be used, as engineering evidence, to assist in making financial decisions related to transformer replacement. The research in this thesis is accomplished using the statistical analysis method; the types of methods available are described later in this thesis. Statistical analysis is performed based on the age of transformers damaged and in service on the national grid. The data of transformers' lifetime are fitted to different distribution models. Due to the independent influence of the random transformer failure mechanism and the aging mechanism of the transformer, the curve of the actual transformer failure risk in the national grid with time is random. Transformer managers are interested in knee point age because aging transformer assets threaten grid reliability, and the transformer replacement strategy must be implemented efficiently.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PAEE56795.2022.9966569 },
  booktitle={ 2022 Progress in Applied Electrical Engineering (PAEE) },
  chapter={0}
}

@article{rayyan-352344851,
  title={ Analysis of Historical Transformer Failure and Maintenance Data: Effects of Era, Age, and Maintenance on Component Failure Rates  -  IEEE Transactions on Industry Applications },
  year={2019},
  author={Stringer, A. D. and Thompson, C. C. and Barriga, C. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809732 },
  abstract={For several decades, The U.S. Army Corps of Engineers has maintained a unique database of equipment failure and maintenance data for critical facilities. This article takes a closer look at historical transformer failure and maintenance data, and provides a unique analysis of failure trends. Detailed analysis shows that failure rates for different categories of transformers demonstrate unique trends over time, with equipment age, and with respect to preventative maintenance levels. By analyzing over 144 thousand unit years of operational data, this article paints a more complete picture of component reliability. The data show that careful consideration of detailed failure and maintenance can better upgrade facility design and maintenance decisions, ultimately leading to improved system reliability and reduced operational costs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2019.2937057 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352344852,
  title={ Techniques for Failures Classification in Power Transformers by High-Frequency Current Transformers  -  2023 15th IEEE International Conference on Industry Applications (INDUSCON) },
  year={2023},
  author={Gouvêa, J. P. and Castro, B. A. De and Alves, A. F. and Lucas, G. B. and Ardila-Rey, J. A. and Smith, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374629 },
  abstract={The interest about transformer monitoring systems has significantly increased in recent years. This interest comes both from academia and industry, as the detection of failures provides a high degree of control over the operating conditions of electrical machines and significant cost savings through timely maintenance. In the stages that precede the total failure of a transformer, it is common to detect partial or full discharges that initiate due to degradation of the dielectric materials that form the insulation in the transformer. Therefore, the identification and classification of these phenomena can indicate the quality of the insulation and allow complete failure of the electrical machine to be avoided. One of the main points to consider is where the fault is occurring. For example, a fault can occur in both the active part of the transformer and in its insulators. Therefore, diagnosing the type of failure is very important as they require different maintenance actions. The frequency spectrum analysis is one of the mostly effective and applied methods in the area of signal processing, because it is possible to extract metrics and observe singular characteristics in a signal One of the principal non-invasive methods is current pulse analysis is using a high frequency current sensor, known as High-Frequency Current Transformer (HFCT), with a bandwidth of up to 50 MHz, to evaluate differences in the current signals originating from discharges in insulators from the total discharges that occur in the active part of an oil-isolated transformer. From this perspective, the Fourier Transform was applied to the acquired current signals and some parameters were extracted, like average bandwidth, skewness, and kurtosis to determine which of these combinations is the most effective in classifying the verified failures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDUSCON58041.2023.10374629 },
  booktitle={ 2023 15th IEEE International Conference on Industry Applications (INDUSCON) },
  chapter={0}
}

@article{rayyan-352344853,
  title={ Risk Assessment by Using Failure Modes and Effects Analysis (FMEA) Based on Power Transformer Aging for Maintenance and Replacement Decision  -  2020 2nd Global Power, Energy and Communication Conference (GPECOM) },
  year={2020},
  author={Eyüboğlu, O. H. and Dindar, B. and Gül, Ö.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247887 },
  abstract={Power transformers are critical assets of the grid due to their missions and economic values. Also, the failures in these equipment cause interruptions and economic losses. Therefore, prevention of these failures are highly necessary. In this study, it is proposed to prevent power transformer failures by using FMEA (Failure Modes and Effects Analysis). The FMEA is implemented to actual power transformer failure data of CIGRE (Conseil International des Grands Réseaux Électriques). Evaluation of failure criteria is divided into subdivisions to predict failures more accurately, different than the other studies in the literature. Also, aging is considered as a factor which affects the whole process. In this regard, the risks are prioritized according to their risk values. Thus, system operators can prevent the failures before they occur by using these prioritized risks. Consequently, supply continuity of the grid will be increased and high economic cost of the failures will be decreased.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GPECOM49333.2020.9247887 },
  booktitle={ 2020 2nd Global Power, Energy and Communication Conference (GPECOM) },
  chapter={0}
}

@article{rayyan-352344854,
  title={ Statistical analysis of subcomponent failures in power transformers  -  2011 Electrical Insulation Conference (EIC). },
  year={2011},
  author={Chmura, L. and Morshuis, P. H. F. and Gulski, E. and Smit, J. J. and Janssen, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5996149 },
  abstract={The transformers are very complex devices, consisting of different subcomponents e.g. winding, tap changer, bushing etc. During operation, all of the subcomponents are stressed and subjected to aging. When the aging reaches certain level, the subcomponent may fail. By application of statistical tools it is possible to investigate the failure occurrence in transformers. That means, that by fitting the mathematical model to the data, the parameters of the transformers' population can be estimated. By doing so, it is possible to see what is the stage of life of transformers, and what can be expected in terms of coming failures. However for a proper analysis, it is important to know how to deal with failures that do not seem to follow the statistical distribution chosen. Such outliers may affect the analysis considerably. In the paper, the influence of the outliers on the results of expected failures is presented. The latter is very important for the utility, as such information can be used as an additional information when deciding about replacement of transformers. Also, when deciding about spare transformers, knowledge about failure expectation is very valuable.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC.2011.5996149 },
  booktitle={ 2011 Electrical Insulation Conference (EIC). },
  chapter={0}
}

@article{rayyan-352344855,
  title={ Failure Mode Distribution of Transformers in Thailand  -  2006 International Conference on Power System Technology },
  year={2006},
  author={Tippachon, W. and Klairuang, N. and Khatsaeng, T. and Teera-achariyakul, N. and Hokierti, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4115942 },
  abstract={This paper evaluates the uptime distribution or failure mode distribution of 22 and 33 kV distribution transformers of the provincial electricity authority of Thailand (PEA). Aging data of 5,343 distribution transformers recorded during 1977-2005 has been used in failure mode distribution evaluation. From uptime data testing, the failure mode of distribution transformers can be represented by the Weibull distribution using curve fitting. From the results, the uptime of distribution transforms installed in later years is constantly higher than the uptime of those installed earlier.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPST.2006.321726 },
  booktitle={ 2006 International Conference on Power System Technology },
  chapter={0}
}

@article{rayyan-352344856,
  title={ Lessons Learned from Analysis of Power Transformer Failure Rates  -  2022 IEEE 40th Central America and Panama Convention (CONCAPAN) },
  year={2022},
  author={Hernandez, R. D. and Hancock, B. and Salmeron, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997796 },
  abstract={This work is a compilation of lessons learned from the analysis of power transformer failures occurred in North and South America based on data collected by Doble Engineering Company over the last ten years. The paper includes annual failure rates and related reports based on voltage rating, failure cause, manufacturing decade, age distribution, among other parameters.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONCAPAN48024.2022.9997796 },
  booktitle={ 2022 IEEE 40th Central America and Panama Convention (CONCAPAN) },
  chapter={0}
}

@article{rayyan-352344857,
  title={ Investigation of Transformer Lockout Event Caused by Breaker Failure Protection Misoperation  -  2023 IEEE Industry Applications Society Annual Meeting (IAS) },
  year={2023},
  author={Korede, I. O. and Midkiff, J. and Starling, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10406222 },
  abstract={Breaker Failure (BF) protection is crucial for the security and reliability of power systems. As one example, a breaker failure event at a Dominion Energy Virginia (DEV) distribution substation resulted in a transformer Lockout (LO). This was due to a fault on one of the circuits associated with the BF relay scheme. The event was investigated by using data from digital fault recorders (DFRs), control drawings, Aspen Oneliner software, and field wiring checks This paper describes the breaker failure, outlines DEV's BF protection scheme, and recommends strategies to mitigate BF misoperation in the future, especially for electromechanical relays.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAS54024.2023.10406222 },
  booktitle={ 2023 IEEE Industry Applications Society Annual Meeting (IAS) },
  chapter={0}
}

@article{rayyan-352344858,
  title={ Hi-Pot Test Failure of Transformer Winding, Impact and Corrective Actions  -  2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA) },
  year={2020},
  author={Darade, P. and Diwan, S. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074891 },
  abstract={The modes of failure, impact and corrective actions have been observed as an effective way to improve reliability, which is a feature used in various power grid fields. This needs continuous monitoring and evaluation of its operation to minimize the cost of the operation. The failures in the transformer are analyzed in detail to identify the reasons and the procedure to find out the solution for the same with enhanced capacity and reliability. Transformer have the most common failure known as winding failure which is detected in Hi-Pot test. Many historical findings of the examination have not showed any early indication of transformer failure, the outcome of the Hi-Pot test showed significant deformation in both primary and secondary winding. To reduce future recurrence corrective actions are suggested.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIMIA48430.2020.9074891 },
  booktitle={ 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA) },
  chapter={0}
}

@article{rayyan-352344860,
  title={ LLMcap: Large Language Model for Unsupervised PCAP Failure Detection  -  2024 IEEE International Conference on Communications Workshops (ICC Workshops) },
  year={2024},
  author={Tulczyjew, Ł. and Jarrah, K. and Abondo, C. and Bennett, D. and Weill, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615433 },
  abstract={The integration of advanced technologies into telecommunication networks complicates troubleshooting, posing challenges for manual error identification in Packet Capture (PCAP) data. This manual approach, requiring substantial re-sources, becomes impractical at larger scales. Machine learning (ML) methods offer alternatives, but the scarcity of labeled data limits accuracy. In this study, we propose a self-supervised, large language model-based (LLMcap) method for PCAP failure detection. LLMcap, leveraging language-learning abilities, employs masked language modeling to learn grammar, context, and structure. Tested rigorously on various PCAPs, it demonstrates high accuracy despite the absence of labeled data during training, presenting a promising solution for efficient network analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCWorkshops59551.2024.10615433 },
  booktitle={ 2024 IEEE International Conference on Communications Workshops (ICC Workshops) },
  chapter={0}
}

@article{rayyan-352344861,
  title={ Identification of the minimum detection of transformer bushing failure based on Frequency Response Analysis (FRA)  -  2016 IEEE 2nd Annual Southern Power Electronics Conference (SPEC) },
  year={2016},
  author={Aljohani, O. and Abu-siada, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846058 },
  abstract={Frequency Response Analysis (FRA) is the most reliable technique for detecting a mechanical failure within electrical power transformers. Associated literature reports the ability of the FRA technique to identify non-mechanical faults such as transformer bushing failures. However, the interpretation of the FRA signature is still a challenge because of its reliance on graphical analysis, which requires an expert person for the interpretation process. Although the impact of transformer failure on the signature of the FRA technique has been intensively investigated, no standard code has been widely adopted. Moreover, the FRA technique is frequently ineligible in detecting minor levels of power transformer fault that decreases the transformer's ability to withstand any further electrical, thermal and mechanical stresses. In order to apply the FRA technique properly, the minimum detection of transformer faults should be estimated. This paper aims to identify the impact of the minimum level of transformer bushing failure on the FRA signature that can be visually detected. In this regard, a 3-D geometric of a 3-phase power transformer is simulated (based on the Finite Element Analysis (FEA) technique) to imitate its real operation during both healthy and faulty conditions. The impact FRA signatures (based on FEA) for various bushing failure levels was obtained and then compared to the healthy signature, and variations are detected if they exist. Results show that the transformer bushing failure has a minimum level that can be visually detected using the FRA technique.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SPEC.2016.7846058 },
  booktitle={ 2016 IEEE 2nd Annual Southern Power Electronics Conference (SPEC) },
  chapter={0}
}

@article{rayyan-352344862,
  title={ Multifactorial Frameworks Modelling Linkages of Power Transformer Failure Modes  -  2018 IEEE Electrical Insulation Conference (EIC) },
  year={2018},
  author={Rampersad, R. M. and Bahadoorsingh, S. and Sharma, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481099 },
  abstract={Power Transformers are among the most critical assets in a power system, with significant costs as well as long lead times for acquisition. Their failure compromises the power system security. Total protection from electrical, mechanical, chemical and environmental stresses are near impossible leaving them vulnerable to failure via multiple mechanisms. Many researchers have analyzed the various failure mechanisms and have attempted to link specific mechanisms to the physical manifestations responsible for the ultimate failure of the transformer. This paper provides a library of failure frameworks in the various components of the transformer (core, windings, bushings, tank, cooling fins) and their link to the transformer dielectric materials (oil and cellulose). This paper will integrate published studies into a series of structured frameworks. Each framework provides a platform on which to develop improved models of plant reliability, identifying direct linkages between the transformer failure mechanisms and failure modes. With the identification of these linkages, reliability engineers can better understand how transformers fail and the measurands present at the time of failure, thus allowing for implementation of predictive/preventive maintenance regimes that shall be effective in identifying potential failure modes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC.2018.8481099 },
  booktitle={ 2018 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352344863,
  title={ An Analysis of Uncertainty for Failure Risk Assessment of Power Transformer  -  2022 IEEE 8th International Conference on Energy Smart Systems (ESS) },
  year={2022},
  author={Bardyk, E. I. and Bolotnyi, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969341 },
  abstract={The diagnostic issues for complex technical objects condition under uncertainty are considered. This problem is relevant in the tasks of ensuring quality, reliability and efficient operation of technical objects. This article is devoted to the problem study of associated with uncertainty in the development and implementation of risk management system for power transformer failure. The proposed approach is based on fuzzy logic. This allows formalizing the expert's knowledge about the fault types of power transformer and decision-making in a multicriteria problem. As a result of the research, a classification of uncertainty types under risk assessment. Recommendations are also made on methods of overcoming problems associated with uncertainty problems that arise during the development and implementation of management systems, through more accurate risk assessment. The proposed approach based on methods of information processing is formalized, convenient for computer implementation and their subsequent verification in the diagnosis of various technical objects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ESS57819.2022.9969341 },
  booktitle={ 2022 IEEE 8th International Conference on Energy Smart Systems (ESS) },
  chapter={0}
}

@article{rayyan-352344864,
  title={ A Proposed Power Transformers Failure Assessment Method for Resolving Harmonic Distortion Problem  -  2021 IEEE PES/IAS PowerAfrica },
  year={2021},
  author={Sinvula, R. and Abo-Al-Ez, K. M. and Kahn, M. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543105 },
  abstract={Power utilities try to protect the power transformers as they are the most expensive assets in the power system. These equipment are highly exposed to the harsh harmonic distortion environment. Power transformers' operation is negatively affected by harmonic distortion as they encounter overheating, increases in power losses, deterioration of their life expectancy, etc. Traditionally, transformer failure investigations exclude the harmonic distortion, this can no longer be ignored. There is an international standard that gives harmonic limits for power transformers. This paper presents a proposed method to be used during transformer failure investigation and transformer harmonic monitoring management. This gives power utility awareness of the number of transformers that are part of the network with the highest total harmonic distortion (THD) and to partake in harmonic mitigation to reduce the exposure. The power transformers will operate based on the expected number of years as per design. The harmonic measurement data assists the transformer's failure investigation by identifying the period the transformer has been exposed to the harmonic distortion.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica52236.2021.9543105 },
  booktitle={ 2021 IEEE PES/IAS PowerAfrica },
  chapter={0}
}

@article{rayyan-352344865,
  title={ Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms  -  2025 8th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE) },
  year={2025},
  author={Ji, C. and Luo, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042521 },
  abstract={With the increasing complexity and rapid expansion of the scale of AI systems in cloud platforms, the log data generated during system operation is massive, unstructured, and semantically ambiguous, which brings great challenges to fault location and system self-repair. In order to solve this problem, this paper proposes an intelligent log processing and automatic debugging framework based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This method is extended on the basis of the existing pre-trained Transformer model, and integrates a multi-stage semantic inference mechanism to realize the context understanding of system logs and the automatic reconstruction of fault chains. Firstly, the system log is dynamically structured, and the unsupervised clustering and embedding mechanism is used to extract the event template and semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round attention mechanism to perform contextual reasoning on the log sequence to generate potential fault assumptions and root cause paths. Furthermore, this paper introduces a reinforcement learning-based policy-guided recovery planner, which is driven by the remediation strategy generated by LLM to support dynamic decision-making and adaptive debugging in the cloud environment. Compared with the existing rule engine or traditional log analysis system, the proposed model has stronger semantic understanding ability, continuous learning ability and heterogeneous environment adaptability. Experiments on the cloud platform log dataset show that LLM-ID improves the fault location accuracy by $16.2 \%$, which is significantly better than the current mainstream methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AEMCSE65292.2025.11042521 },
  booktitle={ 2025 8th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE) },
  chapter={0}
}

@article{rayyan-352344866,
  title={ LLM3: Large Language Model-based Task and Motion Planning with Motion Failure Reasoning  -  2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  year={2024},
  author={Wang, S. and Han, M. and Jiao, Z. and Zhang, Z. and Wu, Y. N. and Zhu, S. -C. and Liu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10801328 },
  abstract={Conventional Task and Motion Planning (TAMP) approaches rely on manually designed interfaces connecting symbolic task planning with continuous motion generation. These domain-specific and labor-intensive modules are limited in addressing emerging tasks in real-world settings. Here, we present LLM3, a novel Large Language Model (LLM)-based TAMP framework featuring a domain-independent interface. Specifically, we leverage the powerful reasoning and planning capabilities of pre-trained LLMs to propose symbolic action sequences and select continuous action parameters for motion planning. Crucially, LLM3 incorporates motion planning feedback through prompting, allowing the LLM to iteratively refine its proposals by reasoning about motion failure. Consequently, LLM3 interfaces between task planning and motion planning, alleviating the intricate design process of handling domain-specific messages between them. Through a series of simulations in a box-packing domain, we quantitatively demonstrate the effectiveness of LLM3 in solving TAMP problems and the efficiency in selecting action parameters. Ablation studies underscore the significant contribution of motion failure reasoning to the success of LLM3. Furthermore, we conduct qualitative experiments on a physical manipulator, demonstrating the practical applicability of our approach in real-world settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IROS58592.2024.10801328 },
  booktitle={ 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) },
  chapter={0}
}

@article{rayyan-352344867,
  title={ Distribution Transformer Failure Prediction for Predictive Maintenance Using Hybrid One-Class Deep SVDD Classification and Lightning Strike Failures Data  -  IEEE Transactions on Power Delivery },
  year={2023},
  author={Mogos, A. S. and Liang, X. and Chung, C. Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104144 },
  abstract={The distribution transformer in field monitoring data failure may be influenced by its maintenance history and risk index in a distribution network associated with keraunic level, average number of lightning strikes, and protection devices employed. Transformer failure is a rare event, and the number of “failed” labels is much smaller than that of “non-failed” labels. Therefore, the transformer failure prediction can be formulated as an anomaly detection or binary classification with an imbalanced dataset, which is challenging to handle. In this paper, we propose a novel distribution transformer failure prediction method through a hybrid one-class deep support vector data description (SVDD) that uses the synthetic minority oversampling technique (SMOTE) to handle the data imbalance between minority and majority class labels. Minimum redundancy maximum relevance (mRMR) is used as a feature selection technique to improve the model's accuracy. The proposed method uses the current condition data of transformers and the distribution network to predict transformer failure for the next year. Real-world field data for 15,066 distribution transformers is used to train and validate the proposed method. It shows superior performance when compared against five benchmark approaches.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2023.3268248 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352344868,
  title={ Analysis of Converter Transformer Failure in HVDC Systems and Possible Solutions  -  IEEE Transactions on Power Delivery },
  year={2009},
  author={Bhuvaneswari, G. and Mahanta, B. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4801546 },
  abstract={An HVDC transmission system has a converter transformer as one of its main components. The failure of the converter transformer is one of the major concerns for electric power utilities all over the world. Invariably, the top portions of the secondary windings of the converter transformers fail whereas the primaries are left unaffected. In this paper, an effort has been made to analyze the causes for these failures by means of modeling a practical HVDC system existing in India which ties up Talcher and Kolar and has a length of 1368 km. The modeling and analysis have been carried out in the MATLAB/SIMULINK environment. Based on the analysis, possible solutions for this problem have been suggested, such as providing passive filters on the secondary windings of the converter transformer, connecting a parallel capacitor on the dc side of the converter and R-C snubbers across the secondary windings. The suggested solutions have been compared to bring out their relative merits and demerits.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2009.2014271 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352344869,
  title={ Survey of Australian power transformer failures and retirements  -  IEEE Electrical Insulation Magazine },
  year={2017},
  author={Martin, D. and Marks, J. and Saha, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8014387 },
  abstract={The utilities in Australia are currently operating in an economically constrained environment, and are therefore interested in optimizing expenditure on asset replacement. In response, the universities are working with the utilities to improve modeling of the economic life cycle of power transformers. Information on failure modes of transformers and reasons for their retirement from service are of great assistance to utilities in planning their asset management strategy. The last major failure survey of power transformers in Australia (and New Zealand) was published in 1996 [1]. Since 20 years have passed since then, it is timely to revisit failure of the transformer fleet.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2017.8014387 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352344870,
  title={ A new diagnostic method to support standard frequency response analysis assessments for diagnostics of transformer winding mechanical failures  -  IEEE Electrical Insulation Magazine },
  year={2014},
  author={Pham, D. A. K. and Pham, T. M. T. and Borsi, H. and Gockenbach, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6749571 },
  abstract={The standard frequency response analysis (FRA) is not fully efficient for diagnostics of mechanical failures in power transformers. The article recommends that physical electrical parameters of the transformers should be analyzed in addition to support the current FRA assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2014.6749571 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352344871,
  title={ Case study: lessons learned from the failure of a new 230-kV transformer-cable termination  -  IEEE Electrical Insulation Magazine },
  year={2010},
  author={Su, C. Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383923 },
  abstract={Investigation of the failure of a new 230 kV transformer-cable termination showed that a micro-crack had developed in the bushing during transportation/handling. It is suggested that commissioning tests should include partial discharge measurements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2010.5383923 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352344872,
  title={ Failure analysis & diagnostics of power transformer using dielectric dissipation factor  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={Malpure, B. D. and Baburao, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580334 },
  abstract={The quality of power transformer insulation system is evaluated on a routine basis by measurement of the dielectric dissipation factor and capacitance of the insulation system. The use of dielectric dissipation factor measurements at the end of the production cycle not only assures that the quality of the transformer meets the specified levels but also provides insight into the subtleties of the manufacturing process. This tool is used for many years for diagnosing the health of electrical apparatus. It is a routine test conducted at site to know the dryness of insulation in transformers. This paper highlights our experience on the measurement of dissipation factor using GST & Guard mode techniques of earthing systems other than dryness of insulation in transformers. All our experiences are presented in this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580334 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352344873,
  title={ Failure statistics and power transformer condition evaluation by dissolved gas analysis technique  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={Suwanasri, T. and Chaidee, E. and Adsoongnoen, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580333 },
  abstract={Due to the degradation of power transformer under its normal and abnormal operating conditions, maintenance activities are vital to restore the condition. However, the preventive maintenance costs are now of primary concern. The scattering failure data are systematically recorded and analyzed to determine the critical component of power transformer. Two transformer models of rated voltage 115/22 kV and 230/115/22 kV have been chosen in this study. The determined critical component with high failure rate requires careful attention. The preventive measures can be setup from the known causes of failure. Then the procedure for power transformer condition evaluation is performed by analyzing the historical test result from the dissolved gas analysis (DGA) method. The transformer conditions are principally evaluated by the key gas method and then verified by the ratios and total combustible gas method. As a result, the aging pattern and trend of the power transformer deterioration can be determined.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580333 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352344874,
  title={ Distribution transformer failure in India root causes and remedies  -  2017 International Conference on Innovative Mechanisms for Industry Applications (ICIMIA) },
  year={2017},
  author={Pandit, N. and Chakrasali, R. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975582 },
  abstract={Transformers play an important role in a power distribution utility. They have a long life of 25 to 30 years; but they fail in large numbers, within 3 years itself, due to various reasons, causing huge economic and service impact on the distribution utilities as well the power consumers. In this paper, causes of failure of distribution transformers and possible solutions to overcome these problems have been discussed. Some of the problems may be particular to distribution utilities of Karnataka state, but most of them are generally, Indian problems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIMIA.2017.7975582 },
  booktitle={ 2017 International Conference on Innovative Mechanisms for Industry Applications (ICIMIA) },
  chapter={0}
}

@article{rayyan-352344875,
  title={ Causes of failure of distribution transformers in India  -  2010 9th International Conference on Environment and Electrical Engineering },
  year={2010},
  author={Singh, R. and Singh, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5489987 },
  abstract={Distribution Transformer plays a crucial role in the power distribution network. Failure of distribution transformer results into interruption of power supply to consumers. This disruption affects the economy of nation in the form of loss of revenue, materials, repairing charges etc. Along with other causes, the main cause of failure of distribution transformers is prolonged overloading. In this paper three distribution transformers are analyzed and results are verified by dissolved gas analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEEIC.2010.5489987 },
  booktitle={ 2010 9th International Conference on Environment and Electrical Engineering },
  chapter={0}
}

@article{rayyan-352344876,
  title={ Failure of service aged 230 kV current transformers  -  2012 IEEE International Symposium on Electrical Insulation },
  year={2012},
  author={McDermid, W. and Black, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6251464 },
  abstract={As of the spring of 2008 Manitoba Hydro had in service up to 39 current transformers rated 230 kV from a particular supplier. These had been manufactured in 1969, 1971 and 1975. Three failed explosively beginning in the summer of 2008. Dissolved gas-in-oil analysis revealed others with significant fault gas. As of the end of 2011 all remaining 230 kV current transformers of this type had been removed from service. The paper reviews the design, transport, service conditions and age which may have contributed to the high failure rate.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ELINSL.2012.6251464 },
  booktitle={ 2012 IEEE International Symposium on Electrical Insulation },
  chapter={0}
}

@article{rayyan-352344877,
  title={ LinguaLinked: Distributed Large Language Model Inference on Mobile Devices  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2024},
  author={J and Zhao and Junchen and Y and Song and Yurun and S and Liu and Simeng and I.G and Harris and G, Ian and S and Jyothi, Abdu and Sangeetha},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203824853&doi=10.18653%2Fv1%2F2024.acl-demos.16&partnerID=40&md5=1e132cdd6f68f9f348f17195cef3ff5d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.acl-demos.16 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352344878,
  title={ EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism  -  Proceedings of Machine Learning Research },
  year={2024},
  author={Y and Chen and Yanxi and X and Pan and Xuchen and Y and Li and Yaliang and B and Ding and Bolin and J and Zhou and Jingren},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203819830&partnerID=40&md5=fa5f8a3e3ca6281205d5f08d6c9d83e8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344879,
  title={ An Attempt to Investigate the Transformer Failure by using DGA and SFRA Analysis  -  2012 IEEE 10th International Conference on the Properties and Applications of Dielectric Materials },
  year={2012},
  author={Patil, S. S. and Chaudhari, S. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6318985 },
  abstract={A sudden increasing power demand leads to manufacture of large number of oil immersed power transformers and other electrical power equipments. Power transformers are the most vital equipment in power system. Any failure in transformer leads to malfunction of whole power system. Unfortunately, the failure rate of these transformers is very high in India, 25% per annum, which is not favorable as compared to international units of 1-2 %. Failures happen due to internal reasons or operational hazardless. Transformer insulation deteriorates as the function of temperature, moisture and time. The core and winding losses, stray losses in tank and metal support structures are the principle sources of heat which cause oil and winding temperature rise. There are multiple reasons for overheating such as improper cooling, excessive eddy currents, bad joints, blocked radiators, overloading, improper earthing and harmonic contents in power supply. This leads to accelerated aging of oil and cellulosic solid insulation, which generate the gases within transformer and further leads to permanent failure. To prevent such failures, effective analysis and diagnosis needs to be investigated. The type of gases generated and amount of gas concentrations in oil efficiently evaluated using Dissolved Gas analysis (DGA). Various other electrical diagnostic tests like winding resistance test, short circuit impedance, oil analysis and sweep frequency response analysis (SFRA) are also helpful for identification of abnormalities and probable fault area. SFRA technique is widely accepted and used for transformer mechanical condition assessment. Based on the type and concentration of gases generated in oil along with application of SFRA test on transformer can help to identify the abnormal areas prior to catastrophic failure. An attempt has made for the investigation on relation of DGA with SFRA response. Case studies are presented here for the transformers which have higher fault gas concentrations (DGA). Additional diagnostic tests and analysis, inspection and history data has found supportive in investigation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPADM.2012.6318985 },
  booktitle={ 2012 IEEE 10th International Conference on the Properties and Applications of Dielectric Materials },
  chapter={0}
}

@article{rayyan-352344880,
  title={ KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation  -  Proceedings of Machine Learning Research },
  year={2024},
  author={M and Cho and Minsik and M and Rastegari and Mohammad and D.K and Naik and K, Devang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203819338&partnerID=40&md5=8ef3ada2a34817dfc8ee0a84ef84e964 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344881,
  title={ Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model  -  Proceedings of Machine Learning Research },
  year={2024},
  author={M and Khona and Mikail and M and Okawa and Maya and J., Hůla and Jan and R and Ramesh and Rahul and K and Nishi and Kento and R.P and Dick and P, Robert and E.S and Lubana and Singh, Ekdeep and H and Tanaka and Hidenori},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203814184&partnerID=40&md5=a16b71cd7d63854a84600e0da8ff4f13 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344882,
  title={ North American transformer outages initiated by transmission equipment failures and human error  -  2016 IEEE Power and Energy Society General Meeting (PESGM) },
  year={2016},
  author={Ekisheva, S. and Lauby, M. G. and Gugel, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7741060 },
  abstract={The North American Electric Reliability Corporation's (NERC's) State of Reliability reports identify types of transformer equipment failures and human errors that significantly contribute to transmission risks to bulk power system (BPS). This paper presents the framework of the statistical analysis of forced transformer outages initiated by failed transmission equipment and human error and discusses results of the first study of the reliability indicators based on the North American inventory and outage data for transformers. NERC recommendations and actions are discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM.2016.7741060 },
  booktitle={ 2016 IEEE Power and Energy Society General Meeting (PESGM) },
  chapter={0}
}

@article{rayyan-352344883,
  title={ Split-and-Denoise: Protect Large Language Model Inference with Local Differential Privacy  -  Proceedings of Machine Learning Research },
  year={2024},
  author={P and Mai and Peihua and R and Yan and Ran and Z and Huang and Zhe and Y and Yang and Youjia and Y and Pang and Yan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203806926&partnerID=40&md5=f428c958522ade83d35041bad083f8ad },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344884,
  title={ HEXGEN: Generative Inference of Large Language Model over Heterogeneous Environment  -  Proceedings of Machine Learning Research },
  year={2024},
  author={Y and Jiang and Youhe and R and Yan and Ran and X and Yao and Xiaozhe and Y and Zhou and Yang and B and Chen and Beidi and B and Yuan and Binhang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203802677&partnerID=40&md5=42012192cca4b548880841413718ec1e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344885,
  title={ Data Mining Techniques for Transformer Failure Prediction Model: A Systematic Literature Review  -  2019 IEEE 9th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  year={2019},
  author={Ravi, N. N. and Drus, S. Mohd and Krishnan, P. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8743987 },
  abstract={Transformer failure may occur in terms of tripping, resulting in an unplanned or unseen failure. Therefore, a good maintenance strategy is an essential component of a power system to prevent unanticipated failures. Routine preventive maintenance programs have traditionally been used in combination with regular tests. However, in recent years, predictive maintenance has become prevalent due to the demanding industrial needs. Due to the increased requirement, utilities are persistently looking for ways to overcome the challenge of power transformer failures. One of the most popular ways for fault prediction is data mining. Data mining techniques can be applied in transformer failure prediction to provide the possibility of failure occurrence. Thus, this study aims to identify the common data mining techniques and algorithms that are implemented in studies related to various transformer failure types. The accuracy of each algorithm is also studied in this paper. A systematic literature review is carried out by identifying 160 articles from four main databases of which 6 articles are chosen in the end. This review found that the most common prediction technique used is classification. Among the classification algorithms, ANN is the prominent algorithm adopted by most of the researchers which has provided the highest accuracy compared to other algorithms. Further research can be done to investigate more on the transformer failures types and fair comparison between multiple algorithms in order to get more precise performance measurement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAIE.2019.8743987 },
  booktitle={ 2019 IEEE 9th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  chapter={0}
}

@article{rayyan-352344886,
  title={ SparQ Attention: Bandwidth-Efficient LLM Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={L and Ribar and Luka and I and Chelombiev and Ivan and L and Hudlass-Galley and Luke and C and Blake and Charlie and C and Luschi and Carlo and D and Orr and Douglas},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203797798&partnerID=40&md5=b47ce195208576cc0d2749d8b57f5207 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344887,
  title={ An advanced analysis of a root cause of a power transformer failure  -  2012 IEEE Electrical Power and Energy Conference },
  year={2012},
  author={Bochenski, B. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6474948 },
  abstract={The paper deals with the problem of forensic investigation of a transformer failure. A forensic engineer may determine the direct cause of the failure on the basis of an inspection. The root cause, however, may be difficult to discover or prove without advanced calculations. Often an analysis of thermal performance and electric and magnetic field (EMF) is sufficient to determine the root cause of the failure. One of the ways to achieve this is by using finite element method (FEM). The author presents an example of such analysis performed for a power transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EPEC.2012.6474948 },
  booktitle={ 2012 IEEE Electrical Power and Energy Conference },
  chapter={0}
}

@article{rayyan-352344888,
  title={ CHAI: Clustered Head Attention for Efficient LLM Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={S and Agarwal and Saurabh and B and Acun and Bilge and B and Hosmer and Basil and M and Elhoushi and Mostafa and Y and Lee and Yejin and S and Venkataraman and Shivaram and D.S and Papailiopoulos and S, Dimitris and C.J and Wu and Jean, Carole},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203792718&partnerID=40&md5=0cfd5e8263e78b1b9aa4e0d3fdd861df },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344889,
  title={ Distribution Transformer Failure Study and Solution Proposal in Ethiopia  -  2020 IEEE PES/IAS PowerAfrica },
  year={2020},
  author={Tariku, A. and Bekele, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9219933 },
  abstract={This paper tries to identify the root causes of frequent distribution transformers failure (DTF) in Addis Ababa, Ethiopia, specifically, at East Addis Ababa Region (EAAR). The utility divides Addis Ababa into four regions; east, west, north and south. Part of the data is collected from EAAR office and the other part by directly visiting the sites. In the region, 89 transformers have burnt down between July 2018 to June 2019. It is likely that similar problems could exist in the other regions of the city as well. During the study, DTF causes have been investigated, including the effect of weather in the different seasons of the year, manufacturers, loading, etc. Problems have been identified and solutions are proposed for the utility to apply.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica49420.2020.9219933 },
  booktitle={ 2020 IEEE PES/IAS PowerAfrica },
  chapter={0}
}

@article{rayyan-352344890,
  title={ INFERCEPT: Efficient Intercept Support for Augmented Large Language Model Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={R and Abhyankar and Reyna and Z and He and Zijian and V and Srivatsa and Vikranth and H and Zhang and Hao and Y and Zhang and Yiying},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203792629&partnerID=40&md5=558f326546969024eb5277babcf5f2ed },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344891,
  title={ Converting Transformers to Polynomial Form for Secure Inference Over Homomorphic Encryption  -  Proceedings of Machine Learning Research },
  year={2024},
  author={I and Zimerman and Itamar and M and Baruch and Moran and N and Drucker and Nir and G and Ezov and Gilad and O and Soceanu and Omri and L and Wolf and Lior},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203792116&partnerID=40&md5=95c56d675d0bf64ff13c78503b721c59 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344892,
  title={ High Voltage Circuit Breaker and Power Transformer Failure Modes and Their Detection  -  2018 Condition Monitoring and Diagnosis (CMD) },
  year={2018},
  author={Antoun, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8535655 },
  abstract={This paper aims to explore the various failure modes associated with High Voltage Circuit Breakers and Power Transformers within transmission and subtransmission electricity networks and identify the online monitoring requirements to ensure effective early detection of issues. This would enable system operators to act appropriately to prevent unexpected failures. These requirements in the context of the capabilities and limitations in currently available Online Monitoring Technologies will also be discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2018.8535655 },
  booktitle={ 2018 Condition Monitoring and Diagnosis (CMD) },
  chapter={0}
}

@article{rayyan-352344893,
  title={ Ditto: Quantization-aware Secure Inference of Transformers upon MPC  -  Proceedings of Machine Learning Research },
  year={2024},
  author={H and Wu and Haoqi and W and Fang and Wenjing and Y and Zheng and Yancheng and J and Ma and Junming and J and Tan and Jin and L and Wang and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203791805&partnerID=40&md5=3acfac5ee34c1802f69048015dad7c5f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344894,
  title={ Tandem Transformers for Inference Efficient LLMs  -  Proceedings of Machine Learning Research },
  year={2024},
  author={P.S and Aishwarya, P. S and P.A and Nair and Ajit, Pranav and Y.B.L and Samaga and B.L, Yashas and T and Boyd and Toby and S and Kumar and Sanjiv and P and Jain and Prateek and P and Netrapalli and Praneeth},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203787760&partnerID=40&md5=5fb8df146a6afaf34e3c06b0ad01cb14 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344895,
  title={ Leveraging Large Language Models for Efficient Failure Analysis in Game Development  -  IEEE Conference on Computatonal Intelligence and Games, CIG },
  year={2024},
  author={L and Marini and Leonardo and L and Gisslén and Linus and A and Sestini and Alessandro},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203524179&doi=10.1109%2FCoG60054.2024.10645540&partnerID=40&md5=68624d0dd831dadf63ff3c8705017a5c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CoG60054.2024.10645540 },
  booktitle={ IEEE Conference on Computatonal Intelligence and Games, CIG },
  chapter={0}
}

@article{rayyan-352344896,
  title={ Diagnosis on Winding Failure Through Impulsive Sound of Power Transformer  -  2018 IEEE International Power Modulator and High Voltage Conference (IPMHVC) },
  year={2018},
  author={Shi, Y. and Ji, S. and Zhan, C. and Zhang, F. and Ren, F. and Zhu, L. and Pan, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936691 },
  abstract={The transformer windings will flow a large impact current in the event of an external short circuit, causing strong vibration, resulting in winding looseness and deformation. Therefore, it is of great significance to carry out the research on fault diagnosis under short-circuit impact. The sound signal can reflect the overall mechanical condition of the equipment. According to the characteristics of the impulsive sound signal in time-frequency domain, two fault parameters like sound entropy (SE) and odd-even ratio (OER) were proposed. It is found that the SE and OER increase when the winding loosens, while they decrease when the deformation occurs. The deviation of parameters can reflect the degree of mechanical failure. According to the proposed fault parameters, a diagnosis on winding failure through the impulsive sound of the transformer is proposed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPMHVC.2018.8936691 },
  booktitle={ 2018 IEEE International Power Modulator and High Voltage Conference (IPMHVC) },
  chapter={0}
}

@article{rayyan-352344897,
  title={ When the Edge Meets Transformers: Distributed Inference with Transformer Models  -  Proceedings - International Conference on Distributed Computing Systems },
  year={2024},
  author={C and Hu and Chenghao and B and Li and Baochun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203201531&doi=10.1109%2FICDCS60910.2024.00017&partnerID=40&md5=3309bf0775d9088dc2f97ef91b2635f4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDCS60910.2024.00017 },
  booktitle={ Proceedings - International Conference on Distributed Computing Systems },
  chapter={0}
}

@article{rayyan-352344898,
  title={ Inference with Transformer Encoders on ARM and RISC-V Multicore Processors  -  Lecture Notes in Computer Science },
  year={2024},
  author={H and Martínez, Héctor and F.D and Igual and D, Francisco and R and Rodríguez-Sánchez and Rafael and S and Catalán and Sandra and A and Castelló and Adrián and E.S and Quintana-Ortí and S, Enrique},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202728101&doi=10.1007%2F978-3-031-69766-1_26&partnerID=40&md5=de1975352383ccc66a3d3e0727cdb387 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-69766-1_26 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344899,
  title={ On the development of power transformer failure models: An Australian case study  -  2017 IEEE Power & Energy Society General Meeting },
  year={2017},
  author={Martin, D. and Marks, J. and Saha, T. and Krause, O. and Russell, G. and Alibegovic-Memisevic, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8274571 },
  abstract={Power transformers are expected to operate reliably for decades. Loading guides and models exist to estimate the functional life remaining of transformer cellulosic insulation. However, failure is essentially probabilistic and dependent on many factors, and so statistical models to ascertain the expected number of failures for a power transformer fleet are highly desirable when planning future investment. Given their low failure rate, approximately 1% per transformer year, a fleet size much larger than an individual Utility owns is required for statistically significant results. Therefore, a large study was performed on the Utilities in Australia who together operate around 6,000 power transformers. For this, data on 626 failures and retirements, over a fifteen year period, were collected. The Weibull distribution was used to determine failure rate for age, voltage class of transformer, and failure mode. Finally, the development of a tool to model future replacements is discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM.2017.8274571 },
  booktitle={ 2017 IEEE Power & Energy Society General Meeting },
  chapter={0}
}

@article{rayyan-352344900,
  title={ WActiGrad: Structured Pruning for Efficient Finetuning and Inference of Large Language Models on AI Accelerators  -  Lecture Notes in Computer Science },
  year={2024},
  author={K.T and Chitty-Venkata and Teja, Krishna and V.K and Sastry and Katti, Varuni and M.K and Emani and Krishna, Murali and V and Vishwanath and Venkatram and S and Shanmugavelu and Sanjif and S and Howland and Sylvia},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202726119&doi=10.1007%2F978-3-031-69766-1_22&partnerID=40&md5=6f38f62d525708c6438017a637a7c118 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-69766-1_22 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344901,
  title={ Attention or Convolution: Transformer Encoders in Audio Language Models for Inference Efficiency  -  nan },
  year={2024},
  author={S and Jeon and Sungho and C and Yeh and Chingfeng and H and Inan and Hakan and W and Hsu and Weining and R and Rungta and Rashi and Y and Mehdad and Yashar and D.M and Bikel and M, Daniel},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202436052&doi=10.1109%2FICASSPW62465.2024.10626117&partnerID=40&md5=40a1104e5898d17bfb3265bd88458c5e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICASSPW62465.2024.10626117 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344902,
  title={ Predicting heart failure prognosis using deep learning based on FT-transformer  -  2023 Fourteenth International Conference on Ubiquitous and Future Networks (ICUFN) },
  year={2023},
  author={Kim, G. and Yang, M. and Kim, G. -H. and Eom, S. -H. and Lee, T. -S. and Park, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200998 },
  abstract={Although heart failure (HF) diagnosis and treatment techniques have advanced, more than 50% of HF patients are readmitted. Readmission worsens the life quality of patients due to economic and psychological burdens. Therefore, readmission prediction for patients is important to prevent unnecessary readmissions. We used a feature tokenizer transformer (FT-transformer) to predict readmission by embedding all features and analyzing via transformer encoder. Our experiment with 615 HF patients outperformed conventional machine learning models, achieving an area under the curve of 0.7434 within 28 days, 0.7063 within 3 months, and 0.7039 within 6 months. FT-transformer can potentially improve patient outcomes by enabling early interventions to prevent readmissions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICUFN57995.2023.10200998 },
  booktitle={ 2023 Fourteenth International Conference on Ubiquitous and Future Networks (ICUFN) },
  chapter={0}
}

@article{rayyan-352344903,
  title={ Comparison of Mamdani and Sugeno Fuzzy Inference Systems to Assess the Health Condition of Power Transformer  -  nan },
  year={2024},
  author={R and Manimala, R and B and Vigneshwaran, B},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202347108&doi=10.1109%2FICOECA62351.2024.00096&partnerID=40&md5=36d34ccf41773ea3026e2b22a1f0bdc8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICOECA62351.2024.00096 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344904,
  title={ Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models  -  nan },
  year={2024},
  author={M and Meeus and Matthieu and S and Jain and Shubham and M and Rei and Marek and Y.A., de Montjoye and Alexandre, Yves},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202280159&partnerID=40&md5=8e67c09b0c3c6b89898613744805536d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344905,
  title={ Experiences with detection of transformer failure based on insulating oil tests  -  2017 IEEE 19th International Conference on Dielectric Liquids (ICDL) },
  year={2017},
  author={Rozga, P. and Piotrowski, T. and Kozak, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8124628 },
  abstract={This article is aimed on presentation of an important role of oil based diagnostics in asset management of the transformers in service. The multilevel system of transformer diagnostics in which at the first level of diagnosis the parameters of oil are measured and analysis of gases dissolved in oil is performed is presented as the tool applied in assessment of technical condition of the transformer in service. On the basis of the theoretical considerations on the system presented the selected case studies were shown where the different transformer failures were detected by means of skillfully performed oil-based diagnostic procedure. The adopted approach helped in the decision making process on withdrawing the faulty oil power transformers from service and sent them for repair in a right time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDL.2017.8124628 },
  booktitle={ 2017 IEEE 19th International Conference on Dielectric Liquids (ICDL) },
  chapter={0}
}

@article{rayyan-352344906,
  title={ Industrial Control Protocol Type Inference Using Transformer and Rule-based Re-Clustering  -  Proceedings - IEEE INFOCOM },
  year={2024},
  author={Y and Liu and Yuhuan and Y and Ding and Yulong and J and Jiang and Jie and B and Xiao and Bin and S.H and Yang, S. H},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201803154&doi=10.1109%2FINFOCOM52122.2024.10621186&partnerID=40&md5=c6f08aae63f98b8a2ae88ac3bfe90925 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOM52122.2024.10621186 },
  booktitle={ Proceedings - IEEE INFOCOM },
  chapter={0}
}

@article{rayyan-352344907,
  title={ Patch-wise Inference using Pre-trained Vision Transformers: NEUON Submission to PlantCLEF 2024  -  CEUR Workshop Proceedings },
  year={2024},
  author={S and Chulif and Sophia and H.A and Ishrat and Ahmed, Hamza and Y.L and Chang and Loong, Yang and S.H and Lee and Han, Sue},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201606874&partnerID=40&md5=77097e869bf125e6ceadf3267ea1b815 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344908,
  title={ Failure mode and effect analysis applied to power transformers  -  2017 52nd International Universities Power Engineering Conference (UPEC) },
  year={2017},
  author={Freitag, S. C. and Sperandio, M. and Marchesan, T. B. and Carraro, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8232021 },
  abstract={This work presents the Failure Modes and Effects Analysis (FMEA) technique applied to an utility's power transformers to obtain a risk value to enable the optimization of a maintenance schedule. The application of the study will lead to greater assertiveness of the investments, providing technical and scientific support and agility in the decision making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UPEC.2017.8232021 },
  booktitle={ 2017 52nd International Universities Power Engineering Conference (UPEC) },
  chapter={0}
}

@article{rayyan-352344909,
  title={ InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management  -  nan },
  year={2024},
  author={W and Lee and Wonbeom and J and Lee and Jungi and J and Seo and Junghwan and J and Sim and Jaewoong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201315278&partnerID=40&md5=c42effd25356950b13465479937ef54d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344910,
  title={ Efficient Tuning and Inference for Large Language Models on Textual Graphs  -  IJCAI International Joint Conference on Artificial Intelligence },
  year={2024},
  author={Y and Zhu and Yun and Y and Wang and Yaoke and H and Shi and Haizhou and T and Siliang and Tang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201281818&partnerID=40&md5=fac0a15c45f75b3559c4d9d729a07b44 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IJCAI International Joint Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352344911,
  title={ Does Metacognitive Prompting Improve Causal Inference in Large Language Models?  -  nan },
  year={2024},
  author={R and Ohtani and Ryusei and Y and Sakurai and Yuko and S and Oyama and Satoshi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201238187&doi=10.1109%2FCAI59869.2024.00092&partnerID=40&md5=d82a07471c6ca3c105d5cd0cd2b7b90d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CAI59869.2024.00092 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344912,
  title={ FwdLLM: Efficient Federated Finetuning of Large Language Models with Perturbed Inferences  -  nan },
  year={2024},
  author={M and Xu and Mengwei and D and Cai and Dongqi and Y and Wu and Yaozong and X and Li and Xiang and S and Wang and Shangguang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201228853&partnerID=40&md5=fcfbcaa0f1fc7e74fe65642aea5e647f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344913,
  title={ A New Approach for the Failure Detection and the Self-healing Process in A Solar-based Tap Changing Transformer  -  2022 International Conference on Electrical, Computer and Energy Technologies (ICECET) },
  year={2022},
  author={Babaei, A. and Ziomek, W. and Gole, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9873028 },
  abstract={In this paper, a new approach for the self-healing process of the on-load tap-changer (OLTC) is proposed. The proposed circuit detects the failed power switch and enables the system to continue operation by using a series relay to disconnect the failed switch from the circuit. When the tap is moving from one level to the other, during this time the failure detection approach checks all power switches. The detection process is based on the tap voltage measurement while all gate signals of power switches are off. If the tap voltage during this time is not less than a certain voltage value, it means one switch fails. Then, the failed switch removes from the circuit via a series relay, and the substitute TRIAC replace the failed one. This removes any possible interruption in the voltage of the load. Also, the presented method is easy to implement, cost-effective and utilizes fewer components. An EMT simulation is performed to examine the effectiveness and robustness of the proposed circuit and methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECET55527.2022.9873028 },
  booktitle={ 2022 International Conference on Electrical, Computer and Energy Technologies (ICECET) },
  chapter={0}
}

@article{rayyan-352344914,
  title={ Context Compression and Extraction: Efficiency Inference of Large Language Models  -  Lecture Notes in Computer Science },
  year={2024},
  author={J and Zhou and Junyao and R and Du and Ruiqing and Y and Tan and Yushan and J and Yang and Jintao and Z and Yang and Zonghao and W and Luo and Wei and Z and Luo and Zhunchen and X and Zhou and Xian and W and Hu and Wenpeng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201226445&doi=10.1007%2F978-981-97-5663-6_19&partnerID=40&md5=750a79c0738ff6c84e4a70a595726af5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-97-5663-6_19 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352344916,
  title={ Application of a new method in detecting a mechanical failure associated with series capacitance change in a power transformer winding  -  2014 IEEE 18th International Conference on Dielectric Liquids (ICDL) },
  year={2014},
  author={Pham, D. A. K. and Pham, T. M. T. and Gockenbach, E. and Borsi, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893098 },
  abstract={The Frequency Response Analysis (FRA) based method is expected as an efficient one in diagnosis of mechanical failures in windings of power transformers, especially in cases other testing methods cannot provide any indication for the diagnostic. However, the current FRA assessment which is based on the relevant Chinese standard and other draft international standards is not sensitive enough in detecting such failures in all cases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDL.2014.6893098 },
  booktitle={ 2014 IEEE 18th International Conference on Dielectric Liquids (ICDL) },
  chapter={0}
}

@article{rayyan-352344917,
  title={ Causal Inference for Confounder-Purify Vision Transformers  -  nan },
  year={2024},
  author={D and Yue and Dengfeng and J and Zou and Jia and X and Jin and Xiaoxiao and T and Leng and Tuo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201191400&doi=10.1109%2FICAIBD62003.2024.10604648&partnerID=40&md5=a14618c504fafba3c5fd9e355cbd20b7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIBD62003.2024.10604648 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344918,
  title={ Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ Transformer Inference  -  Proceedings - IEEE INFOCOM },
  year={2024},
  author={S and Ye and Shengyuan and J and Du and Jiangsu and L and Zeng and Liekang and W and Ou and Wenzhong and X and Chu and Xiaowen and Y and Lu and Yutong and X and Chen and Xu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201168682&doi=10.1109%2FINFOCOM52122.2024.10621342&partnerID=40&md5=85bc39b5f49b2fb6ca922d6559253737 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOM52122.2024.10621342 },
  booktitle={ Proceedings - IEEE INFOCOM },
  chapter={0}
}

@article{rayyan-352344919,
  title={ Uninterruptible power supply systems for railway with predictive diagnostic against power transformer failure  -  2015 IEEE 15th International Conference on Environment and Electrical Engineering (EEEIC) },
  year={2015},
  author={Saponara, S. and Fanucci, L. and Falciani, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165505 },
  abstract={The paper addresses the problem of predictive diagnostic in uninterruptible power supply systems (UPS) for railway. A new UPS for railway applications is proposed. A FMECA (Failure Mode, Effects and Criticality Analysis) analysis carried out on it shows that key issues for the system reliability are the faults occurring in the 3-phase high power transformers and in the battery modules used for energy storage. While at state of art several works address the battery failure problem, for power transformers in known works only thermal and electrical faults are monitored. As a new feature vs. state of art to achieve predictive diagnostic of power transformer fault this work proposes a new electronic instrumentation allowing also for vibration-based mechanical stress diagnosis. Mechanical degradation is tracked through multi-channel vibration measures with sensitivity down to 0.5 mg and signal processing in the transformed frequency domain up to 1 kHz. Experimental measurements on real UPS for railway confirm the validity of the approach.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEEIC.2015.7165505 },
  booktitle={ 2015 IEEE 15th International Conference on Environment and Electrical Engineering (EEEIC) },
  chapter={0}
}

@article{rayyan-352344920,
  title={ ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching  -  nan },
  year={2024},
  author={Y and Zhao and Youpeng and D and Wu and Di and J and Wang and Jun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201161832&doi=10.1109%2FISCA59077.2024.00077&partnerID=40&md5=b0e1c8f825a23c7b0d47677a9dc5d67b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCA59077.2024.00077 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344921,
  title={ LLMCompass: Enabling Efficient Hardware Design for Large Language Model Inference  -  nan },
  year={2024},
  author={H and Zhang and Hengrui and A and Ning and August and R.B and Prabhakar and Baskar, Rohan and D and Wentzlaff and David},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201142444&doi=10.1109%2FISCA59077.2024.00082&partnerID=40&md5=7bb7641d84f4545e625c81321623bf42 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCA59077.2024.00082 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344922,
  title={ Whether Large Language Models Learn at the Inference Stage? Effects of Active Learning and Labelling with LLMs on their Reasoning  -  Communications in Computer and Information Science },
  year={2024},
  author={V and Kulikov and Vladlen and R.G and Neychev and G, Radoslav and I.A and Makarov and A, Ilya},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200974053&doi=10.1007%2F978-3-031-67008-4_4&partnerID=40&md5=0c65e3a899e1485b720dcc46e2a09fa3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1007/978-3-031-67008-4_4 },
  booktitle={ Communications in Computer and Information Science },
  chapter={0}
}

@article{rayyan-352344923,
  title={ k-nearest neighbor algorithm based classification and localization of seven different types of disc-to-disc impulse insulation failures in power transformer  -  2012 IEEE 10th International Conference on the Properties and Applications of Dielectric Materials },
  year={2012},
  author={Ray, K. and Rajamani, P. and Mukherjee, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6318988 },
  abstract={Identification and localization of seven different types of disc-to-disc insulation failure in power transformer using K - Nearest Neighbor classifier (kNN) has been proposed. Proper identification of insulation failure in power transformer is vital to take appropriate corrective measure. In the present work, seven types of series insulation failures are simulated in EMTP based digital model of 33 kV winding of 3 MVA power transformer. Resultant winding currents of each insulation failures are acquired following the tank current method for the time span of 0-500 μs. By correlating healthy and faulty winding currents of 3 MVA transformer, significant time-frequency domain features are extracted by employing cross-wavelet transform. Using extracted features, the k - Nearest Neighbor classifier has successfully identified and localized all seven different types of disc-to-disc insulation failures within ± 9% winding length with acceptable accuracy. Simulation of insulation failures, feature extraction and fault identification are explained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPADM.2012.6318988 },
  booktitle={ 2012 IEEE 10th International Conference on the Properties and Applications of Dielectric Materials },
  chapter={0}
}

@article{rayyan-352344924,
  title={ A Case for Low Bitwidth Floating Point Arithmetic on FPGA for Transformer Based DNN Inference  -  nan },
  year={2024},
  author={J and Wu and Jiajun and M and Song and Mo and J and Zhao and Jingmin and H.K.H and So and Hay, Hayden Kwok},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200774277&doi=10.1109%2FIPDPSW63119.2024.00045&partnerID=40&md5=9b64b19cd0ac56b79a64507eb7b8dff9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPDPSW63119.2024.00045 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344925,
  title={ Evaluating Baselines for Type Inference: Static Code Analysis Versus Large Language Model  -  Lecture Notes in Networks and Systems },
  year={2024},
  author={A and Vagin and Andrey and V and Romanov and Vitaly and V.V and Ivanov and Vladimirovich, Vladimir},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200700194&doi=10.1007%2F978-3-031-64779-6_42&partnerID=40&md5=1d9dbec945c7ec3a0566f0f472f9ae9d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-64779-6_42 },
  booktitle={ Lecture Notes in Networks and Systems },
  chapter={0}
}

@article{rayyan-352344927,
  title={ ICEFORMER: ACCELERATED INFERENCE WITH LONG-SEQUENCE TRANSFORMERS ON CPUS  -  nan },
  year={2024},
  author={Y and Mao and Yuzhen and M and Ester and Martin and K and Li and Ke},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200498592&partnerID=40&md5=4f37de2c4b70f8f49111bc9b6983ddd8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344928,
  title={ Investigation of Failure and Fault Diagnosis of 120MVA Transformers for Electrical Arc Furnace Systems and Data Mining Surveillance Techniques  -  2020 8th International Conference on Condition Monitoring and Diagnosis (CMD) },
  year={2020},
  author={Boonseng, C. and Boonseng, R. and Kularbphettong, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287270 },
  abstract={In this paper, the investigation and diagnosis of the 120MVA arc furnace explosion. The explosion caused the transformer oil to flow through the pressure release value violently. When examined by removing the iron core and the coil, it was found that the tear of the high voltage coil was all damaged. There are signs of severe breakdowns and the automatic tapped changer area of the copper at both the electrodes has melted. The result is a current flowing through the transformer up to 14 kA. According to the examination, it was found that the 2nd air core reactor has disappeared, causing no 2nd harmonic filter in the system and continue to work without the 2nd harmonic filter. Resulting in resonance between the 2nd harmonic and 3rd filter, cause of high current flowing through the transformer. Finally. The method of inspection is proposed using neutral network algorithms for deep learning with Python. The evaluation can be used in real work, the results are satisfactory and comprehensive.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD48350.2020.9287270 },
  booktitle={ 2020 8th International Conference on Condition Monitoring and Diagnosis (CMD) },
  chapter={0}
}

@article{rayyan-352344929,
  title={ Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?  -  nan },
  year={2024},
  author={Y and Intrator and Yotam and M and Halfon and Matan and R and Goldenberg and Roman and R and Tsarfaty and Reut and M and Eyal and Matan and E and Rivlin and Ehud and Y and Matias and Yossi and N and Aizenberg and Natalia},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200149928&doi=10.18653%2Fv1%2F2024.naacl-short.75&partnerID=40&md5=5b30278d6699af8402b3a5d2bdd3f028 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.naacl-short.75 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344930,
  title={ Generative Inference of Large Language Models in Edge Computing: An Energy Efficient Approach  -  nan },
  year={2024},
  author={X and Yuan and Xingyu and H and Li and He and K and Ota and Kaoru and M and Dong and Mianxiong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199986240&doi=10.1109%2FIWCMC61514.2024.10592339&partnerID=40&md5=0e4f764eb08329894c8d2cb7ad1dbf48 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IWCMC61514.2024.10592339 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344931,
  title={ Accelerate Large Language Model Inference on Edge TPU with OpenVX framework  -  nan },
  year={2024},
  author={Y and Wu and Youen and H.I and Wu and I, Hsin and K and Chin and Kuocheng and Y and Yang and Yichun and R and Tsay and Rensong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199923115&doi=10.1109%2FAICAS59952.2024.10595950&partnerID=40&md5=68e8dc891762360fe081a25d0680e1cd },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICAS59952.2024.10595950 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344932,
  title={ Insulation Failure Analysis on Power Transformer by Finite Element Method Simulations  -  2024 IEEE Electrical Insulation Conference (EIC) },
  year={2024},
  author={Ocón-Valdez, R. and Bravo-Ortega, C. P. and Espino-Cortés, F. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579374 },
  abstract={Different types of dielectric failure in the insulation system of high voltage power transformers are analyzed using finite element method (FEM) simulations; cases of failure during lightning impulse, switching impulse, applied potential, and induced potential tests are examined. The analysis aims to understand the failure mechanisms involved in each case, comparing the calculation criteria typically used by designers with the defined safety margins used during the design review process, considering aspects like the drying process and manufacturing tolerances. The finite element method is used to calculate electric field distribution to define the expected design safety margins. For safety margin calculations, some known criteria are compared with Weidmann reference curves, manufacturing design rules, and oil volume stress theory. FEM is a numerical technique that enables engineers to analyze complex structures and simulate the behavior of dielectric materials and allows for a detailed and accurate assessment of the electrical performance of insulation structures. This study is intended to help understand the design criteria used in the insulation design review process. Physical analysis of dielectric failures and the application of advanced calculation tools are fundamental to generating criteria to increase the efficiency of design reviews and thus provide greater reliability to electrical equipment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC58847.2024.10579374 },
  booktitle={ 2024 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352344933,
  title={ AICAS Grand Challenge 2024: Software and Hardware Co-optimization for General Large Language Model Inference on CPU  -  nan },
  year={2024},
  author={J and Tan and Junfeng and G and Yu and Guosheng and J and Li and Jianing and X and Ma and Xiaohan and F and Bao and Fang and E and Pan and Evens and D and Bian and David and Y and Li and Yongfu and Y and Du and Yuan and L and Du and Li},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199903118&doi=10.1109%2FAICAS59952.2024.10595886&partnerID=40&md5=003b48662fa75c1e48c73423a9a75405 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICAS59952.2024.10595886 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344934,
  title={ Vision Transformer Computation and Resilience for Dynamic Inference  -  nan },
  year={2024},
  author={K and Sreedhar and Kavya and J and Clemons and Jason and R and Venkatesan and Rangharajan and S.W and Keckler and W, Stephen and M.A and Horowitz and Alan, Mark},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199882264&doi=10.1109%2FISPASS61541.2024.00027&partnerID=40&md5=b50465a28e08b133f14e098fde800a95 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISPASS61541.2024.00027 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344935,
  title={ Analysis of Historical Transformer Failure and Maintenance Data for Facility Reliability  -  2019 IEEE/IAS 55th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  year={2019},
  author={Stringer, A. D. and Thompson, C. C. and Barriga, C. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733368 },
  abstract={The U.S. Army Corps of Engineers has compiled a unique database of equipment failure and maintenance data for critical facilities. This paper provides an in-depth analysis of transformer failure information to show historical trends in failure rates, and how equipment age and maintenance affect component failure. By analyzing over 144 thousand unit years of operational data, this paper paints a more complete picture of component reliability. The data show that careful consideration of detailed failure and maintenance data can better inform facility design and maintenance decisions, ultimately leading to improved system reliability and reduced operational costs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2019.8733368 },
  booktitle={ 2019 IEEE/IAS 55th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  chapter={0}
}

@article{rayyan-352344936,
  title={ LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models  -  nan },
  year={2024},
  author={S and Diao and Shizhe and R and Pan and Rui and H and Dong and Hanze and K and Shum and Kashun and J and Zhang and Jipeng and W and Xiong and Wei and T and Zhang and Tong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199488505&doi=10.18653%2Fv1%2F2024.naacl-demo.12&partnerID=40&md5=eabd12b0ba54e19071d9c32e3b3ba209 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.naacl-demo.12 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344937,
  title={ Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve  -  nan },
  year={2024},
  author={A and Agrawal and Amey and N and Kedia and Nitin and A and Panwar and Ashish and J and Mohan and Jayashree and N and Kwatra and Nipun and B.S and Gulavani and S, Bhargav and A and Tumanov and Alexey and R and Ramjee and Ramachandran},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199335664&partnerID=40&md5=bef22924ceb621b79e1ac1a60f4d3d83 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344938,
  title={ Assessing power transformer final failure consequences using fuzzy logic  -  2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON) },
  year={2017},
  author={Medina, R. D. and Morales, D. X. and Romero, A. A. and Cabrera, J. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8229538 },
  abstract={This paper presents a method for assess the risk index in a power transformers park, risk index is a metric that allows park administrator to ensure an optimal physical asset management, allocating properly financial and human resources in operation and maintenance actions. Assessing risk index requires calculating two secondary sub-index termed failure probability and consequence factor. Those indexes are integrated into the risk index value. In order to illustrate this process, 16 units risk index is evaluated, those units operates in the national Ecuadorian electric grid, results and discussion are finally presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CHILECON.2017.8229538 },
  booktitle={ 2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON) },
  chapter={0}
}

@article{rayyan-352344939,
  title={ CipherFormer: Efficient Transformer Private Inference with Low Round Complexity  -  nan },
  year={2024},
  author={W and Wang and Weize and Y and Kuang and Yi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199062586&doi=10.1109%2FCSCWD61410.2024.10580655&partnerID=40&md5=56027c6ec430f40a3a5cba248de90948 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCWD61410.2024.10580655 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344941,
  title={ Assessing Inference Time in Large Language Models  -  Lecture Notes in Networks and Systems },
  year={2024},
  author={B and Walkowiak and Bartosz and T and Walkowiak and Tomasz},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197871956&doi=10.1007%2F978-3-031-61857-4_29&partnerID=40&md5=52758b73d832f926fd00ad1c26531efe },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-61857-4_29 },
  booktitle={ Lecture Notes in Networks and Systems },
  chapter={0}
}

@article{rayyan-352344942,
  title={ AMORTIZING INTRACTABLE INFERENCE IN LARGE LANGUAGE MODELS  -  nan },
  year={2024},
  author={E.J and Hu and J, Edward and M and Jain and Moksh and E and Elmoznino and Eric and Y and Kaddar and Younesse and G and Lajoie and Guillaume and Y and Bengio and Yoshua and N and Malkin and Nikolay},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196972704&partnerID=40&md5=e2d41afb3e1fdda8baa00253ae274f4c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344943,
  title={ BEYOND MEMORIZATION: VIOLATING PRIVACY VIA INFERENCE WITH LARGE LANGUAGE MODELS  -  nan },
  year={2024},
  author={R and Staab and Robin and M and Vero and Mark and M and Balunović and Mislav and M.T and Vechev and T, Martin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196581273&partnerID=40&md5=a200011157774b9c4fac1cd5ec9eb036 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344945,
  title={ ServerlessLLM: Low-Latency Serverless Inference for Large Language Models  -  nan },
  year={2024},
  author={Y and Fu and Yao and L and Xue and Leyang and Y and Huang and Yeqi and A.O and Brabete and Octavian, Andrei and D and Ustiugov and Dmitrii and Y and Patel and Yuvraj and L and Mai and Luo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196227125&partnerID=40&md5=765e50157a0202b6de7dbb44b86365d8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344947,
  title={ FlattenQuant: Breaking Through the Inference Compute-bound for Large Language Models with Per-tensor Quantization  -  nan },
  year={2024},
  author={Y and Zhang and Yi and F and Yang and Fei and S and Peng and Shuang and F and Wang and Fangyu and A and Pan and Aimin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195976586&partnerID=40&md5=47608ff740f69e1d37afdfdde7e12e9d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344948,
  title={ SDMTR: A Brain-inspired Transformer for Relation Inference  -  Proceedings of Machine Learning Research },
  year={2024},
  author={X and Zeng and Xiangyu and J and Lin and Jie and P and Hu and Piao and Z and Li and Zhihao and T and Huang and Tianxi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194159635&partnerID=40&md5=c41c5596919ca3aeb810713cab2c2917 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352344949,
  title={ Analysis of fuse failure of voltage transformer in a small resistance grounding system  -  Proceedings of SPIE - The International Society for Optical Engineering },
  year={2024},
  author={J and Wei and Jufang and C and Yao and Chuang and H and Zhang and He and M and Duan and Minghui and L and Liu and Liqing and J and Feng and Junji},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194153089&doi=10.1117%2F12.3024930&partnerID=40&md5=32ac6ee76013f22fa72139462492142d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1117/12.3024930 },
  booktitle={ Proceedings of SPIE - The International Society for Optical Engineering },
  chapter={0}
}

@article{rayyan-352344950,
  title={ sLLM: Accelerating LLM Inference using Semantic Load Balancing with Shared Memory Data Structures  -  Proceedings - International Symposium on Quality Electronic Design, ISQED },
  year={2024},
  author={J and Lin and Jieyu and S and Zhang and Saiqian and A and Leon-García and Alberto},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194063758&doi=10.1109%2FISQED60706.2024.10528703&partnerID=40&md5=191a3de1d3910aad7b7f1e936ba10214 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISQED60706.2024.10528703 },
  booktitle={ Proceedings - International Symposium on Quality Electronic Design, ISQED },
  chapter={0}
}

@article{rayyan-352344951,
  title={ Integrating large language models for improved failure mode and effects analysis (FMEA): a framework and case study  -  Proceedings of the Design Society },
  year={2024},
  author={I and El-Hassani and Ibtissam and T and Masrour and Tawfik and N and Kourouma and Nouhan and D and Motte and Damien and J and Tavčar and Jože},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194055333&doi=10.1017%2Fpds.2024.204&partnerID=40&md5=a57c8c1b3a3b98a1de9ad040d372838d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1017/pds.2024.204 },
  booktitle={ Proceedings of the Design Society },
  chapter={0}
}

@article{rayyan-352344952,
  title={ Research on Image Restoration Combining Lightweight Transformer and Dense Feature Inference  -  Proceedings of SPIE - The International Society for Optical Engineering },
  year={2024},
  author={S and Zhang and Shen and X and Ma and Xuan and Z and Wen and Zijia},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193533672&doi=10.1117%2F12.3029158&partnerID=40&md5=1afe8c69d02f2f6b0abdba298616a1c4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1117/12.3029158 },
  booktitle={ Proceedings of SPIE - The International Society for Optical Engineering },
  chapter={0}
}

@article{rayyan-352344953,
  title={ iML at SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials with LLM Based Ensemble Inferencing  -  nan },
  year={2024},
  author={A and Akkasi and Abbas and A and Khan and Adnan and M.A and Shaaban and A, Mai and M and Komeili and Majid and M.K and Yaqub and K, Mohammad},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191197365&doi=10.18653%2Fv1%2F2024.semeval-1.26&partnerID=40&md5=5ba35a9019dc844fc082ed8825375b17 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.semeval-1.26 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344954,
  title={ NYCU-NLP at SemEval-2024 Task 2: Aggregating Large Language Models in Biomedical Natural Language Inference for Clinical Trials  -  nan },
  year={2024},
  author={L and Lee and Lunghao and C and Chiou and Chenya and T and Lin and Tzumi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191145266&doi=10.18653%2Fv1%2F2024.semeval-1.209&partnerID=40&md5=a150b51a78daa813b5a69aa296bedce7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2024.semeval-1.209 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344956,
  title={ An LPDDR-based CXL-PNM Platform for TCO-efficient Inference of Transformer-based Large Language Models  -  Proceedings - International Symposium on High-Performance Computer Architecture },
  year={2024},
  author={S and Park and Sangsoo and K and Kim and Kyungsoo and J and So and Jinin and J and Jung and Jin and J and Lee and Jonggeon and K and Woo and Kyoungwan and N and Kim and Nayeon and Y and Lee and Younghyun and H and Kim and Hyungyo and Y and Kwon and Yongsuk},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190237695&doi=10.1109%2FHPCA57654.2024.00078&partnerID=40&md5=510bc69a2633b5bac02304c0dfe1586f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPCA57654.2024.00078 },
  booktitle={ Proceedings - International Symposium on High-Performance Computer Architecture },
  chapter={0}
}

@article{rayyan-352344957,
  title={ Searching Optimal Floating-Point Format for Sub-8-Bit Large Language Model Inference  -  nan },
  year={2024},
  author={Y and Hwang and Youngdeok and J and Lee and Janghwan and J and Park and Jiwoong and J and Lim and Jieun and J and Choi and Jungwook},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189243662&doi=10.1109%2FICEIC61013.2024.10457111&partnerID=40&md5=92dc810386568326ed8db9ec29eaf03f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIC61013.2024.10457111 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344958,
  title={ Building an Inference Server Platform for Large Language Models Using Dataflow PIM Platform  -  nan },
  year={2024},
  author={K and Choi and Kyu-hyun and T and Hwang and Taeho},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189242135&doi=10.1109%2FICEIC61013.2024.10457213&partnerID=40&md5=489b2d21bba74d76747e684fa2cd1fd9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIC61013.2024.10457213 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344959,
  title={ Lightweight Error Correction for In-Storage Acceleration of Large Language Model Inference  -  nan },
  year={2024},
  author={J and Jeong and Jinwoo and B and Ahn and Byungmin and D and Shin and Dongmin and J and Choi and Jungwook},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189238917&doi=10.1109%2FICEIC61013.2024.10457117&partnerID=40&md5=1713f3623265843cecd48391cb155fd9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEIC61013.2024.10457117 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344960,
  title={ Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large Language Models for Dynamic Inference  -  nan },
  year={2024},
  author={P and Kavehzadeh and Parsa and M and Valipour and Mojtaba and M.S and Tahaei and S, Marzieh and A and Ghodsi and Ali and B and Chen and Boxing and M and Rezagholizadeh and Mehdi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188659589&partnerID=40&md5=f47207dce89ef86250fbc137ac80ac35 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344961,
  title={ Condition Based Assessment and Diagnostics of Transformer in Smart Grid Network Using Adaptive Neuro Fuzzy Inference System Framework  -  Smart Innovation, Systems and Technologies },
  year={2024},
  author={R and Soni and Rahul and B and Mehta and Bhinal},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178555903&doi=10.1007%2F978-981-99-6774-2_13&partnerID=40&md5=1a054f5690577abcb54a2074aa5007b2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-981-99-6774-2_13 },
  booktitle={ Smart Innovation, Systems and Technologies },
  chapter={0}
}

@article{rayyan-352344962,
  title={ Streamlining Event Relation Extraction: A Pipeline Leveraging Pretrained and Large Language Models for Inference  -  CEUR Workshop Proceedings },
  year={2024},
  author={F.G and Miguel and Gustavo, Flores and Y and Rebboud and Youssra and P and Lisena and Pasquale and R and Troncy and Raphaël},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006891357&partnerID=40&md5=6157e017261810bfe9c687922176bcdc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352344963,
  title={ THEF: A Privacy-Preserving Framework for Transformer Inference leveraging HE and TEE  -  Proceedings of the IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom },
  year={2024},
  author={Z and Li and Zehao and J and Liao and Jiachun and J and Yu and Jinhao and L and Zhang and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006504055&doi=10.1109%2FTrustCom63139.2024.00233&partnerID=40&md5=cd4bcf947917a0638184b40c1f1946d8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TrustCom63139.2024.00233 },
  booktitle={ Proceedings of the IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom },
  chapter={0}
}

@article{rayyan-352344964,
  title={ DiskTransformer: A Transformer Network for Hard Disk Failure Prediction  -  2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  year={2024},
  author={Ge, W. and Liu, P. and Zhang, M. and Zhang, Z. and Lai, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10604547 },
  abstract={The hard disk drive is one of the most commonly damaged components in data centers, which can cause a lot of losses such as unexpected shutdowns and data loss. Therefore, the prediction of hard disk drive failures has received widespread attention in data center management. Existing work has made remarkable progress in the accuracy of failure prediction. However, the prediction performance for long-term failure and small-sample disks is not satisfactory. To address this issue, we propose a new method for hard disk failure prediction. The framework consists of a time-series feature extraction network and a prediction network. The time-series feature extraction network is composed of a Temporal Convolutional Network used to extract different dimensional relationships and a set of Long Short Term Memory networks used to extract independent dimensional time-series features. The prediction network uses a Transformer model, which can fully utilize the high-quality fused features extracted by the time-series feature extraction network for disk drive failure prediction. Experimental results on public datasets have demonstrated that our proposed method can not only predict long-term failure but also has reliable prediction performance when facing small-sample disk data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICAIBD62003.2024.10604547 },
  booktitle={ 2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD) },
  chapter={0}
}

@article{rayyan-352344965,
  title={ A Study on C Code Defect Detection with Fine-Tuned Large Language Models  -  Proceedings - Asia-Pacific Software Engineering Conference, APSEC },
  year={2024},
  author={Y and Wang and Yue and X and Wang and Xu and H and Yu and Hongwei and F and Gao and Fei and X and Liu and Xueshi and X and Wang and Xiaoling},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004734288&doi=10.1109%2FAPSEC65559.2024.00055&partnerID=40&md5=b1b56bbd2d5c7c61b6ca3226a551134a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APSEC65559.2024.00055 },
  booktitle={ Proceedings - Asia-Pacific Software Engineering Conference, APSEC },
  chapter={0}
}

@article{rayyan-352344966,
  title={ Optimizing Transformer Based Inference Efficiency Using CMM-D  -  nan },
  year={2024},
  author={S.S and Deshmukh and S, Shubham and R and Verma and Rajeev and K and J, Kiran and Keerthi and R and Vamsi and Raghu and K and R, Ramana and Kodakandla and P and Das and Paulami and A and Shaik and Afreen and V.C and Thummala and Charan, Vishnu and K and Kim and Kyungsan and J and Park and Jehoon},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004550687&doi=10.1109%2FINDICON63790.2024.10958315&partnerID=40&md5=9d91ee5bee6252cd660db013ea4d0d8f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDICON63790.2024.10958315 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344967,
  title={ Fine-Tuning Transformers for News Topic Classification: Method and Best Practice  -  nan },
  year={2024},
  author={N.A.P and Masaling and Putri, Nikita Ananda and D and Suhartono and Derwin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004414967&doi=10.1109%2FISRITI64779.2024.10963556&partnerID=40&md5=9f61963172eb83894f6d8d7bdec70619 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISRITI64779.2024.10963556 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344968,
  title={ Breakthrough Low-Latency, High-Energy-Efficiency LLM Inference Performance Using NorthPole  -  nan },
  year={2024},
  author={R and Appuswamy and Rathinakumar and M.V and DeBole and V, Michael and B and Taba and Brian and S.K and Esser and K, Steven and A.S and Cassidy and S, Andrew and A and Amir and Arnon and A and Andreopoulos and Alexander and D and Bablani and Deepika and P and Datta and Pallab and J.A and Kusnitz and A, Jeffrey},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002730715&doi=10.1109%2FHPEC62836.2024.10938418&partnerID=40&md5=bbb2e175ceaa657cdbe9d5c8065aab52 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPEC62836.2024.10938418 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344969,
  title={ Intelligent Analysis and Software Development of Converter Transformer Failure Cases Based on Pearson Correlation Coefficient  -  2024 3rd Asian Conference on Frontiers of Power and Energy (ACFPE) },
  year={2024},
  author={He, K. and Zhang, T. and Cao, Y. and Wu, J. and Liu, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10800759 },
  abstract={The occurrence of converter transformer failures frequently results in considerable damage and substantial financial losses. While failure case analysis may assist in reducing these problems, the current analytical methods have yet to fully investigate the manufacturing stage. In order to conduct an in-depth study of converter transformer failure cases and to improve the manufacturing process, we have designed and developed a software platform for processing these cases. This platform enables the identification, extraction and statistical analysis of feature in the failure cases. Furthermore, we put forward a method for constructing a multidimensional feature correlation matrix based on the Pearson correlation coefficient. This provides a transparent visual representation of the relationships between the multidimensional features. Finally, a statistical and computational analysis was conducted to determine the proportion of failure problems and the correlations between features. The results validated the effectiveness of the proposed method in the comprehensive analysis of converter transformer failure cases.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACFPE63443.2024.10800759 },
  booktitle={ 2024 3rd Asian Conference on Frontiers of Power and Energy (ACFPE) },
  chapter={0}
}

@article{rayyan-352344970,
  title={ LLM Inference Serving: Survey of Recent Advances and Opportunities  -  nan },
  year={2024},
  author={B and Li and Baolin and Y and Jiang and Yankai and V.N and Gadepally and N, Vijay and D and Tiwari and Devesh},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002728757&doi=10.1109%2FHPEC62836.2024.10938426&partnerID=40&md5=8e84ef869620fd232670837cd61153b7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPEC62836.2024.10938426 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344971,
  title={ GLITCHES: GPU-FPGA LLM Inference Through a Collaborative Heterogeneous System  -  nan },
  year={2024},
  author={F and Yang and Fan and X and Yang and Xinhao and H and Wang and Hongyi and Z and Wang and Zehao and Z and Zhu and Zhenhua and S and Zeng and Shulin and Y and Wang and Yu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002728624&doi=10.1109%2FHPEC62836.2024.10938498&partnerID=40&md5=fadcfbcbe3b1269c925ebde9cb81df81 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPEC62836.2024.10938498 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344972,
  title={ Multi-Attention Adaptive Graph Transformer Network for Data Inference and Prediction in Vehicular Crowdsensing  -  nan },
  year={2024},
  author={S and Huang and Shouyu and L and Wang and Luhan and R and Zheng and Rui and J and Huo and Jie and X and Wen and Xiangming and Z and Lu and Zhaoming},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001669052&doi=10.1109%2FITSC58415.2024.10920264&partnerID=40&md5=ae8d4f4a328bbe6701fc9bbb4c4a6df0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITSC58415.2024.10920264 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344973,
  title={ Investigation of EHV Current Transformer Failure by Dielectric Frequency Response Technique  -  2020 IEEE Electrical Insulation Conference (EIC) },
  year={2020},
  author={Robalino, D. M. and Güner, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158762 },
  abstract={HV and EHV systems operate in a reliable and safe manner thanks to a proactive operational strategy and qualified expert judgement taken by asset management specialists and equipment manufacturers. Nevertheless, failure during operation is a potential risk that may derive in catastrophic events. In the field, there is a large amount of HV and EHV equipment such as bushings and instrument transformers with paper and mineral oil as main insulation media. For these equipment, oil sampling might be an option but it is not desirable, and sometimes, not even recommended by manufacturers. Aiming to avoid any catastrophic event, Hydro Quebec has relied on a variety of testing techniques to evaluate the condition of instrument transformers and bushings. Hydro Quebec incorporated dielectric frequency response (DFR) for condition assessment of oil-paper and resin-paper insulation systems. Technology now is not limited to low voltage DFR but it incorporates high voltage DFR (HVDFR) and the individual temperature correction (ITC) algorithm which have opened the opportunity for qualitative and quantitative evaluation. HV DFR and ITC present an alternative to intrusive diagnostic techniques for condition assessment and failure analysis of the main insulation of HV and EHV bushings and instrument transformers. The dielectric responses obtained from “normally aged” and “faulty” HV and EHV Current Transformers (CT) are discussed throughout this document, in addition with the analysis of the ITC algorithm as applied to MV, HV and EHV OIP CTs. The work covers a 765 kV rated OIP type CT removed from service and fully dissected to correlate DGA, DFR and actual findings inside the insulation system of the CT.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC47619.2020.9158762 },
  booktitle={ 2020 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352344974,
  title={ A Preliminary Performance Analysis of LLM Inference on Edge Accelerators  -  Proceedings of the IEEE International Conference on High Performance Computing, Data, and Analytics Workshops, HiPCW },
  year={2024},
  author={M and Arya and Mayank and Y.L and Simmhan and L, Yogesh},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001593940&doi=10.1109%2FHiPCW63042.2024.00069&partnerID=40&md5=35ca5eb7842a5dc14664db9e45d119e0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HiPCW63042.2024.00069 },
  booktitle={ Proceedings of the IEEE International Conference on High Performance Computing, Data, and Analytics Workshops, HiPCW },
  chapter={0}
}

@article{rayyan-352344975,
  title={ Towards Real-Time LLM Inference on Heterogeneous Edge Platforms  -  Proceedings of the IEEE International Conference on High Performance Computing, Data, and Analytics Workshops, HiPCW },
  year={2024},
  author={R and Jayanth and Rakshith and N and Gupta and Neelesh and S and Kundu and Souvik and D.A and Mathaikutty and A, Deepak and V.K and Prasanna and K, Viktor},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001568460&doi=10.1109%2FHiPCW63042.2024.00076&partnerID=40&md5=07bc2e4f3b622fa98ad6d5281e8ef237 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HiPCW63042.2024.00076 },
  booktitle={ Proceedings of the IEEE International Conference on High Performance Computing, Data, and Analytics Workshops, HiPCW },
  chapter={0}
}

@article{rayyan-352344976,
  title={ Exploring Multi-Label Data Augmentation for LLM Fine-Tuning and Inference in Requirements Engineering: A Study with Domain Expert Evaluation  -  nan },
  year={2024},
  author={H and Liu and Hanyue and M.B and García and Bueno, Marina and N and Korkakakis and Nikolaos},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000979323&doi=10.1109%2FICMLA61862.2024.00064&partnerID=40&md5=6fd897d2c2d3908aa950f6fd6fac7646 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLA61862.2024.00064 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344977,
  title={ Electrical Insulation Testing and DGA Analysis for the Diagnosis of Insulation Faults and Failures in 24 MVA Transformers for Distribution Systems  -  2020 8th International Conference on Condition Monitoring and Diagnosis (CMD) },
  year={2020},
  author={Boonseng, C. and Boonseng, R. and Kularbphettong, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287279 },
  abstract={The distribution transformers in the electrical system collapse result in damage to industrial property, business, and insurance deductibles. So that to reduce the collapse of the system and the expenses for maintenance. The transformer must be inspected by professional and must be regularly checked. This paper represents the investigation and diagnosis of the 24MVA distribution transformer explosion. The explosion cause the transformer oil to flow through the pressure release value violently. To investigate and diagnose the cause of the transformer explosion, electrical parameters are measured to confirm which parts have been damaged. The result of the measurement shows that there is a fault in the HV coil. Then check the transformer oil by Dissolved Gas Analysis (DGA) method, dating back from 2013 to 2019 and after the explosion. The results can confirm that there has been an abnormality since 2014. The inspection of this transformer shows that every year the electrical parameters and transformer oil inspection and DGA analysis according to IEEE Std C57.104-2019 can prevent an explosion.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD48350.2020.9287279 },
  booktitle={ 2020 8th International Conference on Condition Monitoring and Diagnosis (CMD) },
  chapter={0}
}

@article{rayyan-352344978,
  title={ KG-Infused LLM for Virtual Health Assistant: Accelerated Inference and Enhanced Performance  -  nan },
  year={2024},
  author={S.K and Katta and Kumar, Siva and A and Ray and Aritra and F and Firouzi and Farshad and K and Chakrabarty and Krishnendu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000875983&doi=10.1109%2FICMLA61862.2024.00099&partnerID=40&md5=5945b0af4c04cd9423c4f20103e2f774 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLA61862.2024.00099 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352344979,
  title={ Decentralized LLM Inference over Edge Networks with Energy Harvesting  -  Proceedings - IEEE Global Communications Conference, GLOBECOM },
  year={2024},
  author={A and Khoshsirat and Aria and G and Perin and Giovanni and M and Rossi and Michele},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000833852&doi=10.1109%2FGLOBECOM52923.2024.10901542&partnerID=40&md5=892dd6512733782914c5950af4af7817 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GLOBECOM52923.2024.10901542 },
  booktitle={ Proceedings - IEEE Global Communications Conference, GLOBECOM },
  chapter={0}
}

@article{rayyan-352344981,
  title={ Transformer failure diagnosis based on BP neural network  -  2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC) },
  year={2011},
  author={Yongtao, Z. and Yanjun, Z. and Yajuan, W. and Lan, W. and Pengjie, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025743 },
  abstract={A BP network model for transformer fault diagnosis is established based on the MATLAB environment in this paper. A large number of data samples are collected and tested, L_M algorithm is used for training samples and simulation in network model. The actual output is gained and made comparative study with the expected output. Finally, it confirms that this network model has a high accuracy and can be used for transformer fault diagnosis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEC.2011.6025743 },
  booktitle={ 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC) },
  chapter={0}
}

@article{rayyan-352344982,
  title={ LLM Dataset Inference: Did you train on my dataset?  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={P and Maini and Pratyush and H and Jia and Hengrui and N and Papernot and Nicolas and A and Dziedzic and Adam},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000558481&partnerID=40&md5=6856acac88d577626cb192c11df85c2f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344983,
  title={ Cascade Speculative Drafting for Even Faster LLM Inference  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={Z and Chen and Ziyi and X and Yang and Xiaocong and J and Lin and Jiacheng and C and Sun and Chenkai and K.C.C and Chang and Chuan, Kevin Chen and J and Huang and Jie},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000550805&partnerID=40&md5=8ac223a8b09653094a5b0a8db53a8357 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344984,
  title={ Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={S and Chen and Sijia and Y and Wang and Yibo and Y and Wu and Yifeng and Q and Chen and Qingguo and Z and Xu and Zhao and W and Luo and Weihua and K and Zhang and Kaifu and L and Zhang and Lijun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000546876&partnerID=40&md5=06df137f1ff9882da6bc5c36240ebc8b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344985,
  title={ A study of failure of pole mounted distribution transformers  -  2012 International Conference on High Voltage Engineering and Application },
  year={2012},
  author={Al-Arainy, A. A. and Malik, N. H. and Qureshi, M. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357062 },
  abstract={This paper reports on the findings of a field study carried out to determine the causes of premature failures of pole mounted distribution transformers installed in mountainous regions of Saudi Arabia that have comparatively high isokauranic level. The study consisted of transformer failure data analysis, field surveys to inspect installation of transformers, protective devices and grounding arrangements and measurements of grounding resistances, and laboratory measurements on new and used transformers as well as on surge arresters. Based on the study, several possible causes were identified as contributory factors for high failure rates. Recommendations were extended both to power utility as well as local transformer manufacturers. With the implementations of these recommendations, the failure incidences reduced significantly. This paper provides a summary of the study and main findings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2012.6357062 },
  booktitle={ 2012 International Conference on High Voltage Engineering and Application },
  chapter={0}
}

@article{rayyan-352344986,
  title={ Kraken: Inherently Parallel Transformers For Efficient Multi-Device Inference  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={R.B and Prabhakar and Baskar, Rohan and H and Zhang and Hengrui and D and Wentzlaff and David},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000545076&partnerID=40&md5=56e982708f45e12ce0992758dbd707c7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344987,
  title={ Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={W and Fu and Wenjie and H and Wang and Huangdong and C and Gao and Chen and G and Liu and Guanghua and Y and Li and Yong and T and Jiang and Tao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000542749&partnerID=40&md5=bbd394a6d7ccd05f424033a5174adc6c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344988,
  title={ KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={T and Zhang and Tianyi and J and Yi and Jonah and Z and Xu and Zhaozhuo and A and Shrivastava and Anshumali},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000542621&partnerID=40&md5=dcadb95d4a47e37a294766af3966d5c8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344989,
  title={ Online Partial Discharge Monitoring and Failure Analysis of a 132 kV Current Transformer  -  2021 IEEE Electrical Insulation Conference (EIC) },
  year={2021},
  author={Ward, B. and Whyte, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612280 },
  abstract={This paper describes how an online partial discharge monitoring system has been used to identify the correlation between network events and the degradation of insulation within an oil filled 132 kV Current Transformer. It will cover 4 months of online Partial Discharge data as well as the failure analysis and dissection of the 132kV current transformer. It will explain the reasoning for a permanent online monitoring system as well as the constraints of outdoor switch yard monitoring. The business case will be discussed, focusing on how the obtained data was used operationally in order to increase safety and reduce the probability of unplanned outages. The paper will focus on correlating increases in partial discharge activity with network and environmental events to determine a relationship between common operational data and events with the inception of partial discharge and insulation breakdown.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC49891.2021.9612280 },
  booktitle={ 2021 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352344990,
  title={ DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={Y and Yue and Yang and Y and Wang and Yulin and B and Kang and Bingyi and Y and Han and Yizeng and S and Wang and Shenzhi and S and Song and Shiji and J and Feng and Jiashi and G and Huang and Gao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000540419&partnerID=40&md5=151ba16ed46710ee52a0abf5f698bb83 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344991,
  title={ Nimbus: Secure and Efficient Two-Party Inference for Transformers  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={Z and Li and Zhengyi and K and Yang and Kang and J and Tan and Jin and W and Lu and Wenjie and H and Wu and Haoqi and X.S and Wang and Shaun, Xiao and Y and Yu and Yu and D and Zhao and Derun and Y and Zheng and Yancheng and M and Guo and Minyi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000537285&partnerID=40&md5=5a0dad5ed2ed2b01cbab91e3a48517bb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344992,
  title={ KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={C and Hooper and Coleman and S and Kim and Sehoon and H and Mohammadzadeh and Hiva and M.W and Mahoney and W, Michael and Y.S and Shao and Sophia, Yakun and K.W and Keutzer and W, Kurt and A and Gholami and Amir},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000537041&partnerID=40&md5=6cf8a62a210cd5ba0411f25fbeec18f4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344993,
  title={ Influence of Grid-Tied PV Systems and EV Charging Stations on Power Transformers Failure Rate Behaviour  -  2019 IEEE Workshop on Power Electronics and Power Quality Applications (PEPQA) },
  year={2019},
  author={Torres, S. and Durán, I. and Marulanda, A. and Pavas, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851532 },
  abstract={This document presents the analysis of the failure rate of an oil-inmmersed header distribution transformer due to the presence of current harmonics produced by a Grid-Tied PV system and slow charging stations. Monte-Carlo simulations were performed to generate harmonic profiles in order to calculate the accelerated aging factor that along with the transformer health index determine the behavior of the transformer's failure rate. The results show that harmonic distortion does not have a significant influence on the transformer life reduction, and that degradation of solid and liquid insulation is one of the cause of increase in the failure rate in long-term as they have a high relative weight in the health index.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PEPQA.2019.8851532 },
  booktitle={ 2019 IEEE Workshop on Power Electronics and Power Quality Applications (PEPQA) },
  chapter={0}
}

@article{rayyan-352344994,
  title={ MatFormer: Nested Transformer for Elastic Inference  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={Devvrit and S and Kudugunta and Sneha and A and Kusupati and Aditya and T and Dettmers and Tim and K and Chen and Kaifeng and I.S and Dhillon and S, Inderjit and Y and Tsvetkov and Yulia and H and Hajishirzi and Hannaneh and S.M and Kakade and M, Sham and A and Farhadi and Ali},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000534395&partnerID=40&md5=c0f3f9f9d5e5eb9c78c47dbe21cba583 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344995,
  title={ Reliability of parallel connected power transformers with failure correlation and its preventive maintenance  -  2014 17th International Conference on Electrical Machines and Systems (ICEMS) },
  year={2014},
  author={Yang, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7013623 },
  abstract={This paper studies reliability of power substation with parallel connected power transformers and its preventive maintenance strategy. The processes of transformers failure are modeled by Poisson processes with correlation. Representing by multi-Gaussian Copula function, the mathematical formula of reliability of three power transformers connected parallel is given, and the reliability of substation with preventive maintenance schedule is studied. By the mean of Monte Carlo simulation, the reliability of three power transformers parallel connected is calculated, and its preventive maintenance schedule is discussed. The research of the paper shows that the failure correlation of transformers is key factor to the preventive maintenance schedule.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEMS.2014.7013623 },
  booktitle={ 2014 17th International Conference on Electrical Machines and Systems (ICEMS) },
  chapter={0}
}

@article{rayyan-352344996,
  title={ ARKVALE: Efficient Generative LLM Inference with Recallable Key-Value Eviction  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={R and Chen and Renze and Z and Wang and Zhuofeng and B and Cao and Beiquan and T and Wu and Tong and S and Zheng and Size and X and Li and Xiuhong and X and Wei and Xuechao and S and Yan and Shengen and M and Li and Meng and Y and Liang and Yun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000524349&partnerID=40&md5=f08af93567176f4e1cc8f81cb2b965de },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344997,
  title={ Reducing Probability of Transformer Failure by Managing EV Charging in Residential Parking Lots  -  2021 IEEE Power & Energy Society General Meeting (PESGM) },
  year={2021},
  author={Soleimani, M. and Khoshjahan, M. and Kezunovic, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638079 },
  abstract={The power of electric vehicle (EV) chargers is considerable and high penetration of EVs may lead to overloading and thermal stress for utility transformers. Large buildings usually are connected to the grid through a transformer. By managing EV charging in the building parking lots, the probability of transformer failure may be reduced. We propose a controller to manage the charging of the EVs to reduce the probability of transformer failure without the involvement of distribution grid operator. In order to test the proposed framework, a use case is developed using real and synthesized data from College Station, TX, United States.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM46819.2021.9638079 },
  booktitle={ 2021 IEEE Power & Energy Society General Meeting (PESGM) },
  chapter={0}
}

@article{rayyan-352344998,
  title={ MEGALODON: Efficient LLM Pretraining and Inference with Unlimited Context Length  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={X and Ma and Xuezhe and X and Yang and Xiaomeng and W and Xiong and Wenhan and B and Chen and Beidi and L and Yu and Lili and H and Zhang and Hao and J and May and Jonathan and L.S and Zettlemoyer and S, Luke and O and Levy and Omer and C and Zhou and Chunting},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000524271&partnerID=40&md5=80c6d824dcf0f489c879c3100c104fc4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352344999,
  title={ Block Transformer: Global-to-Local Language Modeling for Fast Inference  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={N and Ho and Namgyu and S and Bae and Sangmin and T and Kim and Taehyeon and H and Jo and Hyunjik and Y and Kim and Yireun and T and Schuster and Tal and A and Fisch and Adam and J and Thorne and James and S and Yun and Seyoung},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000517145&partnerID=40&md5=a1ff83532c8e2e7a57cd37055b891c0a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345000,
  title={ SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={R and Svirschevski and Ruslan and A and May and Avner and Z and Chen and Zhuoming and B and Chen and Beidi and Z and Jia and Zhihao and M and Ryabinin and Max},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000514222&partnerID=40&md5=2fdf3e0b5f92ae02c4e52fadf0d6c14e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345001,
  title={ Investigation of 150/66 kV 100 MVA Transformer Internal Failure  -  2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE) },
  year={2018},
  author={Harsono, B. B. S. D. A. and Kusuma, A. A. and Munir, B. S. and Priambodo, N. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8534796 },
  abstract={An investigation was performed upon the failure of a 150/66 kV 100 MVA power transformer and nearby 66 kV arrester during heavy rain. To verify the possible cause of the failure, an evaluation was conducted by performing visual inspection on the transformer and the arrester after breakdown, analyzing related historical assessment and maintenance data, evaluating recorded lightning activity data from lightning detection system and generating relevant simulation using transformer nameplate and actual configuration. Majority of the historical assessment and maintenance data results showed no indication of transformer early breakdown, but the sweep frequency response analysis (SFRA) test result showed severe deformation on primary and secondary winding. According to the simulation using 20 kA 1.2/50 μs lightning strike on 66 kV transmission line connected to the transformer, overvoltage on the transformer reached 1.69 p.u. for primary winding and 8.47 p.u for secondary winding. However, according to recorded lightning data during time of failure, there's no nearby lightning strike around the transformer or the transmission lines connected to it. Moreover, lightning overvoltage would initially shatter the transformer's bushing rather than directly deforming the transformer tank. The simulation result for short circuit between primary winding phase R to ground showed identical current and voltage waveform with digital fault recorder data during breakdown. According to data and simulation result analysis, lightning activity has no contribution toward the failure of the 150/66 kV 100 MVA transformer. The possible cause of transformer breakdown was internal failure in form of arcing between primary winding phase R to ground.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICITEED.2018.8534796 },
  booktitle={ 2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE) },
  chapter={0}
}

@article{rayyan-352345002,
  title={ Slicing Vision Transformer for Flexible Inference  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={Y and Zhang and Yitian and H and Coskun and Huseyin and X and Ma and Xu and H and Wang and Huan and K and Ma and Ke and X and Chen and Xi and D.H and Hu and Hao, Derek and Y and Fu and Yun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000513564&partnerID=40&md5=3529397cc6a5e12f75df166edad902a0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345003,
  title={ NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={T and Zhang and Tianyi and J and Yi and Jonah and B and Yao and Bowen and Z and Xu and Zhaozhuo and A and Shrivastava and Anshumali},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000505145&partnerID=40&md5=2d31c1dc1936208b1c186b89a4fe11ab },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345004,
  title={ Latent Plan Transformer for Trajectory Abstraction: Planning as Latent Space Inference  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={D and Kong and Deqian and D and Xu and Dehong and M and Zhao and Minglu and B and Pang and Bo and J and Xie and Jianwen and A and Lizarraga and Andrew and Y and Huang and Yuhao and S and Xie and Sirui and Y and Wu and Yingnian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000501154&partnerID=40&md5=28ae13509f7b74edddabd7061feb2100 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345005,
  title={ Speculative Decoding with CTC-based Draft Model for LLM Inference Acceleration  -  Advances in Neural Information Processing Systems },
  year={2024},
  author={Z and Wen and Zhuofan and S and Gui and Shangtong and Y and Feng and Yang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000465957&partnerID=40&md5=6587f0ccb5e3acb8e64f7720d96ef5d9 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345006,
  title={ Investigation of Supply Phase Failure in Phase-Shifting Transformer with Hexagon Scheme and Regulating Autotransformer  -  2021 International Conference on Electromechanical and Energy Systems (SIELMEN) },
  year={2021},
  author={Bosneaga, V. and Suslov, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9600358 },
  abstract={The scope of the work was the study of the phase failure operating for the new FACT’s type phase-shifting device, intended for the flexible connection of AC power systems. The mathematical model has been developed for conducting this study. The device contains the main phase-shifting transformer based on hexagon circuit with additional regulating autotransformer, this creates the possibility of circular regulation of phase shift angle between connected systems. The model includes two 6-winding three-legs transformers, for which two sets of parameters can be independently set based on the data for the short circuit and no-load modes. The data for the direct sequence parameters is usually provided by the transformer manufacturers, and the data for the zero sequence parameters could be obtained upon additional request. As a result of modeling, the vectors of the voltages and currents were obtained in all windings in the investigated modes with supply source phase failure. This makes it possible to analyze the admissibility of such modes and estimate the need for taking special measures of protection against them. It is shown that the voltages on the windings of the main transformer insignificantly depend on the connection mode of the regulating autotransformer, while the pattern of currents distribution in the windings of the main and regulating transformers to a large extent is determined by said connection mode of the autotransformer. The presence of perceptible zero-sequence current flowing through the grounded neutrals of the power supply source and load is noticed. This fact is connected with the release of insignificant magnetic flux from the magnetic circuit in the surrounding space.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SIELMEN53755.2021.9600358 },
  booktitle={ 2021 International Conference on Electromechanical and Energy Systems (SIELMEN) },
  chapter={0}
}

@article{rayyan-352345007,
  title={ The Ups and Downs of Large Language Model Inference with Vocabulary Trimming by Language Heuristics  -  nan },
  year={2024},
  author={N and Bogoychev and Nikolay and P and Chen and Pinzhen and B and Haddow and Barry and A and Birch and Alexandra},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000158498&partnerID=40&md5=73cbc92c0ced211b6ae6788fd798206e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345008,
  title={ A proposed Genetic Algorithm to optimize service restoration in electrical networks with respect to the probability of transformers failure  -  2010 IEEE International Conference on Power and Energy },
  year={2010},
  author={Aminian, M. and Moazami, E. and Mirzaei, M. and Kadir, M. Z. A. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5697701 },
  abstract={Power system reliability, stability and efficiency are the most important issues to insure continuously feeding of customers. However in process of time, system will be age and the probability of failures will increase and faults inevitably will occur. When a fault occurs, the first reaction is isolation of the faulty area, then with aid of software and/or skillful person quick restoration is essentially needed. To minimize the out-of-service area and activity time of restoration many methods are suggested depend on objectives and constraints of restoration strategy. In many researches a Genetic Algorithm is employed as a powerful tool to solve this multi-objective, multi-constraint optimization problem. Out-of-service area minimization, reduce the number of switching operation and minimizing the minimum electrical power loss in restored system are the prior objectives of restoration plan. In this paper, as transformers are the most expensive and more effective equipments in the electrical network, failure probability increasing is introduced as a new constraint in genetic algorithm by authors. Expected results of this new algorithm should lead to a new plan of restoration in permissible ranges of transformer loading in respect of their age, previous experienced faults and condition monitoring.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PECON.2010.5697701 },
  booktitle={ 2010 IEEE International Conference on Power and Energy },
  chapter={0}
}

@article{rayyan-352345009,
  title={ Investigation on the Relationship between Failure Rates and Health Index of Distribution Transformer Population  -  2021 IEEE International Conference on the Properties and Applications of Dielectric Materials (ICPADM) },
  year={2021},
  author={Shariffuddin, N. S. and Azis, N. and Selva, A. M. and Yahaya, M. S. and Jasni, J. and Talib, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493977 },
  abstract={In this paper, a study is carried out to investigate the relationship between failure rate and Health Index (HI) of the transformer population based on condition monitoring information. In total, 3192 oil samples from 370 transformers with age ranging from 1 to 25 years were analysed in this study. First, the HI and failure rate of transformer was computed based on yearly individual condition monitoring data of the oil samples. Several parameters were measured such as oil quality, dissolved gases, furanic compounds and age. The HI of transformers was determined based on scoring and weighting method while the failure rate of transformer was determined based on relative risk method. Next, the average HI and failure rate for each age was computed and the relationship between the HI and failure rate were obtained based on two-parameter exponential function model. Based on the study, it is found that there is a relationship between failure rate and HI of the transformer population. The failure rate increases almost exponentially as the HI decreases to around 55%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPADM49635.2021.9493977 },
  booktitle={ 2021 IEEE International Conference on the Properties and Applications of Dielectric Materials (ICPADM) },
  chapter={0}
}

@article{rayyan-352345010,
  title={ Industrial mechanical equipment failure prediction based on Transformer-CLS  -  2024 7th International Conference on Electrical Engineering and Green Energy (CEEGE) },
  year={2024},
  author={Jin, Y. and Zhou, Z. and Sun, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744072 },
  abstract={Mechanical equipment, serving as the backbone of manufacturing, is crucial to every aspect of industrial production. During its operation, mechanical equipment inevitably encounters issues like wear and tear, leading to a variety of malfunctions that escalate over time, thereby impacting production quality and efficiency. This study presents a visual analysis of the operational and failure data of mechanical equipment. We integrates conventional machine learning techniques with advanced deep learning algorithms to forecast failures. The model’s performance is assessed using metrics such as the confusion matrix, ROC curve, precision, and recall. The paper concludes by affirming the efficacy and advantages of the Transformer-CLS model in predicting failures of industrial mechanical equipment. This approach demonstrates a marked enhancement in the precision and recall rates of failure predictions compared to traditional models, alongside notable transfer learning capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEEGE62093.2024.10744072 },
  booktitle={ 2024 7th International Conference on Electrical Engineering and Green Energy (CEEGE) },
  chapter={0}
}

@article{rayyan-352345011,
  title={ Detection of early failures within traction transformers based on Gaussian-PSO  -  2015 3rd International Conference on Electric Power Equipment – Switching Technology (ICEPE-ST) },
  year={2015},
  author={Zhu, J. and Chen, T. and Fu, Q. and Cheng, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368323 },
  abstract={A novel self-adaptive RBF Neural Network algorithm is proposed in the paper to detect the early failures of electric locomotive traction transformers. In the algorithm, the initial node number and center vector of RBF neural network are obtained by fuzzy C - average (FCM) algorithm firstly, then together with connection weights are optimized by the Gaussian improved particle swarm optimization (PSO) algorithm. The self-adaptive RBF neural network is finally applied to the comprehensive test and fault diagnosis system for electric locomotive traction transformer. The results show that the proposed algorithm can effectively detect the faults that is misinformed and underreported by the original test system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEPE-ST.2015.7368323 },
  booktitle={ 2015 3rd International Conference on Electric Power Equipment – Switching Technology (ICEPE-ST) },
  chapter={0}
}

@article{rayyan-352345012,
  title={ A Probabilistic Maintenance Scheme Evaluation Method for Transformer Based on Failure Rate  -  2017 4th International Conference on Information Science and Control Engineering (ICISCE) },
  year={2017},
  author={Liang, G. and Li, S. and Liu, R. and Cao, J. and Hao, Y. and Chen, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8110256 },
  abstract={Reasonable maintenance for power transformer is critical to the long-term security operation of transformer. At present, the lack of support theory for transformer maintenance decision usually causes reliability and economy issues for power companies, which may cause "over maintenance" or "owing maintenance" problems. For this reason, a probabilistic maintenance scheme evaluation method for transformer based on failure rate is proposed by simulation of the health states of transformer with unexpected operation stress. Firstly, a first order model of transformer paper degradation is proposed to represent the health state of a transformer. Then, variations of Degree of Polymerization (DP) along with time are randomly generated using Monte Carlo Simulation (MCS) based on the Weibull Distribution under different maintenance schemes. Then the failure rate (FR) curve of transformer is then determined. When the FR is higher than a pre-defined threshold value, the transformer should be replaced for reliability purpose. The effectiveness of the proposed maintenance scheme evaluation method is verified by a typical engineering application. Simulation results show that it can be used to determine an optimum maintenance scheme for transformer to avoid failure risk and reduce the maintenance cost of power companies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICISCE.2017.29 },
  booktitle={ 2017 4th International Conference on Information Science and Control Engineering (ICISCE) },
  chapter={0}
}

@article{rayyan-352345013,
  title={ Transformer Life Prediction Based on Failure Probability and Health Index  -  2024 7th International Conference on Energy, Electrical and Power Engineering (CEEPE) },
  year={2024},
  author={Wang, Z. and Ma, W. and Ma, Z. and Chai, W. and Yu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10586550 },
  abstract={In power systems, transformers play a central role in ensuring the efficient transmission and distribution of electrical energy. However, over time and with continued use, transformer performance degrades, increasing the risk of system failure. This performance degradation not only affects the reliability and stability of the system, but can also lead to costly maintenance and sudden power interruptions. Therefore, accurate prediction of the remaining life of a transformer, as well as timely implementation of maintenance and replacement programs, is critical to maintaining the continuity and stability of the power system. Traditional transformer life prediction methods often rely on periodic physical inspections, which is not only time-consuming and labor-intensive, but also difficult to accurately capture the dynamic nature of transformer degradation. Therefore, the development of a more accurate and automated prediction model has become a research priority. To predict the remaining life of the transformer, this paper proposes a prediction method based on failure probability. First, data processing is performed on the transformer failure probability and health index. Then, the processed data is fitted using the least squares method, and a transformer failure probability model is established. A mapping between the health index and failure probability of transformers is proposed, which is used to obtain a set of health index data for the transformer. Finally, polynomial regression is used to predict the remaining life of a transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEEPE62022.2024.10586550 },
  booktitle={ 2024 7th International Conference on Energy, Electrical and Power Engineering (CEEPE) },
  chapter={0}
}

@article{rayyan-352345014,
  title={ Power Transformer Failure Analysis in Maharashtra State: A Case Study  -  2024 IEEE 5th India Council International Subsections Conference (INDISCON) },
  year={2024},
  author={Khergade, A. and Wath, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744332 },
  abstract={Power transformers are essential components in the electrical power system that plays a crucial role in the transmission and distribution of electrical energy. In this case study, various causes of the power transformer failure that occurred in heavily populated areas of the utility are analyzed. The power transformer failure statistic of the Maharashtra State is also presented in this paper. Failure of the power transformers due to internal and external faults, the effect of neutral grounding resistance, age of the power transformers installed at a site, major fault occurrence during excavation and the breather condition of the power transformers are discussed in this article. The compact area wise number of failed power transformers is also presented in this paper. Some key outcomes from the case study during analyses of failure of the power transformers are described in the conclusion section. The purpose of this work is to analyze the reliability of the power transformers and to identify the main causes of its failure, which will also be useful to other state utilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDISCON62179.2024.10744332 },
  booktitle={ 2024 IEEE 5th India Council International Subsections Conference (INDISCON) },
  chapter={0}
}

@article{rayyan-352345015,
  title={ Surge distribution in the Oil Impregnated Paper (OIP) bushing of 400KV transformer to determine failure initiated by draw lead  -  2015 Conference on Power, Control, Communication and Computational Technologies for Sustainable Growth (PCCCTSG) },
  year={2015},
  author={Nanda, B. and Reddy, K. S. and Singh, B. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7503949 },
  abstract={Failure of high voltage bushing leading to partial or complete destruction of power transformer has been considered as severe event in the electrical power system. Apart from power distribution it has led to human tragedy in a number of sites. Transformer industry is concerned with such problems and hence several committees have discussed the phenomena. Amongst other reasons attributed to it, the failure of draw lead causing complete failure of bushing and insulation breakdown in paper insulation between aluminum foil and the core has been major cause at power plant. The present paper aims at formulating an electrical equivalent network comprising inductances, capacitances and resistances representing the bushing and draw lead. The voltage distribution in the annular region of draw lead and aluminum pipe supporting core of HV bushing is calculated using Electro Magnetic Transient Programme [EMTP] programmed for standard and fast impulse voltage surge. The analysis shows that higher stress leads to the failure of draw lead and paper insulation of the core. Photographs of failed bushing along with initiating spots are given in the paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCCCTSG.2015.7503949 },
  booktitle={ 2015 Conference on Power, Control, Communication and Computational Technologies for Sustainable Growth (PCCCTSG) },
  chapter={0}
}

@article{rayyan-352345016,
  title={ Sub-Cyclic Damaging Ferroresonant Overvoltages in 230 kV Transmission Systems Field Experience of 230 kV Transformer-Ended Cable Feeders Failure  -  2017 9th IEEE-GCC Conference and Exhibition (GCCCE) },
  year={2017},
  author={Fares, N. E. Halabi and Sheef, J. and Al-Malki, T. and Rajab, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8448266 },
  abstract={Extensive research and world-class standards have reported the ferroresonance phenomenon as a low-frequency temporary overvoltage with a range of voltage shape starting from 1 cycle. This paper provides a case study for a typical 230 kV transformer-ended cable feeder configuration that has experienced damaging ferroresonant overvoltages in 3/4 cycle. Ferroresonant overvoltages were recorded in two (2) different incidents and a similar 230 kV feeder configuration with magnitudes exceeding 2.75 pu in 12 ms causing a phase insulation breakdown in power transformers and a longitudinal insulation breakdown in circuit breakers. Waveform records captured at 32 samples per cycle are analyzed and used to validate a PSCAD/EMTDC model. Trigger mechanisms of this sub-cyclic ferroresonance profile are identified and preventive/protective measures are discussed based on recommendations for IEEE and IEC standards.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEEGCC.2017.8448266 },
  booktitle={ 2017 9th IEEE-GCC Conference and Exhibition (GCCCE) },
  chapter={0}
}

@article{rayyan-352345017,
  title={ Reliability and Failure Analysis of Boxed-Power Transformers Based on Fault Tree Approach  -  2025 IEEE 3rd International Conference on Power Science and Technology (ICPST) },
  year={2025},
  author={Liang, Q. and Xu, K. and Liang, Y. and Yu, J. and Zhang, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11088663 },
  abstract={In order to accurately find out the causes of transformer failure, the indexes of transformer reliability evaluation and the main failure modes are determined for different types of failure events occurring during the operation of power transformers. Fault tree analysis method was used to analyze the causes of transformer failures, and a computer-aided fault tree analysis system was used to construct a fault tree assessment model of transformer failure, and the calculation methods of reliability, failure rate and importance parameters were determined, and the reliability and failure calculations of the fault tree were analyzed through simulation results. Calculation results show that by reducing the probability of transformer failure and improving the reliability of equipment can improve the reliability level of power transformers, thus providing guidance for transformer condition maintenance, which is of great significance to ensure the safety and reliability of the power grid system operation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPST65050.2025.11088663 },
  booktitle={ 2025 IEEE 3rd International Conference on Power Science and Technology (ICPST) },
  chapter={0}
}

@article{rayyan-352345018,
  title={ An Assessment of Failure Rate of Pole-Mounted Transformers Using Probabilistic Risk Evaluation of Lightning Arresters  -  IECON 2022 – 48th Annual Conference of the IEEE Industrial Electronics Society },
  year={2022},
  author={Koalane, N. P. and Bokoro, P. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9968529 },
  abstract={In this study, the probabilistic risk evaluation of surge arresters is conducted in order to assess protection effectiveness of PMTs against lightning strikes. An 11 kV distribution line located in Arabel Platkoppie − a district area in Johannes-burg, South Africa − which experienced 59% of PMT failure due to lightning between 2017 and 2019, is used as a case-study. Statistical data related to lightning activities around the Arabel Platkoppie area were souced from FALLS. EMTP-RV Simulation results of direct effect of lightning strikes were used. The risk evaluation of lightning arrester, committed to the protection of PMTs, is then assessed using probabilistic failure evaluation. Resuts show that with the frequency of lightning activity recorded in the Arabel Platkoppie area, the annual outage rate is estimated to be 0.1694 outage/100 km/year, which translates to the expected average surge arrester life of 5.8 years.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IECON49645.2022.9968529 },
  booktitle={ IECON 2022 – 48th Annual Conference of the IEEE Industrial Electronics Society },
  chapter={0}
}

@article{rayyan-352345019,
  title={ Failure Testing of Single-Phase Voltage Transformers of Distribution Networks Due to Discharge Phenomena in Insulation  -  2018 Dynamics of Systems, Mechanisms and Machines (Dynamics) },
  year={2018},
  author={Burym, A. A. and Rysev, P. V. and Rysev, D. V. and Serdyuk, V. S. and Sidorova, E. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601469 },
  abstract={Failures of single-phase voltage transformers applied in distribution networks are investigated. The aim of the study is to determine how to comply with the operating conditions the service instruction of the voltage transformers in the cold climate regions, used protection equipment and to generate recommendations for increasing the operational reliability. To achieve the objective, problems of electric strength temperature dependence investigation, transformer oil chromatographic analysis and transformer operation modes computer simulation are solved. As a result, insulation defects of voltage transformers are identified and localized by chromatographic analysis of oil. A neural network is proposed to identify faults by partial discharge parameters. Practical recommendations are founded to increase the reliability of voltage transformer operation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Dynamics.2018.8601469 },
  booktitle={ 2018 Dynamics of Systems, Mechanisms and Machines (Dynamics) },
  chapter={0}
}

@article{rayyan-352345020,
  title={ Temperature Distribution and Failure of Converter Transformer under DC Bias  -  2022 4th International Conference on Electrical Engineering and Control Technologies (CEECT) },
  year={2022},
  author={Wang, Y. and Cong, H. and Zhang, Q. and Lu, P. and Liu, L. and Liu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10030678 },
  abstract={In order to study the influence of DC magnetic bias on transformer temperature failure. In this paper, a three-dimensional model of oil immersed converter transformer is established, the loss under DC bias is calculated, and the temperature distribution under DC bias is simulated by the finite element method. The temperature failure of the transformer under different working conditions is analyzed. It is concluded that when the converter transformer is subjected to more than 10A magnetic bias current for a long time, it will lead to local overheating and reduce converter life.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEECT55960.2022.10030678 },
  booktitle={ 2022 4th International Conference on Electrical Engineering and Control Technologies (CEECT) },
  chapter={0}
}

@article{rayyan-352345021,
  title={ Analysis of Influence of Insulation Failure of Drive Transformer on Drive Circuit of SiC MOSFET  -  2021 11th International Conference on Power and Energy Systems (ICPES) },
  year={2021},
  author={Guancheng, X. and Miao, L. and Xiangjun, M. and Xiaoshuai, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9683922 },
  abstract={The driving circuit plays an important role in the normal operation of a power electronic product. The driving power supply with the driving transformer as the main device is an important part of the driving circuit. Therefore, the performance of transformer parameters has a great impact on the drive circuit. The distributed parameters in high-frequency transformer will have adverse effects on power electronic products. This paper focuses on the influence of insulation failure in distributed parameters on SiC MOSFET drive circuit. A driving circuit for SiC MOSFET is designed, and the hardware circuit of the circuit is built. The influence of insulation failure on the driving circuit is simulated by software, and the influence of insulation failure on the driving circuit is verified by hardware circuit.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPES53652.2021.9683922 },
  booktitle={ 2021 11th International Conference on Power and Energy Systems (ICPES) },
  chapter={0}
}

@article{rayyan-352345022,
  title={ Failure Analysis and Investigation of Electrical Insulation of 10 MVA Oil-Type Transformers Damaged due to Direct Lightning Strikes  -  2020 23rd International Conference on Electrical Machines and Systems (ICEMS) },
  year={2020},
  author={Boonseng, C. and Kammaroeng, D. and Kularbphettong, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291069 },
  abstract={Failures in distribution transformers are associated with high property damage, high business interruption losses and large insurance deductibles. Professional independent inspection and protection design, taken on an ongoing basis, can go a long way towards reducing failures and eliminating unnecessary repair costs. This paper presents the study of the effects of lightning on electrical insulation, damage, and components in and components in 10MVA, 24/6.6kV oil-type transformers. Beginning to investigate and diagnose the cause of the transformer explosion by measuring electrical parameters to confirm which parts have been damaged. The result of the measurement shows that there is a fault in the HV coil. The investigation method focuses on the damage and solutions to prevent the problem from occurring again. Finally, a lightning protection design is necessary.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/ICEMS50442.2020.9291069 },
  booktitle={ 2020 23rd International Conference on Electrical Machines and Systems (ICEMS) },
  chapter={0}
}

@article{rayyan-352345023,
  title={ Snubber Circuit Design for Transformers in an Urban High Rise Office Building  -  IEEE Transactions on Industry Applications },
  year={2015},
  author={Sutherland, P. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116555 },
  abstract={Transformer failures have in recent years led to the development of resistor-capacitor snubber circuits for the protection of the transformer and winding insulation from the damaging effects of high-voltage high-frequency transients. Transformer insulation may be damaged if the basic insulation level is exceeded, during turn-to-turn insulation, when there is excessive rate of change of voltage with time (dv/dt), and in switching devices by restrikes when the transient recovery voltage is exceeded. These transients are most often observed when dry-type transformers are closely coupled to vacuum switching devices. Some manufacturers are now including snubbers in their transformer designs. This paper provides a thorough review of the causes of the transients, methods of analysis, and mitigation of the effects of these transients. An example is provided of transformers to be installed in the basement of an urban high rise office building (where the space is limited and the available fault current is high), where the transformer enclosure includes built-in snubber circuits. The strengths and weaknesses of current methods are examined. Recommendations are made for improvements in snubber circuit design and analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2015.2440357 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345024,
  title={ Improving the FMEA Method to Failure Risk Assessment of Transformers, A Case Study in Tehran Electric Power Distribution Transformers  -  2024 IEEE International Conference on Power and Energy (PECon) },
  year={2024},
  author={Shafei, A. P. and Rezaei, A. and Silva, J. F. A. and Monteiro, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827011 },
  abstract={Distribution transformers play a pivotal role in power networks, serving as critical assets whose failure can lead to substantial expenses for replacement or repair. This study employs an improved Failure Modes and Effects Analysis (FMEA) method, utilizing transformer failures within the Tehran Electric Power Distribution Company over a decade. The Risk Priority Number (RPN) criterion assesses the failure probability associated with various failure modes for quantization within the FMEA method. Risk prioritization is determined through the RPN formulation. This paper proposes new improvements in FMEA, including an expert-based weighting method applied to the weighted RPN's sub-parameters to enhance precision and calculate RPN values based on the age group of each transformer. Subsequently, strategic corrective actions are proposed and implemented to mitigate the risk of transformer failures in the upcoming year. The culmination of this case study results in improved prediction capabilities and more effective failure prevention strategies for the company's transformers, facilitating purposeful asset management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PECon62060.2024.10827011 },
  booktitle={ 2024 IEEE International Conference on Power and Energy (PECon) },
  chapter={0}
}

@article{rayyan-352345025,
  title={ Assessment of Best Practices for Mitigation of Rapid Voltage Change due to Transformer Inrush  -  2019 IEEE Milan PowerTech },
  year={2019},
  author={Singh, G. and Miller, C. and Howe, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8810934 },
  abstract={The penetration of Distributed Energy Resources (DERs) on the power system has come with its own set of problems, especially in the power quality domain. As DERs continue to be integrated at the transmission and sub-transmission voltage level, power quality engineers are faced with the unique situation of having to regulate a source of generation rather than a load. One of the important outcomes of such integration has been the concern about increase in cases of rapid voltage change (RVC). While there is evidence to indicate that DERs themselves do not contribute much to voltage fluctuations in the power grid, there have been recorded instances where the energization of transformers used to integrate DERs to the grid has led to an RVC event. This paper presents the current status of research on RVCs, particularly in terms of regulation, and then outlines the various methods and strategies that can be used to counter the problem of RVC that results from energization of transformers on the utility grid. A case study from an RVC event caused by transformer energization is presented and then used as a baseline, to study the effect of various mitigation techniques, using EMTP simulations. Various techniques have been contrasted and compared in terms of cost and effectiveness. The paper finally closes with a discussion of the future avenues and expected work with regards to Power Quality in this field.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PTC.2019.8810934 },
  booktitle={ 2019 IEEE Milan PowerTech },
  chapter={0}
}

@article{rayyan-352345026,
  title={ Influence of Transformer Axial-Clamping Loss on the Vibration of Transformers  -  2022 IEEE Electrical Insulation Conference (EIC) },
  year={2022},
  author={Würde, A. and Kahlen, J. N. and Langenberg, N. and Moser, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833153 },
  abstract={Due to ageing and dynamic loads, the short circuit strength of transformers in secondary distribution can be reduced. An insufficient short circuit strength may result from reduced axial winding clamping. Vibration analysis offers a promising way in a non-invasive manner to identify changes in the winding clamping.In this paper, experimental investigations are carried out to analyze the influence of axial clamping losses on the transformer vibration. The vibration is measured by fourteen vibration sensors positioned at the side surface of the transformer tank. The clamping of the windings is incrementally decreased to analyze its influence. For each decrement, the transformer is powered in ohmic load scenarios ranging from no-load tests up to rated power tests. The impact of these clamping reductions on the 100 Hz vibration component is analyzed.The results show that the identification of clamping loss depends on the sensor position. Based on the chosen evaluation criteria, only two out of fourteen sensors enable an identification of clamping loss. Furthermore, it can be concluded that the identification of the winding clamping loss is load-dependent. The optimal load to identify winding clamping loss for the tested transformer ranges from 56 % rated power to 65 % rated power.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC51169.2022.9833153 },
  booktitle={ 2022 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345027,
  title={ Assessment of Spare Transformer Requirements for Distribution Stations  -  IEEE Transactions on Power Systems },
  year={2011},
  author={Hamoud, G. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453091 },
  abstract={This paper describes a probabilistic method for determining the number of spare transformers (regular spare transformers and mobile unit substations) required for a group of distribution transformers in order to meet a predetermined level of the group availability. The method is based on a Markov model and accounts for a number of factors that affect the number of spare units. The factors include the use of both regular spare transformers (RSTs) and mobile unit substations (MUSs), type of transformer failure and the various parameters of regular transformers, and spare transformers. Sensitivity analysis is performed to determine the factors that affect most the number of spare units. The proposed method is illustrated using a sample system of the Hydro One's distribution stations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2010.2046429 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345028,
  title={ Types and Mechanisms of Condenser Transformer Bushing Failures  -  IEEE Electrical Insulation Magazine },
  year={2023},
  author={Yuan, Z. and Sun, G. and Tang, H. and Gao, K. and Hu, J. and He, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220242 },
  abstract={This article reviews recent reports and articles on transformer bushing failures, encompassing types and mechanisms such as mechanical, thermal, and insulation failures, along with a summarized knowledge graph supporting At-based operation and maintenance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2023.10220242 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352345029,
  title={ Rural distribution meter failures in Colombia  -  2014 IEEE Industry Application Society Annual Meeting },
  year={2014},
  author={Marin, O. J. S. and Plata, E. A. C. and Farfan, A. J. U. and Younes, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978472 },
  abstract={This paper focuses on the study of the high failure rate of energy meters installed in low voltage networks in rural areas with high keraunic level in the departmento de Caldas. The methodology implemented in this study enables the analysis of failure root cause, the calculation of failure rates and also the identification of the critical zone of meter failure. In addition, conventional solutions and their proper implementation are evaluated to reduce high meter failure rates. The parameters involved in the analysis are described in detail and a case study for the eastern part of the departmento de Caldas is provided. This zone corresponds to the coverage area of La Central Hidroeléctrica de Caldas.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAS.2014.6978472 },
  booktitle={ 2014 IEEE Industry Application Society Annual Meeting },
  chapter={0}
}

@article{rayyan-352345031,
  title={ Preventive Analysis of Internal Failures in 220kV Capacitive Voltage Transformers  -  2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) },
  year={2024},
  author={Li, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10898388 },
  abstract={The study of capacitive voltage transformer (CVT) failure prevention can not only reduce economic losses and enhance the reliability of the power supply system, but also use the causes of failure to drive the need for equipment manufacturing regulation. In this paper, taking an abnormal secondary voltage change in a bus-type CVT as an example, we analyze the cause of the failure from the perspective of structural principles, influencing factors of faults, on-site inspection and judgment, and factory reassembly and verification. This process successfully prevented the occurrence of equipment failure. Furthermore, the paper discusses raw material selection, manufacturing processes, and proposes targeted improvement measures and operational recommendations to provide practical guidance for the reliable operation of power system CVTs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AEECA62331.2024.00019 },
  booktitle={ 2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) },
  chapter={0}
}

@article{rayyan-352345032,
  title={ Transformer Inrush Current Impact on Commutation Failure Prevention of UHVDC Transmission system  -  2019 IEEE 3rd Conference on Energy Internet and Energy System Integration (EI2) },
  year={2019},
  author={Gao, K. and Li, C. and Li, X. and Wang, H. and Rao, Y. and Liu, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9061882 },
  abstract={This paper studied the influence of transformer inrush current on commutation failure prevention control of Ultra-high voltage DC (UHVDC) transmission system. An actual event occurred on Tianzhong UHVDC transmission project was analyzed with data from fault recorder. UHVDC transmission model with commutation failure prevention control was established in PSCAD/EMTDC, and then it was applied to replay the event. It is found that the frequent maloperation of commutation failure control and the fluctuation of DC power exist when inrush current occurred. An improved commutation failure prevention control strategy was proposed to avoid this phenomenon. Validity of the improved method was proved by the simulation results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI247390.2019.9061882 },
  booktitle={ 2019 IEEE 3rd Conference on Energy Internet and Energy System Integration (EI2) },
  chapter={0}
}

@article{rayyan-352345033,
  title={ Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt  -  2024 31st Asia-Pacific Software Engineering Conference (APSEC) },
  year={2024},
  author={Sutoyo, E. and Avgeriou, P. and Capiluppi, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967292 },
  abstract={Self-Admitted Technical Debt (SATD) refers to circumstances where developers use textual artifacts to explain why the existing implementation is not optimal. Past research in detecting SATD has focused on either identifying SATD (classifying SATD items as SATD or not) or categorizing SATD (labeling instances as SATD that pertain to requirement, design, code, test debt, etc.). However, the performance of these approaches remains suboptimal, particularly for specific types of SATD, such as test and requirement debt, primarily due to extremely imbalanced datasets. To address these challenges, we build on earlier research by utilizing BiLSTM architecture for the binary identification of SATD and BERT architecture for categorizing different types of SATD. Despite their effectiveness, both architectures struggle with imbalanced data. Therefore, we employ a large language model data augmentation strategy to mitigate this issue. Furthermore, we introduce a two-step approach to identify and categorize SATD across various datasets derived from different artifacts. Our contributions include providing a balanced dataset for future SATD researchers and demonstrating that our approach significantly improves SATD identification and categorization performance compared to baseline methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APSEC65559.2024.00022 },
  booktitle={ 2024 31st Asia-Pacific Software Engineering Conference (APSEC) },
  chapter={0}
}

@article{rayyan-352345034,
  title={ Reliability Assessment of Distribution Power Transformers Considering Load Transfer Capability  -  IEEE Transactions on Power Systems },
  year={2023},
  author={Hamoud, G. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766448 },
  abstract={A number of reliability models based on stationary Markov processes were developed at Hydro One to evaluate the reliability of a group of similar distribution power transformers. Those models accounted for a number of factors that affected the reliability of the group. The factors included, in addition to the basic Markov model parameters, the redundancy and mobile unit transformer capability at each individual station. There was one factor namely the load transfer capability between the stations that was not considered in the reliability assessment. The objective of load transfer is to further reduce the impact of transformer outages on customers and therefore improve the overall reliability of the system. The policy of load transfer between distribution stations can be simple or complicated and that can have a significant impact on the overall system reliability. This paper describes a probabilistic method based on stationary Markov models for evaluating the impacts of load transfers on the reliability of distribution stations. An example of a real distribution system is used to illustrate the proposed method of assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2022.3171693 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345036,
  title={ Heat generation and failure in padmount transformers due to zero sequence saturation  -  2018 IEEE/IAS 54th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  year={2018},
  author={Fox, J. C. and Hadidi, R. and LaFlair, N. and Leonard, J. and Hodges, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370002 },
  abstract={After a transformer failed following a double phase fault, there was an interest in understanding how the fault mechanism led to the failure. This paper investigate this fault condition in detail and demonstrate the underlying challenges in correcting the failure. The system electrical and thermal models were developed and simulated to analyze the transformer response under double phase fault conditions. Experimental measurements validated the simulation results on a real three phase distribution transformer. This paper presents the results from simulated and experimental analysis from double phase fault on a Yg-Yg distribution transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2018.8370002 },
  booktitle={ 2018 IEEE/IAS 54th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  chapter={0}
}

@article{rayyan-352345037,
  title={ Failure of a big transformer in HPP — Assessment of damage, repair and tests  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={Bojkovic, A. and Gucic, D. and Nikolic, P. and Petrovic, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580288 },
  abstract={The authors present the case of a big three phase generator step-up transformer with three windings and five leg core, from its failure and diagnosis of damage up to repair on site and tests to prove the quality of work, including first preventive tests after its return in operation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580288 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345038,
  title={ Use of Mobile Unit Transformers in Transmission and Distribution Load Stations  -  2024 IEEE Power & Energy Society General Meeting (PESGM) },
  year={2024},
  author={Hamoud, G. A. and Yiu, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10688975 },
  abstract={In recent years, two probabilistic methods based on Markov models were developed at Hydro One for evaluating the economic benefits of using mobile unit transformers (mobile unit substations) in redundant customer delivery systems. One method used two Markov models and the other used three Markov models. Each assessment method convolved its Markov models to compute the mobile unit transformer benefits. This paper extends those two methods of assessment to handle the general case where the mobile unit transformers are utilized at one and two transformer load stations. An example of a sample system is used to illustrate the two extended methods of assessment and to compare their results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM51994.2024.10688975 },
  booktitle={ 2024 IEEE Power & Energy Society General Meeting (PESGM) },
  chapter={0}
}

@article{rayyan-352345039,
  title={ Interpreting the frequency responses of PD signals for PD location in transformer windings - Normalized correlation method  -  2012 IEEE 10th International Conference on the Properties and Applications of Dielectric Materials },
  year={2012},
  author={Jeyabalan, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6318908 },
  abstract={Partial discharge (PD) is the major source of insulation failure in power transformers. PD identification is an important diagnostic tool for the reliable operation of transformers. In this paper, normalization principle is used in correlation method for location of PD pulse. The limitation of normalized correlation method is further improved by using Butterworth band pass filter, standard error and hypothesis t-test which may assist in identifying the salient features of the winding responses due to PD in transformer windings. The experimental studies are performed on 22kV interleaved winding to prove the feasibility of the method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPADM.2012.6318908 },
  booktitle={ 2012 IEEE 10th International Conference on the Properties and Applications of Dielectric Materials },
  chapter={0}
}

@article{rayyan-352345040,
  title={ One Markov Model for Spare Analysis of Distribution Power Transformers  -  IEEE Transactions on Power Systems },
  year={2016},
  author={Hamoud, G. A. and Yiu, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7109939 },
  abstract={This paper describes a probabilistic method for evaluating the number of spare units, regular spare transformers (RSTs), and mobile unit substations (MUSs) required for a group of similar distribution power transformers used at distribution stations in order to meet a pre-determined level of the group availability. The method uses a single Markov model for representing Class I and Class II failures of distribution transformers and a two-state model for representing the mobile unit substation (MUS). The two models are then convolved to obtain the required number of spare units. The proposed method is illustrated using a Hydro One sample of the distribution transformers and the results are compared with the previously published method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2015.2431820 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345041,
  title={ Assessment of spare transformer requirements for high voltage load stations  -  2012 IEEE Power and Energy Society General Meeting },
  year={2012},
  author={Hamoud, G. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6344650 },
  abstract={This paper describes a probabilistic method based on a Markov model for assessing the number of spare transformers required for a group of similar transformers used in high voltage load stations. The proposed method accounts for a number of factors that affect the number of spare units. The factors include the group size, unit failure rate, unit repair time, installation time of a spare unit and the failure criterion defined for each load station. The method uses two criteria in determining the required number of spare units. The 1st criterion assumes that a predetermined level of the group availability is given and the number of spare units is determined when the calculated group availability exceeds the pre-determined level of the group availability. The 2nd criterion uses a cost/benefit analysis method in calculating the number of the spare units. In the 2nd criterion, the number of spare units (optimal number) is determined when the total cost (spare unit capital cost and unit outage cost) is minimum. A sample of Hydro One power transformers is used to illustrate the proposed method of assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM.2012.6344650 },
  booktitle={ 2012 IEEE Power and Energy Society General Meeting },
  chapter={0}
}

@article{rayyan-352345042,
  title={ Experimental validation of a new methodology to reduce hot spots on the screws of power transformer tanks  -  2012 XXth International Conference on Electrical Machines },
  year={2012},
  author={Olivares-Galván, J. C. and Magdaleno-Adame, S. and Escarela-Perez, R. and Ocon-Valdéz, R. and Georgilakis, P. S. and Loizos, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6350206 },
  abstract={In power transformers, the presence of stray currents in the structural elements near to the high current bushings can be considerable and this usually leads to hot spots. This work presents the analysis of the overheating of the screws that join the tank and the cover; these screws are near to the low voltage bushings of the transformer. Overheating results are analyzed and discussed for the case of a 420 MVA, 20/230 kV, OA/FOA transformer. The hot spots in the screws are discovered by thermal maps (thermography) that are obtained during the power transformer operation as part of the preventive maintenance program. This paper proposes the use of copper sill to ensure the connection of both the cover and the tank body because this solution significantly reduces the overheating of the screws. The proposed solution, which has been validated by measurements, significantly reduces the hot spots on the screws of power transformer tank.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICElMach.2012.6350206 },
  booktitle={ 2012 XXth International Conference on Electrical Machines },
  chapter={0}
}

@article{rayyan-352345043,
  title={ Reliability Assessment of Distribution Stations Considering Spare Transformer Sharing  -  IEEE Transactions on Power Systems },
  year={2024},
  author={Hamoud, G. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037212 },
  abstract={A reliability study has been performed recently at Hydro One to evaluate the reliability of groups of distribution stations involved in a spare transformer sharing policy. The groups may include distribution utilities stations and distribution customer own stations. The study used a probabilistic method based on stationary Markov models and two performance criteria namely the group availability criterion and the total cost criterion in the evaluation. The study results demonstrate that the number of spare transformers required for the groups involved in the spare transformer sharing policy will be reduced while maintaining almost the same reliability levels of individual groups. The purpose of this paper is to describe the study, its reliability assessment method and to illustrate it using a sample system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2023.3242450 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345044,
  title={ Spare Assessment of Distribution Power Transformers using Two Markov Models  -  2019 IEEE Power & Energy Society General Meeting (PESGM) },
  year={2019},
  author={Hamoud, G. A. and Lee, L. and Faried, S. O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8973546 },
  abstract={In earlier spare assessment studies of distribution power transformers at Hydro One, the issues of the full utilization of mobile unit substations (MUSs) and their reliabilities were not fully addressed and therefore, the results of spare studies may have been underestimated. This paper describes a study that has been performed recently to address the two mentioned issues. The study used a simple and flexible probabilistic approach that shows how the two issues can be properly addressed and helps explain the results of earlier spare studies. The proposed assessment approach uses two Markov models: one representing minor transformer failures and one representing major transformer failures for a group of similar distribution power transformers. The MUS utilization factor introduced in this study is incorporated into each failure model in order to obtain the group availability as a function of the number of spare units. The results of a sample distribution system show that the two issues can have significant impacts on the spare assessment results. The purpose of this paper is to describe the study and its findings and to compare its results with the earlier spare methods of assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM40551.2019.8973546 },
  booktitle={ 2019 IEEE Power & Energy Society General Meeting (PESGM) },
  chapter={0}
}

@article{rayyan-352345045,
  title={ Spare Assessment of Distribution Power Transformers using Three Markov Models  -  2018 IEEE International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  year={2018},
  author={Hamoud, G. A. and Lee, L. and Faried, S. O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440506 },
  abstract={This paper presents a simple probabilistic method for determining the numbers of spare units (regular spare transformers and mobile unit substations) required for a system of similar distribution power transformers in order to meet a pre-determined level of the system availability. The proposed method is based on 3 Markov models representing transformer minor failures (Class II failures), transformer major failures (Class I failures) and the use of a mobile unit substation (MUS). The MUS model is convolved with each transformer failure model to determine the system availability as a function of the number of spare units. The new method of assessment produces the same results as those obtained using the previously used methods and the Markov models used are much simpler. An example is used to demonstrate the proposed method and to compare its results with the previously used methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PMAPS.2018.8440506 },
  booktitle={ 2018 IEEE International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  chapter={0}
}

@article{rayyan-352345046,
  title={ A fusion inference method for large language models and knowledge graphs based on structured injection and causal inference  -  nan },
  year={2023},
  author={X and Xing and Xueyang and B and Jia and Bo and Z and Huang and Zhicheng and Y and Chen and Yongzhi and J and Wang and Junjie and A and Fan and Anfei and X and Chen and Xin and L and Cao and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192801712&doi=10.1145%2F3653081.3653117&partnerID=40&md5=7a493e990da8083cb20b366cfd890197 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3653081.3653117 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345047,
  title={ TrojBits: A Hardware Aware Inference-Time Attack on Transformer-Based Language Models  -  Frontiers in Artificial Intelligence and Applications },
  year={2023},
  author={M and Ghanim, Al and Mansour and M.H and Santriaji and Husni, Muhammad and Q and Lou and Qian and Y and Solihin and Yan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175813381&doi=10.3233%2FFAIA230254&partnerID=40&md5=81656e0c6ab3cf6c2b096924fb5286f0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.3233/FAIA230254 },
  booktitle={ Frontiers in Artificial Intelligence and Applications },
  chapter={0}
}

@article{rayyan-352345048,
  title={ Poster: PipeLLM: Pipeline LLM Inference on Heterogeneous Devices with Sequence Slicing  -  nan },
  year={2023},
  author={R and Ma and Ruilong and J and Wang and Jingyu and Q and Qi and Qi and X and Yang and Xiang and H and Sun and Haifeng and Z and Zhuang and Zirui and J and Liao and Jianxin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174032260&doi=10.1145%2F3603269.3610856&partnerID=40&md5=3ff736dad565fb56ef7a6792e655cbbe },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3603269.3610856 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345049,
  title={ ITIF: Integrated Transformers Inference Framework for Multiple Tenants on GPU  -  ACM International Conference Proceeding Series },
  year={2023},
  author={Y and Zhang and Yuning and Z and Zhang and Zao and W and Bao and Wei and D and Yuan and Dong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179893588&doi=10.1145%2F3605573.3605585&partnerID=40&md5=4711da1891394609a99b555445daf2e6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3605573.3605585 },
  booktitle={ ACM International Conference Proceeding Series },
  chapter={0}
}

@article{rayyan-352345050,
  title={ Constraint-aware and Ranking-distilled Token Pruning for Efficient Transformer Inference  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2023},
  author={J and Li and Junyan and L.L and Zhang and Lyna, Li and J and Xu and Jiahang and Y and Wang and Yujing and S and Yan and Shaoguang and Y and Xia and Yunqing and Y and Yang and Yuqing and T and Cao and Ting and H and Sun and Hao and W and Deng and Weiwei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171360465&doi=10.1145%2F3580305.3599284&partnerID=40&md5=da2e7328f5581ce57d9b1c7b6c527b68 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3580305.3599284 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352345051,
  title={ Ball Trajectory Inference from Multi-Agent Sports Contexts Using Set Transformer and Hierarchical Bi-LSTM  -  Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  year={2023},
  author={H and Kim and Hyunsung and H and Choi and Han-jun and C and Kim and Changjo and J and Yoon and Jinsung and S and Ko and Sang-ki},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171349345&doi=10.1145%2F3580305.3599779&partnerID=40&md5=4139dcf7aeab21f034efe73607db4380 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3580305.3599779 },
  booktitle={ Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining },
  chapter={0}
}

@article{rayyan-352345052,
  title={ A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing  -  Proceedings of the ACM Conference on Computer and Communications Security },
  year={2023},
  author={H and Kim and Hyunjin and J and Bak and Jin-yeong and K and Cho and Kyunghyun and H and Koo and Hyungjoon},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168148901&doi=10.1145%2F3579856.3582823&partnerID=40&md5=c19ab50efca9895cb0da035955d508bb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3579856.3582823 },
  booktitle={ Proceedings of the ACM Conference on Computer and Communications Security },
  chapter={0}
}

@article{rayyan-352345053,
  title={ Framing the News: From Human Perception to Large Language Model Inferences  -  nan },
  year={2023},
  author={D and del Barrio, Alonso and David and D and Gatica-Pérez and Daniel},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163625493&doi=10.1145%2F3591106.3592278&partnerID=40&md5=6b0855a58d990edb04f8133fedc54cc7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3591106.3592278 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345054,
  title={ Tabi: An Efficient Multi-Level Inference System for Large Language Models  -  nan },
  year={2023},
  author={Y and Wang and Yiding and K and Chen and Kai and H and Tan and Haisheng and K and Guo and Kun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160213896&doi=10.1145%2F3552326.3587438&partnerID=40&md5=28864125238be20f4e44e3605ac74a82 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3552326.3587438 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345055,
  title={ SELECTION-INFERENCE: EXPLOITING LARGE LANGUAGE MODELS FOR INTERPRETABLE LOGICAL REASONING  -  nan },
  year={2023},
  author={A and Creswell and Antonia and M.P and Shanahan and P, Murray and I.V and Higgins and V, Irina},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199898714&partnerID=40&md5=34a9e3b4a2606d0431c86d5d7d4dab80 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345056,
  title={ CONTINUAL TRANSFORMERS: REDUNDANCY-FREE ATTENTION FOR ONLINE INFERENCE  -  nan },
  year={2023},
  author={L and Hedegaard and Lukas and A and Bakhtiarnia and Arian and A and Iosifidis and Alexandros},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198523533&partnerID=40&md5=d70e1211af92dd4b0c4e2f98ab47b977 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345057,
  title={ MDP: Model Decomposition and Parallelization of Vision Transformer for Distributed Edge Inference  -  nan },
  year={2023},
  author={W and Wang and Weiyan and Y and Zhang and Yiming and Y and Jin and Yilun and H and Tian and Han and L and Chen and Li},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197510868&doi=10.1109%2FMSN60784.2023.00086&partnerID=40&md5=0aac4c97d416b2dddb309b75399b1478 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MSN60784.2023.00086 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345059,
  title={ Leftover: Improving Large Language Model Inference Efficiency by Leveraging Idle Resources  -  nan },
  year={2023},
  author={X and Duan and Xu and K and Ye and Kejiang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191686029&doi=10.1109%2FHDIS60872.2023.10499636&partnerID=40&md5=51c7ca77628013027c5d4df3303ebcec },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HDIS60872.2023.10499636 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345060,
  title={ Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline  -  Advances in Neural Information Processing Systems },
  year={2023},
  author={Z and Zheng and Zangwei and X and Ren and Xiaozhe and F and Xue and Fuzhao and Y and Luo and Yang and X and Jiang and Xin and Y and You and Yang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191156262&partnerID=40&md5=96aefdfcc439e39063c4d483d07655d2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345062,
  title={ Distributed Inference and Fine-tuning of Large Language Models Over The Internet  -  Advances in Neural Information Processing Systems },
  year={2023},
  author={A and Borzunov and Alexander and M and Ryabinin and Max and A and Chumachenko and Artem and D and Baranchuk and Dmitry and T and Dettmers and Tim and Y and Belkada and Younes and P and Samygin and Pavel and C and Raffel and Colin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190849346&partnerID=40&md5=59075d8883e1a18f3cf8729cbd466da4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345063,
  title={ Dynamic Patch Sampling for Efficient Training and Dynamic Inference in Vision Transformers  -  nan },
  year={2023},
  author={B and McDanel and Bradley and C.P and Huynh, Ngoc and Phuong, Chi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190137078&doi=10.1109%2FICMLA58977.2023.00020&partnerID=40&md5=0b603b2ee01190131237b0b5c1e99d43 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLA58977.2023.00020 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345064,
  title={ H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models  -  Advances in Neural Information Processing Systems },
  year={2023},
  author={Z and Zhang and Zhenyu and Y and Sheng and Ying and T and Zhou and Tianyi and T and Chen and Tianlong and L and Zheng and Lianmin and R and Cai and Ruisi and Z and Song and Zhao and Y and Tian and Yuandong and C.M., Ré and M, Christopher and C.W and Barrett and W, Clark},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189365449&partnerID=40&md5=43579790c12d6a6d716b8b8d2c51aae7 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345065,
  title={ I-ViT: Integer-only Quantization for Efficient Vision Transformer Inference  -  Proceedings of the IEEE International Conference on Computer Vision },
  year={2023},
  author={Z and Li and Zhikai and Q and Gu and Qingyi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188147412&doi=10.1109%2FICCV51070.2023.01565&partnerID=40&md5=4b5392b9d38d34c378020d0b92b587fd },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCV51070.2023.01565 },
  booktitle={ Proceedings of the IEEE International Conference on Computer Vision },
  chapter={0}
}

@article{rayyan-352345066,
  title={ Joint Foundation Model Caching and Inference of Generative AI Services for Edge Intelligence  -  Proceedings - IEEE Global Communications Conference, GLOBECOM },
  year={2023},
  author={M and Xu and Minrui and D.( and Niyato and (Tao), Dusit and H and Zhang and Hongliang and J and Kang and Jiawen and Z and Xiong and Zehui and S.J.T and Mao and J.T, Shiwen and Z and Han and Zhu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187323575&doi=10.1109%2FGLOBECOM54140.2023.10436771&partnerID=40&md5=5a3791727ca538f928f3277679b11429 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GLOBECOM54140.2023.10436771 },
  booktitle={ Proceedings - IEEE Global Communications Conference, GLOBECOM },
  chapter={0}
}

@article{rayyan-352345067,
  title={ Resolving the Imbalance Issue in Hierarchical Disciplinary Topic Inference via LLM-based Data Augmentation  -  IEEE International Conference on Data Mining Workshops, ICDMW },
  year={2023},
  author={X and Cai and Xunxin and M and Xiao and Meng and Z and Ning and Zhiyuan and Y and Zhou and Yuanchun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186138336&doi=10.1109%2FICDMW60847.2023.00181&partnerID=40&md5=a890f9d9d8fe3fc3a29b957591bd2f7c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDMW60847.2023.00181 },
  booktitle={ IEEE International Conference on Data Mining Workshops, ICDMW },
  chapter={0}
}

@article{rayyan-352345068,
  title={ Cascading Transformer Failure Probability Model Under Geomagnetic Disturbances  -  Proceedings - Winter Simulation Conference },
  year={2023},
  author={P and Shukla and Pratishtha and J.J and Nutaro and J, James and S.B and Yoginath and B, Srikanth},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185386653&doi=10.1109%2FWSC60868.2023.10408098&partnerID=40&md5=e7171f3e6e1dc5fd2f6217fa73dff949 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WSC60868.2023.10408098 },
  booktitle={ Proceedings - Winter Simulation Conference },
  chapter={0}
}

@article{rayyan-352345069,
  title={ Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation  -  nan },
  year={2023},
  author={Z and Yang and Zeyuan and P and Li and Peng and Y and Liu and Yang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184830790&doi=10.18653%2Fv1%2F2023.emnlp-main.109&partnerID=40&md5=d9098f77ee7b7f0150f0b1a63a771537 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.emnlp-main.109 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345070,
  title={ Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?  -  nan },
  year={2023},
  author={C and Zhang and Cheng and J and Cheng and Jianyi and I and Shumailov and Ilia and G.A and Constantinides and A, George and Y and Zhao and Yiren},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184823292&doi=10.18653%2Fv1%2F2023.emnlp-main.617&partnerID=40&md5=6a3d46d205dfdbd4a3614e24994cfb94 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.emnlp-main.617 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345071,
  title={ Accelerating Transformers with Fourier-Based Attention for Efficient On-Device Inference  -  nan },
  year={2023},
  author={H and Jo and Hyeonjin and C and Sim and Chaerin and J and Park and Jaewoo and J and Lee and Jongeun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184809800&doi=10.1109%2FISOCC59558.2023.10396620&partnerID=40&md5=296ebcdb9b104a8e1e73eadeda17f8ce },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISOCC59558.2023.10396620 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345072,
  title={ Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models  -  nan },
  year={2023},
  author={M and Sakarvadia and Mansi and A and Ajith and Aswathy and A and Khan and Arham and D and Grzenda and Daniel and N and Hudson and Nathaniel and A and Bauer and Andre and K and Chard and Kyle and I.T and Foster and T, Ian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184798665&partnerID=40&md5=83cd6b77951d750e054a7d8ede12faaa },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345073,
  title={ Batch Prompting: Efficient Inference with Large Language Model APIs  -  nan },
  year={2023},
  author={Z and Cheng and Zhoujun and J and Kasai and Jungo and T and Yu and Tao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184666678&doi=10.18653%2Fv1%2F2023.emnlp-industry.74&partnerID=40&md5=e5935d73df682bc73ad807da10dfbd6e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.emnlp-industry.74 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345076,
  title={ Using Imperfect Surrogates for Downstream Inference: Design-based Supervised Learning for Social Science Applications of Large Language Models  -  Advances in Neural Information Processing Systems },
  year={2023},
  author={N and Egami and Naoki and M and Hinck and Musashi and B.M and Stewart and M, Brandon and H and Wei and Hanying},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183307872&partnerID=40&md5=757ffabb8e20acb1686fa9c94779a205 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345077,
  title={ TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction  -  nan },
  year={2023},
  author={J and Liu and Junyi and L and Li and Liangzhi and T and Xiang and Tong and B and Wang and Bowen and Y and Qian and Yiming},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183301120&doi=10.18653%2Fv1%2F2023.findings-emnlp.655&partnerID=40&md5=dc6cc2b60852b59f4fd8d00dbd4fbac8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.findings-emnlp.655 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345078,
  title={ Improving Natural Language Inference in Arabic Using Transformer Models and Linguistically Informed Pre-Training  -  nan },
  year={2023},
  author={M.M.S and Deen, Al and Saad, Mohammad Majd and M and Pielka and Maren and J and Hees, Jörn and B.S and Abdou and Soulef, Bouthaina and R and Sifa and Rafet},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182925537&doi=10.1109%2FSSCI52147.2023.10371891&partnerID=40&md5=bc20cda31c83c1d578247560b8d05323 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SSCI52147.2023.10371891 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345079,
  title={ Sources of Hallucination by Large Language Models on Inference Tasks  -  nan },
  year={2023},
  author={N and McKenna and Nick and T and Li and Tianyi and L and Cheng and Liang and M.J and Hosseini and Javad, Mohammad and M.E and Johnson and E, Mark and M.J and Steedman and J, Mark},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182811516&doi=10.18653%2Fv1%2F2023.findings-emnlp.182&partnerID=40&md5=4ed2927c4b570ffba54f64647254e389 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.findings-emnlp.182 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345080,
  title={ High-Level Frameworks: Effect on Transformer Inference Time and Power on Embedded GPU Devices  -  nan },
  year={2023},
  author={M.E and Schubert and E, Marika and D and Langerman and David and A.D and George and D, Alan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182606957&doi=10.1109%2FHPEC58863.2023.10363464&partnerID=40&md5=d3898d7d7e85f186ca17bb14eb52e3a3 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPEC58863.2023.10363464 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345081,
  title={ Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity  -  Proceedings of the VLDB Endowment },
  year={2023},
  author={H and Xia and Haojun and Z and Zheng and Zhen and Y and Li and Yuchao and D and Zhuang and Donglin and Z and Zhou and Zhongzhu and X and Qiu and Xiafei and Y and Li and Yong and W and Lin and Wei and S.L and Song and Leon, Shuaiwen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182603167&doi=10.14778%2F3626292.3626303&partnerID=40&md5=4d577135ca5897da71f226f2adeaa39d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.14778/3626292.3626303 },
  booktitle={ Proceedings of the VLDB Endowment },
  chapter={0}
}

@article{rayyan-352345082,
  title={ From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference  -  nan },
  year={2023},
  author={S.S and Samsi and S, Siddharth and D and Zhao and Dan and J and McDonald and Joseph and B and Li and Baolin and A.M and Michaleas and M, Adam and M and Jones and Michael and W and Bergeron and William and J.V and Kepner and V, Jeremy and D and Tiwari and Devesh and V.N and Gadepally and N, Vijay},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182600249&doi=10.1109%2FHPEC58863.2023.10363447&partnerID=40&md5=4ce736c64f515ac2947822c576c27e1a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HPEC58863.2023.10363447 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345083,
  title={ Compressing Context to Enhance Inference Efficiency of Large Language Models  -  nan },
  year={2023},
  author={Y and Li and Yucheng and B and Dong and Bo and F and Guerin and Frank and C and Lin and Chenghua},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181520173&doi=10.18653%2Fv1%2F2023.emnlp-main.391&partnerID=40&md5=cb72bc1dff6c337d2d327cbeceb8df46 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.emnlp-main.391 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345084,
  title={ SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference  -  IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  year={2023},
  author={W and Wang and Wenxun and S and Zhou and Shuchang and W and Sun and Wenyu and P and Sun and Peiqin and Y and Liu and Yongpan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181403130&doi=10.1109%2FICCAD57390.2023.10323725&partnerID=40&md5=8baca3fcd34418be08321d1abc06042e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCAD57390.2023.10323725 },
  booktitle={ IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  chapter={0}
}

@article{rayyan-352345085,
  title={ RNA-ViT: Reduced-Dimension Approximate Normalized Attention Vision Transformers for Latency Efficient Private Inference  -  IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  year={2023},
  author={D and Chen and Dake and Y and Zhang and Yuke and S and Kundu and Souvik and C and Li and Chenghao and P.A and Beerel and A, Peter},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181401891&doi=10.1109%2FICCAD57390.2023.10323702&partnerID=40&md5=04e6beaedf34e67a2ca1030733ad787b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCAD57390.2023.10323702 },
  booktitle={ IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers },
  chapter={0}
}

@article{rayyan-352345086,
  title={ Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Networks: An Active Inference Approach  -  IEEE Vehicular Technology Conference },
  year={2023},
  author={J and Fang and Jingcheng and Y and He and Ying and F.R and Yu and Richard, Fei and J and Li and Jianqiang and V.C and Leung and C.M, Victor},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181172800&doi=10.1109%2FVTC2023-Fall60731.2023.10333824&partnerID=40&md5=ccd54cd41866fed2109cd940059bcebb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/VTC2023-Fall60731.2023.10333824 },
  booktitle={ IEEE Vehicular Technology Conference },
  chapter={0}
}

@article{rayyan-352345087,
  title={ Design of the self-optimal tuning fuzzy inference system for transformer network-based traveling salesman problem in tidying up objects  -  nan },
  year={2023},
  author={Y and Su and Yuting and Q.Z and Ho and Zao, Qi and T and Chao and Tzuyu and T.S and Li and S, Tzuu-Hseng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179586667&doi=10.1109%2FiFUZZY60076.2023.10324176&partnerID=40&md5=31b54972283e8c5312acce1d8a1f1486 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iFUZZY60076.2023.10324176 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345089,
  title={ Efficient Transformer Inference for Extremely Weak Edge Devices Using Masked Autoencoders  -  Conference Record - International Conference on Communications },
  year={2023},
  author={T and Liu and Tao and P and Li and Peng and Y and Gu and Yu and P and Liu and Peng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178298823&doi=10.1109%2FICC45041.2023.10279202&partnerID=40&md5=ea11ff80fb970287531c4511c9a62c7f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICC45041.2023.10279202 },
  booktitle={ Conference Record - International Conference on Communications },
  chapter={0}
}

@article{rayyan-352345092,
  title={ Moffett Antoum®: A Deep-Sparse AI Inference System-on-Chip for Vision and Large-language Models  -  nan },
  year={2023},
  author={Z and Xiao and Zhibin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175805758&doi=10.1109%2FHCS59251.2023.10254723&partnerID=40&md5=bfddcd0b479bd6b18cdbb5965c5ffdaf },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HCS59251.2023.10254723 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345093,
  title={ Few Shot Profiling of Cryptocurrency Influencers using Natural Language Inference & Large Language Models  -  CEUR Workshop Proceedings },
  year={2023},
  author={E and Villa-Cueva and Emilio and J.M and Valles-Silva and Miguel, Jorge and A.P., López-Monroy and Pastor, Adrián and F., Sánchez-Vega and Fernando and R., López-Santillán and Roberto},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175630767&partnerID=40&md5=3cbe80867e2972e6b22c816317b9f991 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CEUR Workshop Proceedings },
  chapter={0}
}

@article{rayyan-352345094,
  title={ Modular Transformers: Compressing Transformers into Modularized Layers for Flexible Efficient Inference  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2023},
  author={W and Zhou and Wangchunshu and R and Bras, Le and Ronan and Y and Choi and Yejin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175430656&doi=10.18653%2Fv1%2F2023.findings-acl.664&partnerID=40&md5=07ed06369343fc798a4259fb00c5382c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.findings-acl.664 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352345095,
  title={ When Truth Matters - Addressing Pragmatic Categories in Natural Language Inference (NLI) by Large Language Models (LLMs)  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2023},
  author={R and Gubelmann and Reto and A.L and Kalouli and Lida, Aikaterini and C and Niklaus and Christina and S and Handschuh and Siegfried},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175401233&doi=10.18653%2Fv1%2F2023.starsem-1.4&partnerID=40&md5=eb4b182903e9b4bc4a9e24fb74819938 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.starsem-1.4 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352345096,
  title={ Probabilistic Indicators for Assessing Age- and Loading-Based Criticality of Transformers to Cascading Failure Events  -  IEEE Transactions on Power Systems },
  year={2014},
  author={Awadallah, S. K. E. and Milanović, J. V. and Jarman, P. N. and Wang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774473 },
  abstract={The paper investigates the effect of a transformer unplanned outage on the failure probability of the remaining transformers in the network. The probability of consequential dependent failures of transformers might ultimately lead to a multiple or cascading failure. New probabilistic indicators based on the transformer's unavailability under outage conditions have been formulated for individual power transformers and transformer sites to help with this assessment. The effect of thermal stress of transformer on its unavailability due to the new loading condition is taken into account as well as the age and the original loading of the transformer. The Arrhenius-Weibull life-stress model was adopted for assessment of the transformer unavailability. The study identifies both transformers whose outage could initiate cascading failure and those that are the most vulnerable to consequential failure. The effectiveness of the proposed probabilistic indicators in identifying the most critical transformers for multiple failure events is demonstrated on a realistic transmission test system with 154 power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2014.2308581 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345097,
  title={ Llm-Based Code Comment Summarization: Efficacy Evaluation and Challenges  -  2025 17th International Conference on Knowledge and Smart Technology (KST) },
  year={2025},
  author={Sukkasem, P. and Soomlek, C. and Dechsupa, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11003343 },
  abstract={Numerous methodologies have been introduced for code summarization and associated activities, including the utilization of large language model (LLM)-based code summarization, to aid software developers in the comprehension and maintenance of software systems. Code comment is one of the communication channels and practices that can assist developers in developing and maintaining software systems. The interpretation and comprehension of code comments can present significant challenges due to factors such as diverse writing styles and varying levels of background knowledge and experience among developers within a team. Self-admitted technical debt (SATD) is commonly indicated in code comments. This research investigates the efficacy of applying large language models to identify SATD and summarize code comments containing SATD to support code maintenance. We employed three widely used pre-trained LLMs, i.e., BART, Flan-T5, and T5 as summarizers. The experimental results indicated that 75 % of the natural language summaries generated by BART are readable with the appropriate structure and vocabulary used. However, almost all generated summaries are irrelevant to the original code comments while the T5 model can identify SATD and include it in the generated summaries. These findings highlight the potential and the limitations of using pre-trained LLMs for code comment summarization and SATD identification, paving the way for future improvements in this domain.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/KST65016.2025.11003343 },
  booktitle={ 2025 17th International Conference on Knowledge and Smart Technology (KST) },
  chapter={0}
}

@article{rayyan-352345098,
  title={ An Innovative Fuzzy Modeling Technique For Transformer's Failure Modes And Effects Analysis  -  2020 International Conference on Electrical and Electronics Engineering (ICE3) },
  year={2020},
  author={Singh, A. and Patil, A. J. and Sharma, R. K. and Jarial, R. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122822 },
  abstract={Failure mode and effects analysis is a compelling tool for boosting the reliability of a power system network. In this paper, a maintenance strategy is proposed based on the prioritization of maintenance work as per the fuzzy values of risk priority number. The fuzzified approach for the computation of risk assessment uproots the paradoxical behavior of the traditional approach under certain circumstances. Failure modes of each component of a transformer are identified and then occurrence, severity, and detection ratings are assigned for the development of a fuzzy inference system. Based on the input data set, the output surface plots for various parameters are plotted which is subsequently used for maintenance prioritization and suggesting recommended actions. Particular attention is given to the comparison between risk priority number values before and after maintenance or overhaul is performed. This paper will be helpful for researchers and utilities working on the development of optimum maintenance plans for any transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICE348803.2020.9122822 },
  booktitle={ 2020 International Conference on Electrical and Electronics Engineering (ICE3) },
  chapter={0}
}

@article{rayyan-352345099,
  title={ Hierarchical Failure Mode Effect Analysis for the Protection Design of a MV AC-DC Solid State Transformer based EV Extreme Fast Charging Station  -  2023 IEEE Energy Conversion Congress and Exposition (ECCE) },
  year={2023},
  author={Bipu, M. R. H. and Berdugo, O. A. M. and Lukic, S. and Husain, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10362709 },
  abstract={Solid state transformer (SST) is one of the key technologies that enable efficient and high power density extreme fast charging (XFC) stations for electric vehicles (EV). To ensure the safe and reliable operation of the SST, a robust fault protection system is essential. In this paper, a hierarchical failure mode effect analysis (FMEA) is carried out to enable a systematic design of the internal fault protection system of a 1MVA multilevel medium voltage (MV) SST for the Extreme Fast Charger. First, the MV SST is divided into several subsystems based on its functionality and FMEA is conducted on the components to identify and simulate local fault scenarios. From the module level FMEA, a local protection system consisting of sensors, actuators, and the protection logic of the local controller (LCon) is developed. Subsequently, system level FMEA is conducted to develop the global protection system for the SST which is embedded in the central controller (CCon).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECCE53617.2023.10362709 },
  booktitle={ 2023 IEEE Energy Conversion Congress and Exposition (ECCE) },
  chapter={0}
}

@article{rayyan-352345101,
  title={ Transformer aging failure rate evaluation method based on evidence theory for operational risk assessment  -  IEEE PES Innovative Smart Grid Technologies },
  year={2012},
  author={Ji, Guoqiang and Wu, Wenchuan and Zhang, Boming},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6303114 },
  abstract={Failure rate is a basic parameter in the outage model of the component in power systems. A novel aging failure rate evaluation method based on evidence theory is proposed. Transformer is taken as an example to illustrate the proposed method, because the transformers have been widely used online condition monitors. The operational states of a transformer can be classified into four degrees according to IEEE standards. An evaluation method is proposed to identify the operational state of a transformer by combining the data collected from condition monitors, which is based on evidence theory. Hidden Markov Models are used to model the aging process of a transformer, while the transition rate in the models can be obtained from the historical data. The time-varying aging failure rate function can be derived by solving the Markov state equation. A real example is presented to demonstrate the proposed method reasonable.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISGT-Asia.2012.6303114 },
  booktitle={ IEEE PES Innovative Smart Grid Technologies },
  chapter={0}
}

@article{rayyan-352345102,
  title={ Distribution transformer failure rate prediction model based on multi-source information  -  2016 International Conference on Condition Monitoring and Diagnosis (CMD) },
  year={2016},
  author={Niu, Jincang and Su, Jianjun and Yang, Yi and Cai, Yanan and Liu, Hang},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7757980 },
  abstract={For present distribution transformer failure rate prediction model, load and weather forecast information in the future have been not considered. In this paper, distribution transformer failure rate prediction model with parameters is proposed. Firstly, the characteristics of several common failure rate models are analyzed. The failure rate model combined the health index and operating time is established. The integrated correction factor by calculating the appropriate index system is used to modify the health index using guide method. It is the health index correction model of the initial point. Then load and weather forecast information is taken into account to describe the change trend of the health index. At last, it is easy to predict the distribution transformer failure rate by take the health index forecast trend into the failure rate model. The example of 5 kV/100 KVA distribution transformer failure rate prediction has shown that the improved model is based on comprehensive consideration of the future failure rate influence factors and it can improve the accuracy of the predicted failure rate effectively. In addition, the predicted result is more close to the actual transformer failure rate curve.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2016.7757980 },
  booktitle={ 2016 International Conference on Condition Monitoring and Diagnosis (CMD) },
  chapter={0}
}

@article{rayyan-352345103,
  title={ A failure probability model of the moistened oil-paper insulation of transformers based on strength-stress model  -  2016 IEEE International Conference on High Voltage Engineering and Application (ICHVE) },
  year={2016},
  author={Mo, W. and Bai, H. and Cheng, Y. and Zhang, Z. and Huang, D. and Zhao, C. and Li, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7800697 },
  abstract={It's easier for the oil-immersed power transformer to fail when moistened. As is known to us all, moisture may cause the great decrease of the breakdown voltage of the oil-paper insulation system. So, the failure probability model of transformer was established in this paper by using the theory of strength-stress model which is successfully used in the mechanical reliability field. The model could be used to quantitatively calculate the failure probabilities of a single transformer or transformers in a certain region. The appropriate descriptions of stress and strength were introduced to fit the strength-stress model for the two kinds of failures respectively. The random amplitude and times of lightning in a certain period are described by double integral of their probability density functions. The moisture content of one transformer influences the failure probability by changing the strength of the oil gap.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2016.7800697 },
  booktitle={ 2016 IEEE International Conference on High Voltage Engineering and Application (ICHVE) },
  chapter={0}
}

@article{rayyan-352345104,
  title={ Detection of Commutation Failure in LCC-HVDC Transmission System Based on Converter Transformer Valve Side Current  -  2024 International Conference on HVDC (HVDC) },
  year={2024},
  author={Liu, D. and Liu, J. and Li, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722949 },
  abstract={In the line-committed converter-based high voltage direct current (LCC- HVDC) transmission systems, commutation failure (CF) is a prevalent defect, to accurate and reliable detection can provide a basis for system control and protection. The valve side current of the converter transformer, which was easily obtainable in practical engineering, was chosen as the research object to accomplish precise commutation failure detection. The features of this current during commutation failure were researched. Subsequently, a commutation failure discrimination technique was put out, which relied on the converter valve side current's three-phase symmetry and the identical length of each phase's conduction time. A CF detection technique was constructed and tested using a simulation of the CIGRE LCC-HVDC standard testing model. Through simulation, the validity of the theoretical analysis and then the efficacy and precision of the offered CF detection technique were confirmed. This research can provide support in favor of practical engineering.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HVDC62448.2024.10722949 },
  booktitle={ 2024 International Conference on HVDC (HVDC) },
  chapter={0}
}

@article{rayyan-352345105,
  title={ Cheaply Estimating Inference Efficiency Metrics for Autoregressive Transformer Models  -  Advances in Neural Information Processing Systems },
  year={2023},
  author={D and Narayanan and Deepak and K and Santhanam and Keshav and P and Henderson and Peter and R and Bommasani and Rishi and T and Lee and Tony and P and Liang and Percy},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175137944&partnerID=40&md5=d2e5cd5344a458e0f3432994fc0fb7cb },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345106,
  title={ EWDGA and Markov process based failure rate estimation of transformer internal latent fault  -  IEEE PES Innovative Smart Grid Technologies },
  year={2012},
  author={Liang, YongLiang and Li, Kejun and Niu, Lin and Zhao, Jianguo},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6303351 },
  abstract={This paper proposed a novel failure rate estimation model of transformer internal latent fault. The concept of EWDGA is introduced from the thermodynamic view, which is proved to reflect the extent of fault development effectively. Multi-state Markov process model based on EWDGA is proposed which integrated the historical and real-time data. Numerical examples testify the effectiveness of the model, which can distinguish the failure rate of different transformers in the same state but with different fault development extent. This research can help the decision of the transformer maintenance strategy},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISGT-Asia.2012.6303351 },
  booktitle={ IEEE PES Innovative Smart Grid Technologies },
  chapter={0}
}

@article{rayyan-352345107,
  title={ Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference  -  Proceedings of Machine Learning Research },
  year={2023},
  author={C and Wang and Chi and S.X and Liu and Xueqing, Susan and A.H and Awadallah and Hassan, Ahmed},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174789360&partnerID=40&md5=df0dec8b15f3e446dea9fe304b422482 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352345108,
  title={ LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models  -  nan },
  year={2023},
  author={H and Jiang and Huiqiang and Q and Wu and Qianhui and C.Y and Lin and Yew, Chin and Y and Yang and Yuqing and L and Qiu and Lili},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174781496&doi=10.18653%2Fv1%2F2023.emnlp-main.825&partnerID=40&md5=6b44ea7375bfe93157208290eda4dbfc },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.emnlp-main.825 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345109,
  title={ Double Exponential Smoothing in Forecasting the Numbers of Pole-Mounted Transformer Failures  -  2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  year={2024},
  author={Mbuli, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796295 },
  abstract={In this paper, author studied the use of double exponential smoothing (DES) method to forecast the quarterly numbers of pole-mounted transformer failures. To determine the values of smoothing constants, they formulate a nonlinear mathematical programming (NLP) optimisation problem for this purpose, propose the use of an Excel Solver approach and exhaustive search-based method, with a program written in Python, are used to solve the optimisation. The two methods are used to find the optimal parameters of the forecast and results are compared. The exhaustive search-based approach delivers superior forecast results, with the forecasted values responding better with variation in observations and a lower forecast error obtained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECCME62383.2024.10796295 },
  booktitle={ 2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  chapter={0}
}

@article{rayyan-352345110,
  title={ LookupFFN: Making Transformers Compute-lite for CPU inference  -  Proceedings of Machine Learning Research },
  year={2023},
  author={Z and Zeng and Zhanpeng and M and Davies and Michael and P and Pulijala and Pranav and K and Sankaralingam and Karthikeyan and V and Singh and Vikas},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174419993&partnerID=40&md5=e36404c47015859fa2a114de8a480a31 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352345111,
  title={ Fast Inference from Transformers via Speculative Decoding  -  Proceedings of Machine Learning Research },
  year={2023},
  author={Y and Leviathan and Yaniv and M and Kalman and Matan and Y and Matias and Yossi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174407450&partnerID=40&md5=dd04a09c674b56a146a77f677cad5d6d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352345112,
  title={ Accelerating Transformer Inference for Translation via Parallel Decoding  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2023},
  author={A and Santilli and Andrea and S and Severino and Silvio and E and Postolache and Emilian and V and Maiorca and Valentino and M and Mancusi and Michele and R and Marin and Riccardo and E and Rodolà and Emanuele},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174390123&doi=10.18653%2Fv1%2F2023.acl-long.689&partnerID=40&md5=12e8842d66c5bdd86294130fd9d80835 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.acl-long.689 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352345113,
  title={ Strategy of the Intraday Dynamic Capacity Increase Considering the Failure Rate of the Transformer  -  2021 International Conference on Power System Technology (POWERCON) },
  year={2021},
  author={Wang, J. and Liu, C. and Sun, L. and Peng, C. and Li, W. and Guo, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697858 },
  abstract={In the transformer day operation stage, it will face short-term emergency and associated transformer power failure maintenance situation, the operation of transformer intraday dynamic capacity increase can be to a certain extent to deal with the occurrence of the above situation. We establish a model of intraday dynamic capacity increase decision-making of oil-immersed transformers. The model is divided into two stages, the first stage is to meet the safety constraints of the conditions to obtain the transformer pre-capacity scheme; The second stage integrates the risk of capacity increase, calculates the economic index and generates the final strategy that considers economy and safety comprehensively. Through the measured data of a transformer, the concrete study is verified, and the results show that the method can make the decision of the intraday dynamic capacity increase scheme.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/POWERCON53785.2021.9697858 },
  booktitle={ 2021 International Conference on Power System Technology (POWERCON) },
  chapter={0}
}

@article{rayyan-352345114,
  title={ ParaTra: A Parallel Transformer Inference Framework for Concurrent Service Provision in Edge Computing  -  nan },
  year={2023},
  author={F and Cai and Fenglong and D and Yuan and Dong and M and Xie and Mengwei and W and He and Wei and L and Kong and Lanju and W and Guo and Wei and Y and Jiang and Yali and L and Cui and Lizhen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173822197&doi=10.1109%2FICWS60048.2023.00045&partnerID=40&md5=cfafb655ab89bacaacdfbe2c380df96d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICWS60048.2023.00045 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345116,
  title={ Efficient Transformer Inference with Statically Structured Sparse Attention  -  nan },
  year={2023},
  author={S and Dai and Steve and H.N and Genc and Nazim, Hasan and R and Venkatesan and Rangharajan and B.K and Khailany and K, Brucek},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173100526&doi=10.1109%2FDAC56929.2023.10247993&partnerID=40&md5=507885d5d230a3307200f6846ec36659 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DAC56929.2023.10247993 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345117,
  title={ Primer: Fast Private Transformer Inference on Encrypted Data  -  nan },
  year={2023},
  author={M and Zheng and Mengxin and Q and Lou and Qian and L and Jiang and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173091242&doi=10.1109%2FDAC56929.2023.10247719&partnerID=40&md5=027b6d2fdbbd1423ecb652bc55546eca },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DAC56929.2023.10247719 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345118,
  title={ Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference  -  Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition },
  year={2023},
  author={H and You and Haoran and Y and Xiong and Yunyang and X and Dai and Xiaoliang and B and Wu and Bichen and P and Zhang and Peizhao and H and Fan and Haoqi and P and Vajda, Péter and Y.C and Lin and Celine, Yingyan},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172436690&doi=10.1109%2FCVPR52729.2023.01387&partnerID=40&md5=8b8cff21aaa3d0a1b1cb5f32bbf669c0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CVPR52729.2023.01387 },
  booktitle={ Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition },
  chapter={0}
}

@article{rayyan-352345119,
  title={ Securing Foundation Models: Failure Cases, Challenges, and the Future  -  IEEE Intelligent Systems },
  year={2025},
  author={Niu, M. and Zhu, J. and Qiao, H. and Haddadi, H. and Pang, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11187325 },
  abstract={Foundation models (FMs), trained on diverse web-scale datasets, have demonstrated remarkable performance on a broad range of tasks. Despite their strong capabilities, the rapid expansion in scale and complexity of FMs introduces significant challenges that could compromise their reliability upon deployment. Key concerns can include the potential leakage of private data, exacerbation of existing bias, generation of incorrect or even harmful responses, and the risk of malicious use, among other emerging issues. This article discusses the public perception of critical ethical issues surrounding the privacy, safety, and security of FMs and their major challenges and opportunities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIS.2025.3597124 },
  booktitle={ IEEE Intelligent Systems },
  chapter={0}
}

@article{rayyan-352345120,
  title={ Spatiotemporal Transformer for Data Inference and Long Prediction in Sparse Mobile CrowdSensing  -  Proceedings - IEEE INFOCOM },
  year={2023},
  author={E and Wang and En and W and Liu and Weiting and W and Liu and Wenbin and C and Xiang and Chaocan and B and Yang and Bo and Y and Yang and Yongjian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171618885&doi=10.1109%2FINFOCOM53939.2023.10228982&partnerID=40&md5=cac5b5295ec02cb89c099c51ec5fa240 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INFOCOM53939.2023.10228982 },
  booktitle={ Proceedings - IEEE INFOCOM },
  chapter={0}
}

@article{rayyan-352345121,
  title={ Object-Centric Inference for Language Conditioned Placement: A Foundation Model based Approach  -  nan },
  year={2023},
  author={Z and Xu and Zhixuan and K and Xu and Kechun and R and Xiong and Rong and Y and Wang and Yue},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171574325&doi=10.1109%2FICARM58088.2023.10218865&partnerID=40&md5=d7286c9d83f3ca5496fe39563f9f2537 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICARM58088.2023.10218865 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345124,
  title={ Transformer Inference Acceleration in Edge Computing Environment  -  nan },
  year={2023},
  author={M and Li and Mingchu and W and Zhang and Wenteng and D and Xia and Dexin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166732936&doi=10.1109%2FCCGridW59191.2023.00030&partnerID=40&md5=96f4a3e95737c5839eae288a1adf9d2f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCGridW59191.2023.00030 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345126,
  title={ Evaluating Text-to-SQL Model Failures on Real-World Data  -  2024 IEEE 40th International Conference on Data Engineering (ICDE) },
  year={2024},
  author={Ganti, M. and Orr, L. and Wu, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598154 },
  abstract={Text-to-SQL generation models, capable of converting natural language prompts into SQL queries, offer significant potential for streamlining data analytics tasks. Despite state-of-the-art performance on popular academic benchmarks such as Spider [1], recent large language models, such as GPT-4, exhibit a considerable performance degradation on real-world applications with longer, more convoluted schemas [2]. This disparity raises questions about what factors contribute to this drop and whether existing academic benchmarks are effective for representing real-world challenges. To determine these factors, we first examine Text-to-SQL model failures on customer logs. We find that accuracy on customer logs was on average 30% lower than accuracy on Spider. We identify three main challenges in real-world Text-to-SQL applications: long context length, unclear question formulation, and greater query complexity. With these insights, we create a new benchmark built from manually labeled customer logs and evaluate existing open source and private LLMs to demonstrate the impact of each factor on model performance. The benchmark incorporates 20 non-join queries and 30 join queries, each accompanied by three additional question phrasing variations, resulting in 200 queries total. To capture the effects of large schemas, we vary schema size from 5 to over 300 columns while retaining the minimum columns required to answer all questions. We assess the performance of prominent Text-to-SQL models, including GPT-4, GPT-3.5, BigCode's Starcoder [3], and NSQL Llama-2 [4] on both our benchmark and the Spider benchmark for comparative analysis. We use Spider execution accuracy to measure model performance. The evaluation results reveal a) A consistent decline in execution accuracy for longer schemas, dropping about 0.5 percentage points for every additional 10 columns, indicating that existing Text-to-SQL models struggle with progressively larger tables and schema lengths that are characteristic of real-world datasets, b) A decrease in execution accuracy of 12.3 points on average on questions that emulate real-world phrasing compared to questions phrased unambiguously based on academic benchmarks and c) An accuracy drop of an average of 36 and up to 52 points when models must reason over nested or complex queries compared to simple SELECT statements, with models commonly making errors interpreting column schemas correctly. Overall, accuracy drops when the complexity of queries or schemas increases from that of academic benchmarks. Our benchmark highlights this model performance disparity between enterprise and academic settings, emphasizing the need for improvements in handling long context tasks, generating complex queries, and increasing robustness against question ambiguity. We hope to encourage development of enterprise inspired benchmarks to better capture LLM performance in real-world scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDE60146.2024.00456 },
  booktitle={ 2024 IEEE 40th International Conference on Data Engineering (ICDE) },
  chapter={0}
}

@article{rayyan-352345127,
  title={ Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2023},
  author={J and Hoelscher-Obermaier and Jason and J.H and Persson and H, Julia and E and Kran and Esben and I and Konstas and Ioannis and F and Barez and Fazl},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166307252&doi=10.18653%2Fv1%2F2023.findings-acl.733&partnerID=40&md5=d6600b831a73b58bc2d243ea8f59ae0d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.findings-acl.733 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352345128,
  title={ An Efficient Piecewise Linear Approximation of Non-linear Operations for Transformer Inference  -  nan },
  year={2023},
  author={H and Lu and Haodong and Q and Mei and Qichang and K and Wang and Kun},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165942411&doi=10.1109%2FFCCM57271.2023.00034&partnerID=40&md5=0953a6d38549776d29322928100b5f2b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FCCM57271.2023.00034 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345129,
  title={ The Influence of Modeling Transformer Age Related Failures on System Reliability  -  IEEE Transactions on Power Systems },
  year={2015},
  author={Awadallah, S. K. E. and Milanović, J. V. and Jarman, P. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6847250 },
  abstract={The paper investigates the effect of age related failure of power transformers on the identification of most critical transformer sites for system reliability. The end-of-life failure model of power transformers is modified first to integrate loading conditions effect. The adopted Arrhenius-Weibull probability distribution, which represents the effect of thermal stress on the transformer's end-of-life failure, was compared with the commonly used Gaussian probability distribution model. The sensitivity of results to the uncertainty in model parameters is thoroughly assessed, and acceptable level of uncertainty is determined. The results demonstrated the importance of integration of loading conditions into the failure model. The sensitivity analysis revealed that the identification of critical transformer sites is not significantly affected by the uncertainty in the failure model parameters and that approximate ranges of parameters can be used instead of accurate values without significant, if any, loss in accuracy. The case studies were performed on a realistic transmission test system with 154 power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2014.2331103 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345131,
  title={ FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU  -  Proceedings of Machine Learning Research },
  year={2023},
  author={Y and Sheng and Ying and L and Zheng and Lianmin and B and Yuan and Binhang and Z and Li and Zhuohan and M and Ryabinin and Max and B and Chen and Beidi and P and Liang and Percy and C.M., Ré and M, Christopher and I and Stoica and Ion and C and Zhang and Ce},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161962667&partnerID=40&md5=321ce728a16dc6b14b678f69fe988239 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352345132,
  title={ Analysis of physical transformer circuits for frequency response interpretation and mechanical failure diagnosis  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2016},
  author={Pham, D. A. K. and Gockenbach, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534629 },
  abstract={The authors of this paper proposed an effective method applied to frequency response interpretation in low frequency range and mechanical failure diagnosis support based on measurements and analysis of a physical lumped component transformer circuit. To extend the interpretation until medium frequencies where mechanical failures influence most, this paper presents a novel approach on determining parameters in a physical distributed component circuit. The most important contribution of this paper is the possibility of determination of electrical parameters in the distributed circuit without knowing detailed knowledge of the transformer construction, which has been a challenge so far. In addition, the application capability of the distributed circuit in diagnosis of several mechanical failures in a distribution transformer is also investigated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2016.005551 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345133,
  title={ MPCFORMER: FAST, PERFORMANT AND PRIVATE TRANSFORMER INFERENCE WITH MPC  -  nan },
  year={2023},
  author={D and Li and Dacheng and R and Shao and Rulin and H and Wang and Hongyi and H and Guo and Han and E.P and Xing and P, Eric and H and Zhang and Hao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161827958&partnerID=40&md5=2b10d30d515113265def162a46089190 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345134,
  title={ NCUEE-NLP at SemEval-2023 Task 7: Ensemble Biomedical LinkBERT Transformers in Multi-evidence Natural Language Inference for Clinical Trial Data  -  nan },
  year={2023},
  author={C and Chen and Chaoyi and K and Tien and Kaoyuan and Y and Cheng and Yuanhao and L and Lee and Lunghao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161349819&doi=10.18653%2Fv1%2F2023.semeval-1.107&partnerID=40&md5=c674a7032d538945a6d4ed66fb91a1d6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2023.semeval-1.107 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345136,
  title={ Investigation the causes of Transformers Failures in Mellitah Complex - case study  -  2023 IEEE 3rd International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering (MI-STA) },
  year={2023},
  author={Alkar, K. M. and Khanan, M. and Issa, M. A. and Salama, A. -A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10169410 },
  abstract={Power transformers play a critical role in the distribution and management of electrical energy, making their reliability and longevity of paramount importance. However, transformers are susceptible to various types of failures, which can have significant impacts on power systems. A better understanding of the common causes and impacts of transformer failures, as well as methods to improve their performance, is essential for maintaining the reliability and stability of electrical power systems. The power system network of Mellitah Complex, in the "north part of Libya", experienced a number of transformer failures. In this paper, several tests and analyses have been conducted to identify the causes of failure of the transformer in the power system, and to avoid these breakdowns in the future. Also, present two case studies on unexpected failures of power transformer tag No: 40-920-ET-061B and a generator power transformer tag No: 40-910-ET-011B in the Mellitah complex during regular operation. The research is done based on the data that are gathered from several events of transformer failure and tests. The tests are; Insulation Resistance measurement test (IR), phase conductor ohmic resistance, winding resistance test, the transformer voltage ratio test, the time of oil regeneration test, dielectric strength test, IR tests conducted at 5000V for 1 minute, and voltage injection test (ratio test). The investigation showed that the main cause of the malfunction of transformer tag No: 40-920-ET-061B is the entry of water from the rusty roof into the middle HV winding. Additionally, because of not following the maintenance procedures by the maintenance team led to the mysteries of the main cause of the failure of transformer tag No: 40-910-ET-011B.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MI-STA57575.2023.10169410 },
  booktitle={ 2023 IEEE 3rd International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering (MI-STA) },
  chapter={0}
}

@article{rayyan-352345137,
  title={ Exploratory Inference Chain: Exploratorily Chaining Multi-hop Inferences with Large Language Models for Question-Answering  -  nan },
  year={2023},
  author={S and Haji and Shosuke and K and Suekane and Keiichi and H and Sano and Hirofumi and T and Takagi and Tomohiro},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151531894&doi=10.1109%2FICSC56153.2023.00036&partnerID=40&md5=715031f2bf16cb1240c8ac7481247a15 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC56153.2023.00036 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345138,
  title={ Towards Linguistically Informed Multi-objective Transformer Pre-training for Natural Language Inference  -  Lecture Notes in Computer Science },
  year={2023},
  author={M and Pielka and Maren and S and Schmidt and Svetlana and L and Pucknat and Lisa and R and Sifa and Rafet},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150976671&doi=10.1007%2F978-3-031-28238-6_46&partnerID=40&md5=b413cadf161a59bafd6b4c0404b1b852 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-28238-6_46 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352345139,
  title={ Video Inference for Human Mesh Recovery with Vision Transformer  -  nan },
  year={2023},
  author={H and Cho and Hanbyel and J and Ahn and Jaesung and Y and Cho and Yooshin and J and Kim and Junmo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149268388&doi=10.1109%2FFG57933.2023.10042731&partnerID=40&md5=5a4e28515f45d7536a3611bbc47ebab8 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/FG57933.2023.10042731 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345140,
  title={ Style-Guided Inference of Transformer for High-resolution Image Synthesis  -  nan },
  year={2023},
  author={J and Yim and Jonghwa and M and Kim and Minjae},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149000482&doi=10.1109%2FWACV56688.2023.00179&partnerID=40&md5=3bfb4d8ddc0d87ecb97440e505e3672f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WACV56688.2023.00179 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345141,
  title={ Distribution Transformer Failure: Causes and Solutions from the Field Data Analysis  -  2024 3rd International conference on Power Electronics and IoT Applications in Renewable Energy and its Control (PARC) },
  year={2024},
  author={Jain, S. K. and Jain, V. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10486534 },
  abstract={During the past ten years, tremendous growth has been observed in load. The overloaded grid assets, such as distribution transformers, which are a fundamental part of the distribution system, serve in severe and poorly maintained conditions, which account for heavy losses and often result in failure. The failure rate of Distribution Transformers (DTR) is significantly high, especially in developing countries, which leads to loss of revenue and poor customer satisfaction. Therefore, it becomes a need of the hour to study various reasons for DTR failure to identify dominant causes and possible corrective measures to improve the situation. This paper aims to analyze the prevailing situations in the Indian distribution systems based on historical data, field visits, and available infrastructure. Based on the findings, possible reasons for DTR failures are identified, and recommendations are proposed for minimizing the failure rate of DTRs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PARC59193.2024.10486534 },
  booktitle={ 2024 3rd International conference on Power Electronics and IoT Applications in Renewable Energy and its Control (PARC) },
  chapter={0}
}

@article{rayyan-352345142,
  title={ An Efficient Transformer Inference Engine on DSP  -  Lecture Notes in Computer Science },
  year={2023},
  author={K and Chen and Kangkang and H and Su and Huayou and C and Liu and Chaorun and X and Gong and Xiaoli},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148695615&doi=10.1007%2F978-3-031-22677-9_29&partnerID=40&md5=25f071530156a90c6426b9645be7b2df },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-22677-9_29 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352345143,
  title={ Characterizing and Optimizing Transformer Inference on ARM Many-core Processor  -  ACM International Conference Proceeding Series },
  year={2022},
  author={J and Jiang and Jiazhi and J and Du and Jiangsu and D and Huang and Dan and D and Li and Dongsheng and J and Zheng and Jiang and Y and Lu and Yutong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148614469&doi=10.1145%2F3545008.3545022&partnerID=40&md5=912325b840f5d5e93f1d6a83029fea8c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3545008.3545022 },
  booktitle={ ACM International Conference Proceeding Series },
  chapter={0}
}

@article{rayyan-352345144,
  title={ TCB: Accelerating Transformer Inference Services with Request Concatenation  -  ACM International Conference Proceeding Series },
  year={2022},
  author={B and Fu and Boqian and F and Chen and Fahao and P and Li and Peng and D and Zeng and Deze},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148578048&doi=10.1145%2F3545008.3545052&partnerID=40&md5=ebce2faad6fba3b7581967b99ed8a6ad },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3545008.3545052 },
  booktitle={ ACM International Conference Proceeding Series },
  chapter={0}
}

@article{rayyan-352345145,
  title={ NN-LUT: Neural Approximation of Non-Linear Operations for Efficient Transformer Inference  -  nan },
  year={2022},
  author={J and Yu and Joonsang and J and Park and Junki and S and Park and Seongmin and M and Kim and Minsoo and S and Lee and Sihwa and D and Lee and Dong-hyun and J and Choi and Jungwook},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137453553&doi=10.1145%2F3489517.3530505&partnerID=40&md5=25bdab7591a5aa3ec43b538fd0a68a25 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3489517.3530505 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345146,
  title={ Experimental Analysis of Thermal and Overload Failures in Dry-Type Inverter Transformer  -  2024 IEEE 22nd Student Conference on Research and Development (SCOReD) },
  year={2024},
  author={Ching, K. B. and Looi, M. S. and Uttraphan, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10872653 },
  abstract={This paper examines failures in dry-type transformers in inverter systems precisely due to thermal and overload effects. Analysing the thermal capacity and overload limits of inverter transformers is crucial, as these factors directly impact their reliability and operational lifespan. A notable case was reported where a transformer experienced premature ageing before reaching its intended lifespan of twenty years. An experimental study was conducted by developing a prototype inverter transformer operated under various load levels and ambient temperatures. A temperature sensor was installed between the core and windings to serve as the reference point for the highest temperature. Temperature readings were collected using a temperature logger, and the transformer was placed in a temperature regulated test cubicle. This experimental test focused on the maximum temperature recorded at various load levels and the impact of ambient temperature on this maximum temperature. The study found that the transformer temperature could rise to 139 degree Celsius when subjected to a $110 \%$ overload at an ambient temperature of 35 degree Celsius. The research concludes that maintaining the operating temperature of the transformer below 33 degree Celsius is advisable for safe operation at up to $\mathbf{1 1 0 \%}$ overload, reducing the risk of winding overheating and insulation degradation. The paper proposes implementing enhanced cooling mechanisms between the windings to improve thermal capacity and prevent overheating in transformers. The findings from this research provide valuable insights for designing transformers with considerations for thermal performance under overload conditions and high ambient temperatures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCOReD64708.2024.10872653 },
  booktitle={ 2024 IEEE 22nd Student Conference on Research and Development (SCOReD) },
  chapter={0}
}

@article{rayyan-352345147,
  title={ Handling heavy-tailed input of transformer inference on GPUs  -  nan },
  year={2022},
  author={J and Du and Jiangsu and J and Jiang and Jiazhi and Y and You and Yang and D and Huang and Dan and Y and Lu and Yutong},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132821689&doi=10.1145%2F3524059.3532372&partnerID=40&md5=3321d6ec69c207225108c4e8717e8887 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3524059.3532372 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345148,
  title={ Clairvoyant: A Log-Based Transformer-Decoder for Failure Prediction in Large-Scale Systems  -  nan },
  year={2022},
  author={K.A and Alharthi and Ayedh, Khalid and A and Jhumka and Arshad and S and Di and Sheng and F and Cappello and Franck},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132805073&doi=10.1145%2F3524059.3532374&partnerID=40&md5=a77226644512e485471c3e0a456c9c01 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3524059.3532374 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345149,
  title={ Mokey: Enabling Narrow Fixed-Point Inference for Out-of-the-Box Floating-Point Transformer Models  -  nan },
  year={2022},
  author={A.H and Zadeh and Hadi, Ali and M and Mahmoud and Mostafa and A.M.S and Abdelhadi and M.S, Ameer and A and Moshovos and Andreas},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132834188&doi=10.1145%2F3470496.3527438&partnerID=40&md5=78fcf9d2a14b82c7a79180f72e51431d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3470496.3527438 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345150,
  title={ LLMOps: Definitions, Framework and Best Practices  -  2024 International Conference on Electrical, Computer and Energy Technologies (ICECET },
  year={2024},
  author={Sinha, M. and Menon, S. and Sagar, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10698359 },
  abstract={Operationalizing large language models is unlike traditional AI solutioning. As the vestiges of the MLOps paradigm serve as a reminder of the sophistication that surfaces at scale, Generative AI, while mitigating a few of those challenges, brings a few of its own. This is where LLMOps (Large Language Model Operations) comes into the picture. LLMOps is a subset of FMOps (Foundation Model Operations) that builds on the principles of MLOps (Machine Learning Operations) and helps enterprises deploy, monitor, and retrain their LLMs seamlessly. This paper provides a comprehensive definition of LLMOps and a robust framework and highlights best practices accrued through our experience building solutions in different domains. Finally, this work attempts to provide guidance for AI practitioners who want to operationalize their GenAl applications seamlessly.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Included"}},
  doi={ 10.1109/ICECET61485.2024.10698359 },
  booktitle={ 2024 International Conference on Electrical, Computer and Energy Technologies (ICECET },
  chapter={0}
}

@article{rayyan-352345151,
  title={ Towards Efficient Vision Transformer Inference: A First Study of Transformers on Mobile Devices  -  nan },
  year={2022},
  author={X and Wang and Xudong and L.L and Zhang and Lyna, Li and Y and Wang and Yang and M and Yang and Mao},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127542293&doi=10.1145%2F3508396.3512869&partnerID=40&md5=90a44332c59a44fb43d3de00ab9d27a2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3508396.3512869 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345153,
  title={ Understanding the Failure of Batch Normalization for Transformers in NLP  -  Advances in Neural Information Processing Systems },
  year={2022},
  author={J and Wang and Jiaxi and J and Wu and Ji and L and Huang and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163218239&partnerID=40&md5=6096973b54e7ed7bbb05009e4347160a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345154,
  title={ Through fault current effects on distribution transformer and prevention actions using backup protection : Case study of Kelapa Gading transformer  -  2017 International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  year={2017},
  author={Sari, I. M. and Tryollinna, A. and Sudin, A. D. P. and Permata, D. Deka},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8225951 },
  abstract={Failure due to external fault. This external fault, known as through fault current (TFC), determined as fault occur on low side of transformer. This condition become an issue in PLN transmission unit nowadays because this fault highly effected to the lifetime of transformer, especially distribution transformer (150/20 kV and 70/20 kV). Beside the loss of the material, it is also bring the consequence to the quality of the company services. To prevent this condition, some actions must be taken. TFC has three parameters that take effect directly to the transformer condition, i.e. magnitude, duration and frequency of fault. Controlling two of three parameters could be reduce the effect of TFC. Therefore, this paper will present about decreasing the impact of TFC to the transformer by using backup protection in transformer to limiting the value and duration of the TFC. This limitation is done by calculating the backup protection of the transformer for high setting in over current relay (OCR) installed on the incoming side. OCR high set must be calculated by considering equipment safety, system reliability and proper coordination among the OCRs. Hopefully, with the new setting calculation can reduce the number of transformer failure due to TFC.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVEPS.2017.8225951 },
  booktitle={ 2017 International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  chapter={0}
}

@article{rayyan-352345155,
  title={ Iron: Private Inference on Transformers  -  Advances in Neural Information Processing Systems },
  year={2022},
  author={M and Hao and Meng and H and Li and Hongwei and H and Chen and Hanxiao and P and Xing and Pengzhi and G and Xu and Guowen and T and Zhang and Tianwei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162842858&partnerID=40&md5=d1b5e0afeb9e327c8c50a6f01533c49b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345156,
  title={ Zero-Shot Dynamic Quantization for Transformer Inference  -  nan },
  year={2022},
  author={Y and El-Kurdi and Yousef and J.L and Quinn and L, Jerome and A and Sil and Avirup},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152969064&doi=10.18653%2Fv1%2F2022.emnlp-industry.45&partnerID=40&md5=74b79beb3d99b1f3fee72bc1bc5cd8c2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2022.emnlp-industry.45 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345157,
  title={ Capturing Failures of Large Language Models via Human Cognitive Biases  -  Advances in Neural Information Processing Systems },
  year={2022},
  author={E and Jones and Erik and J.S and Steinhardt and S, Jacob},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151858869&partnerID=40&md5=177d84c1dde9005cc9650e84d32eaf14 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Advances in Neural Information Processing Systems },
  chapter={0}
}

@article{rayyan-352345158,
  title={ Investigating the Performance of Transformer-Based NLI Models on Presuppositional Inferences  -  Proceedings - International Conference on Computational Linguistics, COLING },
  year={2022},
  author={J and Kabbara and Jad and J.C.K and Cheung and Kit, Jackie Chi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151253742&partnerID=40&md5=a33dd4d4bc17db01cc6facb48a14e205 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings - International Conference on Computational Linguistics, COLING },
  chapter={0}
}

@article{rayyan-352345160,
  title={ Active Fault Analysis of Distribution Transformer Service Area Based on Intelligent Transformer Terminal Unit  -  2019 IEEE Sustainable Power and Energy Conference (iSPEC) },
  year={2019},
  author={Zhichun, Y. and Yu, S. and Fan, Y. and Lei, S. and Yang, L. and Fangbin, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8975728 },
  abstract={For a long time, Distribution transformer service area lacks effective equipment condition monitoring and operation monitoring methods, and cannot timely grasp information such as power failures in the station area and low-voltage distribution network and positions of power-off, resulting in fault finding and positioning of low-voltage distribution network or user mainly relying on users reported repairs or complaints to 95598, which seriously restrict-ed the efficiency of power supply recovery and customer service. Based on monitored and analyzed in real time of the Transformer Terminal Unit(TTU) to the local information of the distribution transformer station, the low voltage branch box, the meter box and the user intelligent meter, the distributed edge calculation function of TTU is adopted to propose an active fault diagnosis method of low voltage based on TTU, actively grasping the user power outage events and conducting fault research and diagnosis local, solving the problems caused by traditional method such as passive perception of fault, timeliness and information congestion fault for concentrated information collection and diagnosis. Realizing timely and proactively locate faulty areas, and to carry out fault repairs of low voltage distribution network, reduce user blackout time, and improve "active" service and quality service level.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iSPEC48194.2019.8975728 },
  booktitle={ 2019 IEEE Sustainable Power and Energy Conference (iSPEC) },
  chapter={0}
}

@article{rayyan-352345161,
  title={ Testing Large Language Models on Compositionality and Inference with Phrase-Level Adjective-Noun Entailment  -  Proceedings - International Conference on Computational Linguistics, COLING },
  year={2022},
  author={L and Bertolini and Lorenzo and J and Weeds and Julie and D.J and Weir and J, David},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150333348&partnerID=40&md5=09e97ac630f722ac3edf8c7828deab6a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings - International Conference on Computational Linguistics, COLING },
  chapter={0}
}

@article{rayyan-352345162,
  title={ DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale  -  International Conference for High Performance Computing, Networking, Storage and Analysis, SC },
  year={2022},
  author={R.Y and Aminabadi and Yazdani, Reza and S and Rajbhandari and Samyam and A.A and Awan and Ahmad, Ammar and C and Li and Cheng and D and Li and Du and E and Zheng and Elton and O and Ruwase and Olatunji and S and Smith and Shaden and M and Zhang and Minjian and J and Rasley and Jeff},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149264195&doi=10.1109%2FSC41404.2022.00051&partnerID=40&md5=b31e3f234476d14fb41772bbb2e464a6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SC41404.2022.00051 },
  booktitle={ International Conference for High Performance Computing, Networking, Storage and Analysis, SC },
  chapter={0}
}

@article{rayyan-352345163,
  title={ Impact of Misalignment of Voltage Transformers on Transformers Performance in Mellitah Complex - Case Study  -  2023 IEEE 11th International Conference on Systems and Control (ICSC) },
  year={2023},
  author={Alkar, K. M. and Khanan, M. and Issa, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10449864 },
  abstract={The huge number of transformers in electrical networks exposes them to the rise of failures from the design stages to the operation stages. Therefore, keeping the safety of transformers from faults is an urgent need to ensure continuity to provide consumers with energy. Lately, the power system network of Mellitah Complex, in the “north part of Libya”, faced several transformer failures. One of these failures caused power interruption on industrial loads in the seventh distribution station. The reason for the interruption is a fault on a step-down transformer 20 KV /6.6 KV tag No: 85-910-ET- 071B. This paper aims to study and analyze the causes of frequent transformer failures and to suggest practical solutions to overcome these failures. The research is done based on the recorded data on a program and a digital protection relay device called “Sepam Protection”, reports of maintenance and protection engineers, and the results of tests done on the transformer under investigation. The investigation shows; the main cause of the transformer failure was a misalignment between the Voltage Transformer (VT) of the line (L3) and the busbar.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC58660.2023.10449864 },
  booktitle={ 2023 IEEE 11th International Conference on Systems and Control (ICSC) },
  chapter={0}
}

@article{rayyan-352345164,
  title={ THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2022},
  author={T and Chen and Tianyu and H and Bao and Hangbo and S and Huang and Shaohan and L and Dong and Li and B and Jiao and Binxing and D.X and Jiang and Xin, Daxing and H and Zhou and Haoyi and J and Li and Jianxin and F and Wei and Furu},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149142478&doi=10.18653%2Fv1%2F2022.findings-acl.277&partnerID=40&md5=5948a953f2c2b571675ba55458822d80 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2022.findings-acl.277 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352345165,
  title={ Failure Frequencies for High-Voltage Circuit Breakers, Disconnectors, Earthing Switches, Instrument Transformers, and Gas-Insulated Switchgear  -  IEEE Transactions on Power Delivery },
  year={2013},
  author={Runde, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331585 },
  abstract={Failure frequencies for circuit breakers (CBs) (only single pressure SF6), disconnectors and earthing switches, instrument transformers, and gas-insulated switchgear (GIS) have been determined through a comprehensive worldwide utility survey. For CBs and GIS, where comparable results from earlier surveys exist, significant reductions in failure frequencies are observed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2012.2220638 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345167,
  title={ TRANSFORMERS CAN DO BAYESIAN INFERENCE  -  nan },
  year={2022},
  author={S.G., Müller and G, Samuel and N and Hollmann and Noah and S and Pineda and Sebastian and J and Grabocka and Josif and F and Hutter, Frank and Frank},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147240042&partnerID=40&md5=07fbb6b5421b6b9ab824dc9d660b7a6f },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345171,
  title={ Tranception: Protein Fitness Prediction with Autoregressive Transformers and Inference-time Retrieval  -  Proceedings of Machine Learning Research },
  year={2022},
  author={P and Notin and Pascal and M and Dias and Mafalda and J and Frazer and Jonathan and J and Marchena-Hurtado and Javier and A.N and Gomez and N, Aidan and D.S and Marks and Susan, Debora and Y and Gal and Yarin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143710779&partnerID=40&md5=2d039574ffbd050a8c39a98b46ef6cac },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Proceedings of Machine Learning Research },
  chapter={0}
}

@article{rayyan-352345172,
  title={ Identification failure of 3 MVA furnace transformer  -  2016 Diagnostic of Electrical Machines and Insulating Systems in Electrical Engineering (DEMISEE) },
  year={2016},
  author={Brandt, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530472 },
  abstract={The paper deals with the identification of the furnace power transformer state. The furnace transformer was subjected to several prophylactic measurements. Their results are summarized and described in the article. In spite of that it is not a standard power oil transformer there was selected appropriate procedures and practices with respect to international standards. Identified failure was confirmed by the disassembly of the transformer in Repair Company.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DEMISEE.2016.7530472 },
  booktitle={ 2016 Diagnostic of Electrical Machines and Insulating Systems in Electrical Engineering (DEMISEE) },
  chapter={0}
}

@article{rayyan-352345173,
  title={ HTS Transformer: Construction Details, Test Results, and Noted Failure Mechanisms  -  IEEE Transactions on Power Delivery },
  year={2011},
  author={Lapthorn, A. C. and Chew, I. and Enright, W. G. and Bodger, P. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571022 },
  abstract={An experimental high temperature superconducting transformer has been designed and built using Bi2223 HTS tape. The transformer is unique in that the magnetic circuit is comprised of air and a silicon steel partial core. Electrical tests were performed on the transformer and it was found to be 98.6% efficient at full load. The transformer failed during a full load endurance run and an investigation was carried out to determine the cause of the failure. The cause was believed to be from operating the HTS windings close to critical conditions. Presentation of the failure details will be of use to other researchers who are building HTS transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2010.2061874 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345174,
  title={ Impact of power system harmonics on insulation failure of distribution transformer and its remedial measures  -  2011 3rd International Conference on Electronics Computer Technology },
  year={2011},
  author={Deokar, S. A. and Waghmare, L. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5941817 },
  abstract={The ageing of insulation denotes physical and chemical changes, which takes place as a result of electrical stresses in the power system network. In the modern days, a large use of nonlinear devices has resulted into increased distortion in load voltages. The current drawn by all such devices contains harmonics. The losses as well as insulation are more in the equipment at harmonic frequencies than the fundamental frequency. The thermal circuit capability at the fundamental frequency is inadequate to dissipate increased losses due to harmonic current. Hence excessive current drawn during steady state and dynamic power quality problems resulting into the higher temperature rise. The increased use of the non-linear devices in today's network is responsible for faster degradation of insulating material. The transformer transfers electrical energy from one point circuit to another. The additional heating experienced by a transformer depends on the harmonic content of the load current & the design principals of the transformer. In this paper, an attempt has been made to discuss the procedure for loss calculations and analysis of impact of the temperature rise on conventional oil immersed and derated transformer under the non-linear load conditions. Some remedial measures are also suggested to reduce the impact of harmonics on insulation failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECTECH.2011.5941817 },
  booktitle={ 2011 3rd International Conference on Electronics Computer Technology },
  chapter={0}
}

@article{rayyan-352345175,
  title={ Impact of power transformer failures on customer interruptions costs using customer damage functions  -  2017 Nineteenth International Middle East Power Systems Conference (MEPCON) },
  year={2017},
  author={El-Bassiouny, A. and El-Shimy, M. and Hammouda, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301237 },
  abstract={Electrical power is essential in the operation, development, and economy. Depending on their activities, the loads can be classified into five main sectors; industrial, agricultural, commercial, governmental, and residential. Various load sectors are affected by power interruptions which are translated into Customer Interruption Costs (CICs). These costs depend on the class of the load sector, and the interruption duration. Load interruptions can be attributed to lack in the power production and/or failures in various components in the power grid, and supply system. This paper focuses on the impact of failures of power transformers on CICs considering various voltage populations in the Egyptian utility grid. In addition, the impacts of the failures in various subassemblies in power transformers, and other outage causes on CICs are presented. The CIC estimation method is based on combining the Customer Damage Functions (CDFs) of various load sectors into one damage function which is the Composite Customer Damage Function (CCDF). The CCDF is obtained through weighting of the CDFs of various load sectors where the weighting factors are the percentage of various load sectors comprising the load mix composition. In addition, the impact of the interruption durations on the CCDF is considered through the consideration of the interrupted power, and interrupted energy. The determined CCDF is approximated to an algebraic function through curve fitting. The interruptions data of power transformers are obtained from a long term survey of power transformer failures for eight years from years 2002 to 2009 at various locations, and voltage populations in Egypt based on Egyptian Electricity Transmission Company (EETC) surveys. The Customer Damage Functions (CDFs) of various load sectors are obtained from a previous study. The results show the severity of failure in various subassemblies of power transformers in various voltage subpopulations. Therefore, the presented results can contribute in enhancing maintenance schedules, and manufacturing of power transformers as well as estimating the CICs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEPCON.2017.8301237 },
  booktitle={ 2017 Nineteenth International Middle East Power Systems Conference (MEPCON) },
  chapter={0}
}

@article{rayyan-352345176,
  title={ Failure rate estimation of power transformers using inspection data  -  2016 International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  year={2016},
  author={Abbasi, E. and Malik, O. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7764150 },
  abstract={An approach to evaluating the failure rate of power transformers with consideration of inspection and test results is presented. Hazard plotting, a conventional statistical method, is used first to find the best model that fits the aging failure data. Then, by exploring the power transformer's Health Index correlation to age, a method is established to adjust its failure rate based on the evaluated condition. The study of failed and in service units proves the viability of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PMAPS.2016.7764150 },
  booktitle={ 2016 International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  chapter={0}
}

@article{rayyan-352345177,
  title={ Vibration-based robust health diagnostics for mechanical failure modes of power transformers  -  2013 IEEE Conference on Prognostics and Health Management (PHM) },
  year={2013},
  author={Yoon, J. T. and Youn, B. D. and Park, K. M. and Lee, W. -R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6621421 },
  abstract={A power transformer is one of the main components in a power plant and transformer failure may provoke power plant shut-down with significant capital loss. Many techniques of vibration-based health diagnostics have been developed in order to prevent mechanical failures of the transformer. Vibration-based health diagnostics results are generally sensitive to the number of sensors and their locations. This study aims at developing robust health diagnostics for two dominant mechanical failure mechanisms of the transformer. Based upon the characteristics of transformer vibration, robust health indices were developed using sensitivity analysis. This study employed 33 transformers and each with 36~48 accelerometers for demonstration purpose. It is concluded that the proposed health index are suitable for robust health diagnostics and fault identification of power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPHM.2013.6621421 },
  booktitle={ 2013 IEEE Conference on Prognostics and Health Management (PHM) },
  chapter={0}
}

@article{rayyan-352345178,
  title={ Lightning-caused transformer failures in distribution systems  -  2014 International Conference on Lightning Protection (ICLP) },
  year={2014},
  author={Piantini, A. and Janiszewski, J. M. and de Carvalho, T. O. and Obase, P. F. and dos Santos, G. J. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973261 },
  abstract={This paper presents the main results of an investigation conducted with the aim of reducing to an acceptable level the lightning-caused distribution transformer failure rate in a region in the South of Brazil. The region, in the border of the State of Rio Grande do Sul and Argentina, is characterized by a high lightning activity. The analysis of failed transformers and field results shows that the installation of surge arresters at the transformer LV side does not drastically change the failure rate. Computer simulations corroborate this result and confirm that failures are mostly associated with surges coming from the MV side. Therefore, the recommendations are mainly related to the surge arrester installation procedures at the primary side. A discussion is provided on the reasons for the apparent discrepancy with regard to the conclusions of similar investigations carried out in Australia, Norway, and the USA, according to which the installation of secondary arresters leads to substantial reduction in transformer failure rates.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLP.2014.6973261 },
  booktitle={ 2014 International Conference on Lightning Protection (ICLP) },
  chapter={0}
}

@article{rayyan-352345179,
  title={ A case study of voltage transformer failures in a modern data center: Analysis, mitigation, and solution implementation  -  2016 IEEE/IAS 52nd Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  year={2016},
  author={Abdelazim, T. and Dionise, T. J. and Yanniello, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490257 },
  abstract={While preparing a modern data center for startup, the commissioning process involved primary circuit switching that resulted in two voltage transformer (VT) failures. As a result of these failures, the authors conducted a comprehensive investigation of the VT failures. As the investigation proceeded, VT ferroresonance on circuit opening, and high frequency switching transients on closing, emerged as possible root causes of the VT failures. After incorporating extensive transient simulations and three rounds of field transient measurements, the authors designed and implemented a complete solution that included sizing of snubbers to overcome excessive switching transients, and the development of a saturable reactor to protect voltage transformers against the effects of ferroresonance. This paper describes root cause(s), simulations, field measurements, recommend solution(s), and solution implementation. The correlation between field measurements and simulation results show the effectiveness of modeling the implemented solutions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2016.7490257 },
  booktitle={ 2016 IEEE/IAS 52nd Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  chapter={0}
}

@article{rayyan-352345180,
  title={ Fuzzy based transformer failure analysis under uncertainty  -  2014 International Conference on Reliability Optimization and Information Technology (ICROIT) },
  year={2014},
  author={Kansal, M. L. and Agarwal, S. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6798280 },
  abstract={A typical power system consists of three sub-systems, namely, generation, transmission and distribution. The power transformation from generation to transmission to consumers is carried out through step-up or step-down transformers so as to reduce transmission losses as well as for making the electrical appliances to work. Transformers are also used to control voltage and are equipped with tap changers on one or more windings to change the turn ratio. Therefore, successful operation of a power transformer is an essential requirement for any power system to work which makes it an integral part of the entire system. The present study uses the conventional and expert fuzzy based fault tree analysis and highlights the importance of fuzzy based failure analysis of power transformers which will help the power system managers for paying attention towards maintenance. The expert opinions are utilized using the concept of decision making under uncertainty to carry out the failure analysis. It also ranks the importance of various failures which will fix the priority for maintenance. The suggested methodology has been illustrated with the help of an example which is a case study from India.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICROIT.2014.6798280 },
  booktitle={ 2014 International Conference on Reliability Optimization and Information Technology (ICROIT) },
  chapter={0}
}

@article{rayyan-352345181,
  title={ Magnetic Flux Entropy as a Tool to Predict Transformer's Failures  -  IEEE Transactions on Magnetics },
  year={2013},
  author={Estrada, J. H. and Ramı´rez, S. V. and Cortés, C. L. and Plata, E. A. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6566139 },
  abstract={This paper proposes magnetic flux entropy as another technique to assess electric transformer failures. The obtained tool based on entropy may reveal some irregularities, distortions, aging, overloading, and harmonics, all of them reflected over the electrical sine wave that supplies power to dwelling and industry. Some entropy concepts are reviewed and the basic equations are applied to data obtained from magnetic and infrared waves radiated by the (18 watts 110-20 V) prototype. Several experiments were made through non-invasive and indirect measurements of magnetic and thermal fluxes. Entropy, as an accepted indicator of physical complexity, is proportional to the logarithm of the number of states in a thermodynamic system. Failure prediction based on entropy of radiated magnetic waves could be easier, faster, and cheaper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TMAG.2013.2260821 },
  booktitle={ IEEE Transactions on Magnetics },
  chapter={0}
}

@article{rayyan-352345182,
  title={ Learning from success and failure in transformer fault gas analysis and interpretation  -  IET Conference on Reliability of Transmission and Distribution Networks (RTDN 2011) },
  year={2011},
  author={Ding, H. and Heywood, R. and Lapworth, J. and Ryder, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162264 },
  abstract={The importance of transformer fault gas analysis and interpretation is well recognised and documented. However, unlike the diagnosis of human blood where rules have been well established, the diagnosis of faults in transformer oil is not so clearly defined. Whilst some transformer faults are straightforward to diagnose, with dissolved gas analysis (DGA) results pointing to the type and severity of fault, in many other cases it is often difficult to diagnose what type of transformer fault is involved and even harder to determine the cause. In some cases the transformer may be damaged but this may not be obvious from DGA results. This paper introduces the causes of transformer faults and failure; presents an overview of development of DGA diagnostics and discusses the merits and limitation of DGA diagnostic method; and describes five case examples, showing that knowledge from forensic inspection of faults and failures in transformers are of vital importance in understanding results from DGA of oil samples, and an in-depth understanding of the transformer design and life-limiting faults enable better interpretation of DGA results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/cp.2011.0522 },
  booktitle={ IET Conference on Reliability of Transmission and Distribution Networks (RTDN 2011) },
  chapter={0}
}

@article{rayyan-352345183,
  title={ Identification of the power transformer 110/23 kV failure  -  2014 ELEKTRO },
  year={2014},
  author={Brandt, M. and Peniak, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6848953 },
  abstract={This paper deals with power oil transformer 40 MVA complex diagnostics and its state evaluation. The diagnostic methods like the evaluation of capacitances, loss factor tg δ and analysis of frequency responses by SFRA method were used for identification. These diagnostic methods enable identification of fault by comparative measurements. In this paper is shows identification of short circuit by use of interwinding SFRA measurements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ELEKTRO.2014.6848953 },
  booktitle={ 2014 ELEKTRO },
  chapter={0}
}

@article{rayyan-352345184,
  title={ Simple Exponential Smoothing for Forecasting the Numbers of Pole-Mounted Transformer Failures  -  2023 IEEE AFRICON },
  year={2023},
  author={Mbuli, N. and Pretorius, J. -H. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10293359 },
  abstract={Pole-mounted transformers form the vital link between the electric utility company and the final consumer of electricity. In this paper, the authors use the simple exponential smoothing (SES) forecasting technique to forecast the quarterly numbers of pole-mounted transformer failures. The value of the smoothing constant, $\alpha$, to be used in the forecast, is found by first formulating a non-linear programming problem (NLP) problem to minimize the forecast root mean square error (RMSE). Then, a software code that implements exhaustive search algorithm to solve the NLP is written in Python. The SES forecast is compiled and compared to the multiplicative and additive decomposition forecasting methods. Various measures of error, including mean absolute deviation (MAD), mean absolute percentage error (MAPE), mean squared error (MSE), and RMSE. It was found that, irrespective of the measure of error considered, the SES forecast was always outperformed by either of the decomposition methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AFRICON55910.2023.10293359 },
  booktitle={ 2023 IEEE AFRICON },
  chapter={0}
}

@article{rayyan-352345185,
  title={ An Evaluation of Transformer Historical Failure Data for Facility Resiliency and Reliability  -  2019 IEEE Power & Energy Society General Meeting (PESGM) },
  year={2019},
  author={Thompson, C. C. and Stringer, A. D. and Barriga, C. I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8973428 },
  abstract={This paper provides a closer look into transformer failure trends by analyzing data collected from over 160 thousand unit-years of equipment operation. Utilizing an extensive database of failure information compiled by the United States Army Corps of Engineers, this paper looks at year-to-year changes in transformer failure rates to paint a better picture of component reliability. The data show that failure rates trend differently over time, often significantly. A more thorough understanding of equipment failure trends can inform design and operational considerations, ultimately lowering material and operational costs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM40551.2019.8973428 },
  booktitle={ 2019 IEEE Power & Energy Society General Meeting (PESGM) },
  chapter={0}
}

@article{rayyan-352345186,
  title={ Analysis of lightning-caused distribution transformer failures  -  2011 International Symposium on Lightning Protection },
  year={2011},
  author={de Carvalho, T. O. and Piantini, A. and Obase, P. F. and Janiszewski, J. M. and Batista, E. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6088432 },
  abstract={This paper investigates the effects of direct strokes to medium-voltage (MV) lines by analyzing the surges at the primary and secondary sides of a single-phase distribution transformer installed in a typical rural network of the state of Rio Grande do Sul, located in the South of Brazil. The distribution transformers of AES Sul, the electric utility, present a high failure rate and a significant number of the failures are attributed to lightning. The transformers are in general protected by surge arresters at the MV terminals and in a few cases also at the low-voltage (LV) side. Different distances between the MV arrester and the transformer as well as various values of ground resistance are considered in the analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SIPDA.2011.6088432 },
  booktitle={ 2011 International Symposium on Lightning Protection },
  chapter={0}
}

@article{rayyan-352345187,
  title={ A failure rate model for traction transformer based on PHM considering multiple factors  -  2016 Prognostics and System Health Management Conference (PHM-Chengdu) },
  year={2016},
  author={Lin, S. and Sun, X. and Feng, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819818 },
  abstract={A new failure rate model for traction transformer based on PHM is proposed in this paper in order to comprehensively evaluate the operational condition of traction transformer under the impact of multiple factors. The hazard function of this model consists of two parts: the baseline hazard function which reflects the ageing process and the link function in which equipment health status and weather condition are taken into consideration. The maximum likelihood estimation (MLE) method is applied to obtain the model's parameters with historical operational data. Case study shows that the model proposed can reasonably characterize the failure rate.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PHM.2016.7819818 },
  booktitle={ 2016 Prognostics and System Health Management Conference (PHM-Chengdu) },
  chapter={0}
}

@article{rayyan-352345188,
  title={ A transformer failure rate model concering aging process and equipment inspection data  -  2014 International Conference on Power System Technology },
  year={2014},
  author={Jianquan, B. and Mingming, L. and Xiuyu, Y. and Yifei, W. and Chuangxin, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993670 },
  abstract={This paper proposes a new oil-immersed transformer failure rate model based on Cox's time-dependent proportional hazards model (PHM). The proposed model takes both equipment aging process and equipment inspection information into consideration. The failure rate function of PHM consists of two parts: the baseline hazard function which represents the aging process, and the link function which represents the influence of covariant, such as the equipment health condition. In the proposed model, the baseline hazard function follows a winding hot spot temperature-based aging model. The quantity of the dissolved gas in oil is used to estimate the equipment health condition which is used as the covariate of the link function. The probability density function (PDF) of the time to failure is determined, and the maximum likelihood estimation (MLE) is used to estimate the unknown parameters. The case study shows that the proposed model is able to reflect the individual variation and customize the transformer failure rate reasonably and comprehensively. In addition, the maintenance effect can also be taken into account.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/POWERCON.2014.6993670 },
  booktitle={ 2014 International Conference on Power System Technology },
  chapter={0}
}

@article{rayyan-352345189,
  title={ A Case Study: Transformer Failure Detected with Real-time DGA Monitoring  -  2023 IEEE Electrical Insulation Conference (EIC) },
  year={2023},
  author={Leivo, S. and Sattler, D. and Duval, M. and Chiarella, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177343 },
  abstract={The paper discusses a failure of a generation step-up transformer (GSU) and the fault gas formation pattern over its last few days compared to the earlier occurring overheating issue. The DGA based diagnostics demonstrates how the fault type evolved from mild overheating to possible carbonization of paper. The online DGA monitor sent a gas alarm signal to SCADA at an early state of the gassing event. Thus, the utility’s maintenance team was able follow the situation closely and simultaneously execute mitigation actions to secure operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC55835.2023.10177343 },
  booktitle={ 2023 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345190,
  title={ An Analysis of Partial Discharge Characteristics due to Transformer Bushing Failure  -  2022 6th International Conference on Electric Power Equipment - Switching Technology (ICEPE-ST) },
  year={2022},
  author={Ju, H. J. and Lee, J. G. and Han, K. S. and Kang, J. W. and Choi, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757090 },
  abstract={Among the failures of transformers, the main component of power plants, bushing-related failures consist of about 40% of the total failures, excluding the failure of electric/mechanical protective relays and human errors. In addition, bushing failures are generally accompanied by fire, which is why it is classified as a critical failure. In this article, we will consider the implementation of partial discharge diagnosis technologies to identify bushing failures in their early stage as a means of bushing failure prevention and examine the feasibility of implementing those technologies. The categories of bushing faults that can occur at transformer bushings were selected and simulated on a 154kV bushing removed from an actual electrical substation, and partial discharge measurements were taken according to the IEC-60270 and IEC-62478 standards. From the results, electrical characteristics of partial discharge signals generated within the transformer bushings were identified, and the optimal requirements for the implementation of partial discharge diagnosis technologies were derived.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEPE-ST51904.2022.9757090 },
  booktitle={ 2022 6th International Conference on Electric Power Equipment - Switching Technology (ICEPE-ST) },
  chapter={0}
}

@article{rayyan-352345191,
  title={ Fault Diagnostics of Power Transformers Using Autoencoders and Gated Recurrent Units with Applications for Sensor Failures  -  2022 17th International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  year={2022},
  author={Cui, Y. and Tjernberg, L. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9810620 },
  abstract={With the industrial internet of things and 5G technology developing, more and more operation data could be accessible, and condition-based maintenance shows promise for electrical equipment. This paper aims to develop a data-driven fault diagnosis utilizing operation data for high voltage equipment condition monitoring. To understand the asset management of power transformers, an interview is conducted as the expertise input for the study. The paper uses deep learning in an unsupervised way to model normal behaviors and identify underlying operational risks. The autoencoders are used to compress the raw data and extract the key features and the gated recurrent unit to model the dependencies between normal behaviors of power transformers. Finally, the method employs control charts to generate the alarm to indicate the underlying anomalies. The paper uses an online dataset to test the applications for sensor failures. The results show that the method can identify the operational risks before sensor failures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PMAPS53380.2022.9810620 },
  booktitle={ 2022 17th International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  chapter={0}
}

@article{rayyan-352345192,
  title={ Artificial Neural Network for STEM-ED in Power Transformer Failure Investigation Based on Power Utility Practice  -  2023 8th International STEM Education Conference (iSTEM-Ed) },
  year={2023},
  author={Poonnoy, N. and Suwanasri, C. and Suwanasri, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305793 },
  abstract={This research explores the creation of an educational resource that utilizes STEM principles specifically for teaching computer programming in the field of electrical engineering. The fault analysis simulation program in the research tool integrates the Key Gas and Duval Triangle methods, along with a user-friendly Graphical User Interface. 15 students registered in the computer programming course consisted of the sampling group. The instructional tool had an average score of 4.17 out of 5 famous people which is the highest possible score, in the quality evaluation accomplished by 5 experts. The prepared teaching set satisfied the standard criteria utilizing Meguigans' theory with an effectiveness of 1.1 out of 1. The findings indicated a significant impact on learning performance from the initial assessment to the final assessment, with a significant level of 0.05. Electrical engineering education can be provided effectively with this recently developed teaching and learning tool.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iSTEM-Ed59413.2023.10305793 },
  booktitle={ 2023 8th International STEM Education Conference (iSTEM-Ed) },
  chapter={0}
}

@article{rayyan-352345193,
  title={ Internal failure analysis of transformer windings  -  2012 International Conference on High Voltage Engineering and Application },
  year={2012},
  author={Tuethong, P. and Yutthagowith, P. and Kunakorn, A. and Potivejkul, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357063 },
  abstract={This paper presents internal failure analysis of transformer windings based on the characteristic of winding impedance in the frequency domain. Two winding samples are selected to test. The simple equivalent circuit of the transformer winding is investigated and proposed. The two windings under test have 76 turns with different length. An iron core is either inserted or not inserted inside a winding in the test to investigate the effect of the iron core. Turn to turn short circuit on the windings is considered as internal failure in this paper. The simulated turn to turn short on the model is carried out in the experiment to observe impedance characteristic in the frequency domain. A number and position of short turns are varied to observe characteristics of impedances The impedance of the models of the transformer windings are measured by a spectrum analyzer in a wide frequency range upto 2 MHz. From the test results, it is investigated that a resonance frequency of the transformer model is depended on a number and position of short turns. From the investigation, it has high possibility that the characteristic can be used for analysis of internal failures occurring in a transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2012.6357063 },
  booktitle={ 2012 International Conference on High Voltage Engineering and Application },
  chapter={0}
}

@article{rayyan-352345194,
  title={ Root Cause Analysis of Transformer and Generator Stator Failure on Hydropower Plant in Indonesia  -  2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE) },
  year={2018},
  author={Priambodo, N. W. and Harsono, B. B. S. D. A. and Munir, B. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8534825 },
  abstract={This paper presents an investigation related to the transformer and generator failure on a hydropower plant. Comprehensive visual inspection was conducted after the failure and the result showed visible dry band arcing mark along the surface of a transformer cable termination. Further analysis on transformer and generator historical assessment data followed by simulation process using apparatuses specification data and configuration were conducted to get possible root cause of the failure. Transformer historical assessment data showed abnormal result on insulation resistance test which increased the possibility of ground fault and also short circuit between high voltage and low voltage winding of the transformer during failure. According to ground fault and short circuit simulation between high voltage and low voltage winding of the transformer, the voltage at high voltage side of the transformer reached 1.73 times higher than the nominal value while the generator stator voltage reached over 7 times higher than the nominal value. Therefore, the possible cause of transformer and generator stator failure was internal ground fault and arcing between high voltage and low voltage winding of the transformer which caused flashover on cable termination attached to the high voltage side of the transformer and insulation breakdown of generator stator.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICITEED.2018.8534825 },
  booktitle={ 2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE) },
  chapter={0}
}

@article{rayyan-352345195,
  title={ Understanding of HV Current Transformer Failures During Short-Time Current Tests - An Insight of Current Density Calculations Beyond IEC Standards  -  2019 International Conference on High Voltage Engineering and Technology (ICHVET) },
  year={2019},
  author={Rao, N. M. and Vasudevamurthy, B. R. and Girija, G. and Rao, S. A. and Das, S. K. and Deshpande, R. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8724249 },
  abstract={Abnormal current is the result of a power system fault for which all components must be well designed. And also it is highly difficult to estimate the number of such occurrences in the network. As a part of this, it is very important to design an instrument transformer in a manner that it should withstand short-time thermal current and dynamic currents. In general, these tests have been considered as type tests as per IEC and IEEE standards. Short circuit tests on inductive current transformers shall be made on the primary conductor with all secondary windings short-circuited so that the required thermal energy and peak current is created. Dynamic peak test can be combined with thermal test also but major peak current must be at least rated dynamic current (Idyn). Therefore, primary conductor design is to be given a key attention with regard to short circuit withstand capability. Enough cross sectional area along with its support structure decides the performance during these tests. Otherwise it leads to failure at various instants viz. opening of tank in case of oil filled inductive current transformers, cracking of body in case of dry type current transformers and failure during post accuracy measurements. Further as per IEC standard it is mandatory that the immediate insulation covered on conductor must not show any kind of deterioration. In this paper methodology of short-time thermal current and dynamic current tests as per IEC and IEEE standards have been described. Insights of temperature calculations as per IEEE standards have considered for arriving critical current densities. Further, optimum current densities are proposed for oil filled as well as dry type current transformers. Visual inspection is clearly reviewed and necessary recommendations were made. Few failure case studies were analyzed which further helps to manufacturers to improvise the primary conductor designs and its mechanical structure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVET.2019.8724249 },
  booktitle={ 2019 International Conference on High Voltage Engineering and Technology (ICHVET) },
  chapter={0}
}

@article{rayyan-352345196,
  title={ Entry-Flipped Transformer for Inference and Prediction of Participant Behavior  -  Lecture Notes in Computer Science },
  year={2022},
  author={B and Hu and Bo and T.J and Cham and Jen, Tat},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142709965&doi=10.1007%2F978-3-031-19772-7_26&partnerID=40&md5=d5f8fc149c3e4d8bcec41900392d657d },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-031-19772-7_26 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352345198,
  title={ Optimizing Exponent Bias for Sub-8bit Floating-Point Inference of Fine-tuned Transformers  -  nan },
  year={2022},
  author={J and Lee and Janghwan and J and Choi and Jungwook},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139072464&doi=10.1109%2FAICAS54282.2022.9869965&partnerID=40&md5=ae3194e1e390ace86d97707eaaba8c15 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICAS54282.2022.9869965 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345200,
  title={ Paragraph-based Transformer Pre-training for Multi-Sentence Inference  -  nan },
  year={2022},
  author={L and Liello, Di and Luca and S and Garg and Siddhant and L and Soldaini and Luca and A and Moschitti and Alessandro},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138424651&doi=10.18653%2Fv1%2F2022.naacl-main.181&partnerID=40&md5=48d66b359b71e4eb1c18300963915552 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2022.naacl-main.181 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345201,
  title={ Fuse It More Deeply! A Variational Transformer with Layer-Wise Latent Variable Inference for Text Generation  -  nan },
  year={2022},
  author={J and Hu and Jinyi and X and Yi and Xiaoyuan and W and Li and Wenhao and M and Sun and Maosong and X and Xie and Xing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138323430&doi=10.18653%2Fv1%2F2022.naacl-main.51&partnerID=40&md5=679e9bd163dd0f9f22c20e1b3a835071 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2022.naacl-main.51 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345202,
  title={ Tiny Time-Series Transformers: Realtime Multi-Target Sensor Inference At The Edge  -  nan },
  year={2022},
  author={T and Becnel and Tom and K.E and Kelly and Elizabeth, Kerry and P.E and Gaillardon and Emmanuel, Pierre},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137986218&doi=10.1109%2FCOINS54846.2022.9854988&partnerID=40&md5=c753c1a222a4866a3f86db4e87196e34 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COINS54846.2022.9854988 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345203,
  title={ Feature Fusion Transformer Network for Natural Language Inference  -  nan },
  year={2022},
  author={L and Sun and Lei and H and Yan and Hengxin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137841411&doi=10.1109%2FICMA54519.2022.9856400&partnerID=40&md5=ee2ccb6b8fa9eb89a68464b03555e7fa },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMA54519.2022.9856400 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345204,
  title={ Easy and Efficient Transformer: Scalable Inference Solution For Large NLP Model  -  nan },
  year={2022},
  author={G and Li and Gongzheng and Y and Xi and Yadong and J and Ding and Jingzhen and D and Wang and Duan and Z and Luo and Ziyang and R and Zhang and Rongsheng and B and Liu and Bai and C and Fan and Changjie and X and Mao and Xiaoxi and Z and Zhao and Zeng},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137689786&doi=10.18653%2Fv1%2F2022.naacl-industry.8&partnerID=40&md5=4069df82f484f9acf3afd326b709b6ed },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2022.naacl-industry.8 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345205,
  title={ Characterization of MPC-based Private Inference for Transformer-based Models  -  nan },
  year={2022},
  author={Y and Wang and Yongqin and G.E and Suh, G. Edward and W and Xiong and Wenjie and B and Lefaudeux and Benjamin and B and Knott and Brian and M and Annavaram and Murali and H.H.S and Lee and Sean, Hsien Hsin},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134312329&doi=10.1109%2FISPASS55109.2022.00025&partnerID=40&md5=3a3a7bf05b21c0d2d21ba8d7dcd8ebe2 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISPASS55109.2022.00025 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345207,
  title={ Real-time Alert System for Auxiliary Transformer Failures  -  nan },
  year={2022},
  author={A and Dange and Afrin and E and Fernando and Edwin and H.S and Zachariah and Susan, Hanah and D and Kallakuri and Dheeraj},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128033767&doi=10.1109%2FSCEECS54111.2022.9740841&partnerID=40&md5=918d5ab0c7a912b583e146c158c4c125 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCEECS54111.2022.9740841 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345209,
  title={ Domain-principled Inference with ResNet-Transformer Model for 12-lead ECG Classification  -  nan },
  year={2022},
  author={S.C and Racha and Chander, Sai and T and Deb and Trisrota and I and Sahu and Ishan and A and Ukil and Arijit and A and Pal and Arpan and S and Khandelwal and Sundeep},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002582469&doi=10.1109%2FIJCNN55064.2022.9892674&partnerID=40&md5=4227c8ee18475245d240fe923af881a6 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IJCNN55064.2022.9892674 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345210,
  title={ An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures  -  nan },
  year={2021},
  author={T and Singla and Tanmay and D and Anandayuvaraj and Dharun and K.G and Kalu and G, Kelechi and T.R and Schorlemmer and R, Taylor and J.C and Davis and C, James},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180011088&doi=10.1145%2F3605770.3625214&partnerID=40&md5=96c00d49883e08f0f7193a6c413ae8de },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1145/3605770.3625214 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345212,
  title={ An Architecture for Accelerated Large-Scale Inference of Transformer-Based Language Models  -  nan },
  year={2021},
  author={A and Ganiev and Amir and C and Chapin and Colt and A., de Andrade and Anderson and C and Liu and Chen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137339310&doi=10.18653%2Fv1%2F2021.naacl-industry.21&partnerID=40&md5=4d18ba53025832922a148473e36ee14c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2021.naacl-industry.21 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345213,
  title={ Multi-Exit Vision Transformer for Dynamic Inference  -  nan },
  year={2021},
  author={A and Bakhtiarnia and Arian and Q and Zhang and Qi and A and Iosifidis and Alexandros},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132380265&partnerID=40&md5=2076e71629a67c6f153d11cd14dbada5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345215,
  title={ LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference  -  Proceedings of the IEEE International Conference on Computer Vision },
  year={2021},
  author={B.T and Graham and T, Benjamin and A and El-Nouby and Alaaeldin and H and Touvron and Hugo and P and Stock and Pierre and A and Joulin and Armand and H., Jégou and Hervé and M and Douze and Matthijs},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127807764&doi=10.1109%2FICCV48922.2021.01204&partnerID=40&md5=efd7198b7512b481a6b4aec019009a00 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCV48922.2021.01204 },
  booktitle={ Proceedings of the IEEE International Conference on Computer Vision },
  chapter={0}
}

@article{rayyan-352345217,
  title={ Semi-supervised Graph Instance Transformer for Mental Health Inference  -  nan },
  year={2021},
  author={G and Dong and Guimin and M and Tang and Mingyue and L and Cai and Lihua and L.E and Barnes and Elizabeth, Laura and M.O and Boukhechba and O, Mehdi},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125836262&doi=10.1109%2FICMLA52953.2021.00198&partnerID=40&md5=cc38ff87b53f5261e7e7cc757184398c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICMLA52953.2021.00198 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345218,
  title={ Consistent Accelerated Inference via Confident Adaptive Transformers  -  nan },
  year={2021},
  author={T and Schuster and Tal and A and Fisch and Adam and T.S and Jaakkola and S, Tommi and R and Barzilay and Regina},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125029729&doi=10.18653%2Fv1%2F2021.emnlp-main.406&partnerID=40&md5=29cabc7140b6fbf3041dc9bf2ec59894 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2021.emnlp-main.406 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345219,
  title={ Decoupled Transformer for Scalable Inference in Open-domain Question Answering  -  International Conference Recent Advances in Natural Language Processing, RANLP },
  year={2021},
  author={H and ElFadeel and Haytham and S and Peshterliev and Stanislav},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123587601&doi=10.26615%2F978-954-452-072-4_044&partnerID=40&md5=6e3d4b936d7a918fc1b6c30c8043b057 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.26615/978-954-452-072-4_044 },
  booktitle={ International Conference Recent Advances in Natural Language Processing, RANLP },
  chapter={0}
}

@article{rayyan-352345220,
  title={ TRUFM: a Transformer-Guided Framework for Fine-Grained Urban Flow Inference  -  Lecture Notes in Computer Science },
  year={2021},
  author={X and Zhou and Xinchi and D and Zhou and Dongzhan and L and Liu and Lingbo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121917945&doi=10.1007%2F978-3-030-92273-3_22&partnerID=40&md5=7673101fbeb88b845e605cd0361a9078 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-030-92273-3_22 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352345221,
  title={ Power Grid Cascading Failure Prediction Based on Transformer  -  Lecture Notes in Computer Science },
  year={2021},
  author={T and Zhou and Tianxin and X and Li and Xiang and H and Lu and Haibing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121864953&doi=10.1007%2F978-3-030-91434-9_15&partnerID=40&md5=1229434646c2523b8e6cbfcc9ce4df25 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-030-91434-9_15 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352345222,
  title={ Self-supervised Learning for Semantic Sentence Matching with Dense Transformer Inference Network  -  Lecture Notes in Computer Science },
  year={2021},
  author={F and Yu and Fengying and J and Wang and Jianzong and D and Tao and Dewei and N and Cheng and Ning and J and Xiao and Jing},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115125781&doi=10.1007%2F978-3-030-85896-4_21&partnerID=40&md5=71c3e041a66b36e4bb376dfa8038338c },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1007/978-3-030-85896-4_21 },
  booktitle={ Lecture Notes in Computer Science },
  chapter={0}
}

@article{rayyan-352345223,
  title={ Probing for Bridging Inference in Transformer Language Models  -  nan },
  year={2021},
  author={O.A and Pandit and Arun, Onkar and Y and Hou and Yufang},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113883583&doi=10.18653%2Fv1%2F2021.naacl-main.327&partnerID=40&md5=9b0441d17ecb71ab1b4d1364ee8b774e },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2021.naacl-main.327 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345224,
  title={ LightSeq: A High Performance Inference Library for Transformers  -  nan },
  year={2021},
  author={X and Wang and Xiaohui and Y and Xiong and Ying and Y and Wei and Yang and M and Wang and Mingxuan and L and Li and Lei},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110858791&doi=10.18653%2Fv1%2F2021.naacl-industry.15&partnerID=40&md5=4101b23861ea1d4a3a5b432ea43f0c86 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/2021.naacl-industry.15 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345226,
  title={ Energy-efficient Inference Service of Transformer-based Deep Learning Models on GPUs  -  nan },
  year={2020},
  author={Y and Wang and Yuxin and Q and Wang and Qiang and X and Chu and Xiaowen},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099482577&doi=10.1109%2FiThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00067&partnerID=40&md5=3485d30f6c43587a579857fc2396db67 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00067 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345233,
  title={ Efficient automatic punctuation restoration using bidirectional transformers with robust inference  -  Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  year={2020},
  author={M and Courtland and Maury and A and Faulkner and Adam and G and McElvain and Gayle},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101388235&doi=10.18653%2Fv1%2FP17&partnerID=40&md5=1ff852824daf50aa07fcd939c1777a5b },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/P17 },
  booktitle={ Proceedings of the Annual Meeting of the Association for Computational Linguistics },
  chapter={0}
}

@article{rayyan-352345234,
  title={ Train Large, then compress: Rethinking model size for efficient training and inference of transformers  -  nan },
  year={2020},
  author={Z and Li and Zhuohan and E and Wallace and Eric and S and Shen and Sheng and K.Q and Lin and Qinhong, Kevin and K.W and Keutzer and W, Kurt and D and Klein and Dan and J.E and Gonzalez and E, Joseph},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098438706&partnerID=40&md5=2e3c2734a75a4e248737e825f2b8e9b4 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345235,
  title={ Towards fully 8-bit integer inference for the transformer model  -  IJCAI International Joint Conference on Artificial Intelligence },
  year={2020},
  author={Y and Lin and Ye and Y and Li and Yanyang and T and Liu and Tengbo and T and Xiao and Tong and T and Liu and Tongran and J and Zhu and Jingbo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097352977&partnerID=40&md5=ca48c44bc1db3e5078d910097d398a48 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IJCAI International Joint Conference on Artificial Intelligence },
  chapter={0}
}

@article{rayyan-352345237,
  title={ Research on Prediction Model of Insulation Failure Rate of Power Transformer Considering Real-time Aging State  -  nan },
  year={2019},
  author={Q and Li and Qi and Z and Wang and Zheng and H and Zhao and Haibo and H and Liu and Huiqing and L and Tian and Liang and X and Zhang and Xiangyu and J and Qiu and Jue and C and Xue and Chao and X and Zhang and Xiaojian},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084079279&doi=10.1109%2FEI247390.2019.9062104&partnerID=40&md5=0228c753dfc111153553031c6b72908a },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI247390.2019.9062104 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345242,
  title={ Substation transformer failure analysis through text mining  -  nan },
  year={2019},
  author={N.N and Ravi and Nair, Nanthiine and S.M and Drus, Mohd and Mohd, Sulfeeza and P.S.A and Krishnan and A.L, Prajindra Sankar and N and Ghani, Laila Abdul and Nur},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069147125&doi=10.1109%2FISCAIE.2019.8743719&partnerID=40&md5=4a19568a1ce0325ba9499409dcf73063 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAIE.2019.8743719 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345243,
  title={ Video dialog via progressive inference and cross-transformer  -  nan },
  year={2019},
  author={W and Jin and Weike and Z and Zhao and Zhou and M and Gu and Mao and J and Xiao and Jun and F and Wei and Furu and Y and Zhuang and Yueting},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084307406&doi=10.18653%2Fv1%2FD19-1217&partnerID=40&md5=feb4f8702078ffac12ea06e480a00874 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.18653/v1/D19-1217 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345244,
  title={ Gaussian transformer: A lightweight approach for natural language inference  -  nan },
  year={2019},
  author={M and Guo and Maosheng and Y and Zhang and Yu and T and Liu and Ting},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077223535&doi=10.1609%2Faaai.v33i01.33016489&partnerID=40&md5=a810b77eabeed8944d9ee8eb1ac21580 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1609/aaai.v33i01.33016489 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345246,
  title={ How Tapchanger Controls Contribute to Premature Transformer Failures  -  2007 IEEE Power Engineering Society General Meeting },
  year={2007},
  author={Jauch, E. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4275641 },
  abstract={This paper focuses on LTC (load tap changer) transformer control practices, which may cause tapchanger hunting and therefore excessive tapchange operations. Applications of paralleling methods and the determination and confirmation of optimum settings, which may contribute to excessive or untimely tap change operations, are discussed. The transformer applications considered in this paper will include transmission tie transformers as well as transmission-distribution interface transformers. Attention will be drawn to common paralleling commissioning practices in the field that can create conditions for tapchanger "hunting." In many applications, a control function will result in different actions depending on the system configuration and parameters. These changing system conditions are continuously affected by automatic operations on the transmission and distribution systems, such as protective relay operations or load management techniques. Some of these system conditions will also be discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2007.385875 },
  booktitle={ 2007 IEEE Power Engineering Society General Meeting },
  chapter={0}
}

@article{rayyan-352345247,
  title={ High-Frequency Breakdown Characteristics and Insulation Failure Analysis of Epoxy Resin for Power Electronic Transformers  -  2024 CPSS & IEEE International Symposium on Energy Storage and Conversion (ISESC) },
  year={2024},
  author={Xu, C. and Chen, J. and Chen, Y. and Zhao, X. and Chen, W. and Shen, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10785351 },
  abstract={Insulation systems in power electronic transformers are subjected to long-term high-frequency and high-voltage electrical stress, increasing the risk of failure. This study prepared epoxy resin samples for encapsulation insulation in power electronic transformers and tested their high-frequency breakdown characteristics in the 10 kHz to 100 kHz range, analyzing the results using Weibull distribution. Scanning electron microscopy was utilized to investigate the microstructure of the epoxy resin after high-frequency insulation failure. The results showed that the high-frequency breakdown strength conformed to the Weibull distribution, with the scale parameter decreasing and gradually reaching a threshold as frequency increased, ranging from approximately 66 kV/mm to 84 kV/mm. The epoxy resin samples prepared using the scraping method exhibited no significant insulation defects in their morphology. Post-insulation failure, the surface and cross-sectional morphology of the epoxy resin displayed distinct characteristic features.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISESC63657.2024.10785351 },
  booktitle={ 2024 CPSS & IEEE International Symposium on Energy Storage and Conversion (ISESC) },
  chapter={0}
}

@article{rayyan-352345248,
  title={ Failure Analysis Using Different Transformer Models in EMTP-ATP  -  2019 International IEEE Conference and Workshop in Óbuda on Electrical and Power Engineering (CANDO-EPE) },
  year={2019},
  author={Medveď, D. and Kanálik, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110993 },
  abstract={Various transformer models can be used to analyze fault conditions occurring in the power system. In this paper, several transformer models and their influence on the fault current course at different types of short circuits are investigated. Therefore, the 3-ph ideal transformer, the 3-ph saturable transformer (with and without saturation consideration), and the label-entered transformer (BCTRAN) were selected to compare the short-circuit current results. Faults such as 1-ph short-circuit, 2-ph metal short-circuit, 2-ph ground short-circuit and 3-ph short-circuit were considered. The results were compared with the methodology given in standard STN EN 60909-0 (33 3020).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CANDO-EPE47959.2019.9110993 },
  booktitle={ 2019 International IEEE Conference and Workshop in Óbuda on Electrical and Power Engineering (CANDO-EPE) },
  chapter={0}
}

@article{rayyan-352345249,
  title={ Analysis of Failure in Temperature-Rise Test of 10kV Three-Phase Oil-Immersed Amorphous Alloy Transformer  -  2018 China International Conference on Electricity Distribution (CICED) },
  year={2018},
  author={Hao, M. and Yujing, W. and Yingtian, Z. and Xiangshang, X. and Hao, W. and Shengchen, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8592084 },
  abstract={This paper provides the statistical results of 10kV three-phase oil-immersed amorphous alloy transformer sampling inspection of last year. Main unqualified test items are listed and two cases of failing in temperature rise test are analyzed. Then some management control measures are provided to improve product quality and manufacturing standards. This is of great importance in improving the quality of equipment which would be accessed into the grid and maintaining the long-period safe and stable operation of distribute network.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CICED.2018.8592084 },
  booktitle={ 2018 China International Conference on Electricity Distribution (CICED) },
  chapter={0}
}

@article{rayyan-352345250,
  title={ Insulation Breakdown Failure Analysis of a 500kV Power Transformer in Lightning Impulse Test  -  2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2) },
  year={2021},
  author={Feng, J. and Wang, W. and Ma, X. and Wang, N. and Ma, H. and Wei, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713057 },
  abstract={By applying artificial simulated lightning wave to transformer winding terminals, lightning impulse test could investigate impact strength of transformer main insulation and series insulation. We studied an insulation breakdown failure case of a 500kV transformer during its lighting impulse test in factory and analyzed main factors of the insulation breakdown failure. Insulator quality and insulation design related to the flawed components were discussed. This paper could provide some guidance in regarding to improving supply quality of transformer components and avoiding similar insulation weakness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI252483.2021.9713057 },
  booktitle={ 2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2) },
  chapter={0}
}

@article{rayyan-352345251,
  title={ Analysis Of Offshore Platform Current Transformer Failures  -  2022 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC) },
  year={2022},
  author={Gupta, A. and Demiroglu, M. and Isaacs, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181253 },
  abstract={Trip of a diesel generator (DG) differential protection relay in an offshore platform caused delays in remanning and production restoration after hurricane evacuation. This was the first DG differential protection trip since platform commissioning ~12 years back. Investigations revealed that current transformer (CT) casing had cracked to the extent of dislodging CT conductors resulting in differential protection trip.Damaged CTs were replaced by in-stock spare CTs. However, a couple of years later a similar differential trip occurred and was resolved by again replacing damaged CTs with in-stock spares. It became evident that a simple remediation of replacing damaged CTs will not help, as the trips started to happen more frequently only months apart.This paper analyses DG trip incidents, describes root cause failure analysis (RCFA), and presents remedies and learnings to mitigate the issue.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCIC42668.2022.10181253 },
  booktitle={ 2022 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC) },
  chapter={0}
}

@article{rayyan-352345252,
  title={ Analysis of Operation Failure of Transformer Oil Chromatography Online Monitoring Device  -  2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA) },
  year={2023},
  author={Zhang, R. and Qi, Q. and Qi, G. and Liu, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10090506 },
  abstract={In order to research the causes of failure in the operation of the transformer oil chromatography online monitoring device, combined with the situation that the transformer oil chromatography online monitoring device in an UHV substation did not detect acetylene when the acetylene content of transformer oil exceeded the standard, it is judged that the fault cause of the gas chromatography principle device is the detector problem, and the fault cause of the photoacoustic spectroscopy principle device is the acetylene sensor communication problem by means of on-site inspection, test detection and other ways. The fault phenomena of two kinds of principle on-line monitoring devices are verified by experiments. It is suggested that the self-check function should be added to the online monitoring device and the fault alarm list should be improved by optimizing the manufacturing process in the later stage. it can respond timely and remind operation and maintenance personnel to maintain the device when the online monitoring device has abnormal situation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEBDA56825.2023.10090506 },
  booktitle={ 2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA) },
  chapter={0}
}

@article{rayyan-352345253,
  title={ Ferroresonance in Medium Voltage Transformer: A Review of Failure Investigation, Effect, and Mitigation Techniques  -  2023 4th International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  year={2023},
  author={Munir, N. A. A. and Lestari, D. S. and Nursita, E. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257366 },
  abstract={Introduction Ferroresonance is a phenomenon that can occur in medium voltage transformers when certain conditions are met. In medium voltage transformers, ferroresonance can occur when the voltage on the primary side of the transformer changes rapidly, and the load on the secondary side is disconnected. This can cause the voltage on the secondary side to rise rapidly, producing high voltages and creating a dangerous situation. In extreme cases, ferroresonance can cause the transformer to explode, leading to catastrophic damage to the surrounding equipment. There are several techniques to mitigate ferroresonance in medium voltage systems, such as: to use a ferroresonance suppressor, which is a passive device that is connected in parallel with the transformer; Install a surge arrester or a metal oxide varistor (MOV) on the secondary side of the transformer to suppress voltage transients; Install a damping circuit to reduce the effect of ferroresonance. This can include a resistor, capacitor, or a combination of the two; Install a fuse on the primary side of the transformer to prevent overvoltage; etc. This paper reviews the results of the investigation resulting from the failure in 20kV/100V medium voltage transformer on the medium voltage side of the incoming transformer unit 3 at Pantai Indah Kapuk substation which is suspected to be due to ferroresonance along with the resulting impacts and mitigation recommendations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVEPS58902.2023.10257366 },
  booktitle={ 2023 4th International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  chapter={0}
}

@article{rayyan-352345254,
  title={ Failure Analysis on Bursting Disc of 5052 Current Transformer Used in 550kV Substation  -  2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) },
  year={2021},
  author={Bai, N. and Zhao, Y. and Liu, J. and An, D. and Yuan, Q. and Che, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574305 },
  abstract={In order to ensure the substation operating safely and stably in a long time, this paper analyses spot inspection, main chemical element content, fracture morphology, metallographic structure, microhardness, adhesive materials and blasting verification test, to obtain the failure cause of bursting disc of 5052 current transformer used in 550kV Substation. The results shows: the fault cause of 5052 current transformer is the bruising of bursting disc arch face of 5052 current transformer during the carrying or assembling process. The bruising markedly reduces the bursting pressure and use stability of bursting disc to cause bursting disc arch face instability, inversion, blasting under normal conditions for 3 years. The cracking along weakening groove leads to the leakage of SF6 which decrease the insulativity. Thus, the current transformer appears a discharge ablation fault.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AEECA52519.2021.9574305 },
  booktitle={ 2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA) },
  chapter={0}
}

@article{rayyan-352345255,
  title={ Main Transformer Capacity Demands Analysis Method of 220kV Substation based on N-1 Failure  -  2024 IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC) },
  year={2024},
  author={Wang, C. and Hou, Y. and Chen, J. and Jiang, S. and Xie, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575137 },
  abstract={The 220kV substation undertakes the intermediate link of power supply and demand. Substation expansion planning is one of the important contents of substation planning research. In this paper, the load rate of the main transformer N-1 failure in the substation and the maximum load available for supplying in the substation under different scenarios are analyzed first. Next, the demand for the main transformer capacity of the substation is calculated. The demand index of transformer capacity is proposed. Considering the difference between the normal operation load ratio of the substation and the number and capacity of the main transformer, the difference of load rate before and after the increase of the main transformer capacity is calculated. The index of 220kV substation load rate improvement is proposed. Then, the load transfer ability index of the 220kV substation is proposed, considering the adjustment of operation mode to make the substation not overloaded. Finally, the objective function is established. The 220kV substations are sorted according to the value of the objective function, and then the 220kV substations that need to increase the transformer capacity most are found. A provincial regional power grid is used to verify the effectiveness and adaptability of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMCEC59810.2024.10575137 },
  booktitle={ 2024 IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC) },
  chapter={0}
}

@article{rayyan-352345256,
  title={ Evaluation and assessment of transformer failure on 132kV substation  -  2008 IEEE 2nd International Power and Energy Conference },
  year={2008},
  author={Ariff, M. H. Mohammed and Kadir, M. Z. A. Ab and Jasni, J. and Mesron, R. and Salahuddin, M. T. and Lamsi, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4762439 },
  abstract={Insulation coordination models are an essential part of power system studies and are used to determine the expected overhead line back-flashover rate. A study is carried out to investigate and evaluate the effect of lightning stresses on the 132 kV substation in the way to improve its reliability in the event of active lightning activities. This paper also presents the modeling guidelines on substation for this transient analysis in order to evaluate the performance and to recommend such configuration to optimize its design to be not only to withstand the stresses but to be more cost effective. The modeling and simulation are carried out using one of the most powerful power system simulations tools that is PSCAD-EMTDC and the substation layout design is adapted from 132/11 kV Simpang Renggam - Ayer Hitam substation, courtesy of Tenaga Nasional Berhad, Malaysia (TNB). The model is based on single phase line model as it is suggested by the IEEE to be adequate to represent the substation in transient analysis simulation. The outcome of this paper will be the results of lightning stresses in term of voltage level measured at particular points in substation. The results are then compared with the suggested Basic Lightning Insulation Level (BIL) for assessment of transformer failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PECON.2008.4762439 },
  booktitle={ 2008 IEEE 2nd International Power and Energy Conference },
  chapter={0}
}

@article{rayyan-352345257,
  title={ A study of insulation failure in a high voltage current transformer  -  2005 European Conference on Power Electronics and Applications },
  year={2005},
  author={Jimoh, A. A. and Mahlasela, V. S. and Nicolae, D. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1665942 },
  abstract={The ageing and deterioration of insulation in high voltage (HV) plants have been a source of concerns to utilities. Breakdown of insulation leads to failures of HV equipment. The ageing and eventual failure of insulation in a high voltage current transformer (HVCT) is the subject of investigation in this paper. A lumped parameter model of HVCT is developed. This model is used to study the influence of deteriorating and failed insulation on the state variables of the HVCT. Some possible scenarios that could lead to a CT failure are investigated in this paper. For all the scenarios considered, steady and transient equations relating the state variables of the model have been developed and analyzed. The objectives of these analyses are to establish the behavioural characteristics of the state variables, establish the interactions between these variables, and investigate the possible generations of harmonics under the various scenarios of deteriorating and outright failure of insulation in the CT. The paper concludes with a discussion of the results obtained},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EPE.2005.219752 },
  booktitle={ 2005 European Conference on Power Electronics and Applications },
  chapter={0}
}

@article{rayyan-352345258,
  title={ Dielectric failure of electronic voltage regulator due to interaction with a power transformer during switching  -  2024 IEEE Electrical Insulation Conference (EIC) },
  year={2024},
  author={Babaei, A. and Ziomek, W. and Gole, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579326 },
  abstract={This paper will investigate the effect of resonance on the power electronic devices. As a case study, a capacitive-ladder-based electronic voltage regulator has been chosen for the study and experimental test. Firstly, an extensive simulation has been performed in PSCAD software to check the capability of the electronic voltage regulator during different faults and transients originating from the inductive load side. The simulation proved that the system would not fail for the short circuit fault and the voltage regulator could perform its tasks. For the experimental side of the results, an extensive theoretical analysis has been performed to make sure that there will be no resonance in the selected rating for the test, and therefore capacitor value has been chosen to be far away from the resonance region. For the experiment test, the voltage regulator is in series with a main supply transformer with a rating of 168kV-13.8kV, and the voltage regulator provides 10% of the LV side voltage to maintain the load voltage in an acceptable range. To isolate the electronic voltage regulator from HV side, the voltage regulator has been connected through a series transformer. When connecting the electronic voltage regulator to a standalone transformer and increasing the voltage gradually to perform some tests to verify lack of the resonance, a flashover happened to the thyristors in the voltage regulator and some capacitors became faulty, resulting in a loss in the capacitance value of more than 50%. Further investigation has been done, and it proved that at a specific voltage level, a resonance will be amplified between the capacitor and the regulated transformer which causes the system to experience a massive transient voltage. This led us to the conclusion that the parasitic capacitances and internal circuit of the transformer could push the system to the resonance region, even for a short period of time, and it is proven that the power electronic device such as thyristors cannot handle the surge current claimed in their datasheet. The paper will include simulation results and electric stress evaluation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC58847.2024.10579326 },
  booktitle={ 2024 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345259,
  title={ Research on Fuse Failure and Countermeasure of Potential Transformer in Non-effect Grounding System  -  2022 5th Asia Conference on Energy and Electrical Engineering (ACEEE) },
  year={2022},
  author={Ren, H. and Wei, X. and Wu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851832 },
  abstract={In the neutral point non-effective grounding system of medium voltage network, potential transformer fuse fault happened frequently, including fusing during startup and grid connection, operation, shutdown and so on, these faults will directly decrease the accuracy of measurement, metering, protection and other secondary equipment. In this paper, we used EMTP-ATP software, to analysis the typical medium voltage system wiring and parameters. The non-ground neutral system is established in single-phase earth fault occurs and disappear ferroresonance transient process simulation model, and aiming at the existing suppression measures to comparative study on the simulation results, Find out the advantages and disadvantages of different inhibition measures and give suggestions for improvement.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACEEE56193.2022.9851832 },
  booktitle={ 2022 5th Asia Conference on Energy and Electrical Engineering (ACEEE) },
  chapter={0}
}

@article{rayyan-352345260,
  title={ Prediction of Failures in Air Pressure System: A Semi-Supervised Framework Based on Transformers  -  2024 IEEE 22nd International Conference on Industrial Informatics (INDIN) },
  year={2024},
  author={Farea, S. M. and Mumcuoglu, M. E. and Unel, M. and Mise, S. and Unsal, S. and Cevik, E. and Yilmaz, M. and Koprubasi, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774220 },
  abstract={The air pressure system (APS) plays a prime role in pressurizing various subsystems of heavy-duty vehicles (HVDs). However, its reliability is crucial to ensure uninterrupted operation where failures in APS lead to HVDs being stranded on the road with the manufacturers and operators incurring associated high costs. This paper addresses the problem of predicting failures in APS using a semi-supervised transformer-based framework. The proposed framework commences with important preprocessing steps including data segmentation followed by sliding windows to handle the big raw data, and subsequent extraction of distinctive features. Using these features, the transformer model was trained to reconstruct data from healthy vehicles (i.e., vehicles without any APS failures) to capture the normal behavior of the healthy vehicles. At inference, the trained model distinguished the faulty vehicles with detected APS failure from the healthy ones based on their reconstruction errors. This semi-supervised formulation of APS failure detection overcomes limitations such as the imbalanced data issue and anomaly heterogeneity that are associated with the conventional supervised formulation. The model demonstrated robust performance with an F1 score of approximately 0.76, an accuracy of about 85%, and a high recall of 0.833, indicating successful detection of most faulty vehicles. Such advancements promise significant improvements in vehicle diagnostics and predictive maintenance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDIN58382.2024.10774220 },
  booktitle={ 2024 IEEE 22nd International Conference on Industrial Informatics (INDIN) },
  chapter={0}
}

@article{rayyan-352345261,
  title={ Forecasting the Numbers of Pole-Mounted Transformer Failures via Tripple Exponential Smoothing  -  2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  year={2024},
  author={Mbuli, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10797181 },
  abstract={Availability of adequate numbers of spares of pole-mounted transformers can help to reduce the impact of failures of these transformers on customers. Forecasting can assist to determine the optimum number of these spares to be kept so that funds are not locked in unproductive assets and not less than adequate number of spares are available so that responses to failures can be as quick as possible. This research presents the work on using the exponential smoothing methods of forecasting a time series to forecast the quarterly numbers of pole-mounted transformer failures. To derive the smoothing parameters, the Excel Solver is used as the optimisation tool. The ATES outperforms the MTES and the multiplicative decomposition models but is itself outperformed by the additive decomposition model. The MTES is the least performing of all the four models considered in this work. With a view to improving the performance of TES models, it is proposed that the potential of metaheuristic methods in determining the optimal parameters of the TES models be investigated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECCME62383.2024.10797181 },
  booktitle={ 2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  chapter={0}
}

@article{rayyan-352345262,
  title={ Intelligent Fuzzy Logic for STEM-ED in Power Transformer Failure Investigation Based Power Utility Practice  -  2020 5th International STEM Education Conference (iSTEM-Ed) },
  year={2020},
  author={Poonnoy, N. and Suwanasri, C. and Suwanasri, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332793 },
  abstract={The research in this article describes the development of a STEM based teaching tool for a computer programing in electrical engineering course. The research tool applies a Graphical User Interface simulation program for fault analysis by using Total Dissolved Combustible Gas and Key Gas method. The sampling group consisted of 21 students enrolling in the computer programing course. The quality evaluation of the tool from 5 experts indicates a satisfactory result in average of 4.07 out of 5 as a maximum point. The developed teaching set was effective at 1.06 in accordance with the standard criteria using Meguigans's theory. Learning achievement between pre-test and post-test was significantly different at the level of 0.05. This development of teaching and learning tool can be used effectively in teaching of electrical engineering education.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iSTEM-Ed50324.2020.9332793 },
  booktitle={ 2020 5th International STEM Education Conference (iSTEM-Ed) },
  chapter={0}
}

@article{rayyan-352345263,
  title={ Study and diagnosis the failure of power transformers by sweep frequency response analysis  -  2013 International Conference on Power, Energy and Control (ICPEC) },
  year={2013},
  author={Mehta, A. K. and Sharma, R. N. and Chauhan, S. and Agnihotri, S. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6527650 },
  abstract={Sweep Frequency Response Analysis (SFRA) testing has become a valuable tool for verifying the geometric integrity of electrical apparatus, specially transformers. The SFRA technique provides internal diagnostic information using non-intrusive procedure. Power Transformers are specified to withstand the mechanical forces arising from both shipping and subsequent inservice events, such as faults and lightning. Transportation damage may lead to core and winding movement. This research is undertaken to study and diagnosis the failure of power transformer by investigation of transformer mechanical integrity using the Doble's M5200. This paper presents case studies related to the SFRA testing, & their result interpretation through the statistical indicator and the standard interpretations available.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPEC.2013.6527650 },
  booktitle={ 2013 International Conference on Power, Energy and Control (ICPEC) },
  chapter={0}
}

@article{rayyan-352345264,
  title={ Assessing Consequences of the Final Failure of a Power Transformer Using Fuzzy Logic and Expert Criteria  -  2018 IEEE Canadian Conference on Electrical & Computer Engineering (CCECE) },
  year={2018},
  author={Farfan, C. A. and Marín, D. M. and Chacón-Troya, D. and Medina, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447618 },
  abstract={This document presents an innovative tool for assessing the consequence of the final failure a power transformer, this metric considers aspects as: power quality, overload of other equipment, safety, reliability of the system and the environmental & social impact. For this evaluation, existing standards as well experience and industry practices are integrated. For this regard, a fuzzy inference system was proposed, the membership functions and the rules for integrating each input are based on a survey applied over a set of Ecuadorian power transformers; this study considers technical, economic and social characteristics of the impact of the final failure. The resulting membership functions, and the rules are presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CCECE.2018.8447618 },
  booktitle={ 2018 IEEE Canadian Conference on Electrical & Computer Engineering (CCECE) },
  chapter={0}
}

@article{rayyan-352345265,
  title={ Acoustic Emission and Apparent Charge Measurement Applied to Power Transformer Failures Identification  -  2023 15th IEEE International Conference on Industry Applications (INDUSCON) },
  year={2023},
  author={Teopald, A. B. S. and Castro, B. A. De and Andreoli, A. L. and Ardila-Rey, J. A. and Bittencourt, I. R. and Smith, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374773 },
  abstract={The presence of full-discharges in power transformers, which can be characterized by dielectric degradation between turns, is usually found in the stages preceding the total failure of the machine. Although several non-destructive techniques for monitoring these faults are applied, the Acoustic Emission technique stands out due to its low cost and ease of application. This paper uses a piezoelectric transducer to validate acoustic emission as a means to perform full-discharge evolution characterization, attaching it to a power transformer wall and applying different levels of full discharges on it. In order to validate the failure evolution, the apparent charge emitted by the flaw was calculated using a High Frequency Current Transformer (HFCT). The results presented in this article attest that acoustic emission has great potential to evaluate evolution of full-discharges in power transformers since it was found that the energy levels of the acoustic emission increase with the apparent charge.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDUSCON58041.2023.10374773 },
  booktitle={ 2023 15th IEEE International Conference on Industry Applications (INDUSCON) },
  chapter={0}
}

@article{rayyan-352345266,
  title={ PLN's strategy to mitigate the risk of power transformer failure due to hydrolysis in insulation paper  -  2024 6th International Conference on Power Engineering and Renewable Energy (ICPERE) },
  year={2024},
  author={Gumilang, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845622 },
  abstract={Power transformer failures caused by hydrolysis in insulation paper present significant challenges to the reliability of electrical systems. To mitigate these risks, PLN has implemented a comprehensive strategy that includes enhanced diagnostic processes, design improvements, and optimized treatment procedures. Diagnostic improvements have been achieved through ISO 17025 accreditation and participation in international proficiency testing, ensuring the accuracy and reliability of oil testing results. Design improvements focus on specifying the appropriate conservator type, transitioning from open to closed systems to prevent oxidation. In terms of treatment procedures, PLN has introduced a policy to assess the severity of hydrolysis through furan testing before proceeding with oil reclamation, ensuring the economic feasibility and effectiveness of the process. Several case studies are presented to provide a practical illustration of how these improvements are applied in PLN, demonstrating the company's commitment to extending transformer life and enhancing system reliability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPERE63447.2024.10845622 },
  booktitle={ 2024 6th International Conference on Power Engineering and Renewable Energy (ICPERE) },
  chapter={0}
}

@article{rayyan-352345267,
  title={ Comparative analysis of differential relay settings in Langsa substation transformer to avoid protection failure  -  2020 4rd International Conference on Electrical, Telecommunication and Computer Engineering (ELTICOM) },
  year={2020},
  author={Ismail, R. and Hasibuan, A. and Nasution, E. S. and Hardi, S. and Nrartha, I. M. Ari},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230490 },
  abstract={This paper discusses the arrangement of differential relays at the Langsa substation. The ratio of CT mounted on the transformer to the primary side is 150/1 A and on the secondary side is 1000/1 A. This result is taken with consideration of the current value calculated from 127.02 A on the primary and 952.62 A on the secondary side. For the sensitivity of the mismatch error is still good because it is still under 5% on the primary side which is 0.89% and the secondary side is 1.13%. The differential current also shows the normal condition of 0.1 A and the restraint current 1.205 A. Using the ETAP 12.6.0 simulation, relay can work well when interference occurs at the current setting indication 1.29 A is greater than the operating current 1.65 A and the relay does not work during an external fault with a setting current of 1.29 A equals to an operating current of 1.29 A.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ELTICOM50775.2020.9230490 },
  booktitle={ 2020 4rd International Conference on Electrical, Telecommunication and Computer Engineering (ELTICOM) },
  chapter={0}
}

@article{rayyan-352345268,
  title={ Inter-layer voltage distribution and insulation failure of a spiral pulse transformer  -  2009 IET European Pulsed Power Conference },
  year={2009},
  author={Yang, H. and Xu, J. and Zhang, J. and Zhong, Huihuang},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332185 },
  abstract={Several spiral pulse transformers are tested to charge a water pulse forming line to more than 1 MV in ~10 ¿s time. During the experiments, recurrent breakdown failures between turns of the transformer are observed. To find the cause and cure to the problem, the inter-layer voltage distribution is calculated and analyzed. The calculation models the wire wound spiral transformer turns as separate cylinders, and the inductance and coupling matrix is obtained by finite-element method. As the charging time is in microseconds range, the displacement current can be ignored. The inductance matrix is used in a circuit to find the inter-layer voltages at various time against circuit parameters. The results presented show that inter-turn voltage varies with time, position, the primary capacitance and voltage. The results explains that when transformer circuit is under-matched, so that L1C1 < L2C2, where L1C1, and L2C2 are primary and secondary inductances and capacitances, the insulation breakdown occurs early during charging, and at the outer most layers of the secondary coil, adjacent to primary turns. When L1C1 > L2C2, then breakdown takes place near central output of the secondary turns and occurs later during charging. The calculation can well explain the cause of the insulation failure. Suggestions to improve the insulation are discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/cp.2009.1635 },
  booktitle={ 2009 IET European Pulsed Power Conference },
  chapter={0}
}

@article{rayyan-352345269,
  title={ Real-time Alert System for Auxiliary Transformer Failures  -  2022 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS) },
  year={2022},
  author={Dange, A. and Fernando, E. and Zachariah, H. S. and Kallakuri, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740841 },
  abstract={Auxiliary transformers are used extensively in railway systems. Indian Railways use them primarily to convert the 25-kilo volt AC supply into 230-240-volt AC supply as required for various applications. Due to their varied use, many of these auxiliary transformers are often positioned in remote locations. In case of failure of AT supply, no proper feedback system exists as of now. Due to this the lead time on failure attention increases rapidly depending on the location of the transformer. Sometimes this may result in signal failure leading to an increase in train traffic. To cut down on human effort and cost involved, as well as provide a system that continuously monitors these auxiliary transformers, an automated system based on GSM technology is suggested. This system periodically provides updates and generates immediate alerts in case of the occurrence of the failure of an auxiliary transformer, hence bringing a drastic reduction on lead time for failure attention where a failure escalates into costly service losses.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCEECS54111.2022.9740841 },
  booktitle={ 2022 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS) },
  chapter={0}
}

@article{rayyan-352345270,
  title={ Transformer Failure Diagnosis based on VNWOA-MRVM  -  2023 3rd International Conference on Electrical Engineering and Control Science (IC2ECS) },
  year={2023},
  author={Zhou, Z. and Liu, X. and Wu, T. and Guo, Y. and Liu, C. and Liu, Z. and Yang, B. and Wang, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493442 },
  abstract={This paper introduces a new methodology for diagnosing transformer failure to enhance diagnostic accuracy based on the combination of the Von Neumann Whale Optimization Algorithm (VNWOA) and the multi-categorical correlation vector machine (MRVM). Firstly, the whale algorithm is improved by using the principle of Von Neumann topology to increase the converge velocity and the optimization finding veracity of the whale algorithm by constructing a VN topology for each individual whale. Secondly, the VNWOA is applied to the MRVM arithmetic to find the optimal kernel features argument and penalty factor, and a diagnostic model of VNWOA-MRVM is advanced for failure diagnosis of the test data. Finally, the collected DGA data of 276 oil-immersed transformers are classified into exercise data and test data at a rate of 2: 1 for case analysis. After calculation, the accuracy of the proposed method can reach 95.65%, which is improved by 5.95%, 3.56%, 4.76% and 2.37% compared with SVM, PSO-SVM, M-RVM and PSO-RVM methods, respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC2ECS60824.2023.10493442 },
  booktitle={ 2023 3rd International Conference on Electrical Engineering and Control Science (IC2ECS) },
  chapter={0}
}

@article{rayyan-352345271,
  title={ Optimal Selection of Input Variables by BPSO for Diagnosis of Incipient Failures in Power Transformers (by DGA)  -  2019 20th International Conference on Intelligent System Application to Power Systems (ISAP) },
  year={2019},
  author={Enriquez, A. R. S. and Lima, S. L. and Saavedra, O. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065939 },
  abstract={Power transformer immersed in oil is a valuable asset in the operation of the electrical system, therefore, it is of interest to the operating companies to keep the power transformers in perfect operating conditions. Early diagnosis of a fault condition in the power transformer is a fairly addressed research topic, however, inappropriate use and the limited number of data do not allow formulating a robust methodology for a real implementation in the electrical system. This document presents an optimal selection of input variables in diagnosis of power transformer failures by DGA, the sample of inputs is generated from the gas contents (hydrogen, methane, acetylene, ethane and ethylene) and the selection of optimal inputs (VE-BPSO) is extracted with Binary Particle Swarm Optimization (BPSO) in the nearest neighbor classification (Conventional K-NN Classifier). In the validation process for 63 independent data in both Conventional K-NN Classifier and Artificial Neural Network (ANN) the performances for VE-BPSO are superior to the conventional approach (IEC 60599 standard inputs). Therefore, the input variables with the best characterization (clustering) in diagnosis of faults in TP is VE-BPSO, which is the main contribution of this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISAP48318.2019.9065939 },
  booktitle={ 2019 20th International Conference on Intelligent System Application to Power Systems (ISAP) },
  chapter={0}
}

@article{rayyan-352345272,
  title={ Expert Analysis of Lightning Impulse Failure Modes in Oil-Filled Power Transformers Based on Experiential Data  -  2024 IEEE PES/IAS PowerAfrica },
  year={2024},
  author={Nyandeni, D. B. and Thango, B. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759469 },
  abstract={Lightning impulse testing is performed as part of the factory acceptance routine tests in power transformers to check the integrity of the insulation and to ensure that transformer insulation performs according to the design specifications. Lightning impulse testing is a high voltage test and the pass criterion depends on a variety of parameters being met, mainly based on the lightning impulse waveforms. In the event of a test incident, the resultant waveform can be used to classify the fault and through experiential expertise, the waveform can also be used to estimate the location of the fault within the transformer. In this paper, real-life lightning impulse waveforms resulting from a test incident are presented and used to classify the failure as well as the location of the fault.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica61624.2024.10759469 },
  booktitle={ 2024 IEEE PES/IAS PowerAfrica },
  chapter={0}
}

@article{rayyan-352345273,
  title={ Analysis of Voltage Transformer Failure Mechanism and Prevention Measures Based on ATP-EMTP  -  2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2) },
  year={2023},
  author={Yang, Y. and Lin, J. and Wang, X. and Zhao, Y. and Feng, X. and Wang, S. and Song, Y. and Wei, H. and Nie, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10512742 },
  abstract={Targeting potential transformer (PT) analysis of faults and corresponding principles. This article first analyzes voltage transformer fault cases of different voltage levels and analyzes the fault characteristics of PT. Then it mainly focuses on the PT ferromagnetic resonance overvoltage and introduces the fault mechanism of PT. On this basis, an overvoltage model containing PT-type automated terminals was established and its influencing factors were analyzed. Finally, solutions and prevention measures for different types of PT faults were proposed, which will serve as a basis for future PT protection work has laid a certain foundation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI259745.2023.10512742 },
  booktitle={ 2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2) },
  chapter={0}
}

@article{rayyan-352345274,
  title={ Influence of Supporting Failure on Magnetic-structural Displacement for Power Transformer Windings under Short Circuit Fault  -  2022 IEEE 20th Biennial Conference on Electromagnetic Field Computation (CEFC) },
  year={2022},
  author={Zhang, H. and Wang, X. and Jian, Z. and Wan, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940899 },
  abstract={When the power transformer vibrates during operation and withstands short-circuit electromagnetic force many times, the insulation support structure of the transformer winding will appear asymmetric phenomenon. At this time, the winding is again affected by short-circuit electromagnetic force, transformer winding will occur more serious displacement, bulge and collapse. In this paper, a three-dimensional magnetic-structure coupling model is established, and the magnetic flux density and electromagnetic force density of power transformer windings under short-circuit current are calculated by finite element method (FEM). Taking the short-circuit current as the independent variable and the winding displacement as the dependent variable, the electromagnetic field and structural field are simulated and analyzed by Ansys Workbench software to obtain the winding displacement results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEFC55061.2022.9940899 },
  booktitle={ 2022 IEEE 20th Biennial Conference on Electromagnetic Field Computation (CEFC) },
  chapter={0}
}

@article{rayyan-352345275,
  title={ The Low Voltage Isolation Transformer Failure Investigation: Measurements, Analysis and Lessons Learned  -  2020 International Conference on Diagnostics in Electrical Engineering (Diagnostika) },
  year={2020},
  author={Boonseng, C. and Boonseng, R. and Kularbphettong, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214603 },
  abstract={This paper presents a case study of failure analysis for a 200kVA, 400 V isolation transformer at a semiconductor plant with a start-up with problems faced before permanent damage. The basic requirements of the acceleration of the dynamic transformer to achieve a successful start will be checked In addition, the results of the measurement of the location of the electrical parameters and the separation process are shown to indicate the cause of the error and evidence of the testimony. The results are confirmed by a failure analysis report provided by the manufacturer. This paper also addresses the obstacles that are faced due to the limited error and availability of information and how to solve the problem.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/Diagnostika49114.2020.9214603 },
  booktitle={ 2020 International Conference on Diagnostics in Electrical Engineering (Diagnostika) },
  chapter={0}
}

@article{rayyan-352345276,
  title={ Analysis and Treatment of 220kV Main Transformer Insulating Cylinder Discharge Failure  -  2019 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia) },
  year={2019},
  author={Wang, T. and Wang, T. and Liu, B. and Yang, X. and Tao, S. and Yang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8881365 },
  abstract={Through the analysis of dendritic discharge faults on the 220kV transformer insulating cylinder, the basic process of dendritic discharge faults on the insulating cylinder is expounded. It is demonstrated that the insulation moisture and gas inclusion are the main external factors, and the insulation structure defects and the first oil gas distance on the winding surface are the main internal factors causing the fault. Through the simulation of transformer insulating cylinder discharge accident, the mechanism of the insulating cylinder dendritic discharge is obtained, and the countermeasures for preventing the insulating cylinder discharge are proposed. Finally, the concrete measures to prevent the fault of the insulating cylinder dendritic discharge are put forward.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISGT-Asia.2019.8881365 },
  booktitle={ 2019 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia) },
  chapter={0}
}

@article{rayyan-352345277,
  title={ Methodology for the Evaluation of the Consequence Factor of the Final Failure of Distribution Transformers  -  2019 IEEE 39th Central America and Panama Convention (CONCAPAN XXXIX) },
  year={2019},
  author={Chacón-Troya, D. and Borja-Arbito, W. and Medina, R. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977069 },
  abstract={Distribution transformers set represent a significant percentage of the assets of the electric power supply system; its monitoring, forecasting and study allow the system administrator to guarantee parameters of reliability, safety and continuity in its operation. The risk assessment of an asset considers two parameters: probability of failure and the consequences of equipment unavailability, the risk index is a widely used tool for locating investments in maintenance and repowering. This paper proposes a methodology to evaluate the consequence factor of the final unavailability of the distribution transformers considering technical characteristics, location in the network, calendar age, number of customers served and their chargeability. This information is processed through a statistical analysis to later use tools based on expert criteria, fuzzy logic and weighted sums in order to obtain the consequence index of each unit. This methodology was applied to the units to an Ecuadorian distribution company. The results obtained with the tools are consistent and provide information to the administrator about possible actions of maintenance or repowering of critical units},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONCAPANXXXIX47272.2019.8977069 },
  booktitle={ 2019 IEEE 39th Central America and Panama Convention (CONCAPAN XXXIX) },
  chapter={0}
}

@article{rayyan-352345278,
  title={ Identification of Internal Failure in Power Transformers Using Fuzzy Logic Through The Dissolved Gas Analysis in Mineral Insulating Oil  -  2020 IEEE XXVII International Conference on Electronics, Electrical Engineering and Computing (INTERCON) },
  year={2020},
  author={Pacori, R. L. Z. and Alcántara, J. H. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9220214 },
  abstract={Currently in industry there is a great need to keep the production plants operational during 24 hours per day. However, the sudden failures that occur due to an inadequate monitoring of the conditions of the power transformers, make this need impossible, having economic repercussions for the entire Peruvian industry. Because of this, many dissolved gas analysis, DGA methods, have been developed to be able to identify faults in power transformers. In this research, the design of an intelligent system is proposed applying fuzzy logic capable of identifying internal failures in power transformers improving up to 91% of accuracy in failure identification, based on one of the DGA methods with greater accuracy and that has been developed in recent years, such as the "Application of gas-ratio combinations method"},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INTERCON50315.2020.9220214 },
  booktitle={ 2020 IEEE XXVII International Conference on Electronics, Electrical Engineering and Computing (INTERCON) },
  chapter={0}
}

@article{rayyan-352345279,
  title={ Study on the Diagnosis of Transformer Failure Diagnosis Based on the BWODO-VMD-LSTM Model  -  2023 3rd International Conference on New Energy and Power Engineering (ICNEPE) },
  year={2023},
  author={Wang, L. and Wei, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429470 },
  abstract={Aiming at the shortcomings of transformer fault diagnosis, a fusion algorithm (BWODO) based on Beluga algorithm (BWO) and Dandelion algorithm (DO) is proposed, which is combined with variational mode decomposition (VMD) and short and long time memory neural network (LSTM). Firstly, fault classification and feature extraction are carried out based on dissolved gas (DGA) data in oil. Then, the Dandelion algorithm is optimized through chaotic mapping opposition learning strategy, mixed reverse learning strategy, and Beluga whale predation strategy to improve the algorithm's optimization speed and solving accuracy. Then, the improved algorithm is used to optimize VMDLSTM model parameters to improve the model's accuracy of transformer fault identification. The test results show that the accuracy of BWODO-VMD-LSTM model is 97.4%, which is 5.9% and 4.2% higher than that of DO-VMD-LSTM and PSO-VMD-LSTM models, which proves that the proposed method can effectively improve the accuracy of transformer fault diagnosis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICNEPE60694.2023.10429470 },
  booktitle={ 2023 3rd International Conference on New Energy and Power Engineering (ICNEPE) },
  chapter={0}
}

@article{rayyan-352345280,
  title={ Large generator and transformer failures on the rand power companies' systems  -  Transactions of the South African Institute of Electrical Engineers },
  year={1917},
  author={Davies, A. E. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9496452 },
  abstract={In the first place I have to thank Mr. Bright for pointing out informally, an error on page 223 in example 4. The time of ·018 second for ·75 revolution should of course read ·03 second.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ Transactions of the South African Institute of Electrical Engineers },
  chapter={0}
}

@article{rayyan-352345283,
  title={ Standardized survey of transformer reliability: On behalf of CIGRE WG A2.37  -  2017 International Symposium on Electrical Insulating Materials (ISEIM) },
  year={2017},
  author={Tenbohlen, S. and Jagers, J. and Vahidi, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8166559 },
  abstract={There is limited literature available in the public domain discussing failure statistics of transformers. This contribution presents the methodology for a standardized failure data acquisition developed by the Cigré Working Group A2.37. The working group collected 964 major failures which occurred in the period 1996 to 2010, within a total population of 167,459 transformer years, contributed by 58 utilities from 21 countries. The overall failure rates of substation transformer were all within 1%. For three groups of substation transformers, detailed population data were collected enabling the calculation of hazard curves. All populations show a low hazard rate and no distinct bathtub curve character. An increasing probability of failure after a particular age, which would justify an exchange of the transformer, cannot be derived from the available data. Windings, tap changer and bushing related failures were the major contributors, followed by lead exit related failures, irrespective of application or manufacturing period. Dielectric mode failures were the most prominent, followed by mechanical and electrical type failures, for substation transformers, whereas GSU transformers had higher contributions of thermal and dielectric mode failures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/ISEIM.2017.8166559 },
  booktitle={ 2017 International Symposium on Electrical Insulating Materials (ISEIM) },
  chapter={0}
}

@article{rayyan-352345284,
  title={ Transformer fault diagnosis based on autoassociative neural networks  -  2011 16th International Conference on Intelligent System Applications to Power Systems },
  year={2011},
  author={Castro, A. R. G. and Miranda, V. and Lima, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6082196 },
  abstract={This paper presents a new approach to incipient fault diagnosis in power transformers, based on the results of dissolved gas analysis. A set of autoassociative neural networks or autoencoders are trained, so that each becomes tuned with a particular fault mode. Then, a parallel model is built where the autoencoders compete with one another when a new input vector is entered and the closest recognition is taken as the diagnosis sought. A remarkable accuracy is achieved with this architecture, in a large data set used for result validation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISAP.2011.6082196 },
  booktitle={ 2011 16th International Conference on Intelligent System Applications to Power Systems },
  chapter={0}
}

@article{rayyan-352345285,
  title={ Determining an optimal number of spares for hydro one 230/115 kv auto-transformers  -  2017 IEEE Power & Energy Society General Meeting },
  year={2017},
  author={Hamoud, G. A. and Zhao, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8274456 },
  abstract={A reliability study has been performed recently at Hydro One to evaluate the optimal numbers of spare transformers required for 250 MVA and 125 MVA, 230/115 kv, 3 phase auto-transformers of the Hydro One's transmission system. In this study, a probabilistic method based on a Markov model and a bulk power reliability program was developed in determining the number of spare units for each group of auto-transformers. The purpose of this paper is to describe the assessment approach used in the study and to present the study findings and its recommendations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM.2017.8274456 },
  booktitle={ 2017 IEEE Power & Energy Society General Meeting },
  chapter={0}
}

@article{rayyan-352345286,
  title={ Power Transformer Fault Characterization Through Oil Contaminants Evaluation  -  2020 IEEE Electrical Insulation Conference (EIC) },
  year={2020},
  author={Wilhelm, H. M. and Fernandes, P. O. and Steffens, C. and Moscon, K. G. and Mattoso, M. and Peres, S. M. and Ziliotto, M. C. S. and Galdeano, C. and Junior, M. M. S. and Neto, J. B. F. and Marchesan, T. B. and Bender, V. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158679 },
  abstract={Dissolved gas analysis (DGA) in insulating oil is performed periodically to access operating conditions of power transformers. DGA results suggest possible incipient faults and maintenance actions for transformer repair. The more information the process gives, the better and cheaper corrective actions can be. To optimize asset management, determine the need for repair in a transformer failure, or choose options for managing operating conditions, an additional tool that allows maintenance engineering to previously identify failure type would be interesting. When an incipient fault occurs, all construction materials involved will be affected and, therefore leave traces in insulating fluid. This paper is a first step in evaluating potential analytical methods to be used in determining the presence of transformers construction materials in insulating fluids due to incipient faults. Insulating oil samples were first contaminated with different transformer construction materials in order to test different analytical techniques to determine the presence of those materials in oil and/or their influence in oil properties. Samples were thermally aged and then tested by different methods to find out contamination effect on physical chemistry properties, such as total acid number, interfacial tension, dielectric loss and others. The presence of added contaminants both soluble as well as particulate material is also investigated. Soluble contamination materials are determined by use chemical analysis techniques such as Fourier Transform Infrared Spectroscopy (FTIR), Gas Chromatography Mass Spectrometry (GC-MS), Inductively Coupled Plasma (ICP), and enhanced DGA. Some nonconventional analysis techniques were also used to evaluate particulate contaminants related added construction materials, such as particles counting, particle quantification index (PQI), and Analytical Ferrography that gives particles nature, shape and size. This work is part of the R&D research project ANEEL PD-222.2017.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC47619.2020.9158679 },
  booktitle={ 2020 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345287,
  title={ An Integrated Probabilistic Approach for Power Transformers Availability  -  2018 International Symposium on Fundamentals of Electrical Engineering (ISFEE) },
  year={2018},
  author={Mihalcea, C. and Munteanu, F. and Baiceanu, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742432 },
  abstract={The paper present an integrated approach of power transformers availability considering 7 high power 110/6.3 kV and 20 years as the monitoring time interval. With respect to a given load point, the interruptions frequency, duration and cause are revealed on a statistical bases. Not only the PTs and their unavailability but also the surround equipment like circuit-breakers, feeder and load point events were included as interruption sources. For PTs, internal and external failures as well as the planned (maintenance) events were considered.Time to failure, time to repair, mean time between events and its progress over time were probabilistically estimated. The results allow for a better maintenance management and for a good estimation of the quality of supply.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISFEE.2018.8742432 },
  booktitle={ 2018 International Symposium on Fundamentals of Electrical Engineering (ISFEE) },
  chapter={0}
}

@article{rayyan-352345288,
  title={ Capacity Detection Algorithm of Uninterrupted Special Transformer Based on Artificial Immunity and Multi-Object Optimization  -  2023 3rd International Conference on Electrical Engineering and Control Science (IC2ECS) },
  year={2023},
  author={Sun, S. and Liu, K. and Wu, Y. and Wang, J. and Jia, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493830 },
  abstract={Aiming at the problem that the capacity detection error of an uninterruptible special transformer is large, which affects the operation effect of the transformer, a capacity detection algorithm for an uninterruptible special transformer based on artificial immunity and multi-object optimization is proposed. The algorithm combines an artificial immune algorithm and a multi-object optimization algorithm to decompose the vibration signal of the uninterruptible special transformer. According to the decomposition results, the winding deformation detection model of the uninterruptible special transformer is constructed, and the possible problems in the operation of the transformer can be found in time, so that corresponding measures can be taken for maintenance and repair, thus realizing the research on the capacity detection algorithm of the uninterruptible special transformer. The experimental results show that the Euclidean distance value of this algorithm is higher, which shows that its detection results can better express the capacity state of the actual uninterrupted special transformer equipment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC2ECS60824.2023.10493830 },
  booktitle={ 2023 3rd International Conference on Electrical Engineering and Control Science (IC2ECS) },
  chapter={0}
}

@article{rayyan-352345289,
  title={ Best Practices in Dissolved Gases Analysis (DGA) for Power Transformers (Noviembre 2014)  -  2014 IEEE Central America and Panama Convention (CONCAPAN XXXIV) },
  year={2014},
  author={Pérez, J. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000445 },
  abstract={Over the years it has been shown Dissolved Gases Analysis technique for power transformers has become a powerful tool for diagnosing the state and condition, as well as equipment failures, with the advantage that it is possible to do with the transformer in normal operation. This document presents some collected practices of professional exercise to improve the entire process of Dissolved Gases Analysis, from sampling to the diagnostic for power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CONCAPAN.2014.7000445 },
  booktitle={ 2014 IEEE Central America and Panama Convention (CONCAPAN XXXIV) },
  chapter={0}
}

@article{rayyan-352345290,
  title={ Identification of simultaneously occurring dynamic disc-to-disc insulation failures in transformer winding under impulse excitation  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2012},
  author={Rajamani, P. and Chakravorti, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180237 },
  abstract={A method for identification and localization of isolated as well as simultaneous dynamic series insulation failures in transformer winding has been proposed. Trained wavelet network has been employed to identify the fault characteristics, viz. location(s), nature(s) and type of unknown impulse insulation failures. The network identifies the simultaneous dynamic insulation failures using the cross-wavelet transform based features extracted from recorded winding currents resulting impulse excitation. Four different fault emulators have been used to emulate different combinations of simultaneous dynamic disc-to-disc insulation failures in transformer winding. It has been found that the developed network with extracted features has identified the fault characteristics of simultaneous dynamic series insulation failures of transformer winding insulation within ±9% of winding length with good accuracy. The characteristics as well as experimentation details of simultaneously occurring dynamic disc-to-disc insulation failure(s), cross-wavelet transform based feature extraction and wavelet based fault characteristics identification are explained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2012.6180237 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345291,
  title={ Development of probabilistic models for computing optimal distribution substation spare transformers  -  IEEE Transactions on Industry Applications },
  year={2005},
  author={Chowdhury, A. A. and Koval, D. O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542301 },
  abstract={This paper presents probabilistic models developed based on the Poisson probability distribution for determining the optimal number of transformer spares for distribution transformer systems. The outage of a transformer is a random event and the probability mathematics can best describe this type of failure process. The developed models have been illustrated using illustrative 72-kV distribution transformer systems. Industry-average catastrophic transformer failure rate and a 1-year transformer repair or procurement time have been utilized in the examples considered in the paper. Among the models developed for determining the optimum number of transformer spares, the statistical economics model provides the best result as it attempts to minimize the total system cost including the cost of spares carried in the system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2005.858310 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345292,
  title={ Fuzzy fault tree analysis of a power transformer  -  2012 International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering },
  year={2012},
  author={Agarwal, S. S. and Kansal, M. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246393 },
  abstract={Power transformer is an essential and integral part of any power system. Failure of power transformer affects the working of entire system. Since failure probability is smaller as compared to success, it is easier to carry out the failure analysis for estimating the success probability. However, past failure information results in short term failure probability which does not provide reliable information about the future behavior of the system. In order to overcome the uncertainty in the analysis, expert fuzzy number based fault tree analysis may be adopted for estimating the failure probability of the transformer. In this study, fuzzy fault tree approach has been described and applied for failure probability estimation of a distribution transformer. The results are compared with Conventional Fault Tree Analysis. Further, the basic failure events are ranked according to Fuzzy Importance Index (FII). This will help the decision maker to prioritize the components for repair and attention so as to improve the reliability of the system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICQR2MSE.2012.6246393 },
  booktitle={ 2012 International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering },
  chapter={0}
}

@article{rayyan-352345293,
  title={ Effect of different shapes of electrodes on bridging in contaminated transformer oil  -  2014 IEEE Conference on Electrical Insulation and Dielectric Phenomena (CEIDP) },
  year={2014},
  author={Mahmud, S. and Golosnoy, I. O. and Chen, G. and Wilson, G. and Jarman, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6995785 },
  abstract={Contaminated transformer oil has been tested under non uniform electric fields and the effect of different electrode systems presented in this paper. Three different electric fields were examined i.e. DC, AC and DC biased AC. These experiments revealed that with all the different electrodes arrangements, contaminated particles were always formed bridges between electrodes under DC electric field. AC field does not induce any bridging. Combination of AC and DC enhances the bridging dynamics. The bridges were thicker or more particles attracted with more uniform electric field (spherical electrode) than diverse electric field (needle-plane).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEIDP.2014.6995785 },
  booktitle={ 2014 IEEE Conference on Electrical Insulation and Dielectric Phenomena (CEIDP) },
  chapter={0}
}

@article{rayyan-352345294,
  title={ Reliability and Overload Capacity of Power Transformers  -  2023 International Conference on Clean Electrical Power (ICCEP) },
  year={2023},
  author={Gracheva, E. I. and Petrova, R. M. and Sinyukova, T. and Valtchev, S. and Miceli, R. and Caruso, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10247425 },
  abstract={The article describes the reliability of transformers, the failure rate and uptime to the first failure, the durability and maintainability of transformers and their service life, the allowable temperature rises and the dependence of steady-state overheating on the load factor of the transformer. An assessment of the effect of ambient temperature on the rated power of the transformer is shown. Dependences of heating on the changing load of transformers are given. The heating time constant is calculated depending on the power and cooling system of the transformer. The winding heating temperature is considered for real daily load schedules of a 33/11 kV transformer, the maximum actual overheats are compared when loaded with full power with allowable overheats. These studies can be used in transformers 33/11 kV and others with subsequent interpolation of values.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCEP57914.2023.10247425 },
  booktitle={ 2023 International Conference on Clean Electrical Power (ICCEP) },
  chapter={0}
}

@article{rayyan-352345295,
  title={ A Review of Research on Low Carbon Evaluation System Based on Distribution Network Transformers  -  2024 5th International Symposium on New Energy and Electrical Technology (ISNEET) },
  year={2024},
  author={Li, J. and Zhou, E. and Yan, Z. and Xie, L. and Wang, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10956037 },
  abstract={The distribution network transformer serves as an indispensable core component within the power transmission and distribution system, playing a vital role in facilitating the transition of the power system towards a low-carbon future. This emphasizes the critical importance of establishing a scientifically robust low-carbon evaluation framework to enhance system reliability, mitigate environmental impacts, and expedite the adoption of clean energy. This study systematically analyzes the influence of various transformer failure modes on the construction of the low-carbon evaluation framework and subsequently develops a model for assessing the low-carbon status of distribution network transformers. Additionally, different low-carbon assessment methodologies are explored, highlighting their distinct advantages and limitations in evaluating the low-carbon performance of distribution transformers. By integrating these approaches with practical application needs, a scientifically sound carbon emission grading evaluation index system for distribution network transformers is proposed, providing essential guidance for selecting low-carbon evaluation methods. This contributes to ensuring the safe and stable operation of electrical equipment and promotes the low-carbon development of distribution network transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISNEET64164.2024.10956037 },
  booktitle={ 2024 5th International Symposium on New Energy and Electrical Technology (ISNEET) },
  chapter={0}
}

@article{rayyan-352345296,
  title={ Joint balancing (Jbalan) vector coefficient for prediction of non stationary signals: Lightning impulse testing of transformers  -  2016 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES) },
  year={2016},
  author={Velandy, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7914558 },
  abstract={The investigations of synchronization between the signals are commonly used methodology to assess the condition of transformer insulation during lightning impulse test. Hence, a synchronization measure has so to be defined properly for several non stationary signals through appropriate formulation by using any signal processing, statistical and mathematical analysis. In this paper, the principles of vector space representation of signals, projection theorem, normalization, orthogonal matrix and triangular matrix principles are effectively adopted to derive Joint balancing (Jbalan) vector coefficient for impulse testing of any power and voltage rating and type of transformers. It provides the better way to visualize the mutual computation between several non stationary signals. Jbalan vector coefficient allows the testing engineer to completely describe the mutual synchronization of all possible signals involved during impulse test and it avoid tedious evaluations of integral to take a decision about the transformer through numerical value. To validate the analysis, 5MVA, 7.5MVA and 90/120/150 MVA transformers are used.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PEDES.2016.7914558 },
  booktitle={ 2016 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES) },
  chapter={0}
}

@article{rayyan-352345297,
  title={ FEM Based Investigation of Electrical Charecteristics in Three Phase Transformers  -  2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA) },
  year={2023},
  author={Krishnan, K. and Elavarasi, K. and Bharanidharan, R. and Rajasekar, P. and Amudha, A. and Maheshwari, R. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10394929 },
  abstract={Transformers are the most crucial hardware components used in electrical networks since they are required for enabling voltage changes, energy transfer, and distribution. The underlying design of the transformer has stayed the same over a century, hence design efficacy is critical. In this research study, the transformer is developed and analyzed by using the finite element methodology (FEM). FEM is used to calculate the specifications of a genuine transformer and simulate the potential and strength of the electric field. There are simulations of the output frequency and precise symmetry. The finite element method is a particularly efficient method for determining various transformer factors. FEM is used to describe a suggested way of creating models in two and three dimensions of a 3 phase transformer based on the actual transformer requirements. It can solve problems with high precision and reduce the computational complexity in modelling the geometries. Electrical properties such as the imposed voltage, main and auxiliary electricity, core reduction, electromagnetic flux, and flux uniformity are investigated to evaluate the transformer's performance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECA58529.2023.10394929 },
  booktitle={ 2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA) },
  chapter={0}
}

@article{rayyan-352345298,
  title={ A Real Time Monitoring of Breakdown Voltage of Transformer Oil for Condition Based Maintenance  -  2024 6th International Conference on Electrical Engineering and Information & Communication Technology (ICEEICT) },
  year={2024},
  author={Islam, M. S. and Razzak, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10534447 },
  abstract={The most obligatory part of electricity distribution system is transformer. With the increasing number of transformers due to the growth of consumer load, the number of failures of transformer is also increasing day by day which not only create inconvenience to users by the interruption of power supply but also increases both the capital and revenue loss of the power distribution companies (DISCOMS). Among the failures a significant numbers are premature failures. In some countries this rate of failure is more than 10%, where the acceptable range of failure is less than 3%. This high failure rate is a huge concern to all DISCOMS since they spent millions of dollars on repairing and replacement of distribution transformers. These premature failures also increase the value of system average interruption frequency index and system average interruption duration index. It is proven that most of the premature failures are insulation failures which can be reduced by using a real time monitoring system. In this paper, a new prototype was implemented to monitor the condition of transformer oil which will help the condition-based maintenance (CBM). Firstly, a prototype has been developed to record water content and relative humidity present in a live transformer. Whereas in the second phase, investigation was conducted on different transformers to witness the state of transformer oil and compare the resultant data with breakdown voltage of transformer oil of respective transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEEICT62016.2024.10534447 },
  booktitle={ 2024 6th International Conference on Electrical Engineering and Information & Communication Technology (ICEEICT) },
  chapter={0}
}

@article{rayyan-352345299,
  title={ Polynomial pattern recognition analyses for evaluation of transient signals in transformers  -  2018 International Conference on Power, Instrumentation, Control and Computing (PICC) },
  year={2018},
  author={Velandy, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384808 },
  abstract={The polynomial pattern recognition analyses are proposed for identification of winding insulation failure during lightning impulse testing of transformer. The polynomial pattern recognition analyses enables the computation of winding responses (transient signal) measured at neutral terminal of the transformer winding due to impulse voltage excitation. Initially, simple polynomial analysis is performed through residual graph, mean square error to visualize the correlation between the transient signals. The polynomial analysis is further extended for identification of type of relationship between the transient signals. Further, polynomial approach is utilized through Akaike's information criterion to estimate the degree of association between the responses. It is a reliable additional tool which can be used to conclude if a winding insulation of transformer has withstood the rated lightning impulse test voltage or not. To prove the proposed analyses for lighting impulse test 66.7 MVA (138/69/13.8 kV) and 250 MVA (500/275/33 kV) are considered.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PICC.2018.8384808 },
  booktitle={ 2018 International Conference on Power, Instrumentation, Control and Computing (PICC) },
  chapter={0}
}

@article{rayyan-352345300,
  title={ Smart Prompt Advisor: Multi-Objective Prompt Framework for Consistency and Best Practices  -  2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2023},
  author={Phokela, K. K. and Sikand, S. and Singi, K. and Dey, K. and Sharma, V. S. and Kaulgud, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298429 },
  abstract={Recent breakthroughs in Large Language Models (LLM), comprised of billions of parameters, have achieved the ability to unveil exceptional insight into a wide range of Natural Language Processing (NLP) tasks. The onus of the performance of these models lies in the sophistication and completeness of the input prompt. Minimizing the enhancement cycles of prompt with improvised keywords becomes critically important as it directly affects the time to market and cost of the developing solution. However, this process inevitably has a trade-off between the learning curve/proficiency of the user and completeness of the prompt, as generating such a solutions is an incremental process. In this paper, we have designed a novel solution and implemented it in the form of a plugin for Visual Studio Code IDE, which can optimize this trade-off, by learning the underlying prompt intent to enhance with keywords. This will tend to align with developers' collection of semantics while developing a secure code, ensuring parameter and local variable names, return expressions, simple pre and post-conditions. and basic control and data flow are met.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASE56229.2023.00019 },
  booktitle={ 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352345302,
  title={ LLM-Driven Code Refactoring: Opportunities and Limitations  -  2025 IEEE/ACM Second IDE Workshop (IDE) },
  year={2025},
  author={Cordeiro, J. and Noei, S. and Zou, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11052685 },
  abstract={Refactoring is a systematic process of improving code quality while preserving the functional behavior of the software. In recent years, integrated development environments (IDEs) have added or improved automatic refactoring in their features, to enhance developers' productivity and reduce the likelihood of human errors. With the advancement and increasing popularity of large language models (LLMs), coding automation using them has gained enormous attention and has shown to be effective in performing refactorings on the source code automatically. However, this automation can carry the risk of introducing errors or hallucinations that may break or alter the software functionality. The error-proneness and the possibility of hallucinations in LLMs limit their ability to be fully integrated into an automated refactoring pipeline (e.g., IDEs) and often require humans in the loop to verify the performed modifications. In this position paper, we examine the limitations of existing LLM-based refactoring techniques. We propose research directions to address these limitations and improve the quality of LLM-based code refactoring for reliable software maintenance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IDE66625.2025.00011 },
  booktitle={ 2025 IEEE/ACM Second IDE Workshop (IDE) },
  chapter={0}
}

@article{rayyan-352345303,
  title={ A Novel LLM enabled Code Snippet Generation Framework  -  2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM) },
  year={2024},
  author={Sarkar, S. and Kushwaha, S. P. and Sharma, V. and Mishra, N. and Alkhayyat, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10925748 },
  abstract={Large Language Models (LLMs) represent a breakthrough in natural language processing (NLP), leveraging deep learning techniques to achieve exceptional proficiency in code generation, analysis and modification of human languages. These models, characterized by their vast scale and parameter count, like Bidirectional Encoder Representations from Transformers (BERT by Google) and the Generative Pre-trained Transformer series (by OpenAI’s GPT), have revolutionized various applications including text generation, translation, summarization, and question answering. In our paper we investigate the practicality,complications, and significance of using LLMs for code generation. We provide a review analysis of existing LLM models in use and compare their proficiency for code generation. This paper examines the underlying mechanisms of LLMs, specially their ability to grasp the code syntax, semantics, and programming logic from large-scale repositories and their documentations. The models’ training techniques include fine-tuning programming-specific datasets and enhancing the models' competency to generate code snippets that are syntactically correct and contextually relevant.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IIPEM62726.2024.10925748 },
  booktitle={ 2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM) },
  chapter={0}
}

@article{rayyan-352345305,
  title={ The Potential of One-Shot Failure Root Cause Analysis: Collaboration of the Large Language Model and Small Classifier  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Han, Y. and Du, Q. and Huang, Y. and Wu, J. and Tian, F. and He, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765066 },
  abstract={Failure root cause analysis (RCA), which systematically identifies underlying faults, is essential for ensuring the reliability of widely adopted microservice-based applications and cloud-native systems. However, manual analysis by simple rules faces significant burdens due to the heterogeneous nature of resource entities and the massive amount of observability data. Furthermore, existing approaches for automating RCA struggle to perform in-depth fault analysis without extensive fault labels. To address the scarcity of fault labels, we examine an extreme RCA scenario where each fault type has only one example (one-shot). We propose LasRCA, a framework for one-hot RCA in cloud-native systems that leverages the collaboration of the large language model (LLM) and the small classifier. In the training stage, LasRCA initially trains a small classifier based on one-shot fault examples. The small classifier then iteratively selects high-confusion samples and receives feedback on their fault types from LLM-driven fault labeling. These samples are applied to retrain the small classifier. In the inference stage, LasRCA performs a joint RCA through the collaboration of the LLM and small classifier, achieving a trade-off between effectiveness and cost. Experiment results on public datasets with heterogeneous nature and prevalent fault types show the effectiveness of LasRCA in one-shot RCA.CCS CONCEPTS• Software and its engineering → Software testing and debugging; Software reliability; Software performance; • Networks → Cloud computing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352345306,
  title={ Insights from Rights and Wrongs: A Large Language Model for Solving Assertion Failures in RTL Design  -  2025 62nd ACM/IEEE Design Automation Conference (DAC) },
  year={2025},
  author={Zhou, J. and Ji, Y. and Wang, N. and Hu, Y. and Jiao, X. and Yao, B. and Fang, X. and Zhao, S. and Guan, N. and Jiang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11133100 },
  abstract={SystemVerilog Assertions (SVAs) are essential for verifying Register Transfer Level (RTL) designs, as they can be embedded into key functional paths to detect unintended behaviours. During simulation, assertion failures occur when the design’s behaviour deviates from expectations. Solving these failures, i.e., identifying and fixing the issues causing the deviation, requires analysing complex logical and timing relationships between multiple signals. This process heavily relies on human expertise, and there is currently no automatic tool available to assist with it. Here, we present AssertSolver, an opensource Large Language Model (LLM) specifically designed for solving assertion failures. By leveraging synthetic training data and learning from error responses to challenging cases, AssertSolver achieves a bug-fixing pass@1 metric of 88.54% on our testbench, significantly outperforming OpenAI’s o1-preview by up to $\mathbf{1 1. 9 7 \%}$. We release our model and testbench for public access to encourage further research: https://github.com/SEU-ACAL/reproduce-AssertSolver-DAC-25.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DAC63849.2025.11133100 },
  booktitle={ 2025 62nd ACM/IEEE Design Automation Conference (DAC) },
  chapter={0}
}

@article{rayyan-352345307,
  title={ Snubber Design for Transformer Protection  -  IEEE Transactions on Industry Applications },
  year={2016},
  author={Sutherland, P. E. and Valdes, M. E. and Fox, G. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225115 },
  abstract={Historically, failures of distribution transformers due to transient overvoltage phenomena have led to the development of resistor-capacitor snubber circuits for the protection of the transformer and winding insulation. These transients are most often observed when dry-type transformers are close coupled to vacuum switching devices. Typically, snubber circuit design has been specific for the particular application, and complex engineering studies were required. However, the design of a snubber circuit itself may be performed without these detailed studies. If snubber studies are required, the procedures for system modeling and simulation are explained in a step-by-step manner.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2015.2473137 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345308,
  title={ Adequacy of dual-variable Weibull failure distribution for oil-impregnated paper under pulsating DC voltage  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2016},
  author={Li, J. and Bao, L. and Zhang, J. and Li, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534636 },
  abstract={This paper presents an experimental work investigating the failure data of oil-impregnated paper under pulsating DC voltage. The failure data of the oil-impregnated paper specimens were obtained through constant voltage stress tests; the Weibull distribution was used to estimate the statistical distribution of failure data. The exponential function (EF) and the inverse power function (IPF) were used to modify the Weibull distribution of failure data, so as to obtain two dual-variable Weibull failure distributions (WFDs), which were used to analyze failure data of oil-paper specimens obtained under pulsating DC and individual DC and AC voltages. Their adequacies were evaluated by using failure data obtained through the constant stress tests under various voltages. Both EF-modified and IPF-modified WFDs show more adequacy for failure data of oil-paper insulation under DC and pulsating DC voltages than AC voltages. The EF-modified WFD was more adequate than IPF-modified WFD in estimating the statistical distribution of failure data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2016.005565 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345309,
  title={ Failures of Electrical Machines - Review  -  2022 8th International Youth Conference on Energy (IYCE) },
  year={2022},
  author={Leffler, J. and Trnka, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857519 },
  abstract={In general, there are many types of electrical rotating machines and transformers within various classes of power range and duty cycles. These machines are operated under either industrial or civil conditions. It is a matter of fact that every machine can eventually fail and both damage and losses can occur. Therefore it is necessary to evaluate failure rates and their distribution over certain types of electrical machines and their subsystems. This paper presents an analysis based on the publicly available data, summarizes and compares results obtained from the studies which have been carried out in the past years. In this paper, important machines' subsystems in terms of failure rate are identified. The failure rate is presented in examples. The cause and location of the faults are discussed. Furthermore, this paper suggests general possible procedures for failure elimination or mitigation of the risks. Outcomes of this paper may be important in the field of maintenance, diagnostics and testing, project management and asset management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IYCE54153.2022.9857519 },
  booktitle={ 2022 8th International Youth Conference on Energy (IYCE) },
  chapter={0}
}

@article{rayyan-352345310,
  title={ Deriving asset probabilities of failure: effect of condition and maintenance levels  -  2006 IEEE Power Engineering Society General Meeting },
  year={2006},
  author={Anders, G. and Otal, S. and Hjartarson, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1708961 },
  abstract={This paper describes how asset probabilities of failure can be derived from life expectancy curves that are based on asset age, failure data and specific asset knowledge. It is shown how asset failure probabilities can then be adjusted for individual assets through measurement of the actual asset condition by the application of Health Indices. This allows utilities to focus their attention on the highest risk assets and put in place the optimal strategies for intervention to mitigate risks. Such strategies may include adoption of optimal maintenance policies and the paper also presents an overview of a mathematical model for analyzing the effect of maintenance on failure probabilities and overall costs},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2006.1708961 },
  booktitle={ 2006 IEEE Power Engineering Society General Meeting },
  chapter={0}
}

@article{rayyan-352345311,
  title={ Thermal ageing effect on the failure time of oil-paper insulation at combined AC-DC voltage  -  2016 IEEE Electrical Insulation Conference (EIC) },
  year={2016},
  author={Tao, F. and Li, J. and Wei, C. and Li, Y. and Zhang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548602 },
  abstract={The oil-paper insulation of converter transformer withstands a long time electrical aging by combined AC-DC voltage and thermal aging during operation. The aging failure mode of converter transformers insulation exhibits a great difference with that of AC transformers. In this paper, a set of accelerated thermal aging experiments at 130 °C were designed, oil-paper specimens were aged for 5, 10, 20 and 35 days, respectively. The unaged oil-paper specimens were also prepared for comparison. The breakdown voltage and failure time of oilpaper specimens of different aging times at AC and combined AC-DC voltage were measured, respectively. The relationship between the failure time and aging time is obtained by using Weibull analysis method. The experiment results show that the breakdown voltage of oil-paper specimens all decrease not much with the increase of thermal aging time. The oil-paper specimens have a longer failure time at combined AC-DC voltage compared with that at AC voltage.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC.2016.7548602 },
  booktitle={ 2016 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345312,
  title={ Reliability estimation for populations with limited and heavily censored failure information  -  2013 IEEE Electrical Insulation Conference (EIC) },
  year={2013},
  author={Chmura, L. and Morshuis, P. H. F. and Gulski, E. and Smit, J. J. and Janssen, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6554224 },
  abstract={Statistical analysis of the life data, is a useful tool helping to assess the life-time of populations of high-voltage components. More specific, the results of such analysis give overview over the failure behavior of the population under investigation, i.e. number and trend of expected failures. For the analysis, the detailed information about ages and numbers and ages of installed units and failed units has to be collected. Subsequently, the distribution representing the behavior of the population is fitted to the data. The latter allows deriving the time-dependent failure rate function, which in turn, directly indicates the trends of the future failures. However, this method requires homogeneous and independent data of sufficient amount. The latter becomes a problem, particularly that for past periods the failure data is often unavailable. It is important to estimate the population reliability and number of expected failures, for the whole population of components being operated. This is also important in the case when the available failure data comes only from one part of the area where the components are installed. In this paper we will show how to deal with populations where the available failure data is heavily censored, and what will the influence of the data division according to the regions in which the transformers are operated, on the failure expectancy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC.2013.6554224 },
  booktitle={ 2013 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345313,
  title={ A Method for Reducing Commutation Failure Risk in Multi-Infeed HVDC Systems  -  2018 IEEE 2nd International Electrical and Energy Conference (CIEEC) },
  year={2018},
  author={Xing, L. and Yang, D. and Jing, P. and Zhang, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745815 },
  abstract={This paper presents a method to reduce the risk of single or multiple commutation failures in multi-infeed HVDC systems caused by AC faults occurring at the receiving-end AC system. Based on the node impedance matrix, a voltage coupling factor (VCF) is derived to analyze the effect of faults on AC buses on voltage of inverter AC buses. Then, a method to reduce the commutation failure risk of multi-infeed DC systems is proposed, combining with the criterion of commutation failure based on the minimum extinction angle. In the design stage of converter stations, the short-circuit impedance of converter transformers should be reduced as much as possible on the basis of considering all kinds of restrictive factors. By using this method, the critical voltage coupling factor can be increased and the commutation failure risk can be reduced. The effectiveness of this method is demonstrated by the electromechanical-electromagnetic hybrid simulation results based on a practical multi-infeed HVDC system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIEEC.2018.8745815 },
  booktitle={ 2018 IEEE 2nd International Electrical and Energy Conference (CIEEC) },
  chapter={0}
}

@article{rayyan-352345314,
  title={ Robot-Object Manipulation Failure Anticipation using Knowledge Distillation  -  2024 32nd Signal Processing and Communications Applications Conference (SIU) },
  year={2024},
  author={Temel, T. and İnceoğlu, A. and Sariel, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10600719 },
  abstract={An autonomous service robot should be able to safely interact with its environment. However, failures can occur during manipulation execution due to various uncertainties such as perception errors, manipulation inaccuracies, or unforeseen external events. While existing research has primarily focused on the detection and classification of robot failures, this work focuses on anticipation of such failures. The premise is that if a failure can be anticipated early enough, prevention actions can be taken. To this end, we introduce a novel knowledge distillation-based anticipation framework. Our framework leverages the power of video transformers and incorporates a multimodal sensor fusion network capable of processing RGB, depth, and optical flow data. We evaluate the success of our approach using a real-world robot manipulation dataset named FAILURE. Experimental results demonstrate that our proposed framework achieves an 82.12% F1 score, showcasing its efficacy in anticipating robot execution failures up to 1 second in advance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SIU61531.2024.10600719 },
  booktitle={ 2024 32nd Signal Processing and Communications Applications Conference (SIU) },
  chapter={0}
}

@article{rayyan-352345315,
  title={ AtFP: Attention-based Failure Predictor for Extreme-scale Computing  -  2022 13th International Conference on Reliability, Maintainability, and Safety (ICRMS) },
  year={2022},
  author={Li, L. and Znati, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9944604 },
  abstract={Extreme-scale computing is paving the way for unparalleled advances in scientific discovery and innovation. However, as systems scale, their propensity to failure increases significantly, making it difficult for long running applications that span a large number of computing nodes to make forward progress. Achieving high performance in extreme scale environments, while minimizing energy consumption, has emerged as a daunting challenge. Significant advances on how to deal with failure, both physical and logical, have been achieved, with varying degree of success. A key component of fault tolerance relies heavily on the ability of the scheme to predict failure accurately. Varies approaches, including intelligent methods, have been proposed to predict failures. In this paper, we propose an attention-based failure predictor (AtFP), which automatically extracts representative features from the raw event log data to predict failure. The results show that, using the same input and output layers, AtFP outperforms frequently used LSTM methods. The proposed model reduces the F1 score by 39% and the training time by 65%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRMS55680.2022.9944604 },
  booktitle={ 2022 13th International Conference on Reliability, Maintainability, and Safety (ICRMS) },
  chapter={0}
}

@article{rayyan-352345316,
  title={ SNP Position Filtering and Multimodal Approach in Heart Failure Risk Prediction  -  2025 IEEE International Conference on Big Data and Smart Computing (BigComp) },
  year={2025},
  author={Shin, S. and Lee, S. and Kim, K. and Lee, H. and Song, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936856 },
  abstract={Heart failure (HF) is a leading cause of mortality worldwide, with an 80% death rate within a year of diagnosis. Early identification of high-risk patients is crucial for timely interventions. Conventional HF prediction models based on electronic health records (EHR) face limitations due to irregular data intervals and missing information, while models based on genetic data like single nucleotide polymorphisms (SNPs) are difficult to learn and suffer from the curse of dimensionality. In this study, we propose a multimodal model combining EHR and SNP data to improve mortality prediction for HF patients. The model applies feature selection and filtering to SNP data, reducing its dimensionality to 1.7% to enhance trainability. We use Transformer architecture to process SNP sequences and a multilayer perceptron (MLP) to handle EHR data. Experimental results show that models trained on SNP data significantly outperform EHR-only models. However, our multimodal approach integrating both data types outperforms single modality models, demonstrating improved prediction accuracy. This work suggests that combining genomic and clinical data enhances the prediction of heart failure mortality, overcoming the limitations of traditional methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigComp64353.2025.00067 },
  booktitle={ 2025 IEEE International Conference on Big Data and Smart Computing (BigComp) },
  chapter={0}
}

@article{rayyan-352345317,
  title={ Reliability evaluation for complex systems with load sharing and failure dependence: A case study on LTD  -  2017 Second International Conference on Reliability Systems Engineering (ICRSE) },
  year={2017},
  author={Ren, F. and Jiao, J. and Hu, Y. and Zhao, T. and Zhou, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8030724 },
  abstract={Many real-world systems such as multi-processor computing and power transmission systems have load sharing attribute where the whole system workload is distributed to different system elements. In these systems, when one element fails, other remaining elements would take over the workload which will change their failure behavior and cause a dynamic dependence of failure, thus a reliability evaluation work will be necessary for a high mission success probability of these systems. In this paper, the reliability evaluation problem of Linear Transformer Driver (LTD) system with typical attribute of load sharing and failure dependence is discussed. Firstly, the LTD system with reliability concerns is introduced. Then, the load sharing and failure dependence properties are specified with mathematic formulations. Finally, the key factors of initial work coefficient, load distribution strategy and failure model in the LTD development stage are analyzed from the reliability perspective. As a preliminary exploration, the result would provide a guidance for better industrial application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRSE.2017.8030724 },
  booktitle={ 2017 Second International Conference on Reliability Systems Engineering (ICRSE) },
  chapter={0}
}

@article{rayyan-352345318,
  title={ Studying and Understanding the Effectiveness and Failures of Conversational LLM-Based Repair  -  2025 IEEE/ACM International Workshop on Automated Program Repair (APR) },
  year={2025},
  author={Chen, A. and Wu, H. and Xin, Q. and Reiss, S. P. and Xuan, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029649 },
  abstract={Automated program repair (APR) is designed to automate the process of bug-fixing. In recent years, thanks to the rapid development of large language models (LLMs), automated repair has achieved remarkable progress. Advanced APR techniques powered by conversational LLMs, most notably ChatGPT, have exhibited impressive repair abilities and gained increasing popularity due to the capabilities of the underlying LLMs in providing repair feedback and performing iterative patch improvement. Despite the superiority, conversational APR techniques still fail to repair a large number of bugs. For example, a state-of-the-art conversational technique Chatrepair does not correctly repair over half of the single-function bugs in the Defects4J dataset. To understand the effectiveness and failures of conversational LLM-based repair and provide possible directions for improvement, we studied the exemplary Chatrepair with a focus on comparing the effectiveness of its cloze-style and full-function repair strategies, assessing its key iterative component for patch improvement, and analyzing the repair failures. Our study has led to a series of findings, which we believe provide key implications for future research.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APR66717.2025.00014 },
  booktitle={ 2025 IEEE/ACM International Workshop on Automated Program Repair (APR) },
  chapter={0}
}

@article{rayyan-352345319,
  title={ Enhancing Training Efficiency: A Novel Approach to Handling GPU Failures in Large-Scale Distributed System for LLM Training  -  2025 IEEE 7th International Conference on Artificial Intelligence Circuits and Systems (AICAS) },
  year={2025},
  author={Gunnam, K. and Mandal, P. T. and Khandelwal, S. and Bhagwat, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11173089 },
  abstract={In large-scale distributed machine learning systems for LLM Training, GPU failures can significantly disrupt training processes, often necessitating restoration from prior checkpoints. This paper proposes an alternative approach to handle GPU failures by ignoring updates from the batches processed by the failed GPUs and rescheduling these batches at a later feasible time. The rescheduling can occur at a subsequent time step, the final time step, or as part of a prologue to pre-training. This method aims to minimize the downtime and computational overhead associated with checkpoint restoration, thereby enhancing the efficiency and robustness of the training process. Experimental results demonstrate that this approach maintains model accuracy while reducing the time and resources required for recovery from GPU failures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AICAS64808.2025.11173089 },
  booktitle={ 2025 IEEE 7th International Conference on Artificial Intelligence Circuits and Systems (AICAS) },
  chapter={0}
}

@article{rayyan-352345320,
  title={ Technical Debt Classification in Issue Trackers using Natural Language Processing based on Transformers  -  2023 ACM/IEEE International Conference on Technical Debt (TechDebt) },
  year={2023},
  author={Skryseth, D. and Shivashankar, K. and Pilán, I. and Martini, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10207085 },
  abstract={Background: Technical Debt (TD) needs to be controlled and tracked during software development. Support to automatically track TD in issue trackers is limited. Aim: We explore the usage of a large dataset of developer-labeled TD issues in combination with cutting-edge Natural Language Processing (NLP) approaches to automatically classify TD in issue trackers. Method: We mine and analyze more than 160GB of textual data from GitHub projects, collecting over 55,600 TD issues and consolidating them into a large dataset (GTD dataset). We use such datasets to train and test Transformer ML models. Then we test the model’s generalization ability by testing them on six unseen projects. Finally, we re-train the models including part of the TD issues from the target project to test their adaptability. Results and conclusion: (i) We create and release the GTD dataset, a comprehensive dataset including TD issues from 6,401 public repositories with various contexts; (ii) By training Transformers using the GTD dataset, we achieve performance metrics that are promising; (iii) Our results are a significant step forward towards supporting the automatic classification of TD in issue trackers, especially when the models are adapted to the context of unseen projects after fine-tuning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TechDebt59074.2023.00017 },
  booktitle={ 2023 ACM/IEEE International Conference on Technical Debt (TechDebt) },
  chapter={0}
}

@article{rayyan-352345323,
  title={ IEEE Guide for Protecting Power Transformers - Redline  -  IEEE Std C37.91-2008 (Revision of IEEE Std C37.91-2000) - Redline },
  year={2008},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5983368 },
  abstract={This guide is intended to provide protection engineers and other readers with guidelines for protecting three-phase power transformers of more than 5 MVA rated capacity and operating at voltages exceeding 10 kV. In some cases, a user may apply the techniques described in this guide for protecting transformers of less than 5 MVA ratings or operating at voltages less than 10 kV. Information to assist protection engineers in applying properly relays and other devices to protect transformers used in transmission and distribution systems is provided in this guide. General philosophy, practical applications, and economic considerations involved in power transformer protection are discussed. Emphasis is placed on practical applications. Types of faults in transformers are described. Technical problems with the protection systems, including the behavior of current transformers during system faults, are discussed. Associated problems, such as fault clearing and reenergization, are discussed as well.;Revision of IEEE Std C37.91-2000. This guide is intended to provide protection engineers and other readers with guidelines for protecting three-phase power transformers of more than 5 MVA rated capacity and operating at voltages exceeding 10 kV. In some cases, a user may apply the techniques described in this guide for protecting transformers of less than 5 MVA ratings or operating at voltages less than 10 kV. The guide provides information to assist protection engineers in applying properly relays and other devices to protect transformers used in transmission and distribution systems. General philosophy, practical applications, and economic considerations involved in power transformer protection are discussed. Emphasis is placed on practical applications. Types of faults in transformers are described. Technical problems with the protection systems, including the behavior of current transformers (CTs) during system faults, are discussed. Associated problems, such as fault clearing and re-energization, are discussed as well.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IEEE Std C37.91-2008 (Revision of IEEE Std C37.91-2000) - Redline },
  chapter={0}
}

@article{rayyan-352345324,
  title={ Time-Distributed Vision Transformer Stacked With Transformer for Heart Failure Detection Based on Echocardiography Video  -  IEEE Access },
  year={2024},
  author={Ramadhan, M. M. L. and Yudha, A. W. A. N. and Rachmadi, M. F. and Tandayu, K. M. H. J. and Liastuti, L. D. and Jatmiko, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10776969 },
  abstract={Heart failure is a disease many consider to be the number one global cause of death. Despite its mortality, heart failure is still underdiagnosed clinically, especially in a remote area that experiences cardiologists shortage. Existing studies have employed artificial intelligence to help with heart failure screening and diagnosis processes based on echocardiography videos. Specifically, most existing studies use a convolutional neural network that only captures the local context of an image hindering it from learning the global context of an image. Moreover, the frame sampling algorithms only sample certain consecutive frames which makes it questionable whether the dynamic of the left ventricle during a cardiac cycle is included. This study proposed a novel deep learning model consisting of a time-distributed vision transformer stacked with a transformer. The time-distributed vision transformer learns the spatial feature and then feeds the result to the transformer to learn the temporal feature and make the final prediction afterward. We also proposed a frame sampling algorithm by squeezing the video and sampling the frame after a certain interval. Consequently, the video still contains the sequential information up until the end of the video with some in-between frames removed by a certain interval. Thus, the dynamic of the left ventricle is preserved. Our proposed method achieved an F1 score of 95.81%, 96.19%, and 93.43% for the apical four chamber view, apical two chamber view, and parasternal long axis view respectively. The overall trustworthiness of our model is quantified using the NetTrustScore and achieved a score of 0.9712, 0.9767, and 0.9527 for the apical four chamber view, apical two chamber view, and parasternal long axis view respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3510774 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345328,
  title={ Transformer tank vibration modeling as a method of detecting winding deformations-part II: experimental verification  -  IEEE Transactions on Power Delivery },
  year={2006},
  author={Garcia, B. and Burgos, J. C. and Alonso, A. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1564196 },
  abstract={In Part I of the paper, a tank vibration model was proposed as a method to detect the winding deformations in power transformers. This model is incorporated in a model-based monitoring system for power transformers. In this paper, the experimental verification of the proposed model that calculates vibration on the transformer tank is reported. The model was validated in a 1500-kVA experimental transformer constructed as a reduced scale model of a 60-MVA 220-kV unit. In order to load the test transformer, the opposition method described in IEC 60076-2 Standard was used allowing to vary the load and power factor over a wide range. Sensors to measure vibrations and temperature were installed in the test transformer. The model was validated under different test transformer operating conditions. In order to verify the model's ability to detect failures, a deformation was provoked in the test transformer winding. Model predictions were compared with the measured vibration in that situation. The model has also been applied to four (30-40 MVA) grid transformers. Some results of this field validation are presented in this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2005.852275 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345329,
  title={ Influence of the winding design of wind turbine transformers for resonant overvoltage vulnerability  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2015},
  author={Soloot, A. H. and Høidalen, H. K. and Gustavsen, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7076828 },
  abstract={Switching transients and earth faults may lead to resonant overvoltages at wind turbine transformer terminals as well as inside High Voltage (HV) and Low Voltage (LV) windings. The winding design in a transformer could strongly influence the internal voltage distribution as function of frequency, and this has a great impact on risk of insulation failure. In this paper, resonant overvoltages in three winding designs; layer, disc and pancake, are investigated and analyzed for the application in offshore wind farm. To achieve this, a prototype 500 kVA transformer with the three winding types on the HV side and taps for voltage measurements is designed and produced. The measurements show that a HV winding of layer type gives the highest transferred voltage to the LV terminal and that this happens at 1.6 MHz which could be excited for close-up earth faults. Although disc winding seems the least vulnerable when measuring the transferred voltage to the LV terminal, it has higher potential of internal resonances in the HV winding compared to the two other types both voltage-to-ground and voltage drops. Pancake and layer windings have less vulnerability in the case of internal resonances. Pancake windings have modular design characteristic. This advantage eases the repair for offshore wind applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2015.7076828 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345330,
  title={ Development of pulsed method for diagnostics of transformer windings based on short probe impulse  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2015},
  author={Lavrinovich, V. A. and Mytnikov, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7179164 },
  abstract={Insulation destruction is one of many failure reasons of power transformers which belong to the most expensive and strategically important components of any electrical energy system. Insulation damage due to short circuit currents can cause an emergency situation at any moment. Thus, the reliable control of winding state is an important task of a modern power engineering technology. The paper deals with the experimental research of the pulsed method of transformer winding control. A new approach to winding state control technology is described. The proposed method is based on short (compared with a typical pulsed technology) probe pulse and front pulse durations. The experimental results of sensitivity growth at decreasing front pulse duration are shown. The experimental equipment and measurements are described. A comparison of the experimental results of the proposed pulsed method and FRA is given. It is shown that shorter front of probe pulse duration allows upgrading sensitivity of the diagnostic procedure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2015.004745 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345331,
  title={ Statistical Techniques for Partial-Discharge Location in Transformer Windings  -  IEEE Transactions on Power Delivery },
  year={2011},
  author={Jeyabalan, V. and Usa, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734881 },
  abstract={To locate the partial discharge in transformer windings, statistical techniques are proposed. The experimental studies are performed on a 22-kV prototype interleaved winding to prove the feasibility of the methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2011.2112490 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345332,
  title={ Power transformer disruptions- a case study  -  IEEE Electrical Insulation Magazine },
  year={2014},
  author={Marques, A. P. and de Jesus Ribeiro, C. and Azevedo, C. H. B. and dos Santos, J. A. Lopes and de Carvalho Sousa, F. R. and da Cunha Brito, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6749569 },
  abstract={A power transformer is one of the most important and costly pieces of equipment in electrical systems. Its importance is attributed directly to the continuity in the supply of electrical power, since its loss through failure or defect means an interruption in the supply of electrical power. This is a large piece of equipment whose substitution is expensive and involves a lengthy process.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2014.6749569 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352345333,
  title={ Design of an oil immersed power transformer monitoring and self diagnostic system integrated in Smart Energy Management System  -  2021 3rd Global Power, Energy and Communication Conference (GPECOM) },
  year={2021},
  author={Laayati, O. and Bouzi, M. and Chebak, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587640 },
  abstract={The power transformers are one of the most important components in the electrical grid, where the failures are highly critical and can impact all sources and terminals, including production and distribution systems. This paper presents the interactions of the power transformer failures classification algorithms and health index calculation with the smart energy management system in an electrical grid and proposes a new monitoring approach of this component. This system can classify the different power transformer failures using predictive analytics. The integrated models calculate important characteristics such as loss of life, health index of oil quality, dissolved gas analysis and insulation paper. Since each fault of power transformer has an impact on the grid, the objective is looking for new correlations between different monitoring techniques of the power transformer with the power quality data acquired in the primary and secondary. These correlations results can reduce the cost of the instrumentation and the calculation time. A list of the requirements to design an optimized intelligent and online predictive maintenance system for power transformer is also proposed, integrating instrumentation, important KPIs and data to be monitored, stored, and analyzed. These data are used to classify the critical defects, using probabilistic models and machine learning algorithms to propose maintenance rescheduling and an effective predictive maintenance plan to avoid blackouts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GPECOM52585.2021.9587640 },
  booktitle={ 2021 3rd Global Power, Energy and Communication Conference (GPECOM) },
  chapter={0}
}

@article{rayyan-352345334,
  title={ Coherent Phase Detection Technique for Location of Partial Discharge in Transformer Windings  -  IEEE Transactions on Power Delivery },
  year={2011},
  author={Jeyabalan, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5898439 },
  abstract={The coherent phase detection technique is used for location of partial discharge (PD) in transformer windings. The experimental studies are performed on a 22-kV interleaved winding to prove the feasibility of the method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2011.2153450 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345335,
  title={ Asset management of power transformer: Optimization of operation and maintenance costs  -  2014 International Electrical Engineering Congress (iEECON) },
  year={2014},
  author={Suwnansri, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6925972 },
  abstract={This paper proposes asset management of power transformer in order to diminish operating and maintenance costs. The strategy for the asset management consists of failure statistic analysis, assessment on power transformer condition and importance, and inventory management of power transformer spare part. To determine the critical components and failure causes, the failure statistics of power transformer are analyzed. The failure data is used for estimating lifetime of main power transformer components by Weibull distribution technique. To manage maintenance tasks of power transformer, risk-based maintenance is developed by a combination of condition and importance assessment of each transformer. The condition assessment is performed by analysis of electrical test, insulating oil test and visual inspection. The importance is evaluated from load criticality, impact on system stability, possibility of failure, failure consequence, damage to property, as well as social impact and environmental concern. Subsequently, risk-based maintenance in form of risk matrix is developed for evaluating the risk of each transformer. The transformer with high risk will be focused firstly. To optimize spare parts and minimize inventory cost, inventory management strategies are applied to components of power transformer by using Statistical distribution technique and economic order quantity. Therefore, a suitable time period for reordering and optimum ordering quantity are determined. Besides, computerized web-application program is developed for practical use. Finally, maintenance of power transformer fleet can be effectively managed. The proposed method will be further applied to other high voltage equipments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/iEECON.2014.6925972 },
  booktitle={ 2014 International Electrical Engineering Congress (iEECON) },
  chapter={0}
}

@article{rayyan-352345336,
  title={ Validation of diagnostic monitoring technical state of iron and steel works transformers  -  2016 IEEE NW Russia Young Researchers in Electrical and Electronic Engineering Conference (EIConRusNW) },
  year={2016},
  author={Khramshin, V. R. and Nikolayev, A. A. and Evdokimov, S. A. and Kondrashova, Y. N. and Larina, T. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448253 },
  abstract={By the example of OJSC Magnitogorsk Iron and Steel Works, the paper considers the issues of introduction of systems designed for diagnostic monitoring technical state of transformers. It highlights the need for life extension and managing priorities at renovation of power equipment. It gives an estimate of the most deteriorated transformers differing in the levels of supplied voltage. Network and unit transformers are distributed according to the operation durability. The study provides dependencies of the specific damage rate and registers their dependencies on provisions of the theory considering failures of the process systems. It determines characteristic failures of the network and unit transformers. There is a list of process disturbances accompanied by internal short circuits. It is proved that most damages appear in the windings and at the high-voltage inputs. The paper takes a look at issues of technical- and-economic efficiency of commercialization of diagnostic monitoring systems. Expenditures for complex inspection and introduction of the stationary system are compared. The study provides evidence to the fact that efficiency of accident prevention and reduction of corresponding losses are significantly higher due to the use of the monitoring systems compared to the routing inspections. It specifies results of introduction of the systems for continuous condition control of network, unit and furnace transformers at OJSC Magnitogorsk Iron and Steel Works. There is a challenge to develop the engineering practice for failure detection and identification.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIConRusNW.2016.7448253 },
  booktitle={ 2016 IEEE NW Russia Young Researchers in Electrical and Electronic Engineering Conference (EIConRusNW) },
  chapter={0}
}

@article{rayyan-352345337,
  title={ Power transformer risk index assessment for an asset management plan  -  2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON) },
  year={2017},
  author={Medina, R. D. and Morales, D. X. and Toledo, M. A. and Cabrera, J. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8229535 },
  abstract={This paper presents a method for assess the risk index in a power transformers park, risk index is a metric that allows park administrator to ensure an optimal physical asset management, allocating properly financial and human resources in operation and maintenance actions. Assessing risk index requires calculating two secondary sub-index termed failure probability and consequence factor. Those indexes are integrated into the risk index value. In order to illustrate this process, 16 units risk index is evaluated, those units operates in the national Ecuadorian electric grid, results and discussion are finally presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CHILECON.2017.8229535 },
  booktitle={ 2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON) },
  chapter={0}
}

@article{rayyan-352345338,
  title={ Statistical analysis of power transformer component life time data  -  2007 International Power Engineering Conference (IPEC 2007) },
  year={2007},
  author={Jongen, R. and Gulski, E. and Morshuis, P. and Smit, J. and Janssen, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4510221 },
  abstract={With statistical analysis it is possible to describe the ageing processes of power transformers components statistically. Because of the complexity of power transformers it is interesting to show the failure behaviour of the different components. As input for the analysis a population of power transformers with different ratings, designs and makes is used. From the reported failures the different failure modes of the components are distinguished. The failure data is fitted with mathematical statistical distributions and its parameters can be estimated. From the analysis it can be seen in which life phase the components are and what can be expected for the future regarding failures of some transformer components. The results can be used to determine if there is a reason for concern in the next coming years and if replacement or maintenance is necessary to secure a reliable network operation. It can also help to determine in what way a population of spare transformers is needed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2007 International Power Engineering Conference (IPEC 2007) },
  chapter={0}
}

@article{rayyan-352345339,
  title={ Use of mobile unit transformers in high voltage load stations  -  2008 IEEE Power and Energy Society General Meeting - Conversion and Delivery of Electrical Energy in the 21st Century },
  year={2008},
  author={Hamoud, G. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4596114 },
  abstract={Electric utilities schedule power transformers in high voltage load stations (customer delivery or regional supply systems) for planned outages such as unit refurbishment, unit replacement, etc. that may last for a few weeks. During the planned outage time, companion units may fail causing a complete loss of supply to customers. Mobile unit transformers (MUTpsilas) could be used in these emergency situations to reduce the impact of the loss of the entire supply to customers. These MUTpsilas cost utilities money and utilities need to answer the question of whether the purchase of these units is justified or not. This paper describes a probabilistic method based on a Markov model for evaluating the benefit from the use of MUTpsilas in customer delivery systems. The benefit from an MUT is expressed in terms of annual reduction in total customer interruption costs. The estimated annual benefit can then be compared with the annual charge of carrying the MUT to see whether the use of MUT is justified or not. Sensitivity studies are carried out to evaluate the impacts of changes in some system parameters on the benefits from the MUT. A case study is presented to illustrate the proposed method and to compare the results with those obtained using a frequency and duration approach.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2008.4596114 },
  booktitle={ 2008 IEEE Power and Energy Society General Meeting - Conversion and Delivery of Electrical Energy in the 21st Century },
  chapter={0}
}

@article{rayyan-352345340,
  title={ The reliable design of PCB Rogowski Coil current transformer  -  2006 International Conference on Power System Technology },
  year={2006},
  author={Yan, Z. and Hongbin, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4116282 },
  abstract={PCB Rogowski coil has a particular structure that interconnects the conductive imprints on the upper and lower sides of the each printed circuit board by plated through holes and connects printed circuit boards in series by soldering points. Once a plated through hole or a soldering point falls, PCB Rogowski coil opens and outputs incorrect signal, which causes current measurement unreliable and misoperation of protecting relays. Thus, This paper focuses on the reliability study of PCB Rogowski coil: failure modes and failure mechanism of plated through holes are presented; failure criterion of PCB Rogowski coil is proposed; reliability model of PCB Rogowski coil is established; and the relationship between coil failure rate and plated through holes as well as soldering points is quantificationally deduced. Finally, mean time to failure of PCB Rogowski coil for 300 A current measurement is predicted about 27 years based on GJB/Z299B-98.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPST.2006.321457 },
  booktitle={ 2006 International Conference on Power System Technology },
  chapter={0}
}

@article{rayyan-352345341,
  title={ Analysis of Maintenance in Transformers Based on a Fuzzy Logic Method  -  2018 IEEE PES Transmission & Distribution Conference and Exhibition - Latin America (T&D-LA) },
  year={2018},
  author={Rosero-Z, L. and Pavas, A. and Durán, I. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8511772 },
  abstract={In this paper, an evaluation of Power transformer assessment is developed in order to determine when maintenance is feasible from the point of view of economics and aging of the asset. For this purpose, a model of health condition and failure rate is used and then fuzzy logic method is applied for some other considerations needed to stablish the action required in the transformer along the simulation. This is a new approach for estimating the need of maintenance in a power transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDC-LA.2018.8511772 },
  booktitle={ 2018 IEEE PES Transmission & Distribution Conference and Exhibition - Latin America (T&D-LA) },
  chapter={0}
}

@article{rayyan-352345342,
  title={ A reliability assessment method for traction transformer of high-speed railway considering the load characteristics  -  2015 IEEE Conference on Prognostics and Health Management (PHM) },
  year={2015},
  author={Feng, D. and He, Z. and Wang, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7245049 },
  abstract={Reliability assessment of traction transformers is critical to reliability research of the entire high-speed rail traction power supply system. In this paper the impact of high-speed rail load characteristics on the reliability of traction transformer is analyzed, and reliability assessment of traction transformers is proposed. Considering the imbalance, impact and nonlinearity of high-speed rail traction load in this method, transformer derating rate was calculated based on the standard IEEE C57.110 procedures, and thermal circuit model and its differential equations were applied to obtain transformer hot-spot temperature and quantify the traction load characteristics. Then Arrhenius-Weibull model was utilized for transformer reliability assessment. In the example the feasibility of this method was validated by the measured data, and traction transformer reliability index was calculated for reliability assessment. The results show that the impact of the traction load characteristics of high-speed rail on transformer reliability can't be ignored. The assessment results can assist reasonable decision to reduce the operation risk of traction transformer and meet the demand of safety and reliability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPHM.2015.7245049 },
  booktitle={ 2015 IEEE Conference on Prognostics and Health Management (PHM) },
  chapter={0}
}

@article{rayyan-352345343,
  title={ Diagnostic technology for transformers: Methods synergy and Double-Coordinate Location  -  2009 IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives },
  year={2009},
  author={Aksenov, Y. P. and Yaroshenko, I. V. and Noe, G. and Andreev, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5292768 },
  abstract={This paper contains summary information on Diacs technology principles comprising the following subjects: power transformers on-line testing and defects location procedure; on-line diagnostic technology and data analysis; examples of test results. Possible failure scenarios are observed here, as well as general tools available for power transformer life assessment. Specific technology of Diagnostic Methods Synergy for transformer insulation analysis is described in the paper, one the most important components of which are methods of Double-Coordinate Location and n(Q) distribution analysis, on-line PD location, gas-in-oil analysis, thermovision.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DEMPED.2009.5292768 },
  booktitle={ 2009 IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives },
  chapter={0}
}

@article{rayyan-352345344,
  title={ Application limitation of electronic current and Voltage Transformers in digital substations  -  2011 IEEE Power Engineering and Automation Conference },
  year={2011},
  author={Weifeng, Li and Shuangle, Zhang and Weiping, Ma and Ming, Ao},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6134983 },
  abstract={Electronic voltage transformer (EVT) and electronic current transformer (ECT) are important equipments in smart grid. In order to meet the requirements of power reliability in the grid, the annual failure rate of EVT and ECT should be less than 0.2% during normal operation. Power transformer is the electrical device, its annual failure rate is only 0.01%, and the comprehensive reliability of secondary relay protection devices can be improved to more than 99.8% by redundancy design. EVT and ECT's reliability can be hardly improved to 99.8% due to the limit of failure relevance, unless designed and manufactured according to aerospace standards. EVT and ECT's utilization is limited in the digital substation considering of reliability and economy. In the digital substation, Non-traditional transformer is an economical and rational design, because the reliability of 99.8% can be guaranteed by sending analog small-signals from non-traditional transformers to the relay unit. Non-traditional transformer's analog output is sent to the merged cell of transformer, and a digital signal is converted into the data bus serving for substation monitoring and control systems, so the reliability can reach 99%. Thus non-traditional transformer's analog output and merged cell's output can respectively meet the reliability requirements of relay protection and monitoring system's informatization in the digital substation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PEAM.2011.6134983 },
  booktitle={ 2011 IEEE Power Engineering and Automation Conference },
  chapter={0}
}

@article{rayyan-352345345,
  title={ Location of faults in transformer winding using SFRA  -  2013 IEEE 1st International Conference on Condition Assessment Techniques in Electrical Systems (CATCON) },
  year={2013},
  author={Usha, K. and Joseph, J. and Usa, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6737497 },
  abstract={Power transformer failures mostly arise from winding faults. Detection and localization of winding faults is essential for preventing damages to the transformer. This contribution is aimed at locating faults by using the impedance characteristics of the winding. Sweep frequency measurement and analysis is done on a 22 kV continuous disc winding. Methods for determining the extent and location of faults have been developed. The developed method yields a generalized algorithm for locating faults in transformer windings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CATCON.2013.6737497 },
  booktitle={ 2013 IEEE 1st International Conference on Condition Assessment Techniques in Electrical Systems (CATCON) },
  chapter={0}
}

@article{rayyan-352345346,
  title={ Improving the life cycle management of power transformers transforming data to life  -  SoutheastCon 2015 },
  year={2015},
  author={Waugh, N. T. and Muir, D. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132977 },
  abstract={Power transformers are essential in the transmission of alternating current and are the most costly equipment in the substation. Although their failure rate is relatively low (less than two percent), the in-service failure of a power transformer can be very catastrophic. The restoration cost of in-service power transformer failures increases by up to seventy-five percent and loss of revenue by sixty percent. It is therefore prudent for utility companies to optimize the life of power transformers and mitigate in-service failures. “Early Detection Saves Lives”, a slogan associated with the fight against cancer is also very relevant to the life cycle management of power transformers. The health of the power transformer is reflected through its insulation strength. There are several on-line and offline tests used to assess the health of power transformer. These give rise to an enormous amount of data to be analyzed. Many utilities manually analyze these results and only focus on the most recent test results. This method of analysis is time consuming and is subject to human error. It abets the back-log of testing and not correcting developing faults in a timely manner. There are benefits that can be gained from using a computer program to store, analyze and trend power transformer data, as well as predict and monitor developing power transformer faults. Software are available to test and monitor power transformer oil via online devices; while other maintenance software analyze single electrical field tests. There is the potential to gain greater benefits from having one computer program that incorporates oil and electrical field tests results, as well as the age, loading and inspection data of the power transformers to determine their health status or condition index. This paper outlines the proposed architecture and features of a custom built Power Transformer Maintenance Software (PTMS). PTMS facilitates a paradigm shift from reactive maintenance (such as practiced at the Jamaica Public Service Company Limited) to a predictive maintenance approach. This study proposes the use of a customized integrated data management system to improve the life cycle management of power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SECON.2015.7132977 },
  booktitle={ SoutheastCon 2015 },
  chapter={0}
}

@article{rayyan-352345347,
  title={ A maintenance decision optimization method based on life cycle cost of converter transformer  -  2016 IEEE Electrical Insulation Conference (EIC) },
  year={2016},
  author={Zhou, L. and Wang, Y. and Li, Y. and Zhu, M. and Du, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548603 },
  abstract={Converter transformer is one of the most important equipment in ultra-high voltage direct current transmission system, periodic preventive maintenance strategy is widely in its maintenance. Excessive maintenance often arises in the attempt to always ensure the reliable operation of converter transformers. To solve this problem, this study proposes a maintenance decision optimization method for converter transformers that is based on life-cycle cost(LCC). This approach introduces the concepts of LCC and discount rate, obtains an LCC model of the converter transformer and presents the value conversion method; by improving the maintenance equipment failure rate and the calculation method of economic losses, this method improves the accuracy of failure loss cost in the LCC model; by comparing the different maintenance modes of the converter transformer LCC, the reasonable maintenance strategy is optimized, thereby achieving the objectives of reliability and economy. A decision-making example using a ±800kV converter transformer shows that the proposed method can calculate the LCC of converter transformers, yield the optimized maintenance strategy and provide technical support for condition-based maintenance of the converter transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC.2016.7548603 },
  booktitle={ 2016 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345348,
  title={ The remote monitoring system of transformer fault based on The internet of Things  -  Proceedings of 2011 International Conference on Computer Science and Network Technology },
  year={2011},
  author={Cheng, Xiao-hui and Wang, Yang},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181914 },
  abstract={The damage of the transformer is a result that was caused by the fault of the oil-immersed transformer which is difficult to remove. After analysis of the need of transformer fault remote monitoring system, here introduce the system's overall composition and the design of terminal equipment circuit. Here compares many combination ways of internet of Things and power, the traditional oil-immersed transformer monitoring system is analyzed, here found that it has a high cost, loss intelligent data analysis and feedback control of function. Therefore, this paper proposes the use GSM (Global System for Mobile communication) of SMS technology, by the relevant data analyze, to achieve that the Transformer failure is automatically judged, and control transformer temperature of the transform fault remote monitoring system, and complete the appropriate hardware and software design.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCSNT.2011.6181914 },
  booktitle={ Proceedings of 2011 International Conference on Computer Science and Network Technology },
  chapter={0}
}

@article{rayyan-352345349,
  title={ A reliability prediction model for power transformers  -  2021 IEEE International Conference on Environment and Electrical Engineering and 2021 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe) },
  year={2021},
  author={Adinolfi, G. and Ciavarella, R. and Ricca, A. and Merola, A. and Valenti, M. and Graditi, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9584596 },
  abstract={Power systems reliability assessment represents a complex task due to large number of systems and subsystems and for the significant number of different stresses affecting on individual components. Different models, methods and metrics can be used for electric and electronic systems in specific applications. The aim of this paper consists in the development of a reliability prediction models for power transformers in hybrid AC/DC grids. Future energy scenario with bidirectional power flows could stress transformers components. The propose approach intends to evaluate thermo-mechanical, environment and quality stress factors for each transformer subsystem with particular attention to ageing phenomena. The overall transformer reliability performances are calculated in real operating conditions characterizing 2030 scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEEIC/ICPSEurope51590.2021.9584596 },
  booktitle={ 2021 IEEE International Conference on Environment and Electrical Engineering and 2021 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe) },
  chapter={0}
}

@article{rayyan-352345350,
  title={ Power transformer risk management: Predictive methodology based on reliability centered maintenance  -  2018 Simposio Brasileiro de Sistemas Eletricos (SBSE) },
  year={2018},
  author={Freitag, S. C. and Sperandio, M. and Marchesan, T. B. and Carraro, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395532 },
  abstract={This paper has the objective of developing a methodology, through a technique of Reliability Centered Maintenance, in order to rank transformers with greater risk to the system through a risk indicator. The application of the study will lead to the greater assertiveness of investments, providing technical and scientific support and agility in decision making.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SBSE.2018.8395532 },
  booktitle={ 2018 Simposio Brasileiro de Sistemas Eletricos (SBSE) },
  chapter={0}
}

@article{rayyan-352345351,
  title={ Possible indicators of aging in oil-filled transformers part 1: measurements  -  IEEE Electrical Insulation Magazine },
  year={2010},
  author={Birlasekaran, S. and Ledwich, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383925 },
  abstract={Although a detailed explanation of all the data presented here has not yet been formulated, it seems likely that aging of transformers can be qualitatively assessed using DRA (dielectric response analysis) and PD measurements at operating temperatures. It may also be possible to apply such measurements to generators, motors, and circuit breakers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2010.5383925 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352345352,
  title={ Risk-based Inspection and Maintenance Analysis of Distribution Transformers: Development of a Risk Matrix and Fuzzy Logic Based Analysis Approach  -  2022 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM) },
  year={2022},
  author={Attanayake, A. M. S. R. H. and Rathnayake, R. M. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989688 },
  abstract={Distribution transformers (DTs) play a central role in assuring the delivery of crucial functions in electric power distribution systems. To sustain the reliability and availability of an electricity distribution network, it is important to minimize the risk of potential failures of DTs. The risk-based prioritization of inspection, maintenance, and repair tasks enables expensive repairs/replacements, loss of efficiency, loss of revenue, and power loss to consumers to be avoided, by optimizing the utilization of resources. This manuscript demonstrates the use of a fuzzy inference system that enables potential failures of DTs to be prioritized, to prevent the potential failure risk of DTs. The suggested approach enables the risk based on likelihood and the consequence of such failures (i.e., the severity and effects of potential failures) to be calculated. The calculated risks of potential failures enable prioritization of the inspection, maintenance, and repair tasks for DTs at optimal resource utilization. The findings from this study are useful for electric power distribution-related inspection, maintenance, and repair personnel, as well as for asset management professionals.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEM55944.2022.9989688 },
  booktitle={ 2022 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM) },
  chapter={0}
}

@article{rayyan-352345353,
  title={ Experimental Study on Effects of Nozzle Explosion Damage on Performance of Water Spray Fire Protection System of Ultra-high Voltage Transformer  -  2021 6th Asia Conference on Power and Electrical Engineering (ACPEE) },
  year={2021},
  author={Li, W. and Shang, F. and Zhang, J. and Zhu, S. and Guo, Y. and Huang, Y. and Su, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437001 },
  abstract={In order to evaluate the effect of nozzle explosion damage on the performance of water spray fire protection system of ultra-high voltage (UHV) transformer, experiments were conducted with 0%, 10%, 30%, 50% of falling nozzle to simulate the damage of explosion on water spray fire protection system. The effects of the failure of different ratios of nozzles on the water mist envelope effect, nozzle pressure and pipeline flow rate of UHV transformers were analyzed. The results showed that the nozzle pressure and pipeline flow rate of water spray fire protection system were significantly affected by the proportion of falling nozzles. When the proportion of falling nozzles exceeded 10%, the working pressure of most nozzles fell below the minimum working pressure specified by the standard. The range of the sprinklers decreased and the coverage area was reduced. Meanwhile, the water spray fire protection system cannot effectively envelop the transformer. The firefighting water in the fire branch pipe was sprayed to the transformer body and its surroundings in the form of the water jet, which did not have the fire extinguishing ability through the water mist envelope. It may cause a hot oil fire, risk of boiling, splashing, or expanding fire. In actual projects, it is recommended to take protective measures such as explosion-proof and high-temperature resistant spray nozzles or spraying fire-resistant coatings on spray nozzles and pipelines, which could avoid or reduce the damage to the spray nozzles caused by explosion and high temperature during fire. Thus, it could improve the effectiveness of water spray fire protection system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACPEE51499.2021.9437001 },
  booktitle={ 2021 6th Asia Conference on Power and Electrical Engineering (ACPEE) },
  chapter={0}
}

@article{rayyan-352345354,
  title={ Snubber design for transformer protection  -  2014 IEEE Petroleum and Chemical Industry Technical Conference (PCIC) },
  year={2014},
  author={Sutherland, P. E. and Valdes, M. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6961900 },
  abstract={Historically, failures of distribution transformers due to transient overvoltage phenomena has led to the development of Resistor-Capacitor snubber circuits for the protection of the transformer and winding insulation. These transients are most often observed when dry-type transformers are close coupled to vacuum switching devices. Typically, snubber circuit design has been specific for the particular application, and complex engineering studies were required. However, the design of a snubber circuit itself may be performed without these detailed studies. If snubber studies are required, the procedures for system modeling and simulation are explained in a step by step manner.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCICon.2014.6961900 },
  booktitle={ 2014 IEEE Petroleum and Chemical Industry Technical Conference (PCIC) },
  chapter={0}
}

@article{rayyan-352345355,
  title={ Analyzing Differences in Useful Life of Power Transformers across Utilities for Better Strategic Spares Management  -  2018 IEEE Power & Energy Society General Meeting (PESGM) },
  year={2018},
  author={Martin, D. and Saha, T. K. and Buckley, G. and Chinnarajan, S. and MacArthur, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585533 },
  abstract={Improving the determination of the number of spare power transformers that an asset manager should store is advantageous to optimize asset investment while maintaining a reliable network. These calculations use the expected failure rate of a fleet of power transformers to ascertain the probability of a spare being available when a failure occurs. An existing model uses the assumption that the failure rate of a power transformer is constant throughout its life. While this is not true during the wear-out period of a transformer, this is likely to hold during its useful life when failures are mostly caused by random events. In this article the variance in useful life between different Australian utilities is evaluated, with the significance being whether these utilities can use the same useful life and failure rate, or if different ones are required. Applying the analysis of variance method to the failure rates of these utilities, during the random failure period, did not find the differences to be statistically significant.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM.2018.8585533 },
  booktitle={ 2018 IEEE Power & Energy Society General Meeting (PESGM) },
  chapter={0}
}

@article{rayyan-352345356,
  title={ A methodology to predict the lightning insulation strength for distribution transformers by applications of reduced lightning standard impulse voltages  -  2012 IEEE International Symposium on Electrical Insulation },
  year={2012},
  author={Lopes, G. P. and Martinez, M. L. B. and Salustiano, R. and Faria, I. P. and Telles, V. G. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6251490 },
  abstract={The lightning withstanding of transformers are based on a set of impulse voltage applications with 1.2/50 μs shape, in accordance with international standards. The standard lightning impulse test is a destructive test, in which the transformer insulation strength is predicted by comparisons between reduced and rated levels for full and chopped impulses. In this paper a different method named “progressive impulse test” is proposed to provide estimation with respect to the voltage level in which evidences of insulation failure appears. Modifications on oscillation frequency of current waveforms may indicate sparks or short-circuits between turns, layers or between windings and the ground. By comparisons among these current waveforms it is possible to predict the insulation performance, as well as manufacturing quality process without the necessity to submit the transformer to all lightning impulse sequence test.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ELINSL.2012.6251490 },
  booktitle={ 2012 IEEE International Symposium on Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345357,
  title={ Reliability Modeling and Assessment of Dual Active Bridge Based DC Transformer for DC Power Distribution Application  -  IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society },
  year={2019},
  author={Gou, Y. and Tian, J. and Yu, K. and Liu, C. and Zhuo, F. and Wang, F. and Zhang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8927019 },
  abstract={As the core apparatus in dc distribution grid, the reliability of de transformer (DCT) directly affects the safe and stable operation of the entire dc grid. Firstly, the structure and characteristics of dual active bridge (DAB) based dc transformer are analyzed. Then, the hierarchical reliability model of dc transformer is established by using reliability block diagram (RBD). Furthermore, based on k-out-of-n redundancy model and Markov process theory, considering module redundant number, redundancy mode and component repair rate, a detailed and comprehensive reliability evaluation model of de transformer is proposed. Finally, based on the proposed reliability model of dc transformer, the influence of different redundancy designs and the component repair rate on the reliability of dc transformers are investigated through an example. The research results can provide a theoretical basis for redundancy design, redundancy mode selection and maintenance strategy of dc transformer, and contribute to the reliability of the whole dc grid.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IECON.2019.8927019 },
  booktitle={ IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society },
  chapter={0}
}

@article{rayyan-352345358,
  title={ Reliability analysis on operation of a kind, of All Fiber-Optic Current Transformer  -  2014 China International Conference on Electricity Distribution (CICED) },
  year={2014},
  author={Liu, X. and Wang, X. and Xiao, H. and Liu, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991959 },
  abstract={Compared with other kinds of electronic instrument transformers, the All Fiber-Optic Current Transformer (FOCT) have the advantages of high accuracy, wide dynamic range, strong ability to resist electromagnetic interference environment, simple and flexible of installation. But because of the short-time application, the operation reliability of FOCT can't be assessed base on the operational log we have now. According to this situation, the study on the structure and work environment had been done, in order to find the main environment parameter which affect on the aging of FOCT. Then the accelerated aging tests had been done on the components of a FOCT such as photo detector, optical source and optical phase modulator Then the mean time between failures (MTBF) of these components had been estimated base on the results of aging tests. Finally we can assess the operation reliability of FOCT. The results indicated that the method of reliability analysis can be applied on any kinds of electronic instrument transformers. The current transformer which was studied on can work no less than 20 years in normal conditions. It can meet the requirement on electronic current transformer of users'.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CICED.2014.6991959 },
  booktitle={ 2014 China International Conference on Electricity Distribution (CICED) },
  chapter={0}
}

@article{rayyan-352345359,
  title={ The Limitations of Arc Detection Using Semiconductive Light Sensing Elements Inside the Transformer Tank  -  2023 13th International Conference on Power, Energy and Electrical Engineering (CPEEE) },
  year={2023},
  author={Sharifi, A. and Kuhnke, M. and Werle, P. and Akbari, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10217559 },
  abstract={Transformer explosions and fires are the most dangerous consequences of transformer faults. As protection each transformer is equipped with a Buchholz relay (BHR), which identifies the faults, thus a circuit breaker (CB) can trip the transformer. However, in some cases, the tripping of the transformer is not fast enough in order to prevent a tank rupture and the damages. Therefore, faster arc detection systems are under an investigation like the use of photo sensitive semiconductors inside the transformer tank to detect the light emission from an arc and to trigger the circuit breaker. In this paper, the characteristics of different light sensitive semiconductors, such as light dependent resistors (LDRs), and photodiodes are compared in regard to their possible application inside oil filled power transformers. Moreover, the performance of certain measuring circuits with the different semiconductors is presented and compared at different distances to an arc with temperature variation. It is experimentally observed that the photosensitive semiconductors have serious limitations to operate at an elevated temperature closer to $100^{\circ} C$ in oil and the environment of electromagnetic fields. Finally, the advantages and disadvantages of the different semiconductor types and their limitations of arc sensing with light sensors are concluded.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CPEEE56777.2023.10217559 },
  booktitle={ 2023 13th International Conference on Power, Energy and Electrical Engineering (CPEEE) },
  chapter={0}
}

@article{rayyan-352345360,
  title={ Evaluation of DFIG Wind Turbine Generator and Transformer Conditions with Electrical Signature Analysis  -  2022 IEEE Electrical Insulation Conference (EIC) },
  year={2022},
  author={Penrose, H. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833161 },
  abstract={During field studies of Doubly-Fed Induction Generators (DFIG) and Singly-Fed Induction Generators (SFIG) transformer and generator failures several unusual conditions were detected. A combination of sub-synchronous control interaction, sub-synchronous torsional interaction, and starting resonances were detected with electrical signature analysis in specific operating conditions of the machines. A review of historical operating conditions, wind, thermal and power distribution system design indicate that low-level sub-synchronous resonances are present that result in unusual transformer heating/aging, generator rotor component electrical and mechanical fatigue, and gearbox wear after years of service. The severity of the condition results from a combination of average loading and distance from customer loads and wind farm configuration. In this paper we will discuss the discovery and progress in the research with potential in-service solutions to be presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC51169.2022.9833161 },
  booktitle={ 2022 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345361,
  title={ The transformer fault management information system design based on the risk assessment  -  2012 International Conference on High Voltage Engineering and Application },
  year={2012},
  author={-t. Hu, W. and Yang, Hai-tao and Yan, Jia-wen and Zhu, Xiao-hui},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357088 },
  abstract={Risk assessment is defined to measure the probability and security of risk resources synthetically. In this paper, risk assessment theory is employed firstly to maintenance tactics of transformer, the probability and severity of all failure modes of transformer are measured synthetically, and risk maintenance tactics of usual transformer's failure modes are obtained .Based on these, 5×5 risk matrix and 4 kinds of risk ranges are adopted to express the risk of all transformer's failure modes, and responding risk maintenance strategies are obtained; finally, a example is analysis to verify the correctness of the risk assessment frame and risk maintenance strategies. And the Visual Basic language and the Access database are applied in this paper to design the MIS of the transformer risk management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2012.6357088 },
  booktitle={ 2012 International Conference on High Voltage Engineering and Application },
  chapter={0}
}

@article{rayyan-352345362,
  title={ Remarkable life cycle management by effective condition monitoring and assessment system of power transformer in CLP power system  -  2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  year={2014},
  author={Kwong, C. L. and Tim, C. Y. and Kwong, W. M. and Kit, L. C. and Yan, K. Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066192 },
  abstract={Effective power transformer condition monitoring and assessment system requires a great variety of state-of-art technologies to be applied for supporting a remarkable life cycle management in power networks. Power transformers are usually very reliable and durable components of the power generation, transmission and distribution networks. Their performance is often taken for granted and they are overlooked until a problem occurs. Unfortunately, when a fault occurs in a transformer, the result can be catastrophic and the failures are usually very expensive as it often results in the loss of the most expensive plant item in a substation if the power transformer is not uneconomical to repair. Cost of resulting loss in generation or transmission restraints is occurred until a replacement comes into effect. Clearly, despite the high reliability of power transformers, in view of the serious consequences of failures, it is important to employ an effective condition assessment system under smart grid operations so that faults can be detected at an early stage in order to improve the prospects for repairs and minimize the impact of any failures, under more optimization of operations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APPEEC.2014.7066192 },
  booktitle={ 2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  chapter={0}
}

@article{rayyan-352345363,
  title={ Preparation of power transformer’s CBM implementation in PLN P3B Jawa Bali  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={A.W, N. U. and Pharmatrisanti, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580414 },
  abstract={Since year of 2004 PLN P3B Jawa Bali has decided to apply a new strategy of maintenance, i.e.: condition based maintenance (CBM) to its high voltage assets. Transformer, which is the most crucial and expensive asset in electrical power network, becomes the first priority to be applied on. Performing FMECA (Failure mode Effect and Criticality Analysis) in order to find failure path of each transformer subsystem and developing model became the first step should be done by PLN P3B Jawa Bali. There are two kinds of model developed by PLN P3B Jawa Bali; they are statistic model and physical model. This paper focuses on preparation of statistic model development. There are five kinds of data that PLN has been collected for 5 last years related to critical component found by FMECA process , they are : DGA (dissolved gas analysis), Load and Temperature (manual reading by operator),Polarization Index, Tan delta, Oil characteristic test. Through data trending analysis, PLN has found that the data collected was not sufficient enough for model development. Therefore PLN has analyzed the problems and defined the new step to handle them, i.e.: Maintenance procedure standardization, DGA oil sampling standardization, Regular calibration of testing equipment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580414 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345364,
  title={ Multi-Point Vibration Monitoring of Power Transformer Based on Optical Fiber Sensing System  -  2024 IEEE 5th International Conference on Dielectrics (ICD) },
  year={2024},
  author={Wang, S. and Zhang, X. and Hu, J. and Liu, H. and -q. Qin, W. and -m. Ma, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10613281 },
  abstract={Vibration signal analysis is an effective method to diagnose mechanical condition of transformers online. A multi-point vibration sensing system phase-sensitive optical time domain reflectometer (φ-OTDR) is proposed for transformer tank vibration monitoring. Compared with piezoelectric accelerometers commonly used in the field, the proposed system has high electromagnetic interference immunity and complexing ability. In this paper, the vibration sensing principle based on φ-OTDR is first introduced. Then, an optical fiber sensor for transformer tank vibration is proposed. Next, the vibration sensing performance of the system is calibrated experimentally. Finally, vibration monitoring tests are carried out online on a 500 kV transformer, verifying the accuracy and comprehensiveness of the proposed system for transformer vibration monitoring.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICD59037.2024.10613281 },
  booktitle={ 2024 IEEE 5th International Conference on Dielectrics (ICD) },
  chapter={0}
}

@article{rayyan-352345365,
  title={ Planning of transformer placement using reliability in PLN Transmisi Jawa Bagian Barat  -  2017 International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  year={2017},
  author={Tryollinna, A. and Bastian, A. and Taufik, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8225923 },
  abstract={Nowadays, the population of installed transformer in PT PLN (Persero) Transmisi Jawa Bagian Barat is 305 units which consists of many variations of manufacturers and types. It consists of 21 manufacturers and 38 types along with different operational age from the young age transformers (under 20 years) until the old age transformers (more than 20 years). It means, TJBB needs different strategy for each transformer. For the old transformers, the strategies are whether relocating the transformer to another location and replacing it with new transformer or improving maintenance activities of the transformer to increase their reliability. While with the young transformer, TJBB has to plan the quantities of the spare will be needed. However, due to many variations of transformer manufacturers and types, it will be difficult when determining the number of spare and the type of maintenance. Meanwhile, the addition of the new transformer from the addition project or replacement project will be taking a role on the addition of the variations of manufacturers and types. Therefore, the information of the transformer performance is required. That information can be used to help the utilities to know the service performance of those various manufacturers, provide important inputs for utilities when specifying and buying transformer and also organize maintenance for transformer. In this paper, one of the information that stated above can be obtained by analyzing the failure that occurred on the transformer for the past few years. From the failure data, we will calculated the value of transformer reliability per manufacturer. The transformer reliability describes the probability of the existing population to survive beyond a certain age. This paper will discuss about the statistics of transformer failure that classified based on the voltage level, the cause of transformer failure and more focused on the current reliability level of transformer population which modeled by using weibull analysis into transformer reliability curve. In the reliability calculation, the failure data from each manufacturer will be grouped into a big group of manufacturer based on the similarity of the history of ownership and the technology used to manufacture the transformer. This paper have a purpose to determine transformer placement in PT PLN (Persero) Transmisi Jawa Bagian Barat by comparing the reliability with the type of location and customer that will be supplied.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVEPS.2017.8225923 },
  booktitle={ 2017 International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  chapter={0}
}

@article{rayyan-352345366,
  title={ Effectiveness of electrostatic shielding in suppressing the impact of fast transients on transformer insulation  -  2015 IEEE Conference on Electrical Insulation and Dielectric Phenomena (CEIDP) },
  year={2015},
  author={Khanali, M. and Jayaram, S. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352146 },
  abstract={Transformers installed in wind and solar power plants require specific design considerations in order to protect them from the adverse effects of voltage distortions. A number of manufacturers practice the implementation of electrostatic shields in transformer windings to filter the transferred voltages. Although this method has shown some improvements, effectiveness of the electrostatic shielding for a broad frequency range requires further studies. Through an experimental study, the effectiveness of electrostatic shielding in alleviating the transfer of high frequency distortions from LV winding to HV winding and vice versa. To compare the internal field enhancement at different frequencies in the presence and absence of an electrostatic shield, the frequency response of the voltage distribution inside the transformer's winding is also measured and analyzed. The results have shown that at some frequencies, the shield is beneficial in suppressing the stress, while at some other frequencies it amplifies the transferred voltages.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEIDP.2015.7352146 },
  booktitle={ 2015 IEEE Conference on Electrical Insulation and Dielectric Phenomena (CEIDP) },
  chapter={0}
}

@article{rayyan-352345367,
  title={ Evaluation of Bubble Formation in Transformer Insulation Systems - a Step Forward  -  2022 IEEE 21st International Conference on Dielectric Liquids (ICDL) },
  year={2022},
  author={Pößniker, C. and Matharage, S. Y. and Wang, Z. and Walker, D. and Krause, C. and Hilker, A. and Daghrah, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9830969 },
  abstract={Bubble formation in transformers could result in severe consequences leading to power outages and huge financial losses. There is an increased risk of bubble formation in the future due to increasing load demand and much higher loading fluctuations. The bubble formation process in transformer insulation has been studied for decades and the water content in the paper has been addressed as the most influential impact parameter. However, results from the most common insulating material combination of Kraft paper and mineral oil vary widely and a meaningful comparison for other parameters or insulating material combinations is challenging. This paper presents the development and verification of a simple test setup that can be used to study various impact factors on the bubble formation process with a high degree of confidence.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDL49583.2022.9830969 },
  booktitle={ 2022 IEEE 21st International Conference on Dielectric Liquids (ICDL) },
  chapter={0}
}

@article{rayyan-352345368,
  title={ Inventory management method to determined spare transformer optimization  -  TENCON 2015 - 2015 IEEE Region 10 Conference },
  year={2015},
  author={Marbun, Musa Partahi and Sinisuka, Ngapuli Irmea and Hariyanto, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372875 },
  abstract={This paper present an analysis to determined 500/150 kV spare transformer in Java Bali System. To obtain the desired reliability value, the spare transformer failure rate is determined from the failure rate value. This study uses the method of Inventory Management to get the value of failure rate. Inventory Management and Pareto Law will analyze transformer data such as impedance and location get a classification of transformer. Pareto Law method determined which disturbance of transformer components are the major failure. The failure rate will be calculated using historical data and the classification above. Finally, the spare transformer calculation will be determined using several calculation as a benchmark, the favored calculation or method of this study is Markov Chain Method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TENCON.2015.7372875 },
  booktitle={ TENCON 2015 - 2015 IEEE Region 10 Conference },
  chapter={0}
}

@article{rayyan-352345369,
  title={ Thermal Consequences of Elevated Current Density: Effects on Transformer Longevity and Reliability  -  2024 IEEE 1st International Conference on Advances in Signal Processing, Power, Communication, and Computing (ASPCC) },
  year={2024},
  author={Ojha, S. and Pradhan, R. and Sahoo, T. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881327 },
  abstract={This paper presents a detailed investigation into the thermal and magnetic effects of elevated current density on power transformers and inductors, highlighting its impact on their longevity and reliability. Current density, a key parameter in electrical and magnetic design, dictates the operational limits of conductors by influencing magnetic field strength and temperature rise. As current density increases, it can cause excessive heat generation, resulting in accelerated aging, reduced efficiency, and potential failure of critical components. This study introduces novel thermal management strategies that optimize transformer performance under high current density conditions. By incorporating advanced cooling techniques and innovative conductor materials, the paper presents both theoretical models and practical case studies to quantify improvements in thermal dissipation and magnetic efficiency. The results demonstrate that by carefully controlling current density, material selection, and cooling design, the adverse thermal effects can be significantly mitigated, thus enhancing the lifespan and operational reliability of transformers and inductors. This research provides actionable insights into designing high-current-density components with superior thermal resilience, which is vital for modern high-performance power systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ASPCC62191.2024.10881327 },
  booktitle={ 2024 IEEE 1st International Conference on Advances in Signal Processing, Power, Communication, and Computing (ASPCC) },
  chapter={0}
}

@article{rayyan-352345370,
  title={ Capacitor Coupled Voltage Transformer Inaccuracy Effect on Circuit Breaker Operation  -  2023 23rd International Scientific Conference on Electric Power Engineering (EPE) },
  year={2023},
  author={Asefi, S. and Andreesen, G. and Kilter, J. and Landsberg, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10149279 },
  abstract={Instrument transformers are widely applied in power networks for metering, protection, and control applications. Inaccuracy in the output signal of ITs will cause deficiency in the performance of these applications. This paper proposes a method to take into account the probability of failure which is induced by the imprecision of capacitor coupled voltage transformers (CCVT). One of the common failure modes of the CCVT is capacitor insulation breakdown. An exponential distribution has been applied to model this failure mode which provides the possibility to obtain the probability of failure. The simulations are implemented within the PSCAD environment and the obtained results demonstrate the proposed model fits properly to the failure mode. It is worth mentioning that the proposed probability of failure modeling is of great importance for accurate risk assessment of the power system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EPE58302.2023.10149279 },
  booktitle={ 2023 23rd International Scientific Conference on Electric Power Engineering (EPE) },
  chapter={0}
}

@article{rayyan-352345371,
  title={ An investigation into improving the measurement of the water content of transformer electrical insulation  -  2017 IEEE Innovative Smart Grid Technologies - Asia (ISGT-Asia) },
  year={2017},
  author={Martin, D. and Saha, T. and Hockey, J. and Caldwell, G. and Buckley, G. and Chinnarajan, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8378358 },
  abstract={Direct and indirect techniques are available to measure the water content of the cellulosic insulation of a power transformer. The measurement of the water content of cellulose is necessary because if it becomes too high, bubbles of water will be ejected from the cellulose insulation which may cause failure. Taking a sample of oil for Karl Fischer titration analysis is a simple and cheap laboratory based method to estimate the water content of the cellulosic insulation. However, it has been suggested in an IEEE Standard that errors of up to 200 % can be present. Due to a utility often operating a large number of power transformers, it is not practical to use better online methods (due to installation costs) or dielectric response (having to disconnect the unit) to monitor water content in a financially constrained economy. Therefore, a field study was performed to investigate how to improve the accuracy of determining the water content of paper using the traditional Karl Fischer titration method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISGT-Asia.2017.8378358 },
  booktitle={ 2017 IEEE Innovative Smart Grid Technologies - Asia (ISGT-Asia) },
  chapter={0}
}

@article{rayyan-352345372,
  title={ Protection of Terminal Distribution Transformers: A Case Study of Kenya Power  -  2018 IEEE PES/IAS PowerAfrica },
  year={2018},
  author={Muriuki, J. and Muriithi, C. M. and Ngoo, L. and Nyakoe, G. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8521121 },
  abstract={The paper presents and analyses the main causes of high failure rate of Terminal Distribution Transformers (TDTs) in Kenya. These transformers are the most susceptible to faults emanating from lightning strikes and associated overvoltage. Over a period of time and more recently, the failure rate of the TDTs have been on an upward trend despite the standard earthing and protection systems being provided. Failed TDTs are quickly replaced without due diligence for innovative ideas to prevent future failures leading to huge revenue loss for Kenya power and electricity consumers. This research therefore provides an innovative solution for TDTs by extending the Medium Voltage (MV) power line one span away from the TDT where installation of Terminal Surge Diverters Earth (TSDE) and Terminal Medium Voltage Earth (TMVE) are done. The results show that with the adoption of this innovative arrangement, the failure rate of TDTs have reduced significantly.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica.2018.8521121 },
  booktitle={ 2018 IEEE PES/IAS PowerAfrica },
  chapter={0}
}

@article{rayyan-352345373,
  title={ More Efficient AC Filterless HVDC with Low Noise of Transformer  -  2020 12th IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  year={2020},
  author={Luo, L. and Li, C. and Wu, J. and Li, Y. and Zhuang, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9220541 },
  abstract={In order to improve the commutation performance of HVDC transmission system and reduce the noise interference generated by the converter transformer during operation, the AC filterless HVDC system based on shunt capacitor commutation (ASCCC) is proposed in this paper. This system can achieve good harmonic filtering performance without a passive filter. Firstly, the topology structure and mathematical model of the system are given, and the principle of commutation and filtering is analyzed. Combined with the principle of transformer magnetostriction, the noise reduction mechanism of converter transformer is given. Finally, based on the proposed topology, a prototype is built for experiments. The results show that the system can prevent inverter commutation failure without AC filter, filter out harmonics generated in the system and reduce noise generated by the transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APPEEC48164.2020.9220541 },
  booktitle={ 2020 12th IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  chapter={0}
}

@article{rayyan-352345374,
  title={ Decision guidelines for transformer tank stress analysis using finite element method  -  2014 International Conference on Smart Structures and Systems (ICSSS) },
  year={2014},
  author={Abbas, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006198 },
  abstract={The transformer tank is designed to withstand pressure and vacuum loads as required by the standards and customer requirements. The analysis of the design requires finite element analysis since closed form solutions are not available for the transformer tank type structures. The transformer tank failure is usually due to excessive permanent deformation but sometimes the tank also develops cracks under pressure loads. Materially nonlinear analysis is required because rarely, if ever does transformer tank not sustain permanent deformations which are caused by material nonlinearity. But the analysts often resort to linear analysis as the nonlinear analyses are very time consuming. Generally Localized high stresses due to stress concentrations are often ignored since the steel used for tank is ductile and localized plasticity is usually alleviated by the plastic deformation of the plates. This analysis procedure poses problems as the stress concentration can sometimes cause local cracking of the tank. In this work, this phenomenon is investigated and guidelines to deal with the same are formulated. Also a case study is presented implementing the same.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSSS.2014.7006198 },
  booktitle={ 2014 International Conference on Smart Structures and Systems (ICSSS) },
  chapter={0}
}

@article{rayyan-352345375,
  title={ Experimental study on operational reliability of a kind of all fiber-optic current transformer  -  2014 International Conference on Power System Technology },
  year={2014},
  author={Liu, X. and Xiao, H. and Dai, J. and Guo, K. and Yang, F. and Wang, X. and Chen, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993799 },
  abstract={Compared with other kinds of electronic instrument transformers, the All Fiber-Optic Current Transformer (FOCT) have the advantages of high accuracy, wide dynamic range, strong ability to resist electromagnetic interference environment, simple and flexible of installation. But because of the short-time application, the operation reliability of FOCT can't be assessed base on the operational log we have now. According to this situation, the study on the structure and work environment had been done, in order to find the main environment parameter which affect on the aging of FOCT. Then the accelerated aging tests had been done on the components of a FOCT such as photo detector, optical source and optical phase modulator Then the mean time between failures (MTBF) of these components had been estimated base on the results of aging tests. Finally we can assess the operation reliability of FOCT. The results indicated that the MTBF of SLD light source is shorter than other Optical Components in the current transformer which was studied on. And dual-redundant design could be used to increase the MTBF of optical sensor parts. Thus the MTBF of this all-optical current transformer could satisfy the requirement of 30 years long-term stable operation of instrument transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/POWERCON.2014.6993799 },
  booktitle={ 2014 International Conference on Power System Technology },
  chapter={0}
}

@article{rayyan-352345376,
  title={ A Countermeasure for the Restraint of the Differential Protection in Converter Transformer  -  2018 IEEE International Conference on Automation, Electronics and Electrical Engineering (AUTEEE) },
  year={2018},
  author={Danhui, W. and Yu, C. and Junchao, Z. and Minghao, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8720758 },
  abstract={The differential protection is one of the most common main protections of the converter transformer. In order to deal with the mal-operation of the differential protection when magnetizing inrush occurs, it's highly recommended that the 2nd order harmonic restraint criterion should be introduced to restrain the differential protection when magnetizing inrush occurs. However, there will be a new problem after the introduction of the 2nd order harmonic restraint criterion when internal faults occur. When faults occur at the inverter side, the faults may cause the inverters happen commutation failure, which may produce abundant harmonic components. Then, the 2nd order harmonic, which is caused by the commutation failure, may be high enough to make the 2nd order harmonic restraint criterion restrains the differential protection in converter transformer. In order to avoid the restraint of the differential protection, this paper proposes an effective countermeasure by using the commutation failure protection, and proves the effectiveness of the countermeasure via simulations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AUTEEE.2018.8720758 },
  booktitle={ 2018 IEEE International Conference on Automation, Electronics and Electrical Engineering (AUTEEE) },
  chapter={0}
}

@article{rayyan-352345377,
  title={ Research on application of multivariate cumulative chart in transformer fault warning  -  2022 4th International Conference on Electrical Engineering and Control Technologies (CEECT) },
  year={2022},
  author={Zhou, H. and Bin, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10030733 },
  abstract={Transformer as a key part of the power system, whether in the transmission link or distribution link, to a large extent, whether the normal operation of power transformer can be guaranteed determines the stable operation of the power system. In order to find transformer faults in time, some scholars have put forward many related methods. Although it has been proposed to solve the problem that traditional methods are difficult to early warn transformer faults by introducing control charts in mathematical statistics, this method dose have certain limitations. When the sample data analyzed is discontinuous or missing, the analysis accuracy of control chart will decrease. In addition, this method is a pure theoretical analysis of dissolved gas data in oil, which does not take into account the influence of the actual operation of the transformer on the analysis results, so the reliability of the results cannot be guaranteed. After optimization, the multivariate cumulative sum control chart with parameter estimation can overcome the problems of too high parameter requirements and no early warning when the data is missing and can achieve better prediction accuracy even lack of data, which is more suitable for transformer fault early warning.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEECT55960.2022.10030733 },
  booktitle={ 2022 4th International Conference on Electrical Engineering and Control Technologies (CEECT) },
  chapter={0}
}

@article{rayyan-352345378,
  title={ Comprehensive Method for Determining Transformer Decommissioning Life Considering Economic Life and Physical Life  -  2021 31st Australasian Universities Power Engineering Conference (AUPEC) },
  year={2021},
  author={Xu, Y. and Liu, F. and Lai, X. and Yu, M. and Yang, X. and Wen, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597728 },
  abstract={Accurately calculating the decommissioning life of power transformers is not only helpful for maintaining their operational security and reliability, but also can enhance the economic operation of the power system concerned. This paper proposes a comprehensive method to determine the decommissioning life of power transformers considering both the economic life and physical life. First, according to the Life Cycle Cost (LCC) model of power transformers, a mathematical model of initial cost, operating and maintenance cost, failure cost and disposal cost is established. Then the economic life of power transformers is obtained based on the annual average LCC curve. Secondly, the physical life of power transformers is calculated by first correcting the expected service life with the load factor, temperature factor and humidity factor, and then correcting it with the failure number during operation. Finally, the theoretical decommissioning life of power transformers is attained by comprehensively considering both the economic life and physical life.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AUPEC52110.2021.9597728 },
  booktitle={ 2021 31st Australasian Universities Power Engineering Conference (AUPEC) },
  chapter={0}
}

@article{rayyan-352345379,
  title={ Modeling based on frequency to oversee the condition of transformer  -  2017 Innovations in Power and Advanced Computing Technologies (i-PACT) },
  year={2017},
  author={Sasikumar, S. and Kulkarni, V. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245192 },
  abstract={Although transformers are one of the most familiar parts of the power system they are even more complex to model. With modeling comes the question of accuracy. These days due to varied reasons, mainly short circuit faults, the transformer failures have increased excessively. For this reason and so as to predict the faults before their occurrence the modeling of transformers becomes imperative. This paper discusses the numerous reasons for transformer deterioration. Also it discusses the internal condition monitoring of the transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPACT.2017.8245192 },
  booktitle={ 2017 Innovations in Power and Advanced Computing Technologies (i-PACT) },
  chapter={0}
}

@article{rayyan-352345380,
  title={ Economic Analysis and Research of Electronic Traction Transformer used in Flexible Traction Power Supply System  -  2022 IEEE 17th Conference on Industrial Electronics and Applications (ICIEA) },
  year={2022},
  author={Gao, X. and He, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10006332 },
  abstract={The flexible traction power supply system based on power electronic device can cancel the electrical phase separation of the existing railway, which can bring many direct and indirect economic benefits to the railway. This paper takes flexible traction power supply system as the research background, and takes its core equipment -- electronic traction transformer as the research object. Firstly, this paper studies the topological structure and control mode of three-level three-phase to single-phase cascaded converter. Under the scheme of 1700V, 3300V and 4500V voltage class level IGBT, the system parameters and the number of cascaded modules are designed, and the simulation model of the system is built in Matlab/Simulink. The reliability analysis method of "device level - module level - system level" and the average fault-free working time for electronic traction transformer are studied. The investment cost of electronic traction substation is studied, and the reliability - cost benefit comparison analysis of three schemes is made. The recommended system switch tube and module number selection are given. In this paper, the economic analysis of electronic traction transformer used in flexible traction power supply system is carried out, which can provide the basis for the engineering popularization of the system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIEA54703.2022.10006332 },
  booktitle={ 2022 IEEE 17th Conference on Industrial Electronics and Applications (ICIEA) },
  chapter={0}
}

@article{rayyan-352345381,
  title={ Optimization of Transformer Replacement Strategies for Cost Efficiency  -  2024 10th International Conference on Condition Monitoring and Diagnosis (CMD) },
  year={2024},
  author={Do, I. and Park, G. -H. and Kim, Y. -H. and Park, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766254 },
  abstract={Replacing power equipment requires a cost-effective approach due to budget constraints. Recent studies have proposed methods to predict the usable life of transformers and reduce costs through life assessment. Based on this life assessment, this study proposes a model that optimizes using the B&C (Bound & Cut) technique to maximize the net present value (NPV) within the investment planning period. The B&C technique involves dividing the problem into subproblems and solving each subproblem to derive the optimal solution. The proposed model compares and analyzes the costs and benefits of life-based equipment replacement and optimization-based equipment replacement to propose strategies for maximizing the efficiency of power equipment replacement within a limited budget. This approach is expected to contribute significantly to ensuring the stability and economy of power equipment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/CMD62064.2024.10766254 },
  booktitle={ 2024 10th International Conference on Condition Monitoring and Diagnosis (CMD) },
  chapter={0}
}

@article{rayyan-352345382,
  title={ Condition monitoring and reliability analysis of underground transformers  -  2017 IEEE Conference on Energy Internet and Energy System Integration (EI2) },
  year={2017},
  author={Wang, Q. G. and Ding, Z. Q. and Wang, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245346 },
  abstract={In the context of underground cavern facilities, the electrical power substation is now located underground instead of the conventional aboveground. The operating environment of the power system has therefore changed, which may directly degrade the heat dissipation capability of the power system. Power system components such as transformers and power cables generate heat as a consequence of ohmic and magnetic losses. To ensure the safe and reliable operation of underground power systems, the online condition monitoring and reliability analysis system (CMRAS) for cast-resin dry-type transformers was designed, test-bedded and studied in rock caverns. The CMRAS includes the condition monitoring and data retrieving, prediction, early warning and alarm for management of operational status of dry-type transformers in real time. As the harsher underground operation environment will impact the durability of the key components of the underground substation, aging analysis was conducted with algorithms developed to forecast failures and estimate residual life span of the dry-type transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI2.2017.8245346 },
  booktitle={ 2017 IEEE Conference on Energy Internet and Energy System Integration (EI2) },
  chapter={0}
}

@article{rayyan-352345383,
  title={ Research on Transformer Risk Assessment Model Considering Offshore Petroleum and Gas Environment  -  2023 Panda Forum on Power and Energy (PandaFPE) },
  year={2023},
  author={Ni, P. and Chen, G. and Yang, W. and Zhang, L. and Tang, T. and Hu, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10140636 },
  abstract={Transformer is one of the key equipment in the power system platform, and its operation status is directly related to the system operation status. In order to ensure the reliable and stable operation of the transformer, it is necessary to develop a condition-based maintenance plan for it. Therefore, it is of great significance to carry out effective risk assessment and formulate corresponding maintenance strategies according to the assessment results. Divide risk probability into failure rate and risk consequence, build failure rate model based on state assessment, aging, weather and system coupling, and quantify risk from maintenance, power grid, human and environment. Establish risk assessment model for transformer. Finally, the feasibility and effectiveness of the model is verified by the risk assessment of a transformer on an offshore platform. The model can reflect the operation status of transformer more comprehensively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PandaFPE57779.2023.10140636 },
  booktitle={ 2023 Panda Forum on Power and Energy (PandaFPE) },
  chapter={0}
}

@article{rayyan-352345384,
  title={ On the transmission power transformers in Nigeria: Lagos sub region as case study  -  2016 IEEE PES PowerAfrica },
  year={2016},
  author={Ayodele, T. R. and Ogunjuyigbe, A. S. O. and Ojo, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556594 },
  abstract={Increasing pressure from both customers and regulators to maintain and enhance service reliability, while at the same time controlling costs has put power utilities on their toes. In view of this, asset management has become an increasingly important aspect of power business strategies such that electricity companies can utilize assets to the fullest while maintaining system reliability. This paper discusses the transformer fleet in the most obvious region of the Nigerian Electricity Industry. 15 years data (1990–2004) on transformer failure was collected and collated for the transformer population of the region. Statistical means was used to express the age distribution of transformer for 10year spread (2007–2017) and identified that about 58.82% of these transformers will exceed the average technical life. It thus, present the need for a proper replacement/refurbishment expenditure profile for transformers over the next 10 years; development of a user friendly condition assessment and prioritization tool for field personnel and management reporting, such that the subsequent failure rate of transformers can be reduced.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica.2016.7556594 },
  booktitle={ 2016 IEEE PES PowerAfrica },
  chapter={0}
}

@article{rayyan-352345385,
  title={ Analysis of 750kV Main Transformer High Voltage Side Bushing Faults Based on Multi-Detection Technology  -  2022 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  year={2022},
  author={Xiu, Z. and Kui, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9961811 },
  abstract={Shahu 750 kV substation is the hub substation of the northern Ningxia power grid, the station's 750 kV system is directly connected to the 750 kV system of the ±800 kV Shanghaimiao EHV converter station, the reliable operation of the 750 kV main transformer at Shahu Station has a huge impact on the ±800 kV Shanghaimiao EHV DC outgoing transmission. The high voltage side bushing is one of the most important components of the 750 kV main transformer, and in recent years there have been a number of power grid outages caused by the high voltage side bushing of the main transformer, even resulting in a forced shutdown of the DC outgoing transmission. This paper takes the C-phase high-voltage side bushing of the No. 3 main transformer of the Shahu 750 kV substation as an example. Through site investigation and protection recording analysis, the fault site is identified, then the electrical test, physical and chemical test, and simulation analysis are used to clarify the fault mechanism and causes, and finally, the same type of bushing is investigated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE53725.2022.9961811 },
  booktitle={ 2022 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  chapter={0}
}

@article{rayyan-352345386,
  title={ Comprehensive economic benefit evaluation method of transformer update based on risk assessment theory  -  CICED 2010 Proceedings },
  year={2010},
  author={Zhang, Yongjun and Xu, Tao and Shi, Hui},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5736153 },
  abstract={The economic benefit evaluation of transformer update is the key issues to promote the energy-saving reconstruction of distribution systems in China. In this paper risk assessment theory is applied to evaluate the benefit of distribution transformer update. Transformer failure modes are analyzed in view of the different failure mechanisms in various operating phases and characteristics of all kinds of failure modes are introduced. Unavailability of repairable and non-repairable forced failures is separately derived based on the probability theory. Quantified unavailability is integrated with the corresponding power outage loss caused by transformer failures to calculate transformer operational risks. And the risk difference also known as risk return between old transformer and updated transformer is calculated by discrete numerical analysis. Based on payback period method, the comprehensive economic benefit model of distribution transformer update is presented by integrating the risk return,old transformer residual value,decreasing reactive power compensation cost, decreasing transmission and generating capacity investment and annual power loss saving of networks. Simulation shows that as risk return and decreasing transmission and generating capacity investment are taken into account, the payback period of transformer update project becomes greatly shorter, furthermore SH15-type transformer's energy-saving effect is superior to S13-type transformer. The proposed model is more integrated and rational than traditional evaluation methods in accord with Entire Life-Cycle Management Viewpoint and offers a new idea for economic benefit evaluation of transformer update project.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ CICED 2010 Proceedings },
  chapter={0}
}

@article{rayyan-352345387,
  title={ A Fault Diagnosis Method of Power Transformer Based on Improved DDAG-SVM  -  2021 IEEE 2nd China International Youth Conference on Electrical Engineering (CIYCEE) },
  year={2021},
  author={Wang, G. and Xia, G. and Su, Z. and Dai, Y. and Lu, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676904 },
  abstract={With the development of artificial intelligence technology, neural networks, fuzzy technology, expert systems, grey system theory, fuzzy clustering and other methods have gradually been applied to transformer fault diagnosis, and have achieved better diagnostic results. However, the above methods all have certain shortcomings. For example, knowledge-based methods such as artificial neural networks need to obtain an infinite number of fault samples, and the training time is long, and there are problems such as local optimal solutions; This paper proposes a transformer fault diagnosis method based on the improved DDAG-SVM, which enriches the transformer fault diagnosis information, and combines the dissolved gas composition, content and change in the oil, operating voltage and current and other information to establish a comprehensive fault diagnosis system based on the transformer. It is helpful to guide the efficient development of maintenance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIYCEE53554.2021.9676904 },
  booktitle={ 2021 IEEE 2nd China International Youth Conference on Electrical Engineering (CIYCEE) },
  chapter={0}
}

@article{rayyan-352345388,
  title={ A Multilevel Diagnosis Method for Large Transformer Fault Modes under Multi-sensor Information Fusion  -  2024 IEEE 2nd International Conference on Power Science and Technology (ICPST) },
  year={2024},
  author={Liu, S. and Yang, H. and Cai, M. and Ye, Y. and Wang, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602399 },
  abstract={The conventional multi-level diagnosis method for fault mode of large transformers mainly uses INGO (Impacted Northern Goshak Optimization) random differential perturbation to improve the Northern Goshawk algorithm to build a quasi segment model, which is vulnerable to the influence of NGO search and update behavior, resulting in abnormal diagnosis alarms. Therefore, a multi-level diagnosis method for fault mode of large transformers under multi-sensor information fusion is proposed. That is to say, using multi-sensor information fusion to build a multi-level diagnosis framework of large-scale transformer fault mode, and design a multi-level diagnosis algorithm of large-scale transformer fault mode, thus completing the multi-level diagnosis of large-scale transformer fault mode. The experimental results show that the designed fault mode multi-level diagnosis method for large transformers can effectively complete the alarm at different diagnosis times, and each diagnostic index is good, which proves that the designed fault mode multi-level diagnosis method has good diagnosis effect, reliability, and certain application value, and has made certain contributions to reducing the operation safety risk of large transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPST61417.2024.10602399 },
  booktitle={ 2024 IEEE 2nd International Conference on Power Science and Technology (ICPST) },
  chapter={0}
}

@article{rayyan-352345389,
  title={ Influence of Capacitor Voltage Transformer's Transient Response on Commutation of HVDC Transmission System  -  2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA) },
  year={2020},
  author={Dandan, Z. and Yilie, C. and Danzhen, G. and Sanshan, Z. and Chenlei, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213577 },
  abstract={The capacitor voltage transformer (CVT) has a transient response when a fault occurs on the inverter side of HVDC. The output voltage at the secondary side of CVT can not accurately reflect the change of the input voltage at the primary side in time, which will affect the commutation process of the DC system. This paper first establishes a simulation model in PSCAD/EMTDC with the actual parameters of the 220kV saturated CVT, and analyzes the effects of different factors on the transient process. The principle of commutation failure predictive control (CFPREV) is analyzed, and its input voltage has an impact on the commutation process of the DC system. Based on the simulation of East China Power Grid Ge Nan DC model, the AC voltage considering the CVT transient response is used as the input voltage for CFPREV, and the CFPREV link and commutation process are analyzed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AEECA49918.2020.9213577 },
  booktitle={ 2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA) },
  chapter={0}
}

@article{rayyan-352345390,
  title={ LVQ neural network for identification of abnormal conditions within transformers  -  2015 50th International Universities Power Engineering Conference (UPEC) },
  year={2015},
  author={Beshr, E. and Sharkawy, R. M. and El-Hamid, A. S. Abd},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339845 },
  abstract={Simulation and discrimination of several different types of insulation failure has been proposed. In the present paper, five types of insulation failures that are apt to occur in power transformers are simulated using PSIM. Input-output voltage as well as input current of each insulation failure type is monitored and hence constructing the (ΔV- Iin) locus diagram which is used for providing the state of the transformer. A discrimination process utilizing neural networks is developed to distinguish any deviations of the locus with respect to the reference one.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UPEC.2015.7339845 },
  booktitle={ 2015 50th International Universities Power Engineering Conference (UPEC) },
  chapter={0}
}

@article{rayyan-352345391,
  title={ Measurement of Partial Discharges in Distribution Transformers Immersed in Insulating Liquids  -  2024 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  year={2024},
  author={Fagundes, T. F. D. and Neto, E. T. W. and Lopes, G. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10676147 },
  abstract={In distribution networks, one of the most common and important equipment is the oil-insulated transformer, which can suffer irreparable damage to the system under load if it presents any failure, especially in the insulation. One of the factors involved in this type of defect is partial discharge (PD), which can cause degradation of the paper and insulating oil, causing inoperability and reducing the useful life of the transformer. Therefore, it is essential to carry out a study on the types of partial discharges present in the transformer and the methods for detecting this phenomenon. In this sense, this work proposes carrying out tests using the electrical method to detect PD in a set of five samples of oil-insulated distribution transformers. To this end, a specific procedure was adopted to carry out the test, as there is no method in Brazil described in standards for distribution transformers immersed in insulating liquids with a voltage lower than or equal to 72.5 kV. In this sense, after the test, it was possible to identify partial discharges in the internal insulation of some transformer samples, in addition to recognizing the need to carry out periodic inspections and predictive maintenance on this equipment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE61955.2024.10676147 },
  booktitle={ 2024 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  chapter={0}
}

@article{rayyan-352345392,
  title={ Fault tracing method for high voltage electronic current transformer during its performance test based on the FMEA  -  2018 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) },
  year={2018},
  author={Wang, P. and Jinsong, L. and Hailong, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409693 },
  abstract={Electronic current transformer (ECT) is a new type of high-voltage instrument transformer. It constitutes more components than that of the traditional one. To locate the fault accurately and rapidly during its performance tests, this paper proposed a fault tracing method based on the failure modes and effects analysis (FMEA). From the measuring results of the ECT under test, together with its failure patterns and the test types, we can easily locate its fault in the FMEA tables, and repair them quickly. The presented method is verified to be useful in the results of the analysis on two practical examples.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/I2MTC.2018.8409693 },
  booktitle={ 2018 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) },
  chapter={0}
}

@article{rayyan-352345393,
  title={ Remaining Useful Life Prediction Based on Transformer with A Tiny Representation Network  -  2022 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD) },
  year={2022},
  author={Wang, G. and Liu, D. and Cui, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058279 },
  abstract={Remaining useful life (RUL) prediction is of great significance to the prognostic and health management of rolling bearings. The effectiveness of the typical RUL prediction relies on the constructed health indicator (HI) which only represents limited degradation information. In addition, rolling bearing degradation is a long-term process, while existing RUL prediction models show a limited ability to learn a long-distance dependency. To fill the above research gap, we propose a novel RUL prediction Transformer (RPT) which consists of a tiny convolution-based representation network (RN) and an advanced Transformer feature extractor. In the proposed RPT, the row vibration signals are concisely and efficiently embedded into a tiny feature space by the RN. Then, embedded vectors of historical run-to-failure data are input into the transformer feature extractor to learn potential prediction knowledge. Due to the global attention machine, the RPT can learn long-distance dependency, which significantly improves the RUL prediction. Compared with state-of-the-art models, RPT attains more accurate RUL prediction.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSMD57530.2022.10058279 },
  booktitle={ 2022 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD) },
  chapter={0}
}

@article{rayyan-352345394,
  title={ On Deep Learning for Condition Assessment of Power Transformers  -  2024 IEEE PES 16th Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  year={2024},
  author={Jiang, H. and Ekanayake, C. and Ma, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922252 },
  abstract={Accurately assessing power transformers' health condition and calculating their probability of failure (PoF) can facilitate decision-making with respect to the operation and maintenance of transformers. Among various data and information used for transformer condition assessment and PoF calculation, the Dissolved Gas Analysis (DGA) plays a key role in diagnosing transformer incipient faults. In this paper, we have developed a deep learning-based model to improves the effectiveness of DGA interpretation for transformer condition assessment. Then, the refined DGA results are used alongside other transformer measurement data to support the PoF calculation and risk cost analysis. The method developed in this paper has been validated using the dataset collected from numerous in-service power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APPEEC61255.2024.10922252 },
  booktitle={ 2024 IEEE PES 16th Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  chapter={0}
}

@article{rayyan-352345395,
  title={ Importance evaluation method on the fault modes of power transformer based on trapezoidal fuzzy number  -  2012 China International Conference on Electricity Distribution },
  year={2012},
  author={Liu, Jun and Chen, Wei-gen and Zhou, Jing-jing},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6508477 },
  abstract={The fault modes of the components of the power transformer is complex and highly correlated, and the implementation of reliability tests is difficult because of the high value of the equipment, so it is hard to make importance evaluation by using traditional method. Aiming at those problems, a new evaluation method on importance based on trapezoidal fuzzy number is proposed in this paper. Firstly, the evaluation index system of importance is established which using the Delphi method to formulate the score rating criteria and applying the coordination degree to amend the scores. Secondly, the trapezoidal fuzzy numbers is applied to determine the weight indicator. Last, the importance of each failure mode of transformer is determined on the basis of the indicator combining with the weight through the linear weighting method. It is shown by the instance that this method is convenient and effective, which can be used in making the reliability evaluation and maintenance decision of the power transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CICED.2012.6508477 },
  booktitle={ 2012 China International Conference on Electricity Distribution },
  chapter={0}
}

@article{rayyan-352345398,
  title={ Inference of the definition of the predicate transformer WP with occurrences of the predicate domain based on denotational semantics of GCL on ZF set theory  -  nan },
  year={2018},
  author={F and Flaviani and Federico},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071095138&doi=10.1109%2FCLEI.2018.00095&partnerID=40&md5=41ec4a4236ee110856e7e3151f1f3459 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CLEI.2018.00095 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345402,
  title={ Electric power system simulation for risk assessment of power transformer failure under external short-circuit conditions  -  nan },
  year={2017},
  author={E.I and Bardyk and I, Evgen and N.P and Bolotnyi, N. P},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039912953&doi=10.1109%2FUKRCON.2017.8100527&partnerID=40&md5=9c603f517c645153ee3d5815fd2ce6a0 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/UKRCON.2017.8100527 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345405,
  title={ Health index assessment for power transformers with thermal upgraded paper up to 230kV, using fuzzy inference. Part II: A sensibility analysis  -  nan },
  year={2017},
  author={D.P and Chacón-Troya and Paul, Diego and J.P and Lata and Pablo, Juan and R.D and Medina and David, Ricardo},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025813127&doi=10.1109%2FICCDCS.2017.7959705&partnerID=40&md5=998e922e08d04639f0729c21d95edb06 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCDCS.2017.7959705 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345407,
  title={ Transformer paper condition assessment using Adaptive Neuro-Fuzzy Inference System model  -  nan },
  year={2017},
  author={R.A and Prasojo and Azis, Rahman and K and Diwyacitta and Karunika and S and Suwarno and Suwarno and H and Gumilang and Harry},
  url={ https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040229185&doi=10.1109%2FICECOS.2017.8167141&partnerID=40&md5=1fe7b8e192a0075a93750098c97363c5 },
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECOS.2017.8167141 },
  booktitle={ nan },
  chapter={0}
}

@article{rayyan-352345408,
  title={ Risk-Cost Integrated Assessment Based Overhaul Strategies for Transformers  -  2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2) },
  year={2023},
  author={Li, H. and Zhu, B. and Chen, X. and Wen, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10513241 },
  abstract={Reliable operation of transformers is of significant importance to the entire power system concerned. Therefore, it is necessary to reduce the failure rate of transformers through timely overhaul. Given this background, the optimal overhaul planning problem for transformers is addressed in this work based on risk-cost integrated assessment. First, a linear aging regression model is established employing the Weibull distribution based failure rate model of transformers. The investment and operation costs of transformers are next classified and calculated according to the theory of Life Cycle Cost (LCC). Subsequently, from the perspective of managing risk, the optimal overhaul time under different overhaul frequencies is formulated as an optimization problem and solved by the Particle Swarm Optimization (PSO) algorithm, and economic analysis based on the annual average LCC is carried out. Finally, a case study is conducted to demonstrate the proposed approach.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI259745.2023.10513241 },
  booktitle={ 2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2) },
  chapter={0}
}

@article{rayyan-352345409,
  title={ Fast Arc Detection in Power Transformer Using Fiber Optic Sensor  -  2024 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  year={2024},
  author={Sharifi, A. and Kuhnke, M. and Werle, P. and Akbari, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10676059 },
  abstract={Arc is one of the most dangerous faults in transformers, and it can increase the internal pressure of the transformer tank within milliseconds, resulting in serious consequences such as explosion. Transformers are equipped with Buchholz relays (BHR) to detect faults, enabling circuit breakers (CB) to disconnect the transformer. The time duration between the internal fault occurrence and the disconnection of the transformer is typically around 100 milliseconds. Due to the intensity of the arc energy and the sudden increase in pressure inside the transformer, the power interruption cannot be performed fast enough in some cases, leading to a tank rupture. Therefore, the objective of this investigation is to develop a method for detecting arcs before the rapid increase in pressure. To achieve this objective, a novel sensor is designed using fiber optic cable to recognize the visible light emitted by the arc. In this article, the sensor and its operation are introduced first, and then it is tested in different conditions such as different oils, temperature variations, reflecting housing, and oils with different degrees of aging. According to the results, the method presented in this study shows a high potential for fast arc detection. Moreover, this sensor is well optimized for application inside the transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE61955.2024.10676059 },
  booktitle={ 2024 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  chapter={0}
}

@article{rayyan-352345410,
  title={ A 110kV Main Transformer Substation Insulation Fault Analysis  -  2024 International Conference on Electrical Power Systems and Intelligent Control (EPSIC) },
  year={2024},
  author={Li, P. and Li, H. and Ma, M. and Ai, Y. and Zhang, Y. and Li, H. and Yin, Q. and Guo, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10803566 },
  abstract={This paper briefly describes the failure situation of qinghe 1 # main transformer, and according to the comprehensive data of high pressure test and oil chromatography test, the failure cause of the A phase winding is analyzed, and finally put forward the reasonable accident prevention measures, to provide reference to prevent the occurrence of similar faults in the future.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EPSIC63429.2024.00015 },
  booktitle={ 2024 International Conference on Electrical Power Systems and Intelligent Control (EPSIC) },
  chapter={0}
}

@article{rayyan-352345411,
  title={ Fault Analysis of a Transformer Tripping and Protection Rejection  -  2019 IEEE 3rd Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC) },
  year={2019},
  author={Niu, S. and Hu, F. and An, R. and Liang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984073 },
  abstract={Two-phase ground short circuit occurred on 35kV side of main transformer in a 220 kV substation. The low voltage side 301 circuit breaker did not jump off. Then the differential protection of the main transformer is started, which causes tripping of the three sides of the main transformer and no load loss. In this paper, the primary equipment, secondary equipment and monitoring background information related to the fault are investigated and analyzed in detail, and the causes and development process of the fault are restored. Because of the special fault, in order to avoid the similar situation happening again, some suggestions are put forward for the improvement of the merged intelligent device.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMCEC46724.2019.8984073 },
  booktitle={ 2019 IEEE 3rd Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC) },
  chapter={0}
}

@article{rayyan-352345412,
  title={ Least deviation methods for location of partial discharge in transformer windings  -  2010 Joint International Conference on Power Electronics, Drives and Energy Systems & 2010 Power India },
  year={2010},
  author={Jeyabalan, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5712489 },
  abstract={Partial discharge location is important for transformer maintenance and repair. In this paper, the location of PD is identified using least deviation methods. The simulation studies are carried out on lumped layer winding to prove the feasibility of the methods and also validated with 22kV transformer windings. The efficacy of the methods is also checked with standard PD calibrator and multiple discharges.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PEDES.2010.5712489 },
  booktitle={ 2010 Joint International Conference on Power Electronics, Drives and Energy Systems & 2010 Power India },
  chapter={0}
}

@article{rayyan-352345413,
  title={ Protection Configuration and Circuit Optimization Schemes of 220kV Line Transformer Group  -  2023 IEEE International Conference on Advanced Power System Automation and Protection (APAP) },
  year={2023},
  author={Li, Y. and Shi, H. and You, H. and Chen, X. and Yang, Q. and Shi, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10348479 },
  abstract={Currently, the green and low-carbon transformation of electricity is accelerating, and the cumulative installed scale of new energy is constantly expanding. In order to save investment, some 220kV new energy plants adopt line transformer group wiring, and separate circuit breakers protection are required to achieve failure protection function. This article proposes two types of protection configuration and circuit optimization schemes for 220kV line transformer groups. By optimizing the secondary circuit, the circuit by which line protection actions to trip the main transformer is added, and separate circuit breaker protection can no longer be configured. After optimization, it can achieve dual failure protection functions, avoid the risk of no failure protection or dead zone protection caused by improper circuit breaker protection configuration, save investment costs, and reduce equipment operation and maintenance costs, enhance reliability of protection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APAP59666.2023.10348479 },
  booktitle={ 2023 IEEE International Conference on Advanced Power System Automation and Protection (APAP) },
  chapter={0}
}

@article{rayyan-352345414,
  title={ Examination of failure modes on tertiary side of transformers in Czech transmission power system  -  2017 18th International Scientific Conference on Electric Power Engineering (EPE) },
  year={2017},
  author={Dudek, J. and Hrbac, R. and Veleba, J. and Ullman, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967313 },
  abstract={This paper describes the Failure Mode and Effects Analysis (FMEA) focusing on tertiary side of (E)HV/HV/MV transformers and MV self-consumption subsystem of the Czech transmission power system. The goal of this FMEA is a) to identify all possible failure modes, which can occur in the examined system; b) to determine the impact of each failure mode on upstream (E)HV/HV system (referred to as FMEA I.) and on MV self-consumption subsystem (referred to as FMEA II.); c) to evaluate the severity and frequency of each failure mode; and d) to propose suitable actions for mitigation or complete elimination of these failure modes and their impacts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EPE.2017.7967313 },
  booktitle={ 2017 18th International Scientific Conference on Electric Power Engineering (EPE) },
  chapter={0}
}

@article{rayyan-352345415,
  title={ A modification of the Norris failure criterion for the prediction of the mechanical failure of the aged paper insulation in the windings of a power transformer  -  2022 IEEE 4th International Conference on Dielectrics (ICD) },
  year={2022},
  author={Oria, C. and Ferreño, D. and Carrascal, I. and Ortiz, A. and Fernández, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9863458 },
  abstract={The deterioration of the insulation in the windings of power transformers affects their lifespan. A commercial insulated Continuously Transposed Conductor (CTC) was studied experimentally, numerically and analytically. The purpose was to understand the mechanisms governing the mechanical failure of the insulating paper, and to achieve a criterion for predicting failure under different conditions. Samples of that insulated CTC were extracted from a coil and aged at $150^{\circ}{\mathrm{C}}$ for different durations inside vessels filled with naphthenic oil. Then the degree of polymerisation and tensile, compressive and shear mechanical properties of the insulation were measured/estimated. Aged insulated CTC samples were subjected to three-point bending tests, producing deformations compatible with a short circuit, and the fractures in the insulation were analysed. The bending test over a CTC sample was simulated by means of a FEM Program. The Norris failure model, applicable to a lamina, was adapted to the studied insulation materials. The predictions of that failure criterion agreed with experimental observations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICD53806.2022.9863458 },
  booktitle={ 2022 IEEE 4th International Conference on Dielectrics (ICD) },
  chapter={0}
}

@article{rayyan-352345416,
  title={ Knowledge Management for Automobile Failure Analysis Using Graph RAG  -  2024 IEEE International Conference on Big Data (BigData) },
  year={2024},
  author={Ojima, Y. and Sakaji, H. and Nakamura, T. and Sakata, H. and Seki, K. and Teshigawara, Y. and Yamashita, M. and Aoyama, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10826046 },
  abstract={This paper presents a knowledge management system for automobile failure analysis using retrieval-augmented generation (RAG) with large language models (LLMs) and knowledge graphs (KGs). In the automotive industry, there is a growing demand for knowledge transfer of failure analysis from experienced engineers to young engineers. However, failure events are phenomena that occur in a chain reaction, making them difficult for beginners to analyze them. While knowledge graphs, which can describe semantic relationships and structure information is effective in representing failure events, due to their capability of representing the relationships between components, there is much information in KGs, so it is challenging for young engineers to extract and understand sub-graphs from the KG. On the other hand, there is increasing interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for knowledge management. However, when using the current Graph RAG framework with an existing knowledge graph for automobile failures, several issues arise because it is difficult to generate executable queries for a knowledge graph database which is not constructed by LLMs. To address this, we focused on optimizing the Graph RAG pipeline for existing knowledge graphs. Using an original Q&A dataset, the ROUGE F1 score of the sentences generated by the proposed method showed an average improvement of 157.6% compared to the current method. This highlights the effectiveness of the proposed method for automobile failure analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/BigData62323.2024.10826046 },
  booktitle={ 2024 IEEE International Conference on Big Data (BigData) },
  chapter={0}
}

@article{rayyan-352345417,
  title={ Research on Heart Failure Mortality Prediction Model Based on Imbalanced Medical Dataset  -  2024 3rd International Conference on Health Big Data and Intelligent Healthcare (ICHIH) },
  year={2024},
  author={Guo, Z. and Huang, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11064743 },
  abstract={This study utilized a clinical dataset from Zigong Hospital, accessible through the PhysioNet website, to investigate six-month mortality prediction in patients with heart failure using machine learning and deep learning approaches. Both algorithm-driven and data-driven strategies were compared to address the challenge of data imbalance. The potential of large language models (LLMs) in this domain was also explored. The analysis employed Python for feature selection and data preprocessing, constructing nine predictive models: logistic regression, support vector machine (SVM), decision tree, random forest, XGBoost, LightGBM, CatBoost, multi-layer perceptron (MLP), and one-dimensional convolutional neural network (1D-CNN). Stratified 5-fold cross-validation was utilized for comparative experiments, with the area under the receiver operating characteristic curve (AUC) and Recall as evaluation metrics. The results demonstrated that the data-driven Borderline-SMOTE method substantially improved Recall, though its effect on AUC was minimal. Furthermore, the algorithm-driven threshold adjustment method achieved a more pronounced improvement in Recall compared to the data-driven approach. The LLM-based model attained an AUC of 0.796 and a Recall of 0.358. Among the nine models with threshold adjustment, the LLM's AUC outperformed only the decision tree model, while its Recall exceeded those of XGBoost and LightGBM. In summary, the findings suggest that threshold adjustment is a more effective method for addressing data imbalance. While the LLM-based model exhibited lower performance than the top-performing models, this represents a pioneering effort in leveraging such models for predicting heart failure mortality, offering valuable insights and a foundation for future research.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHIH63459.2024.11064743 },
  booktitle={ 2024 3rd International Conference on Health Big Data and Intelligent Healthcare (ICHIH) },
  chapter={0}
}

@article{rayyan-352345418,
  title={ Best practices for Dielectric Frequency Response measurements and analysis in real-world substation environment  -  2012 IEEE International Conference on Condition Monitoring and Diagnosis },
  year={2012},
  author={Ohlen, M. and Werelius, P. and Cheng, J. and Skoldin, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416421 },
  abstract={Modern technology and developments in signal acquisition and analysis techniques have provided new tools for transformer and bushing diagnostics. Of particular interest are dielectric response measurements where insulation properties of oil-paper systems can be investigated. Dielectric Frequency Response, DFR (also known as Frequency Domain Spectroscopy, FDS), was introduced more than 20 years and has been thoroughly evaluated in a number of research projects and field tests with good results. DFR data in combination with mathematical modeling of the oil-paper insulation is proven as an excellent tool for moisture and oil conductivity assessment of power transformers. Dielectric response measurements are usually performed at a much lower voltage level than traditional power frequency tan-delta measurements. Due to this, the signal-to-noise ratio may sometimes be extremely low, especially at low frequencies and when measuring low capacitance objects e.g. bushings and instrument transformers. The interference suppression capability of the test set thus becomes an important parameter when considering different methods and instruments. In this paper investigation of the electromagnetic interference in terms of AC hum currents, induced DC currents and low frequency interference in AC as well as HVDC substations are presented. Solutions to handle these different types and levels of interference are investigated and examples of measurements under those conditions are presented. The paper also covers DFR response analysis using the XY-model. Numerical analysis using COMSOL has been performed and compared with the simplified analytical XY-model to investigate how non-ideal conditions influence geometry parameters and results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2012.6416421 },
  booktitle={ 2012 IEEE International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345419,
  title={ Measuring Improvement of F1-Scores in Detection of Self-Admitted Technical Debt  -  2023 ACM/IEEE International Conference on Technical Debt (TechDebt) },
  year={2023},
  author={Aiken, W. and Mvula, P. K. and Branco, P. and Jourdan, G. -V. and Sabetzadeh, M. and Viktor, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10207102 },
  abstract={Artificial Intelligence and Machine Learning have witnessed rapid, significant improvements in Natural Language Processing (NLP) tasks. Utilizing Deep Learning, researchers have taken advantage of repository comments in Software Engineering to produce accurate methods for detecting Self-Admitted Technical Debt (SATD) from 20 open-source Java projects’ code. In this work, we improve SATD detection with a novel approach that leverages the Bidirectional Encoder Representations from Transformers (BERT) architecture. For comparison, we re-evaluated previous deep learning methods and applied stratified 10-fold cross-validation to report reliable F1-scores. We examine our model in both cross-project and intra-project contexts. For each context, we use re-sampling and duplication as augmentation strategies to account for data imbalance. We find that our trained BERT model improves over the best performance of all previous methods in 19 of the 20 projects in cross-project scenarios. However, the data augmentation techniques were not sufficient to overcome the lack of data present in the intra-project scenarios, and existing methods still perform better. Future research will look into ways to diversify SATD datasets in order to maximize the latent power in large BERT models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TechDebt59074.2023.00011 },
  booktitle={ 2023 ACM/IEEE International Conference on Technical Debt (TechDebt) },
  chapter={0}
}

@article{rayyan-352345420,
  title={ An Empirical Study of Code Smells in Transformer-based Code Generation Techniques  -  2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM) },
  year={2022},
  author={Siddiq, M. L. and Majumder, S. H. and Mim, M. R. and Jajodia, S. and Santos, J. C. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10006873 },
  abstract={Prior works have developed transformer-based language learning models to automatically generate source code for a task without compilation errors. The datasets used to train these techniques include samples from open source projects which may not be free of security flaws, code smells, and violations of standard coding practices. Therefore, we investigate to what extent code smells are present in the datasets of coding generation techniques and verify whether they leak into the output of these techniques. To conduct this study, we used Pylint and Bandit to detect code smells and security smells in three widely used training sets (CodeXGlue, APPS, and Code Clippy). We observed that Pylint caught 264 code smell types, whereas Bandit located 44 security smell types in these three datasets used for training code generation techniques. By analyzing the output from ten different configurations of the open-source fine-tuned transformer-based GPT-Neo 125M parameters model, we observed that this model leaked the smells and non-standard practices to the generated source code. When analyzing GitHub Copilot's suggestions, a closed source code generation tool, we observed that it contained 18 types of code smells, including substandard coding patterns and 2 security smell types.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCAM55253.2022.00014 },
  booktitle={ 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM) },
  chapter={0}
}

@article{rayyan-352345421,
  title={ Transformer failures in regions incorrectly considered to have low GIC-risk  -  2007 IEEE Lausanne Power Tech },
  year={2007},
  author={Gaunt, C. T. and Coetzee, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538419 },
  abstract={A close association has been identified between the theoretical calculation of geomagnetically induced currents (GICs) in a large network, practical measurements of GICs, the results of dissolved gas analysis (DGA) records, and damage in recently failed transformers in Southern Africa. Together these indicate that GICs may contribute significantly to transformer failures on large transmission systems in mid-latitude regions, where GICs are generally thought not to be significant.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCT.2007.4538419 },
  booktitle={ 2007 IEEE Lausanne Power Tech },
  chapter={0}
}

@article{rayyan-352345422,
  title={ Corrosive Sulfur Induced Failures in Oil-Filled Electrical Power Transformers and Shunt Reactors  -  IEEE Transactions on Power Delivery },
  year={2009},
  author={Scatiggio, F. and Tumiatti, V. and Maina, R. and Tumiatti, M. and Pompili, M. and Bartnikas, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5109873 },
  abstract={The nature and causes of corrosive sulfur induced failures are examined in oil-filled transformers and shunt reactors. Copper sulfide, which is formed when the corrosive sulfur in a mineral oil reacts with the copper conductors, is likely to diffuse into the paper tapes insulating the conductors. Since copper sulfide is partially conducting, the dielectric losses of the contaminated oil-impregnated-paper tapes are markedly increased; paper tapes in close proximity to the copper conductors are found to attain tan delta values > 1.0 even at room temperature. It is highly likely that thermal instabilities develop at those sites at operating temperatures, leading to increased loss currents and, ultimately, short circuits between the turns. This sequence of events is substantiated by evidence from the field, which indicates large areas of thermally degraded insulations and charred breakdown regions along the coils, the extent of which becomes more pronounced at higher operating temperatures (toward the top of the windings).},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2008.2005369 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345423,
  title={ A new method for purposes of failure diagnostics and FRA interpretation applicable to power transformers  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2013},
  author={Pham, D. A. K. and Pham, T. M. T. and Borsi, H. and Gockenbach, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6678850 },
  abstract={To diagnose electrical and mechanical failures on the active part of power transformers efficiently, different state-of-the-art testing methods are recommended to be performed since transformers are complex devices. Measurement results can be equivalent electrical parameters relating to the windings (resistances, leakage/zero-sequence inductances and capacitances), core magnetic property (via induced voltages and exciting currents) or terminal frequency responses (standard FRA tests). Consequently, it is not easy for normal users to implement all necessary measurements, which require much time and training skills due to use of different specialized testing devices. To help users for fast and efficient diagnostics, the paper presents a new method in determining most electrical parameters of the transformer active part based on only the driving-point impedance tests performed by means of a vector-network analyzer. More importantly, the method can be applied to give a FRA interpretation based on physical electrical parameters, which is currently requested from relevant standards. The physical FRA interpretation is found to be useful in calculating immeasurable series capacitances of windings in transformer bulk, which is still problematic until now. Investigation on a large distribution transformer shows that the new method is simple, less time consuming but efficient.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2013.6678850 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345424,
  title={ Analysis and mitigation of Australian and New Zealand power transformer failures resulting in fires and explosions  -  IEEE Electrical Insulation Magazine },
  year={2019},
  author={Martin, D. and Beckett, C. and Brown, J. and Nielsen, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878255 },
  abstract={When making decisions on infrastructure operation and replacement, utilities must take into account the risk of an asset failing and starting a fire or exploding. However, the challenge in determining the likelihood of such a failure is that since their rate is so low, there is often little statistical information available on which to analyze. A question posed by the Australian and New Zealand utilities is whether transformer fires and explosions become more likely with age. Since the power transformer fleets of these two countries are comparable, with a large number entering the later years of their useful lives, a relationship between nameplate age and fire and explosion likelihood will have implications on replacement policy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2019.8878255 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352345425,
  title={ Investigation Into Modeling Australian Power Transformer Failure and Retirement Statistics  -  IEEE Transactions on Power Delivery },
  year={2018},
  author={Martin, D. and Marks, J. and Saha, T. K. and Krause, O. and Mahmoudi, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316925 },
  abstract={Analyzing the probability of power transformer failure is challenging because to observe a sufficient number of failures requires a fleet size larger than what is often operated by one utility. Parametric distributions have been applied to small datasets to model failure. However, an assumption is that the failure follows the chosen distribution. Reliability data from 97% of the 6057 utility-owned power transformers operating in mainland Australia and Tasmania were collected and analyzed to develop a more accurate understanding of failure statistics. Information on 564 failures and retirements occurring between 2000 and 2015 was collected, stratified into distribution, subtransmission, and transmission voltage class units, and then analyzed. The useful life of the three different populations was estimated, and the relationship between age and different failure types was investigated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2018.2814588 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345426,
  title={ Condition Data Aggregation with Application to Failure Rate Calculation of Power Transformers  -  Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06) },
  year={2006},
  author={Pathak, J. and Jiang, Yong and Honavar, V. and McCalley, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1579787 },
  abstract={Cost-effective equipment maintenance for electric power transmission systems requires ongoing integration of information from multiple, highly distributed, and heterogeneous data sources storing various information about equipment. This paper describes a federated, query-centric data integration and knowledge acquisition framework for condition monitoring and failure rate prediction of power transformers. Specifically, the system uses substation equipment condition data collected from distributed data resources, some of which may be local to the substation, to develop Hidden Markov Models (HMMs) which transform the condition data into failure probabilities. These probabilities provide the most current knowledge of equipment deterioration, which can be used in system-level simulation and decision tools. The system is illustrated using dissolved gas-in-oil field data for assessing the deterioration level of power transformer insulating oil.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/HICSS.2006.93 },
  booktitle={ Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06) },
  chapter={0}
}

@article{rayyan-352345427,
  title={ Bayesian Networks applied to Failure Diagnosis in Power Transformer  -  IEEE Latin America Transactions },
  year={2013},
  author={Carita, A. Javier Quispe and Leite, L. Cambraia and Medeiros, A. Pedro Pires and Barros, R. and l. Sauer},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601752 },
  abstract={This work describes the structure, learning and application of Bayesian Network to diagnosis of faults in power transformer through the dissolved gases analysis (DGA) in oil. The Bayesian Network uses the concentration ratios of gases methane/hydrogen (CH4/H2), ethane/methane (C2H6/CH4), ethylene/ethane (C2H4/C2H6) and acetylene/ethylene (C2H2/C2H4), as elements that activate the network diagnosis: normal deterioration, electrical failure and thermal failure. The learning was performed from historical database, and the Bayesian Network presented a high degree of reliability and consistency. The simulations suggest good results when compared to some existing in the literature.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TLA.2013.6601752 },
  booktitle={ IEEE Latin America Transactions },
  chapter={0}
}

@article{rayyan-352345428,
  title={ A Data Mining Approach for Transformer Failure Rate Modeling Based on Daily Oil Chromatographic Data  -  IEEE Access },
  year={2020},
  author={Huang, W. and Li, X. and Hu, B. and Yan, J. and Peng, L. and Sun, Y. and Cheng, X. and Ding, J. and Xie, K. and Liao, Q. and Wan, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204652 },
  abstract={Evaluating the real-time failure rate of transformers can effectively guide the planning of maintenance and reduce their failure risk. This paper proposed a novel transformer failure rate model that considers the impact of maintenance based on daily oil chromatographic monitoring data mining. Firstly, to ensure the quality of the modeling data, an improved k-nearest neighbor (KNN) algorithm based on genetic algorithm (GA) is proposed to repair the missing monitoring data. The repaired data is then mapped to the equivalent state duration (ESD) by the M-BPNN proposed, which is used to modify the multistate Markov process of transformers so as to quantify the impact of maintenance on failure rate. Considering the changing characteristics of the dissolved gases’ content in the short period, the ESD is further merged in sequential periods to obtain the merged equivalent state duration (MESD). Finally, an analytical function of the transformer failure rate with respect to the MESD is obtained. Case studies on a typical substation demonstrate that the proposed approach has the ability to characterize the impact of maintenance and the actual failure rate, thereby improving the accuracy of the substation reliability assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2020.3026171 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345429,
  title={ Impact of the Use of Vegetable Oil on the Mechanical Failure of the Cellulosic Insulation of Continuously Transposed Conductors in Power Transformers  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2022},
  author={Oria, C. and Méndez, C. and Carrascal, I. and Ortiz, A. and Ferreño, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730938 },
  abstract={Natural esters have become of interest for the industry in recent years as dielectric liquids for power transformers, and many studies are focused on their dielectric and chemical properties and on their influence in the degradation of the solid insulation due to aging. However, very little is known about their impact on the evolution of the mechanical properties of the paper insulation, which are acknowledged to have a considerable influence in their overall performance and reliability during the operating life of power transformers. This work studies the effects of thermal aging with vegetable oil in some commercial components, which are commonly used in power transformers, such as an insulated continuously transposed conductor (CTC) and samples of thermally upgraded crepe insulation. The changes in the properties of the crepe paper insulation are characterized through the degree of polymerization and tensile testing. Failure initiation and propagation in the insulation of the CTC is analyzed macroscopically. The results are compared with those obtained when using mineral oil, showing that the use of vegetable oil has a protective effect over mechanical properties of the studied types of paper insulation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2022.3157936 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345430,
  title={ An analysis of Australian power transformer failure modes, and comparison with international Surveys  -  2016 Australasian Universities Power Engineering Conference (AUPEC) },
  year={2016},
  author={Marks, J. and Martin, D. and Saha, T. and Krause, O. and Alibegovic-Memisevic, A. and Russell, G. and Buckley, G. and Chinnarajan, S. and Gibson, M. and MacArthur, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749314 },
  abstract={Power transformers are expensive items, and a utility must decide when it is economically preferable to replace one, or when to invest in refurbishments or repairs. The expected probability of failure of a transformer is often used in this determination. A challenge frequently encountered by a utility when analyzing their power transformer data is that because this failure rate is so low, a population size larger than they own is required to make meaningful statistical conclusions. For the Australian region such extensive surveys are uncommon. International surveys have been produced on mode and probability of failure, but it is unknown how representative the data is for Australian usage. Consequently, a study was performed where the Australian utilities were surveyed to find the number of failures and retirements, and the age, when this occurred. Data on 630 failures and retirements was collected and then analysed. Proportions of failure modes are presented and discussed in this article.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AUPEC.2016.7749314 },
  booktitle={ 2016 Australasian Universities Power Engineering Conference (AUPEC) },
  chapter={0}
}

@article{rayyan-352345431,
  title={ Experimental and numerical analysis of cellulosic insulation failures of continuously transposed conductors under short circuits and thermal ageing in power transformers  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2020},
  author={Oria, C. and Carrascal, I. and Ortiz, A. and Fernández, I. and Ferreño, D. and Afshar, R. and Gamstedt, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8985650 },
  abstract={The integrity of the cellulosic insulation in power transformers is considered one of the most relevant parameters that affects their performance and reliability. Electric faults, such as short circuits, have thermal and mechanical effects that degrade the paper and can eventually produce the end-of-life of the transformer. The evolution of the properties of the paper insulation of a commercial continuously transposed conductor due to thermal ageing was characterised through the degree of polymerisation and tensile testing. Failure initiation and propagation in the paper was analysed macroscopically and microscopically using scanning electron microscope. A finite element numerical mechanical model of the conductor was implemented to reproduce the experiments and to obtain the load level and strain state that produce failure at each ageing state, aiming at developing a failure model for the insulation. This model may contribute to an improvement in manufacturing processes and management of the electrical system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2019.008342 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345432,
  title={ A Risk Assessment for Utilities to Prevent Transformer OLTC Failures Caused by Silver Sulphide Corrosion  -  IEEE Transactions on Power Delivery },
  year={2022},
  author={Samarasinghe, S. and Ekanayake, C. and Ma, H. and Saha, T. K. and Baniya, J. and Allan, D. and Russell, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9618778 },
  abstract={Silver sulphide corrosion is a recently identified failure mechanism of transformer onload tap changers (OLTC). The corrosive sulphur in transformer oil reacts with the silver coated components of OLTC tap selector and forms silver sulphide films. During OLTC operation, the silver sulphide flakes can be detached from the tap selector and mix with the transformer oil. The silver sulphide is a semi conductive material. As a result, the dielectric strength in the transformer oil around the OLTC silver coated contacts or elsewhere in the transformer, wherever the semi conductive particles travel, will be reduced. Eventually, due to either high electric field stress or aged oil with a low dielectric strength, oil breakdown can occur between adjacent contacts. This can cause a catastrophic failure of the OLTC and quite often the tapping winding as well. Since such failures affect the transformer reliability, utilities are interested in methods of detecting and mitigating silver sulphide corrosion on OLTCs. This paper presents a risk assessment criterion to identify the degree of significance of silver sulphide corrosion in transformers using existing diagnostic techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2021.3128623 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345433,
  title={ Temperature-Triggered Failure Hazard Mitigation of Transformers Subject to Geomagnetic Disturbances  -  2021 IEEE Texas Power and Energy Conference (TPEC) },
  year={2021},
  author={Dehghanian, P. and Overbye, T. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384921 },
  abstract={Geomagnetic Disturbances (GMDs) could potentially damage the power grid through reactive power losses and overheating the high-voltage power transformers. A high-impact Low-frequency event such as GMD could induce a hotspot temperature rise over the transformer's overall temperature during a full load condition leading to an accelerated asset loss of life and increased risk of failure. This paper focuses on the impact of GMDs on transformers heating and its consequences on transformer's loss of life cycle and failure risk. Moreover, this paper proposes a transformer hazard mitigation approach to reduce the temperature-dependent transformer risk of failure. The proposed method is tested in the synthetic Texas 2000-bus grid, and the results are numerically analysed, demonstrating the effectiveness of the algorithm.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPEC51183.2021.9384921 },
  booktitle={ 2021 IEEE Texas Power and Energy Conference (TPEC) },
  chapter={0}
}

@article{rayyan-352345434,
  title={ Substation Transformer Failure Analysis Through Text Mining  -  2019 IEEE 9th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  year={2019},
  author={Ravi, N. N. and Drus, S. Mohd and Krishnan, P. S. and Ghani, N. Laila Abdul},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8743719 },
  abstract={Transformer failure could occur in terms of tripping that results in an unplanned or unseen outage. A good maintenance strategy is therefore an essential component in a power system to prevent unexpected failures. In this paper, the causes of transformer failure within the power transformer systems have been reviewed. Data is obtained from the transmission substation assets from the whole of Peninsular Malaysia for the past 5 years. However, the challenge is that the problem descriptions of the datasets are all in text formats. Thus, text mining approach is chosen for the data analysis using R. This paper covers the most common steps in R, from data preparation to analysis, and visualization through wordcloud generation. This study mainly focuses on bag-of-word text analysis approaches, which means that only word frequencies per text are used and word positions are ignored. Although this simplifies text content dramatically, research and many applications in the real world show that word frequencies alone contain adequate information for many types of analysis. As a result of analysis, keywords like "leak", "lightning", "animal", "cable" and "temperature" are identified as the main causes of transformer failures based on the number of word frequency in the tripping dataset. Further enhancement could be made in the future to predict the failure beforehand using predictive analytics approaches.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISCAIE.2019.8743719 },
  booktitle={ 2019 IEEE 9th Symposium on Computer Applications & Industrial Electronics (ISCAIE) },
  chapter={0}
}

@article{rayyan-352345435,
  title={ Fuzzy Failure Rate Model of Power Transformer Based on Condition Monitoring  -  2022 5th International Conference on Energy, Electrical and Power Engineering (CEEPE) },
  year={2022},
  author={Zhang, D. and Chu, Z. and Guo, H. and Wang, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783308 },
  abstract={Aiming at the bottleneck problem of the lack of equipment fuzzy failure rate that can reflect its own health state in the calculation process of fuzzy probability hybrid reliability evaluation of power system, a fuzzy failure rate model of power transformers based on multi-source condition monitoring information is proposed. This method first establishes the transformer condition monitoring index system considering fuzzy condition monitoring information, expresses the condition monitoring data through the fuzzy normal distribution membership function, and uses the fuzzy synthetic evaluation method to evaluate the health state of the transformer; the concept of evaluation set is extended, the state evaluation result data is processed by means of decomposition, superposition, mapping and fitting. Finally, the transformer condition failure rate expressed by membership function is obtained. The calculation example of a power grid in a certain area shows the calculation process of the fuzzy failure rate of the transformer, and the results conform to the statistical law of reliability data, which can reflect the current state of the equipment. The fuzzy failure rate can be used to calculate the fuzzy probability hybrid reliability index of the power system, and can provide decision support for further equipment maintenance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEEPE55110.2022.9783308 },
  booktitle={ 2022 5th International Conference on Energy, Electrical and Power Engineering (CEEPE) },
  chapter={0}
}

@article{rayyan-352345436,
  title={ Raw Mill Engine Failure Detection from Transformer Gated Convolutional Unit Networks  -  2023 IEEE International Conference on Data and Software Engineering (ICoDSE) },
  year={2023},
  author={Muliatama, B. P. and Mukhlash, I. and Iqbal, M. and Hidayat, N. and Kimura, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291294 },
  abstract={From the era of Industry 4.0, Internet-of-Things (IoT) technology has developed an industrial maintenance strategy, namely Predictive Maintenance (PdM), to boost massive production processes. One task in PdM is to estimate the engine failure time to help the decision-making on maintenance strategies, called diagnostic task. Besides that, diagnostic tasks play a dominant role as they can ensure uninterrupted production steps in almost all industry fields, including a sand-cement factory. In this work, we focus on raw mill as the first major engine in sand-cement production. Further, we attempt to estimate the failure time of the raw mill engine as early as possible by applying Transformer-Gated Convolutional Unit Networks (T-GCUN). In brief, the Gated Convolutional Unit (GCU) captures the local features of the multi-sensor data. The transformer estimates the failure time of raw mill engine by learning the short and long-term dependencies and local features from GCU. In the experiments, we studied multi-sensor data from the raw mill engine in one of the sand-cement factories in Indonesia around 2015, as most failures occurred. Within various time cycles, T-GCUN can predict the failure time of raw engine earlier than the ground truth.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoDSE59534.2023.10291294 },
  booktitle={ 2023 IEEE International Conference on Data and Software Engineering (ICoDSE) },
  chapter={0}
}

@article{rayyan-352345437,
  title={ A Generalized GNN-Transformer-Based Radio Link Failure Prediction Framework in 5G RAN  -  IEEE Transactions on Machine Learning in Communications and Networking },
  year={2025},
  author={Hasan, K. and Papry, K. and Trappenberg, T. and Haque, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11018489 },
  abstract={Radio Link Failure (RLF) prediction system in Radio Access Networks (RANs) is critical for ensuring seamless communication and meeting the stringent requirements of high data rates, low latency, and improved reliability in 5G networks. However, weather conditions such as precipitation, humidity, temperature, and wind impact these communication links. Usually, historical radio link Key Performance Indicators (KPIs) and their surrounding weather station observations are utilized for building learning-based RLF prediction models. However, such models must be capable of learning the spatial weather context in a dynamic RAN and effectively encoding time series KPIs with the weather observation data. Existing work utilizes a heuristic-based and non-generalizable weather station aggregation method that uses Long Short-Term Memory (LSTM) for non-weighted sequence modeling. This paper fills the gap by proposing GenTrap, a novel RLF prediction framework that introduces a Graph Neural Network (GNN)-based learnable weather effect aggregation module and employs state-of-the-art time series transformer as the temporal feature extractor for radio link failure prediction. The GNN module encodes surrounding weather station data of each radio site while the transformer module encodes historical radio and weather observation features. The proposed aggregation method of GenTrap can be integrated into any existing prediction model to achieve better performance and generalizability. We evaluate GenTrap on two real-world datasets (rural and urban) with 2.6 million KPI data points and show that GenTrap offers a significantly higher F1-score of 0.93 for rural and 0.79 for urban, an increase of 29% and 21% respectively, compared to the state-of-the-art LSTM-based solutions while offering a 20% increased generalization capability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TMLCN.2025.3575368 },
  booktitle={ IEEE Transactions on Machine Learning in Communications and Networking },
  chapter={0}
}

@article{rayyan-352345438,
  title={ Statistical and Physical Approaches on the Initial Failure Rate of High Voltage Power Transformers  -  2018 International Conference on Applied and Theoretical Electricity (ICATE) },
  year={2018},
  author={Pierrat, L. and Helerea, E. and Sangeorzan, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8551423 },
  abstract={Concerning the failure of power transformer, it is found that the failure rate due to dielectric breakdown decreases in time.. These failures are connected with a possible pollution of the transformer oil by introducing unexpected conductive particles. In this paper, starting from a sample with few data, a proposed Weibull statistical model confirms this decrease. Then, a stochastic model based on a particle extinction process is also developed. Finally, the correlation between the two models makes possible an interpretation of the physical phenomena and the quantification of the parameters which characterize the predictive reliability of power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICATE.2018.8551423 },
  booktitle={ 2018 International Conference on Applied and Theoretical Electricity (ICATE) },
  chapter={0}
}

@article{rayyan-352345439,
  title={ Transformer-Based Link Failure Detection in 5G Cellular Networks  -  ICC 2025 - IEEE International Conference on Communications },
  year={2025},
  author={Farooq, U. and Hameed, A. and Leivadeas, A. and Lambadaris, I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11161928 },
  abstract={Radio Link Failure (RLF) detection in Radio Access Networks (RANs) is crucial for ensuring seamless communication in 5G networks. Nonetheless, current approaches based on traditional Machine Learning (ML) algorithms fail to find a trade-off between accuracy and computational complexity. Thus, in this paper, we explore advanced and computationally efficient types of transformers, such as Linformer and Performer. These models significantly reduce computational complexity while maintaining strong performance by leveraging different attention mechanisms. Extensive evaluations using a realistic dataset under various percentages of link failures show that Linformer provides a favourable balance between accuracy and training time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICC52391.2025.11161928 },
  booktitle={ ICC 2025 - IEEE International Conference on Communications },
  chapter={0}
}

@article{rayyan-352345440,
  title={ Towards LLM-based Root Cause Analysis of Hardware Design Failures  -  2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS) },
  year={2025},
  author={Qiu, S. and Wang, M. and Afsharmazayejani, R. and Shahmiri, M. M. and Tan, B. and Pearce, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11125748 },
  abstract={With advances in large language models (LLMs), new opportunities have emerged to develop tools that support the digital hardware design process. In this work, we explore how LLMs can assist with explaining the root cause of design issues and bugs that are revealed during synthesis and simulation, a necessary milestone on the pathway towards widespread use of LLMs in the hardware design process and for hardware security analysis. We find promising results: for our corpus of 34 different buggy scenarios, OpenAI’s o3-mini reasoning model reached a correct determination 100% of the time under pass@5 scoring, with other state of the art models and configurations usually achieving more than 80% performance and more than 90% when assisted with retrieval-augmented generation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/COINS65080.2025.11125748 },
  booktitle={ 2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS) },
  chapter={0}
}

@article{rayyan-352345442,
  title={ Analysis of integral snubber circuit design for transformers in urban high rise office building  -  48th IEEE Industrial & Commercial Power Systems Conference },
  year={2012},
  author={Sutherland, P. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6229607 },
  abstract={Transformer failures have in recent years led to the development of Resistor-Capacitor snubber circuits for the protection of the transformer and winding insulation from the damaging effects of high-voltage high-frequency transients. Transformer insulation may be damaged if the Basic Insulation Level (BIL) is exceeded, turn-to-turn insulation when there is excessive rate of change of voltage with time (dv/dt), and to switching devices by restrikes when the Transient Recovery Voltage (TRV) is exceeded. These transients are most often observed when dry-type transformers are close coupled to vacuum switching devices. Some manufacturers are now including snubbers in their transformer designs. This paper provides a thorough review of the causes of the transients, methods of analysis, and mitigation of the effects of these transients. An example is provided of transformers to be installed in the basement of an urban high rise office building, where the space is limited and the available fault current is high, where the transformer enclosure includes built-in snubber circuits. The strengths and weaknesses of current methods are examined. Recommendations are made for improvements in snubber circuit design and analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2012.6229607 },
  booktitle={ 48th IEEE Industrial & Commercial Power Systems Conference },
  chapter={0}
}

@article{rayyan-352345443,
  title={ Determination of Optimal Number of Spare Transformer Using Probabilistic Method: A Study Case of Pematangsiantar Distribution Unit  -  2023 4th International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  year={2023},
  author={Zidny, I. and Ardiansyah, M. R. and Putra, R. P. and Lewi, I. and Banjar-Nahor, K. M. and Hariyanto, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257415 },
  abstract={Transformer failure is an event that is difficult to avoid, especially in distribution networks where thousands of distribution transformers must be maintained for reliability. A Transformer is an important piece of equipment in the distribution of electricity to customers where one distribution substation has only one transformer. The case study of the Pematangsiantar Distribution Unit has more than five thousand transformers (20kV/400V) to serve low voltage customers, namely 0.45 kVA - 197 kVA power. The transformer capacity which is the object of research is 25 kVA-250 kVA. Determination of the optimal number of spare transformers is carried out using the Poisson Distribution probability method by comparing the desired level of reliability, the Mean Time Between failures (MTBF), and Statistical Economics. The result of the case is the most number of spare transformers is MTBF, Reliability, and Statistical Economic criterion respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVEPS58902.2023.10257415 },
  booktitle={ 2023 4th International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  chapter={0}
}

@article{rayyan-352345445,
  title={ ARCS-R: Mission Critical Combined Reliability and Cybersecurity Systems Engineering Analysis  -  2024 Annual Reliability and Maintainability Symposium (RAMS) },
  year={2024},
  author={Bossuyt, D. L. Van and Papakonstantinou, N. and Hale, B. and Arlitt, R. and Palatheerdham, S. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10457626 },
  abstract={This paper explores how reliability analysis and cyber-security analysis can be combined using Artificial Intelligence and Machine Learning (AI/ML), and Large Language Models (LLM) to produce a continuously updated resilience analysis. This is achieved by modeling both the hardware and software of the system, and employing LLMs and AI/ML to continuously search for new software vulnerabilities and feed that information into continuously updating resilience models. A case study of a drone is presented that demonstrates the promise of the proposed method. It is expected that using the proposed method, named Assessment for Risk in Cybersecurity and Safety - Resilience (ARCS-R), will reduce failure rate of mission-critical cyber-physical systems by reducing the likelihood of a potential initiating event causing a prolonged degradation in system performance that impacts system resilience.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAMS51492.2024.10457626 },
  booktitle={ 2024 Annual Reliability and Maintainability Symposium (RAMS) },
  chapter={0}
}

@article{rayyan-352345446,
  title={ Detection of Failures Within Transformers by FRA Using Multiresolution Decomposition  -  IEEE Transactions on Power Delivery },
  year={2014},
  author={Arispe, J. C. Gonzales and Mombello, E. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6763102 },
  abstract={The detection of failures within power transformers is considered an important issue since these components are of critical importance for power system reliability; moreover, their replacement cost is extremely high. In monitoring the transformer condition along its useful life, frequency-response analysis (FRA) has gained great interest due to its sensitivity to failures in the windings and the iron core. These failures can be detected by evaluating transfer function changes by means of statistical and mathematical indices and classified according the frequency band in which these changes take place. However, this procedure involves evaluation inaccuracies due to disturbances or minor changes during FRA measurements. The new methodology is based on the decomposition of the original responses in several levels of decomposition (filtering) using the discrete wavelet transform, and the subsequent comparison using smooth versions of the responses. Fault detection is further supported with statistical indices calculated using the frequency band where abnormal differences appear. This procedure gives more robustness to the method and reduces the possible influence of disturbances during measurement in the diagnosis result. The methodology has been tested using different failure cases and two of them are used for validation purposes in this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2014.2306674 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345447,
  title={ CCVT Failure due to Improper Design of Auxiliary Voltage Transformers  -  IEEE Transactions on Power Delivery },
  year={2012},
  author={Davarpanah, M. and Sanaye-Pasand, M. and Ajaei, F. Badrkhani},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081975 },
  abstract={In-situ tests of coupling capacitor voltage transformers (CCVTs) in some of the high-voltage substations indicate that the ratio error of a considerable number of CCVTs has increased to more than 5%. Experimental analyses reveal that the CCVTs excessive ratio error is mainly due to the short-circuited capacitor elements of CCVTs. Comprehensive tests and investigations indicate that the occurrence of ferroresonance due to saturation of the auxiliary voltage transformers (AVTs) is one of the main reasons for this problem. These small transformers are usually utilized inside the protective relays and control and measuring equipment or are connected to the secondary side of CCVTs as an interface between the CCVT and the equipment. Imposed stress on CCVT components and the voltage oscillations' effect on transmission-line distance relay are also scrutinized in this paper. Finally, appropriate specifications for AVTs are recommended to prevent undesirable CCVT overvoltages and distance relay maloperation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2011.2171511 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345448,
  title={ When Silicon Fails Silently: Characterizing Hardware-Induced Corruption in LLM Training  -  2025 IEEE 31st International Symposium on On-Line Testing and Robust System Design (IOLTS) },
  year={2025},
  author={Ma, J. and Pei, H. and Lausen, L. and Karypis, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11116834 },
  abstract={As the scale of training large language models (LLMs) increases, one emergent failure is silent data corruption (SDC), where hardware produces incorrect computations without explicit failure signals. In this work, we summarize the first investigation of the impact of real-world SDCs on LLM training presented in our ACL work [1]. In our investigation, we compare model training between healthy production nodes and unhealthy nodes exhibiting SDCs. With the help from a cloud computing platform, we access the unhealthy nodes that were swept out from production by automated fleet management. Using deterministic execution via XLA compiler and our proposed synchronization mechanisms, we isolate and analyze the impact of SDC errors on these nodes at three levels: at each submodule computation, at a single optimizer step, and at a training period. Our results reveal that the impact of SDCs on computation varies on different unhealthy nodes. Although in most cases the perturbations from SDCs on submodule computation and gradients are relatively small, SDCs can lead models to converge to different optima with different weights and even cause spikes in the training loss.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IOLTS65288.2025.11116834 },
  booktitle={ 2025 IEEE 31st International Symposium on On-Line Testing and Robust System Design (IOLTS) },
  chapter={0}
}

@article{rayyan-352345449,
  title={ Estimation of Individual Failure Rates for Power System Components Based on Risk Functions  -  IEEE Transactions on Power Delivery },
  year={2019},
  author={Jürgensen, J. H. and Nordström, L. and Hilber, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8701475 },
  abstract={The failure rate is essential in power system reliability assessment and thus far, it has been commonly assumed as constant. This is a basic approach that delivers reasonable results. However, this approach neglects the heterogeneity in component populations, which has a negative impact on the accuracy of the failure rate. This paper proposes a method based on risk functions, which describes the risk behavior of condition measurements over time, to compute individual failure rates within populations. The method is applied to a population of 12 power transformers on transmission level. The computed individual failure rates depict the impact of maintenance and that power transformers with long operation times have a higher failure rate. Moreover, this paper presents a procedure based on the proposed approach to forecast failure rates. Finally, the individual failure rates are calculated over a specified prediction horizon and depicted with a 95% confidence interval.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2019.2913777 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345450,
  title={ Failure to Follow Standard Procedures can Lead to a Serious Incident: Copyright Material IEEE, Paper No. PCIC-2018-54  -  2018 IEEE Petroleum and Chemical Industry Technical Conference (PCIC) },
  year={2018},
  author={Rachford, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080451 },
  abstract={Proper communication is a key to performing any task safely. Following standard procedures is absolutely essential for that to work. There is no room for complacency when performing a task based on standard instructions. This paper will discuss the importance and failings of proper communication. First, a simple experiment was conducted around following standard instructions. The results will then be summarized. The paper will then examine two incidents that happened in the low voltage world and the high voltage world as a result of failing follow standard procedures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCIC31437.2018.9080451 },
  booktitle={ 2018 IEEE Petroleum and Chemical Industry Technical Conference (PCIC) },
  chapter={0}
}

@article{rayyan-352345451,
  title={ A Human-in-The-Loop Approach to Robot Action Replanning Through LLM Common-Sense Reasoning  -  IEEE Robotics and Automation Letters },
  year={2025},
  author={Merlo, E. and Lagomarsino, M. and Ajoudani, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11145762 },
  abstract={To facilitate the wider adoption of robotics, accessible programming tools are required for non-experts. Observational learning enables intuitive human skills transfer through hands-on demonstrations, but relying solely on visual input can be inefficient in terms of scalability and failure mitigation, especially when based on a single demonstration. This letter presents a human-in-the-loop method for enhancing the robot execution plan, automatically generated based on a single RGB video, with natural language input to a Large Language Model (LLM). By including user-specified goals or critical task aspects and exploiting the LLM common-sense reasoning, the system adjusts the vision-based plan to prevent potential failures and adapts it based on the received instructions. Experiments demonstrated the framework intuitiveness and effectiveness in correcting vision-derived errors and adapting plans without requiring additional demonstrations. Moreover, interactive plan refinement and hallucination corrections promoted system robustness.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/LRA.2025.3604702 },
  booktitle={ IEEE Robotics and Automation Letters },
  chapter={0}
}

@article{rayyan-352345452,
  title={ A method for economic evaluation of field failures such as low-voltage side lightning surge failure of distribution transformers  -  IEEE Transactions on Power Delivery },
  year={1988},
  author={Henry, G. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4321 },
  abstract={The problem of quantifying the costs of transformer failures on a distribution system is addressed. A method for estimating failure costs is developed using simple statistical methods and familiar life-cycle costing techniques. Example applications of the method are given to support the principles introduced.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.4321 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345453,
  title={ High Voltage Insulation Failure on HV Current Transformer: A Case Study in Diagnosis of HV CT Failure at Bekasi 150 kV Substation  -  2021 3rd International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  year={2021},
  author={Mahendrayana, I. G. N. and Makhfud, I. and Norgiyanto, A. I. and Prabandaru, Z. O. and Winarno},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9600930 },
  abstract={Insulation in high-voltage equipment has a very important function as a part that separates the voltage from other parts, failure of insulation in high voltage equipment causes losses in operating of electric power transmission. High voltage Current Transformer (CT) with OIP type is a type of high voltage CT that is widely used to measure current in electrical power installations. Insulation on high voltage equipment is designed to be able to operate reliably, but the presence of stress such as voltage, heat, vibration, environmental conditions on the equipment causes a decrease in the insulation ability which can cause insulation failure. The conventional diagnostic methods to determine dielectric conditions in high voltage CT are by electrical testing including the tan delta test, capacitance and insulation resistance. A case study of the failure of the 150 kV CT occurred at the 150 kV Bekasi Substation in Indonesia, based on the results of the last electrical test that was carried out showed that the CT insulation condition was still in normal condition, for tan delta test with <1%, capacitance with <10% nameplate and insulation resistance > 11 GΩ but a major breakdown occurs on March 2021, according to this case study a comprehensive diagnostic method for dielectric conditions is needed to determine the insulation condition correctly and to avoid a breakdown due to insulation failure. The diagnostic method for high voltage CT that will be explained is by knowing the increase or grading of the tan delta test and combined with nonconventional method by dielectric frequency response test and partial discharge test.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVEPS53178.2021.9600930 },
  booktitle={ 2021 3rd International Conference on High Voltage Engineering and Power Systems (ICHVEPS) },
  chapter={0}
}

@article{rayyan-352345454,
  title={ Probabilistic Methodologies for Determining the Optimal Number of Substation Spare Transformers  -  IEEE Transactions on Power Systems },
  year={2010},
  author={da Silva, A. M. Leite and de Carvalho Costa, J. G. and Chowdhury, A. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5291717 },
  abstract={This paper presents new probabilistic methodologies for computing the optimal number of transformer spares for power distribution substations. The basic idea consists of three steps: 1) the reliability evaluation of a given system of transformers with inventory of spares; 2) the calculation of investment and operational costs of the system for different alternatives of inventory composition; and 3) the identification of the number of spares that minimizes the total cost. Two new models are proposed for the reliability evaluation step. In the first one, the system operational states are represented by a Markov process. The second one uses a chronological Monte Carlo simulation model to assess the reliability performance of a system with inventory of spares. Both models are able to provide indices such as probability, frequency, and duration of failures, as well as estimates of energy not supplied and the corresponding costs. The proposed methodologies are applied to a 72-kV distribution transformer system, and the obtained results are compared to those from a widely used model based on a Poisson distribution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2009.2030280 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345455,
  title={ Wavelet power ratio signature spectrum analysis for prediction of winding insulation defects in transformer and shunt reactor  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2017},
  author={Suryavanshi, H. and Velandy, J. and Sakthivel, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8035443 },
  abstract={The reliable analysis for identification of winding insulation defects in transformer and shunt reactor are necessary for power industries during lightning impulse test. In this paper, wavelet power ratio signature spectrum analysis is proposed to identify the short duration of partial discharge (PD) pulses of 170 ns and 30 ns within windings due to impulse voltage excitation. It provides a solution to the problems associated with several random features in the measured winding responses at neutral terminal of the winding due to PD pulse through visual assessment of mutual strength between normal winding response and one with PD response using appropriate mathematical formulation in wavelet transform. In this context, the normalized response due to reduced impulse voltage excitation is formed to be a basis function to identify the PD pulse. If the surge impedance characteristic of the winding is changed due to PD pulse at full wave impulse voltage excitation, then formulated wavelet power ratio signature spectrum analysis will extract the evidence of potentially interesting features through assessment between basis function response and one with PD response. To prove feasibility of the proposed analysis, experimental analysis is performed on a layer winding.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2017.006328 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345456,
  title={ Reduction of Stray Losses in Flange–Bolt Regions of Large Power Transformer Tanks  -  IEEE Transactions on Industrial Electronics },
  year={2014},
  author={Olivares-Galvan, J. C. and Magdaleno-Adame, S. and Escarela-Perez, R. and Ocon-Valdez, R. and Georgilakis, P. S. and Loizos, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6584734 },
  abstract={In large power transformers, the presence of stray currents in the structural elements near the high current bushings can be considerable, and this leads to hot spots. This work presents a practical analysis of overheating in the bolts that join the tank and the cover, which are near the high current bushings of the transformer. Overheating results are analyzed and discussed for the case of a 420-MVA transformer. The hot spots in the flange-bolt regions are discovered by thermal maps that are obtained during power transformer operation as a part of a preventive maintenance program. In this paper, we use copper links to ensure the connection of both the cover and tank body, significantly reducing the overheating of the flange-bolt region. The copper link solution has been validated by measurements. We have used calibrated measurement instruments in all the experiments. Moreover, a 3-D finite-element analysis of the geometry of interest has been used to verify the copper link solution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIE.2013.2279373 },
  booktitle={ IEEE Transactions on Industrial Electronics },
  chapter={0}
}

@article{rayyan-352345457,
  title={ Influence of different adhesives on partial discharge in power transformer winding cylinder insulation  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2020},
  author={Indarto, A. and Murti, A. W. and Husnayain, F. and Garniwa, I. and Rahardjo, A. and Hudaya, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099726 },
  abstract={In this study, 238 power transformers (PTs) with operating voltages between 150-500 kV and capacities in the range of 60-167 MVA are tested for partial discharge (PD). Thirty-eight of the PTs exceeded the pre-determined value of 70 pC at 1.5 maximum voltage of the PT. Failure analysis of the failed 38 PTs showed that 21% of the PD sources originate from the winding cylinder, which is formed by bonding the edges of a pressboard with an adhesive. Therefore, in this study, the effect of casein- and polyvinyl-based adhesives used in winding cylinders was investigated through standard PD measurements. The results indicate that pressboards bonded with casein-based adhesives exhibit PD values 20-25 pC lower than those bonded with polyvinyl-based adhesives (50-400 pC) at identical applied voltages (7.5-25 kV or 3-10 kV/mm). The excellent performance of casein-based adhesives is mainly attributed to its porous structure, which accelerates the impregnation of oil into the adhesive and pressboard, as revealed by scanning electron microscopy observations. This practical study will be beneficial in the process of designing and manufacturing PTs and highlight materials for producing PTs with low PD values.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2020.008533 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345458,
  title={ Modeling and simulation of power transformer breakdowns to implement predictive maintenance  -  2023 3rd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET) },
  year={2023},
  author={Ayar, H. and Nhaila, H. and Khaili, M. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152941 },
  abstract={Electrical power substations, whether generation or distribution substations, are the main element ensuring the availability of the electrical network. Today, more than ever, power transformers are among the strategic elements of an electricity transmission and distribution infrastructure. The cause of failure of a power transformer can be due to a combination of electrical, mechanical or thermal stresses. These failures can be uncontrollable and sometimes catastrophic and always cause irreversible internal damage. Most of these failures can result in significant costs to replace or repair the transformer. Unscheduled downtime of a power transformer is always costly. At this level, transformer maintenance is an activity that is integrated into the management process of a transformer fleet, and the operator must have an eye on each unit of his fleet. In this activity, maintaining the availability of transformers is one of the major objectives of any operator. This objective is achieved by maintaining the reliability of each transformer through a level of maintenance adapted to each context of use and management of the transformers. The maintenance of transformers is deployed within the framework of a policy that implements both material and economic means and adequate human resources. As for any device, there is a documentation provided by each manufacturer of transformers. It generally defines the main lines of maintenance in relation to the technological choices used. There are also guides in the literature that propose best practices based on experience in this field. In this paper, we describe how to distinguish between the two most commonly used types of transformers, based on several elements. Then, we will explain the types of failures and the solutions to diagnose each failure with the different technologies used, to generate then a mathematically equivalent version of a power transformer, which will allow us to follow closely the impact of the defects generated by simulation, on voltage and current time evolution in the line and active components of the power transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IRASET57153.2023.10152941 },
  booktitle={ 2023 3rd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET) },
  chapter={0}
}

@article{rayyan-352345459,
  title={ Bivariate dependent rate analyses for fault identification in transformer windings during impulse test  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2015},
  author={Velandy, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367560 },
  abstract={Identification of winding insulation failure during lightning impulse testing of transformer has been an important issue over a long period of time. It requires a significant human expertise and knowledge for proper judgment of transformer insulation. In this paper, the bivariate dependent rate analyses are proposed to identify the failure in transformer windings. The proposed analyses enable the calculation of winding response due to any impulse voltage excitation of full wave (FW) and chopped wave impulse (CW) for typical transformers. Initially, the line of best-fit on the scatter diagram is utilized to visualize the similarities between the measured winding responses and also to identify the type of relationship with potential outliers. Further, ellipse analysis is utilized to calculate the diversification (size, shape and orientation) between the responses. The actual interdependency between winding responses is established through nonlinear interpretation coefficients. To prove the feasibility of the analyses, 66.7 MVA, 90 MVA, 150 MVA, 250 MVA transformers, 80 MVAr reactor and 22 kV interleaved winding are used.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2015.004759 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345460,
  title={ Evaluation of a Unique Transient Hardened Transformer Designed to Withstand Primary Switching Transients: Simulation, Lab Tests and Analysis  -  2019 IEEE/IAS 55th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  year={2019},
  author={Buehler, S. H. and Dionise, T. J. and Shipp, D. and Penner, F. A. and Abdelazim, T. and Natali, T. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733377 },
  abstract={Many modern electrical distribution systems, such as those used in data centers, demand high power densities, small electrical footprints, high efficiency transformers, redundant systems and frequent testing requiring switching at primary voltages. These various parameters that ensure the highest reliability and availability to mission-critical loads also place the facility in the highest risk category for distribution transformer failures due to primary switching transients. Over the last decade, this phenomenon has been attributed to a significant number of failures of certain types of transformers involving primary circuit breaker switching in data centers and other facilities exhibiting similar characteristics. Although the RC snubber has been proven to safely mitigate the transient overvoltage imposed on the primary winding of the transformer, manufacturers have continued to look for other solutions to the primary switching transients problem resulting in an alternative solution: a unique transient hardened transformer designed to withstand switching transients. The authors conducted an evaluation to prove analytically, through a combination of simulations and field tests, that the transient hardened transformer design will withstand switching transients without the need for transient mitigation using RC snubbers, relying only on conventionally applied surge arresters. This paper focuses specifically on data center transformers, however, the lessons learned here may be applied to numerous applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2019.8733377 },
  booktitle={ 2019 IEEE/IAS 55th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  chapter={0}
}

@article{rayyan-352345461,
  title={ Improved Power Transformer Condition Assessment under Uncertainty using Fuzzy Logic  -  2022 IEEE 8th International Conference on Energy Smart Systems (ESS) },
  year={2022},
  author={Bardyk, E. I. and Bolotnyi, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969327 },
  abstract={There is a problem of transition to equipment maintenance according to its technical condition. Solving this problem should contributed to more efficient management of power companies resources and increase their competitiveness. This paper proposes an approach to quantitative assessment of technical condition for power transformer using an integrated technical deterioration index. The proposed approach is based on fuzzy logic and fuzzy set theory. This allows you to formalize expert assessments of defect development in power transformer. The formalization of technical condition evaluation for power transformer in knowledge base form is implemented in expert system prototype. The integrated technical deterioration index of power transformer was determined based on test results of technical condition parameters for functional units of power transformer using expert judgments. The considered approach to uncertainty formalization about technical condition of power transformer allows constructing the deterministic scheme of decision-making on further service strategy. The procedures of ranking, out of service of specific objects are implemented based on objective criteria in this service strategy of power transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ESS57819.2022.9969327 },
  booktitle={ 2022 IEEE 8th International Conference on Energy Smart Systems (ESS) },
  chapter={0}
}

@article{rayyan-352345462,
  title={ Research on Fault Prediction Model of Gateway Metering Transformer Based on Data Mining  -  2024 6th International Academic Exchange Conference on Science and Technology Innovation (IAECST) },
  year={2024},
  author={Zheng, K. and Peng, X. and Liu, T. and Zeng, X. and Liu, Y. and Zhang, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118169 },
  abstract={Gate measuring transformers, including voltage and current transformers, are critical for accurate electric energy measurement and maintaining grid stability. However, complex operating environments and aging equipment often lead to failures, causing metering errors and potential power accidents. Traditional fault detection methods are inefficient, reactive, and underutilize available data. This paper presents a fault prediction model for gateway metering transformers based on data mining, utilizing random forest algorithms to analyze operational data. Preprocessing techniques such as missing value handling and feature selection with XGBoost were applied. Experimental results show a 97.5% prediction accuracy, significantly enhancing fault prevention and grid reliability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAECST64597.2024.11118169 },
  booktitle={ 2024 6th International Academic Exchange Conference on Science and Technology Innovation (IAECST) },
  chapter={0}
}

@article{rayyan-352345463,
  title={ Analysis of internal winding stresses in EHV generator step-up transformer failures  -  IEEE Transactions on Power Delivery },
  year={1996},
  author={Morched, A. S. and Marti, L. and Brierley, R. H. and Lackey, J. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=489348 },
  abstract={This paper describes studies carried out to investigate the failure of one phase of a 990 MVA generator step-up transformer bank at one of Ontario Hydro's major generating stations. A high accuracy frequency dependent transformer model was used to determine the behaviour of the transformer at the terminals under transient conditions. With this information, and with measured transfer functions between the terminals and various points inside the windings, it was possible to create internal voltage distribution maps. This information was then used to evaluate the insulation stresses within the winding, and to ascertain that the use of additional capacitance at the HV terminals to reduce the magnitude and frequency of incoming transients would be adequate to reduce the disk-to-disk stresses near the line end of the HV winding. The values of the HV terminal capacitances were chosen so that no undue stresses in other portions of the winding would take place.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.489348 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345464,
  title={ Failures in power system transformers and appropriate monitoring techniques  -  1999 Eleventh International Symposium on High Voltage Engineering },
  year={1999},
  author={Minhas, M. S. A. and Reynders, J. P. and Klerk, P. J. De},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=820336 },
  abstract={Failure analysis of 188 power transformers in the voltage range of 88 kV to 765 kV and MVA rating from 20 to 800 is presented. The analysis of the data shows that in smaller transformers ageing related failures are dominant. In the medium MVA rating class, tap-changer failures constitute the highest failure rate. In the large transformers, insulation coordination failure is the most common cause in the early service life of the transformer. This study is an update of earlier investigations. Appropriate monitoring techniques have been suggested with a view to transformer size and voltage rating.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/cp:19990516 },
  booktitle={ 1999 Eleventh International Symposium on High Voltage Engineering },
  chapter={0}
}

@article{rayyan-352345465,
  title={ Analysis of converter transformer failures and application of periodic on-line partial discharge measurements  -  Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.01CH37264) },
  year={2001},
  author={McDermid, W. and Grant, D. H. and Glodjo, A. and Bromley, J. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965761 },
  abstract={Of a group of eight 3-phase core form HVDC converter transformers, six have now failed in service. The final failure mechanism has consisted of a turn-to-turn fault, usually in the valve winding. All the windings were produced using continuously transposed conductors. Thermal aging of the insulating materials was evident. This paper summarizes the results of the various tests and inspections that were made in an attempt to better understand the circumstances that may have contributed to these failures. On-line partial discharge measurements using an electrical detection method are being made on a periodic basis on a number of large power transformers, primarily those used in HVDC conversion. This paper describes the measuring system and methods of noise deletion. An example of the test results has been provided describing a significant failure hazard that was detected.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEIC.2001.965761 },
  booktitle={ Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.01CH37264) },
  chapter={0}
}

@article{rayyan-352345466,
  title={ Failure analysis of dry-type power transformer  -  IEEE Transactions on Industry Applications },
  year={2001},
  author={Paul, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=924746 },
  abstract={This paper provides the failure analysis of a three-phase, dry-type, silicone resin vacuum-pressure encapsulated, 750/1000 kVA, AA/FA, 34.5 kV-480 Y/277-V, delta-wye power transformer. Transient overvoltage switching surge propagation through the transformer winding and protection margin is discussed. An arbitrary sensitivity of 10 pC at 120% rated voltage generally used for the partial discharge tests at the factory may be inadequate for the design of the failed transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/28.924746 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345467,
  title={ Corrosive sulphur in mineral oils: its detection and correlated transformer failures  -  Conference Record of the 2006 IEEE International Symposium on Electrical Insulation },
  year={2006},
  author={Tumiatti, V. and Maina, R. and Scatiggio, F. and Pompili, M. and Bartnikas, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1665342 },
  abstract={The presence of corrosive sulphur in current insulating oils is discussed and typical winding failures in transformers and shunt reactors, due to the resultant formation of copper sulphide films and participate matter, are described. Different standard test methods for the detection of corrosive sulphur in oils are compared and ASTM D1275 is shown to be the most sensitive},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ELINSL.2006.1665342 },
  booktitle={ Conference Record of the 2006 IEEE International Symposium on Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345468,
  title={ Failure of Electromagnetic Voltage Transformer Due to Sustained Over-Voltage on Switching - an Indepth Field Investigation and Analytical Study  -  IEEE Transactions on Power Apparatus and Systems },
  year={1981},
  author={Aggarwal, R. P. and Saxena, N. S. and Sharma, B. S. and Kumar, S. and Krishan, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4110529 },
  abstract={An electromagnetic voltage transformer (EMVT) was damaged when the 220KV bus bar was being de-energised by a circuit breaker fitted with grading capacitors across its contacts. This paper describes the field investigations and analyses the phenomenon using the principle of harmonic balance. It is established that the failure occurred due to fero-resonance between CB grading capacitors and non-linear EMVT inductance causing sustained over-voltage and consequently much higher than usual current. It could be a thermal or insulation failure or both. The analytical results obtained are shown to be similar to those determined by actual field. tests.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1981.316859 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345469,
  title={ Analysis of winding failures in HVDC converter transformers  -  Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.99CH37035) },
  year={1999},
  author={McDermid, W. and Glodjo, A. and Bromley, J. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=826288 },
  abstract={In spite of periodic off-line electrical tests and on-line gas-in-oil analysis, three HVDC converter transformers have failed within a 12-month period. The possible causes of failure are reviewed together with changes in maintenance, monitoring and system operation that might prolong the life of similar transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEIC.1999.826288 },
  booktitle={ Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.99CH37035) },
  chapter={0}
}

@article{rayyan-352345470,
  title={ Impulse-Failure-Detection Methods as Applied to Distribution Transformers  -  Transactions of the American Institute of Electrical Engineers },
  year={1945},
  author={Stewart, H. C. and Holcomb, J. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5059193 },
  abstract={Investigation of several methods for the detection of impulse failures in distribution transformers has strengthened our belief in the inadequacy of the methods described in American Standard C57.2. All of the methods are discussed in detail, and the most hopeful one is comnpared with the present method of analyzing the voltage wave and making the physical observations as outlined in the Standards. Data are presented on transformers utilizing present and proposed methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/T-AIEE.1945.5059193 },
  booktitle={ Transactions of the American Institute of Electrical Engineers },
  chapter={0}
}

@article{rayyan-352345471,
  title={ Failure analysis and replacement strategies of distribution transformers using proportional hazard modeling  -  Annual Reliability and Maintainability Symposium, 2003. },
  year={2003},
  author={Prasad, P. V. N. and Rao, K. R. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1182043 },
  abstract={The paper presents a graphical method for plotting mean cumulative repair function (MCRF) for different capacities or types of distribution transformers. The plots provide information about their failure behavior with time. The intensity function graphs obtained using parameters of Weibull process proportional hazard model confirms the results obtained from nonparametric MCRF graphs. Proportional hazard modeling (PHM) technique is quite helpful to consider the effect of covariates on the failure performance of different transformers with time. The property of proportionality is validated with the help of graphical and analytical methods. The higher values of intensity function for 100 kVA transformers and rural environment transformers show their poor performance compared to less than 100 kVA transformers and urban environment transformers respectively. This information is quite helpful in evaluating maintenance/replacement policies. It is considered that normal life of distribution transformer is about 25 years, for a capacity of 100 kVA or less. The present study indicates that in case of 100 kVA transformers and rural transformers an early replacement is required.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/RAMS.2003.1182043 },
  booktitle={ Annual Reliability and Maintainability Symposium, 2003. },
  chapter={0}
}

@article{rayyan-352345472,
  title={ Failure Statistics and Condition Evaluation for Power Transformer Maintenance  -  2011 Asia-Pacific Power and Energy Engineering Conference },
  year={2011},
  author={Chaidee, E. and Tippachon, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5749108 },
  abstract={Power transformer has degraded under its normal and abnormal operating conditions, maintenance activities are vital to restore the condition back to the normal condition. Even though the traditional preventive maintenance is well known and successfully performed, but the method had a high cost. Therefore, the objective of this paper is to improve the drawback by systematical record of the scattering failure statistics and analysis, in order to determine critical component. Power transformer models of rated voltage 115/22 kV and 230/115 kV have been adopted based on the available technical data, history test record and number in service. The component with high failure rate must be carefully focused. The known causes of failure could be prevented. Furthermore, the component with the highest percentage of failure is analyzed by Weibull distribution in order to estimate life time which can be used to support in maintenance activity. The procedure for power transformer condition evaluation is performed by analyzing the historical testing result from the Dissolved Gas Analysis (DGA) method. The transformer conditions are principally evaluated by the Key Gas method and then verified with the other methods. As a result, the aging pattern and trend of the power transformer deterioration can be determined.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APPEEC.2011.5749108 },
  booktitle={ 2011 Asia-Pacific Power and Energy Engineering Conference },
  chapter={0}
}

@article{rayyan-352345473,
  title={ Modelling of losses due to eddy currents and hysteresis in converter transformer cores during failure  -  IEEE Transactions on Magnetics },
  year={1995},
  author={Juszczak, E. Napieralska- and Grzybowski, R. and Brudny, J. F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=376366 },
  abstract={The paper deals with the analysis of eddy-currents and hysteresis losses in the core of three-phase transformer supplying a static converter bridge during failure of a diode in this bridge. The applied simulation methods are described as well as the results of an analysis in the most important case: the breakdown of one diode of the bridge produces an internal short circuit disconnected by the fuse. Then the operation continues without one diode, changing greatly the values of all currents and core losses. The computation of all quantities required the application of coupled circuit and field methods.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/20.376366 },
  booktitle={ IEEE Transactions on Magnetics },
  chapter={0}
}

@article{rayyan-352345474,
  title={ A procedure to evaluate the risk of failure of distribution transformers insulation due to lightning induced voltages  -  22nd International Conference and Exhibition on Electricity Distribution (CIRED 2013) },
  year={2013},
  author={Lopes, G. P. and Napolitano, F. and Martinez, M. L. B. and Nucci, C. A. and Borghetti, A. and Uchoa, J. I. L. and Santos, G. J. G. D. and Fagundes, D. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6683861 },
  abstract={The aim of the paper is to assess the risk of insulation failure of distribution transformers connected to overhead distribution due to indirect lightning induced voltages. The annual frequencies of occurrence of dangerous voltages are evaluated through a Monte Carlo procedure and by using the LIOV-EMTP code for the calculation of the Lightning Electromagnetic Pulse (LEMP) and its effects on the multiconductor line. The probability of distribution transformers insulation to withstand the stresses caused by lightning overvoltages is inferred from the results of experimental test.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/cp.2013.1258 },
  booktitle={ 22nd International Conference and Exhibition on Electricity Distribution (CIRED 2013) },
  chapter={0}
}

@article{rayyan-352345475,
  title={ Wind turbine generator step-up transformer failure investigation  -  PES T&D 2012 },
  year={2012},
  author={Hope, E. M. and Bellei, T. A. and Reyes, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6281584 },
  abstract={This paper presents an investigation into the recurring failures of pad-mounted generator step-up transformers that have been experienced by Exelon Wind at a wind farm in Northern Texas. Observations indicate that the transformer failures are typically a result of contaminated oil due to arcing within the transformer expulsion fuse tube. To determine the underlying cause of this phenomena, S&C Electric Company installed digital monitoring equipment to capture electrical and thermal data at a pad-mounted generator step-up transformer over a four-month period. Electrical data was also captured at the point of interconnect between the wind farm and the local utility. The data captured in this time frame revealed that high-current surges and current cycling frequently occurred due to the WTG cycling on and off from the highly variable wind speeds in the area. High-current surges and current cycling places thermomechanical stress on the transformer and expulsion fuse links, which may ultimately lead to the types of failures experienced at this location.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDC.2012.6281584 },
  booktitle={ PES T&D 2012 },
  chapter={0}
}

@article{rayyan-352345476,
  title={ Creep stress failure in high voltage transformer interwinding insulation  -  2007 Annual Report - Conference on Electrical Insulation and Dielectric Phenomena },
  year={2007},
  author={Mitchinson, P. M. and Lewin, P. L. and Chen, G. and Jarman, P. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4451519 },
  abstract={Three phase transformers have an insulation system which is a complex three dimensional structure of paper and pressboard surrounding the conductors immersed in a large volume of mineral oil. In core form transformers, a key insulation area is the region between adjacent phases which is often reinforced with vertical pressboard barriers. At the higher voltages, these pressboard barriers provide a crucial element in the insulation structure between the phases. The barriers are subjected to large electrical and thermal stresses. The pressboard barriers sit in the time varying electric field pattern generated from the transformer winding coils which are operating with 120deg phase difference. The electric field can be resolved along the surfaces of the pressboard and this is termed creep stress or tangential stress. This electric stress can lead to surface tracking along the oil-pressboard boundary layer. A large scale test facility has been developed to investigate the effects of creep stress with the goal of understanding the onset of surface tracking on the pressboard. This paper details the main features of the test platform and control equipment. Finally, the paper includes some initial results of experiments conducted to detect partial discharge under two temperature conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEIDP.2007.4451519 },
  booktitle={ 2007 Annual Report - Conference on Electrical Insulation and Dielectric Phenomena },
  chapter={0}
}

@article{rayyan-352345477,
  title={ Power transformer failure analysis using interval type-2 fuzzy set theory based fault tree analysis  -  2016 IEEE 7th Power India International Conference (PIICON) },
  year={2016},
  author={Mitra, R. and Reddy, G. H. and Goswami, A. K. and Choudhury, N. B. Dev},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8077349 },
  abstract={Reliable power supply depends on proper equipment functioning. Power transformer keeps up voltage and power level of the system. Power transformer failure is caused by insulation failure, low voltage bushing, frequent tap change, tank leakage etc. These causes are analysed with the help of probability of occurrence of each event. The value of probability is assigned to fault tree analysis (FTA). The uncertainties and the randomness of reasons of power failure are handled by fuzzy numbers. Normal distribution concept is applied to deal with fuzzy numbers. Interval type 2 fuzzy system (IT2FS) fuzzifies failure probability and uncertainty of occurrence of failure events more accurately than type 1 fuzz system (T1FS) and conventional FTA do. Thus IT2FS helps to ascertain the chances of failure of power transformer in different conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/POWERI.2016.8077349 },
  booktitle={ 2016 IEEE 7th Power India International Conference (PIICON) },
  chapter={0}
}

@article{rayyan-352345478,
  title={ Events leading to failure of transformer oil duct spacers  -  Conference on Electrical Insulation & Dielectric Phenomena - Annual Report 1976 },
  year={1976},
  author={McGrath, P. B. and Nelson, J. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7733936 },
  abstract={Insulation present as a result of the necessary mechanical construction in power transformers results in interfaces of solid and liquid insulation, both in series and parallel, between current carrying conductors. This complex construction has received little experimental attention1 compared with studies of electrical failure occurring in insulating oils between bare metallic electrodes. The present preliminary work is concerned with the adoption of previously developed optical techniques2 to probe a full scale solid-to-liquid interface modelled on a transformer oil duct.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEIDP.1976.7733936 },
  booktitle={ Conference on Electrical Insulation & Dielectric Phenomena - Annual Report 1976 },
  chapter={0}
}

@article{rayyan-352345479,
  title={ Abnormal Failure Rate on High Voltage Current Transformers Affected by Environmental Conditions  -  Conference Record of the 2008 IEEE International Symposium on Electrical Insulation },
  year={2008},
  author={Reyes, O. and Garcia-Colon, V. R. and Lara, H. and Robles, E. and Guzman, M. and Elizarraraz, F. and Martinez, J. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4570321 },
  abstract={The Mexican Grid has been severely affected by numerous failures on 230 kV and 400 kV Substations Current Transformers (CT's). The failure rate increased in the latter years and became extremely critical. Several studies and laboratory tests on aged CT's were carried out to identify the main factors and mechanisms that contribute to the progressive deterioration of the oil paper insulation system. It is important to identify those apparatus with a high failures risk; therefore, an attempt to classify their conditions was performed. The results are shown in this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ELINSL.2008.4570321 },
  booktitle={ Conference Record of the 2008 IEEE International Symposium on Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345480,
  title={ An Analysis of Power Transformer Failures using the Mixed Weibull Statistics  -  2020 International Symposium on Electrical Insulating Materials (ISEIM) },
  year={2020},
  author={Lee, J. -H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275753 },
  abstract={A method for evaluating replacement life of substation transformers required to build an asset management system is presented. The electrical utilities are replacing the transformers at the time when the failure rate of the transformers increases to prevent sudden failures. In this study, the mean time to failure of the transformers was defined as the technical end of life, and 52 years was calculated by analyzing the cumulative density function of the failure data. The replacement time of the transformers was defined as the strategic end of life, and 32 years was calculated by failure rate (Bathtub curve) analysis. These lives of the substation transformers are calculated based on 154kV three-phase transformers with sufficient failure data, and the lives of 154kV single-phase transformers applied since 1995 should be recalculated when failure data is sufficiently collected. In addition, the replacement life of the transformers should be strategically decided according to the business value of the company and the risk associated with the failure of the transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2020 International Symposium on Electrical Insulating Materials (ISEIM) },
  chapter={0}
}

@article{rayyan-352345481,
  title={ Transformer failure modes and planned replacement  -  IEE Colloquium on Transformer Life Management (Ref. No. 1998/510) },
  year={1998},
  author={Lapworth, J. and McGrail, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=745401 },
  abstract={Transformers are usually very reliable and durable items of electrical equipment, so much so that their performance is often taken for granted, especially in a power station environment where there are often many more immediate claims on the attention of maintenance engineers. Unfortunately, when a fault occurs in a transformer, it can develop catastrophically and failures are usually very expensive if not uneconomic to repair, often resulting in the loss of what is the most expensive plant item in a substation. Costs of resulting loss of generation or transmission restraints until a replacement can be effected can also be severe. There has been considerable interest in the subject of life management of transformers. Planned replacement is the ideal from the point of view of maintaining system reliability in the face of an ageing population of transformers. To implement such a policy, information on failure modes and asset health is required, which necessitates a careful programme of inspections of redundant units, basic research and condition assessments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/ic:19981013 },
  booktitle={ IEE Colloquium on Transformer Life Management (Ref. No. 1998/510) },
  chapter={0}
}

@article{rayyan-352345482,
  title={ Root Cause Analysis in Power Transformer Failure with Improved Intelligent Methods  -  2022 IEEE International Power and Renewable Energy Conference (IPRECON) },
  year={2022},
  author={Baiju, S. S. and S, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059538 },
  abstract={Root cause investigation, diagnosis and fault classification in power transformers are the essential features to look for when trying to ensure dependability and power quality with minimum interruptions. To achieve greater diagnostic precision, a novel method that combines Stacked Denoising Auto Encoder and Bidirectional Long-Short Term Memory (SDAE-BiLSTM) is indicated in this work. Dissolved gas analysis is the most effective method for determining the cause of electric power transformers(DGA) problems. All forms of faults can be differentiated by separating samples from power transformers. The SDAE-BiLSTM method has much research potential because it uses the dissolved gas in the transformers for analysis and fault diagnosis. A comparative study has been done using various machine learning models, such as Support Vector Machine, Random Forest and Convolutional Neural Network. Compared to the performance of these models, it is clear that the SDAE-BiLSTM model possesses superior accuracy because it has more parameters.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPRECON55716.2022.10059538 },
  booktitle={ 2022 IEEE International Power and Renewable Energy Conference (IPRECON) },
  chapter={0}
}

@article{rayyan-352345483,
  title={ Analysis of high and low voltage grid failure propagation in large wind farms considering transformers, cables and VAR-compensators  -  2008 IEEE Power Electronics Specialists Conference },
  year={2008},
  author={Lohde, R. and Fuchs, F. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4592087 },
  abstract={This work presents an analysis of grid failure propagation in large wind farms. Stringent grid codes require the turbine for a certain voltage range to stay connected to the grid even during grid failures. These grid code requirements are defined for the point of common coupling (PCC) of the wind farm. Grid failures are propagated through the wind farm's internal distribution system consisting of resistive, capacitive and inductive elements such as cables, transformers and compensation units like STATCOMs and capacitor banks. This paper presents three-phase models of a representative wind park distribution network. Simulation results of failure propagation in large wind park for different grid faults considering energy storage effects will be presented and discussed. Conclusions will be drawn by means of system specific parameters like cable length and rated power.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESC.2008.4592087 },
  booktitle={ 2008 IEEE Power Electronics Specialists Conference },
  chapter={0}
}

@article{rayyan-352345484,
  title={ Failure of Electromagnetic Voltage Transformer Due to Sustained Over-Voltage on Switch off - Preventive Measures  -  IEEE Transactions on Power Apparatus and Systems },
  year={1982},
  author={Igarwal, R. P. and Saxena, N. S. and Gupta, J. C. and Sharma, B. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4111288 },
  abstract={The damage to a 220 KV electromagnetic voltage transformer (EMVT) due to sustained over-voltage on switch-off by a circuit breaker (CB) fitted with grading capacitors, and subsequent studies for the steady-state period have already been reported [1]. In this paper, the pre-steady state period is analyzed and excellent agreement shown between field and analytical results. The concerned parameters for various makes of CB's, EMVT's and bus-bar capacitance have been collected and a. number of studies conducted. It is concluded that the control of. the EMVT saturation characteristic is superior compared to the measures su, ggested earlier to prevent such over-voltages. A suitable saturation characteristic for the worst case has been identified.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1982.317306 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345485,
  title={ Significant failure rate observed at short-circuit testing of large power transformers  -  2003 IEEE PES Transmission and Distribution Conference and Exposition (IEEE Cat. No.03CH37495) },
  year={2003},
  author={Smeets, R. P. P. and te Paske, L. H. and Lathouwers, A. G. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1335380 },
  abstract={Recent experience shows that at initial access to short-circuit tests, 48% of the transformers (with power 25 MVA and above) fail to pass short-circuit tests. When only the change of winding reactance (in accordance with IEC standard 60076-5) is taken into account, the initial failure rate drops to 28%. These results are discussed in the context of the reported much smaller failure rate in service. It is concluded that although statistically every transformer faces several full short-circuits during its life, the current that really occurs at such a full short-circuit current is smaller than the rated short-circuit for which the transformer is designed. In the future, however, this gap will narrow due to more efficient utilisation of the networks and growth of energy consumption.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDC.2003.1335380 },
  booktitle={ 2003 IEEE PES Transmission and Distribution Conference and Exposition (IEEE Cat. No.03CH37495) },
  chapter={0}
}

@article{rayyan-352345486,
  title={ Research on Failure Risk Assessment and Maintenance Tactics of Transformer based on the Extension Engineering Method and IAHP  -  2008 International Conference on High Voltage Engineering and Application },
  year={2008},
  author={Xie, Q. and Li, Y. and Liu, Y. and Li, Y. and Lv, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4774032 },
  abstract={There are many failure modes of transformer, and their probability and failure severity differ from each other. Based on the statistic data and experts advice, the probability of all failure modes are calculated, and divided into 5 grades. Meanwhile, IAHP was applied to calculate the weight of the transformer failure information, and Extension evaluation method was employed to create the frame work of the severities of failure modes qualitatively and divided them into 5 grades as well. Then, risk matrix is adopted to describe risk grades of failure modes, and power transformer risk maintenance strategies are obtained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2008.4774032 },
  booktitle={ 2008 International Conference on High Voltage Engineering and Application },
  chapter={0}
}

@article{rayyan-352345487,
  title={ Analysis of vacuum tap changer failures in power and converter transformers and maintenance suggestions  -  The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020) },
  year={2020},
  author={Yuan, Y. and Yang, J. and Bao, L. and Zhang, W. and Zhao, L. and Li, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538309 },
  abstract={In this paper, four vacuum tap changer failures in power and converter transformers are investigated. It is shown that oil contamination and arcing of auxiliary contacts are the main reasons for the failures. The protection and recorded fault current waves are analyzed. The three-phase imbalance current rate is proposed for the early warning of tap changer failure due to the delay initiation and activation of differential protection. A magnetic field FEM simulation model is also established to study the effect of tap changer failure on convert transformer, and the failure progress process has been reproduced successfully. Finally, the historical DGA data sets of thousands of vacuum tap changers in a certain region are collected and analyzed. Caution limits of acetylene of vacuum tap changers are obtained. According to the failure analysis and inspections, maintenance suggestions are proposed for the reference of power grid and manufacturers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2020.0083 },
  booktitle={ The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020) },
  chapter={0}
}

@article{rayyan-352345488,
  title={ The Hydran/sup (R/)-a system for the detection and monitoring of failure conditions in power transformers  -  IEE Colloquium on Monitors and Condition Assessment Equipment (Digest No. 1996/186) },
  year={1996},
  author={Martin, G. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=600664 },
  abstract={The author discusses early detection of transformer faults using dissolved gas analysis. The author describes Hydran technology used in dissolved gas analysis, and in particular the Hydran 201R on-line gas in oil monitor, the Hydran 201R Model i (microprocessor controlled device) and the Hydran 103B portable battery powered device.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/ic:19961066 },
  booktitle={ IEE Colloquium on Monitors and Condition Assessment Equipment (Digest No. 1996/186) },
  chapter={0}
}

@article{rayyan-352345489,
  title={ The influence of modelling transformer age related failures on system reliability  -  2015 IEEE Power & Energy Society General Meeting },
  year={2015},
  author={Awadallah, S. K. E. and Milanovic, J. and Jarman, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7285705 },
  abstract={The paper investigates the effect of age related failure of power transformers on the identification of most critical transformer sites for system reliability. The end-of-life failure model of power transformers is modified first to integrate loading conditions effect. The adopted Arrhenius-Weibull probability distribution, which represents the effect of thermal stress on the transformer's end-of-life failure, was compared with the commonly used Gaussian probability distribution model. The sensitivity of results to the uncertainty in model parameters is thoroughly assessed, and acceptable level of uncertainty is determined. The results demonstrated the importance of integration of loading conditions into the failure model. The sensitivity analysis revealed that the identification of critical transformer sites is not significantly affected by the uncertainty in the failure model parameters and that approximate ranges of parameters can be used instead of accurate values without significant, if any, loss in accuracy. The case studies were performed on a realistic transmission test system with 154 power transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESGM.2015.7285705 },
  booktitle={ 2015 IEEE Power & Energy Society General Meeting },
  chapter={0}
}

@article{rayyan-352345490,
  title={ The Development of a Distribution Transformer Not Subject to Destructive Failure  -  IEEE Transactions on Power Apparatus and Systems },
  year={1982},
  author={Ghinazzi, J. M. and Sokoly, T. O. and Stanger, R. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4111505 },
  abstract={Various materials and processes required for the construction of a nondestructive 15-kV class 50-kVA distribution transformer are being developed. High-temperature paint, low-temperature-melting glass, fiberglass cloth, and porcelain tubes have been used in modeling coils and transformers to prove the feasibility of an inorganically insulated distribution transformer. Techniques and equipment for applying the insulations and winding the coils are being developed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1982.317218 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345491,
  title={ Experience with distribution transformer loading and failure prediction  -  2006 IEEE Power Engineering Society General Meeting },
  year={2006},
  author={Henderson, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1709652 },
  abstract={Summary form only given. Utilities have used for years indicators such as loading, hot spot and top oil temperatures to determine ratings and health of substation transformers where the required data is readily available. However, the same level of data is not available for low voltage distribution transformers and loading prediction is difficult. Overload failures of distribution transformers, while not particularly significant to the utility network, can strain maintenance budgets, drain resources and sour customer relationships. Typically utilities use a transformer load management program that aggregates customer usage, estimates a peak and aggregates the peaks to a transformer for determining transformer load. Transformer replacement programs will then use loading as an indicator of replacement priority. However, most utilities have many more overloaded distribution transformers than they can economically replace, and predicting transformer failure is a very inexact science. One cause among several is poor data quality. Yet estimating loading requires good customer to transformer connectivity data and validated usage data at a minimum. We presented here one utility's experience with a continuous program of proactive distribution transformer replacements based on continuous calculation of loading from end use data. This program was the result of an alarming rate of transformer failures experience during several recent hot summers. Byproducts of this program were the recognition that loading alone is not a good indicator of potential outage, and that transformer age appears to have little or no correlation with transformer outages. Three consecutive years of locating and proactively replacing transformers that are likely to cause a transformer outage were presented including: data sources; methods; analysis; results to date; issues; conclusions to date. Calculated loading on actually failed distribution transformers was compared with loading of a large control group of not, or not-yet failed, distribution transformers, showing a clear correlation of calculated loading with probability of transformer failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2006.1709652 },
  booktitle={ 2006 IEEE Power Engineering Society General Meeting },
  chapter={0}
}

@article{rayyan-352345492,
  title={ FEM-study on converter transformer failures in the Celilo HVDC converter station  -  IEEE Power Engineering Society. 1999 Winter Meeting (Cat. No.99CH36233) },
  year={1999},
  author={Elliott, F. E. and Lavier, B. E. and Kuehn, W. P. and Kuechler, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=747346 },
  abstract={Two converter transformer failures occurring at the Celilo terminal of the Pacific Intertie HVDC transmission system, (one during commissioning in 1989 and one in operation in 1995), caused considerable concern regarding the reliability of the remaining converter transformers. These failures and discoloration of bushing porcelains observed during maintenance demanded a review of electric field stresses. This was done using a FEM field simulator and building a model which most accurately reflects the bushing/transformer arrangement with regard to the shape and data of the various conducting and insulating materials. Study results show that factory tests do not necessarily cover actual service stresses. Also the magnitude of the stress within critical areas might exceed withstand capabilities.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESW.1999.747346 },
  booktitle={ IEEE Power Engineering Society. 1999 Winter Meeting (Cat. No.99CH36233) },
  chapter={0}
}

@article{rayyan-352345494,
  title={ A 62.5 kVA 3-Phase Ferroresonant Transformer Cures Equipment Failures Caused by Severe Utility Interface Conditions  -  INTELEC '84 - International Telecommunications Energy Conference },
  year={1984},
  author={Powell, J. and Rhyne, E. and Ward, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4794123 },
  abstract={Unusual failure rates in satellite communications earth stations purchased by the Algerian government and steps taken to reduce fault occurrences are reviewed. Discussed in this case study are problems resulting from operation of tele-communications equipment in remote areas where 220/380 volt utility power experienced swings of 100 volts, transients ranged to 2000 volts, noise levels exceeded 60 volts, and harmonic distortion was sometimes greater than 20%. The primary causes of these power problems were electrical utility systems with marginal capability to meet demand, due to continuing industrialization programs. Environmental conditions also were a factor. Ambient temperatures to 60° C, and brief but violent electrical storms also contributed to equipment failures. This combination of hostile environment and unstable power resulted in excessive earth station downtime; Mean Time Between Failure (MTBF) was measured in days. After study of power conditions, and investigation of a variety of isolation devices, the project team decided on ferroresonance as the primary power conditioning technology. Custom transformers, based on an Uninterruptible Power Supply (UPS) three-phase ferro were designed and installed. This approach reduced voltage swings to acceptable levels, provided the necessary transient suppression and produced distortion-free sine-wave power. These power conditioning systems have been operating satisfactorily for some seven years. This design proved to be the forerunner of one of today's most successful versions of power conditioning equipment. Since installation of the original systems, the concept has evolved into an even higher reliability, higher performance product.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INTLEC.1984.4794123 },
  booktitle={ INTELEC '84 - International Telecommunications Energy Conference },
  chapter={0}
}

@article{rayyan-352345495,
  title={ Experimental Study on Dual parameter WeiBull Failure Model of Oil-Paper Insulation in Converter Transformers Considering the Influence of Harmonic Voltage  -  2024 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  year={2024},
  author={Zhang, N. and Hao, J. and Xu, J. and Wang, J. and Chen, H. and Liao, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10676178 },
  abstract={The main causes of harmonic distortion in new power systems are high percentage renewable energy grid connections and high percentage power electronic equipment access. These factors pose a serious threat to the ultra-high voltage converter transformers’ ability to perform as oil-paper insulation, and little research has been done on the failure law of oil-paper insulation that takes the effects of harmonic voltage into account. This paper presents the design and construction of a typical oil-paper insulation structure breakdown test platform, as well as the oil-paper insulation breakdown voltage under various frequency and content of harmonic voltage superimposed on the fundamental voltage. The dual parameter WeiBull distribution model is used to investigate the oil-paper insulation failure law under the influence of various harmonic voltage components. The experimental results show that the breakdown voltage of oil-paper insulation significantly decreases relative to the breakdown voltage of power frequency under the action of harmonic voltages with different frequencies and contents, and all follow a dual parameter WeiBull probability distribution. Among them, the minimum $\boldsymbol{U}_{63.2 \%}$ is about 13.47 kV when the 7 th and 11th harmonic voltage are superimposed, and the minimum $U_{63.2 \%}$ is about 13 kV when the 5th and 13th harmonic voltage are superimposed, which is about $\mathbf{2 3 \%}$ lower than the power frequency. Secondly, the fitting distribution of test data under the action of harmonic voltage of different frequencies and contents is approximately parallel, indicating that the failure mechanism of oil-paper insulation is the same.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE61955.2024.10676178 },
  booktitle={ 2024 IEEE International Conference on High Voltage Engineering and Applications (ICHVE) },
  chapter={0}
}

@article{rayyan-352345496,
  title={ Control Practices Contribute To Premature Transformer Failures  -  2007 IEEE Power Engineering Society Conference and Exposition in Africa - PowerAfrica },
  year={2007},
  author={Jauch, E. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4498036 },
  abstract={This paper focuses on tapchanger control practices and settings that may cause excessive or untimely tapchange operations. Recent case study evaluations of premature LTC (Load Tap Changer) transformer failures on utility systems identified the tap changers as a major contributing factor. Common practices discussed include basic voltage control ranges and setting effects, timing options available, LDC (line drop compensation) misapplications, first house protection methods and various paralleling techniques. The transformer applications considered include transmission tie transformers as well as transmission-distribution interface transformers. Attention is drawn to unusual network conditions as well as emergency or contingency system operations. These conditions and operations are continuously affected by automatic operations on the transmission and distribution systems, such as protective relay operations or load management techniques. Also detailed is common, in-field, paralleling commissioning practices that can create conditions for tapchanger "hunting." In many applications, a control function will result in different actions depending on the system configuration and parameters.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PESAFR.2007.4498036 },
  booktitle={ 2007 IEEE Power Engineering Society Conference and Exposition in Africa - PowerAfrica },
  chapter={0}
}

@article{rayyan-352345497,
  title={ A safety concept against destructive consequences of high voltage instrument transformer failures  -  Proceedings of the 1991 IEEE Power Engineering Society Transmission and Distribution Conference },
  year={1991},
  author={Innerling, J. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=169568 },
  abstract={High energy discharges in conventional oil paper insulated instrument transformers lead to explosions with disastrous consequences for the other substation equipment and the environment. The use of SF/sub 6/ gas as the insulating medium and a new transformer construction solves the problems and guarantees the prevention of any consequential damage. The physics, construction, and function of SF/sub 6/-insulated instrument transformers are described. Results from field experiences over a period of more than 10 years show the reliability of this safety concept.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDC.1991.169568 },
  booktitle={ Proceedings of the 1991 IEEE Power Engineering Society Transmission and Distribution Conference },
  chapter={0}
}

@article{rayyan-352345498,
  title={ An Application of Dissolved Gas Analysis (DGA) in the Assessment of Transformer Failures: A Focus on Geomagnetic Disturbances (GMDs)  -  2018 IEEE PES/IAS PowerAfrica },
  year={2018},
  author={Jerry, R. and Gope, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520973 },
  abstract={Power transformers are an integral part of transmission and distribution plant and are often characterised by long procurements lead-times as they usually cannot be bought off-the-shelf. The procurement and replacement of a power transformer may require processes of transformer design specification, tendering, bid evaluation, contract award, designing, transformer testing and transformer test certification, before delivery and commissioning of such a central transmission plant. As a result, power transformer failure may be costly to utilities depending on the severity of the failure. Power transformer failures arise due to a number of factors which may include electrical stress, mechanical factors and thermal degradation. Power transformer failure has also been shown to arise due to space weather-related phenomenon in the form of Geomagnetic Disturbances (GMDs) and the associated Geomagnetically Induced Currents (GICs). This study used empirical data from a power utility to investigate and re-assess a number of transformer failure cases from four substations - Substation 1, Substation 2, Substation 3 and Substation 4, in order to ascertain if the failures could have been induced by GMDs and the associated effects of GICs. For each Case-Study a Low Energy Degradation Triangle (LEDT) was developed using Dissolved Gas Analysis (DGA) data. There were 31 events which were reported from the Case Studies and for each event, geomagnetic storm disturbances preceding the fault day were plotted and analysed. The LEDT analys is showed an abnormality early in the lives of the power transformers, especially at Substation 2 and Substation 3. The analysis suggested that most of the power transformer faults were preceded by some geomagnetic activity, hence the Case Studies imply a causal relationship between power transformer faults and geomagnetic activity for these events. There were warning triggers on six (6) transformers in which four (4) of these failed within a year following their first triggers. On average the lifespan of a transformer is 40 years, however, this paper presents that the average lifespan of the power transformer units which failed within the power utility and had to be replaced was found to be 22.6 years. The results seem to suggest that Substation 3 and Substation 2 were the most affected by these geomagnetic storm activities compared to Substation 4 and Substation 1.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PowerAfrica.2018.8520973 },
  booktitle={ 2018 IEEE PES/IAS PowerAfrica },
  chapter={0}
}

@article{rayyan-352345499,
  title={ Thermal failure of transformers  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={Kulshreshtha, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580281 },
  abstract={The thermal failure in high voltage equipment is little heard and is generally known to have the slow & deteriorating effect on the insulation system, which ultimately reduce the life of the equipment. In a unique classical case, 9 units of 100 MVA 230/110/11 kV oil filled auto transformers supplied to one of the electrical utility in India failed in quick succession due to oil starvation in a particular part of the winding leading to thermal failure of complete lot of 9 nos. transformers at sites. In spite of oil starvation, the transformer withstood the voltage and passed all the dielectric tests successfully, which concludes that the dielectric failure had not occurred. The failure due to thermal failure was further confirmed by the different degrees of blackening of cellulose insulation depending upon the time, it has put into service. In this paper, findings of the studies made and corrective measures taken to avert such failures have been discussed & detailed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580281 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345501,
  title={ Association rule mining from failure analysis test reports of transformers  -  The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020) },
  year={2020},
  author={Hu, H. and Wang, D. and Fu, J. and Mao, Y. and Zhang, Z. and Guo, J. and Wen, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538194 },
  abstract={This paper proposes a methodology of association rule mining from the collected failure analysis test reports of distribution transformers. The failure rate of distribution transformers is much higher than that of high voltage power transformers in the main power network, because of numerous amounts, wide distribution, and low average budget of maintenance. Once a distribution transformer is out of operation, the proprietor will send the faulty transformer to a specialist institute to discover the cause of the failure and avoid the similar problem occurs again. Specialists firstly conduct various diagnostic tests on the faulty transformer, and disassemble the object for inspection if necessary. The specialists then provide the proprietor with a failure analysis report based on the tests and inspection. These institutes have accumulated years of testing cases and developed their own database. In experience, there is always a high possibility of common defects in distribution transformers sharing certain same factors. The process proposed in the paper offers a methodology to extract frequent patterns of failure test reports. The mined results are expected to help the specialist institute find strong related factors to failure causes of distribution transformers, and further help the proprietors reduce similar failure risks.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2020.0016 },
  booktitle={ The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020) },
  chapter={0}
}

@article{rayyan-352345502,
  title={ Transformer impulse failure detection methods  -  Electrical Engineering },
  year={1949},
  author={Aicher, L. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6444705 },
  abstract={COMMERCIAL impulse tests, which have been performed for approximately 16 years, are conducted in various manners depending upon the rules in effect at the time. Periodically, the rules are amended to incorporate improvements in the technique of testing. It is a purpose of this article to show how excitation during an impulse test complicates the test and interpretation of results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EE.1949.6444705 },
  booktitle={ Electrical Engineering },
  chapter={0}
}

@article{rayyan-352345503,
  title={ Failure causes and operational life of measuring transformers intalled in 150Kv transmission network  -  13th Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MEDPOWER 2022) },
  year={2022},
  author={Barkas, D. A. and Katemliadis, S. and Tarousinof, G. and Kalkanis, K. and Psomopoulos, C. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10137677 },
  abstract={Electric power infrastructures are the most critical. The required monitoring of electricity networks is achieved using instrument transformers. The instrument transformers' operating conditions must be kept steady and within safe limits. However, this entails the comprehension of the several reasons that lead toto failure. These reasons can introduce condition assessment monitoring techniques aiming to protect this type of electrical equipment and maybe contribute to their predictive maintenance. This paper describes the probable failures in high voltage instrument transformers with an operating voltage of 150kV, the rate and trend of failures as well as the basic sources for these failures. More specifically, this research has been applied to the 150kV instrument transformers that are installed at the Hellenic Electricity Transmission Network.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2022.3329 },
  booktitle={ 13th Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MEDPOWER 2022) },
  chapter={0}
}

@article{rayyan-352345505,
  title={ Internal winding failure due to resonance overvoltage in distribution transformer caused by winter lightning  -  2006 IEEE Power Engineering Society General Meeting },
  year={2006},
  author={Hori, M. and Nishioka, M. and Ikeda, Y. and Noguchi, K. and Kajimura, K. and Motoyama, H. and Kawamura, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1708981 },
  abstract={Summary form only given. In this paper, we describe the internal winding failures of the No. 3 distribution transformer at Katayamazu substation caused by winter lightning. Almost the same internal winding part of the transformer was damaged in January 1997 and November 2001. Therefore, detailed investigations of the cause of failures were carried out. From the investigations on the measurement of the frequency characteristics of transformer windings and detailed lightning surge analysis used by electro-magnetic transients program (EMTP), it was found that resonance overvoltages were generated by resonance phenomena between the surge waveform passing through the transformer and the natural frequency characteristics of the transformer winding. This finding was used to improve the winding form of tap windings and install a surge protection device between tap windings. After the improvement of winding structures, it was clearly shown that the internal stress of tap windings was reduced and the breakdown probability of the damaged part was significantly reduced},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2006.1708981 },
  booktitle={ 2006 IEEE Power Engineering Society General Meeting },
  chapter={0}
}

@article{rayyan-352345507,
  title={ Safety of distribution transformers against internal failure  -  14th International Conference and Exhibition on Electricity Distribution. Part 1. Contributions (IEE Conf. Publ. No. 438) },
  year={1997},
  author={Even, A. and Desmedt, M. and Schevensteen, R. Van},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=671637 },
  abstract={Tests have been carried out by LABORELEC and PAUWELS, on ELECTRABEL's initiative, in order to verify the efficiency of current limiting fuses and overpressure detecting devices to avoid any external effect in case of transformer internal failure. The test programme was set up with the following objectives: to know the pressure/volume relationship for a transformer tank of the type used on the network; to know the highest pressure in service, including overloading conditions; to know the pressure withstand limit; to know the time and current limits for the tank withstand against internal failure; to investigate the behaviour of arcs in oil; to make full scale tests with simulation of different types of faults; and to check the working of two types of pressure detecting devices. The tests have been done on hermetically sealed transformers which therefore have a specific design of the tank and cooling ribs. For the considered transformers, the tests have confirmed the efficiency of the fuse protection which could prevent any external effect during the tests. Despite those results and of the good service performance, one can not completely exclude that a fault in the secondary windings causes a pressure rise which goes beyond the tank withstand limit, but those can be controlled by a complementary protection using pressure detection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/cp:19970457 },
  booktitle={ 14th International Conference and Exhibition on Electricity Distribution. Part 1. Contributions (IEE Conf. Publ. No. 438) },
  chapter={0}
}

@article{rayyan-352345509,
  title={ Superconducting transformer failure: Testing and investigation  -  2009 Australasian Universities Power Engineering Conference },
  year={2009},
  author={Chew, I. and Lapthorn, A. and Bodger, P. and Enright, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5356596 },
  abstract={A partial core superconducting transformer, that was built in the Electrical and Computer Engineering Department, was tested under no-load, short-circuit, full-load and a two minute full-load endurance run. The first no-load, short-circuit and full load tests were only partially successful because the accuracy of the meters were not satisfactory enough to confirm the mathematical models. The transformer failed the endurance run; voltage dipping and rapid liquid nitrogen boil-off was observed one minute and a half into the test. An investigative approach was taken to determine the cause of the failure. The radial field at ends of the partial core, was determined not to have caused the tape to go out of its superconducting state. An open circuit test was performed on one of the outside winding which led to the discovery of a shorted turn. The windings and insulation of the transformer were taken apart to visually observe the faulty turns.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2009 Australasian Universities Power Engineering Conference },
  chapter={0}
}

@article{rayyan-352345510,
  title={ Case study of the failure of two 13.8KV control & metering transformers that caused significant equipment damage  -  2012 IEEE IAS Electrical Safety Workshop },
  year={2012},
  author={Dreifuerst, G. and Chew, P. E. D. and Mangonon, P. E. H. and Swyers, P. E. P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165539 },
  abstract={The degradation and failure of cast-coil epoxy windings within 13.8kV control power transformers and metering potential transformers has been shown to be dangerous to both equipment and personnel, even though best industrial design practices were followed. Accident scenes will be examined for two events at a U.S. Department of Energy laboratory. Failure modes will be explained and current design practices discussed with changes suggested to prevent a recurrence and to minimize future risk. New maintenance philosophies utilizing partial discharge testing of the transformers as a prediction of end-of-life will be examined.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ESW.2012.6165539 },
  booktitle={ 2012 IEEE IAS Electrical Safety Workshop },
  chapter={0}
}

@article{rayyan-352345511,
  title={ Online monitoring prevented catastrophic failure of a GSU transformer  -  Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Technology Conference (Cat. No.03CH37480) },
  year={2003},
  author={Garg, T. C. and Huber, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1247900 },
  abstract={Mirant Mid-Atlantic LLC experienced two generator step-up (GSU) transformer failures in 2001. Both failures occurred despite disciplined adherence to traditional regiments for electrical tests and dissolved gas analyses. In 2002, localized temperatures and accelerated hydrogen gas generation were the results of an active fault on the Morgantown Unit 02 GSU. In response, the frequency of dissolved gas analyses increased, and an on-line hydrogen and moisture analyzer was installed. The on-line analyzer provided advance warning of failure while the fault condition remained in the incipient stage. On-line monitoring of hydrogen generation prevented catastrophic failure, and enabled an inventive repair of the winding and expedited return to service of the step-up transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EICEMC.2003.1247900 },
  booktitle={ Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Technology Conference (Cat. No.03CH37480) },
  chapter={0}
}

@article{rayyan-352345513,
  title={ Investigation of internal resonances and winding insulation stresses in grounding transformer failures  -  Proceedings of the 6th International Conference on Properties and Applications of Dielectric Materials (Cat. No.00CH36347) },
  year={2000},
  author={Minglin, Zhu and Zishu, Zhu and Zhijian, Jin and Zhiyin, Qian},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=876365 },
  abstract={In Shanghai's 220 kV transformer substations, most 35 kV buses are connected with grounding transformers. In the past two years, several grounding transformers have failed, in which the internal insulation was damaged. In order to cope with the problem, this paper calculates and analyzes the switching overvoltages and electromotive force of the grounding transformer. Also the internal resonance feasibility of the winding was investigated, and electric potential distribution of disk-to-disk and turn-to-turn along the winding during the lightning impulse test was measured. A critically stressed position in the winding insulation was found and studied. Subsequently this paper shows that the main reason for failure of the grounding transformer is turn-to-turn insulating breakdown or damage near the HV line terminals. So effective steps are put forward; one is adding insulating thickness of turn to-turn near the incoming line, the other is decreasing the gradient of intrusive lightning surge.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPADM.2000.876365 },
  booktitle={ Proceedings of the 6th International Conference on Properties and Applications of Dielectric Materials (Cat. No.00CH36347) },
  chapter={0}
}

@article{rayyan-352345514,
  title={ Comparison of PD classification capabilities for transformer failure and typical noise models with neural network applications  -  2000 Annual Report Conference on Electrical Insulation and Dielectric Phenomena (Cat. No.00CH37132) },
  year={2000},
  author={Jin, X. H. and Wang, C. C. and Cheng, T. C. and Li, F. Q. and Dong, X. Z. and Jiang, Lei and Zhu, D. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=885283 },
  abstract={This paper presents three kinds of Neural Networks (NNs) for classifying Partial Discharges (PDs) of failure models which are extracted from internal insulation configurations of power transformers and typical noise in substations. The test results show that three networks can fairly classify the designed models. The performance of Back-Propagation (BP), Learning vector Quantization (LVQ) and Fuzzy ARTMAP networks is evaluated. The classification accuracies obtained from the three networks are compared with each other. In addition to the classification accuracy, the neural networks are analyzed for their generalization capability and stability of the results. Best results (accuracy and convergence time) are obtained with the Fuzzy ARTMAP network. Classification rate for the designed models is 100% at voltage level 3. Simulation results serve to illustrate the properties of various networks we used as well as the stability with respect to various critical parameters.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEIDP.2000.885283 },
  booktitle={ 2000 Annual Report Conference on Electrical Insulation and Dielectric Phenomena (Cat. No.00CH37132) },
  chapter={0}
}

@article{rayyan-352345515,
  title={ The Investigating of Winding Failure on 50 MVA Power Transformers by Performing SFRA Combined with Traditional Measurement  -  2020 8th International Conference on Condition Monitoring and Diagnosis (CMD) },
  year={2020},
  author={Singkhawat, P. and Pattanadech, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287193 },
  abstract={This paper presents the assessment for transformer winding's conditions by using the test method in terms of Sweep Frequency Response Analysis (SFRA), short-circuit leakage impedance, and winding capacitance measurement. The strength and weaknesses of the mentioned test methods are discussed in detail. The investigation of two power transformers rated of 50 MVA 115-23 kV is presented. The insulation condition of the first transformer was extremely risky. This transformer was experienced with the severely fault current and then was tripped out from the system. The test results indicated that one phase winding of this transformer deformed and eventually led to a shorted turn. For the second transformer, it was subjected to frequent non-severe external faults; the condition of this transformer was regularly investigated after each fault occurrence. The test results showed that the winding is likely to be deformed. Therefore, it was replaced by a new transformer to prevent sudden failure, which may happen if the defected transformer was still used in the power system. From these experiences, it is shown that the combination testing methods are needed to provide the efficiency investigation of the transformer problems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD48350.2020.9287193 },
  booktitle={ 2020 8th International Conference on Condition Monitoring and Diagnosis (CMD) },
  chapter={0}
}

@article{rayyan-352345516,
  title={ Development of a Distribution Transformer Not Subject to Destructive Failure--An Update  -  IEEE Transactions on Power Apparatus and Systems },
  year={1984},
  author={Sokoly, T. O. and Baranowski, J. F. and Goedde, G. L. and Ghinazzi, J. M. and Porter, J. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4112879 },
  abstract={This paper reviews the application of a pancake coil winding in a 25 kVA, 15 kV class distribution transformer that is constructed using inorganic insulating materials. Techniques for designing transformers utilizing pancake coils have been developed and confirmed in full-size working models.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1984.318246 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345517,
  title={ An interpretation of neural networks as inference engines with application to transformer failure diagnosis  -  2004 International Conference on Probabilistic Methods Applied to Power Systems },
  year={2004},
  author={Castro, A. R. G. and Miranda, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1378823 },
  abstract={An artificial neural network concept has been developed for transformer fault diagnosis using dissolved gas-in-oil analysis (DGA). A new methodology for mapping the neural network into a rule-based inference system is described. This mapping makes explicit the knowledge implicitly captured by the neural network during the learning stage, by transforming it into a fuzzy inference system. Some studies are reported, illustrating the good results obtained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2004 International Conference on Probabilistic Methods Applied to Power Systems },
  chapter={0}
}

@article{rayyan-352345518,
  title={ The study of transformer failure diagnose expert system based on rough set theory  -  The 4th International Power Electronics and Motion Control Conference, 2004. IPEMC 2004. },
  year={2004},
  author={Xinjian, Xiang and Jianfen, Shan and Fuchs, F. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1375624 },
  abstract={On the basis of the traditional diagnose expert system of transformer failure, hereby we introduce a theory to solve the bottleneck problem of what expert system can hardly obtain complete knowledge. By the decision table formed by recorded failure data, the system uses "RS" theory to simplify and set up the knowledge model of expert system. The trustiness of the diagnose rule is expressed by counting the rough degree of inferring rule, inferring machine and failure data is used to realize the dynamic protection of knowledge storage.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ The 4th International Power Electronics and Motion Control Conference, 2004. IPEMC 2004. },
  chapter={0}
}

@article{rayyan-352345519,
  title={ Research on Voltage Compensation Measures Based on Reducing Commutation Failure and Converter Transformer Tap Loss  -  EMIE 2022; The 2nd International Conference on Electronic Materials and Information Engineering },
  year={2022},
  author={Qiao, G. and Yu, Z. and Niu, Y. and Wang, Y. and Chen, T. and Ma, L. and Wang, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048285 },
  abstract={Commutation failure is one of the most common faults in HVDC transmission. The frequent action of converter transformer tap will shorten the service life and reliability of converter transformer, which may lead to commutation failure. In order to reduce the tap loss of converter transformer and suppress the occurrence of commutation failure, a method of voltage compensation with controllable voltage source on the valve side of converter transformer is proposed. Simulation results show that the proposed method not only greatly reduces the tap action of converter transformer, but also plays a certain role in restraining commutation failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ EMIE 2022; The 2nd International Conference on Electronic Materials and Information Engineering },
  chapter={0}
}

@article{rayyan-352345520,
  title={ Failure analysis of dry type power transformer  -  Conference Record of the 2000 IEEE Industry Applications Conference. Thirty-Fifth IAS Annual Meeting and World Conference on Industrial Applications of Electrical Energy (Cat. No.00CH37129) },
  year={2000},
  author={Paul, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=882629 },
  abstract={This paper provides the failure analysis of three phase, dry type, silicone resin vacuum pressure encapsulated, 750/1000 kVA, AA/FA, 34.5 kV-480 Y/277 V, delta-wye, power transformer. Transient overvoltage switching surge propagation through the transformer winding and protection margin is discussed. An arbitrary sensitivity of 10 pico-coulombs (pc) at 120% rated voltage generally used for the partial discharge tests at the factory may be inadequate for the design of the failed transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAS.2000.882629 },
  booktitle={ Conference Record of the 2000 IEEE Industry Applications Conference. Thirty-Fifth IAS Annual Meeting and World Conference on Industrial Applications of Electrical Energy (Cat. No.00CH37129) },
  chapter={0}
}

@article{rayyan-352345521,
  title={ A Study of Rectifier Circuit Failure with Special Winding Type Twenty-four-phase Transformer  -  2024 13th International Conference on Renewable Energy Research and Applications (ICRERA) },
  year={2024},
  author={Matsunaga, A. and Goto, T. and Yukita, K. and Nanahara, T. and Kato, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10815534 },
  abstract={This paper examines the effects of a missing diode in the rectifier circuit of a special winding twenty-four-phase transformer. Until recently, we studied AC-DC transformers developed for grid power in dc distribution networks. We developed a special winding structure transformer that reduces the number of windings more effectively than traditional designs. We found that when the positive-side diode of Rl was missing, the DC ripple increased by 8.35%. but when other locations were lacking, no change in DC voltage was observed. For line voltage, when the positive diode of phase Rl is missing, the base phase shifts from phase Rl to phase T8 and S6. When diodes in other phases are missing, the line voltage lacks one phase.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICRERA62673.2024.10815534 },
  booktitle={ 2024 13th International Conference on Renewable Energy Research and Applications (ICRERA) },
  chapter={0}
}

@article{rayyan-352345522,
  title={ The assessment of deteriorating level of transformer oil by (A) ferrographic technique and (B) thermal ageing failure data  -  Proceedings of 1995 Conference on Electrical Insulation and Dielectric Phenomena },
  year={1995},
  author={Raghavender, D. and Chede, S. D. and Banerjee, N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=483726 },
  abstract={The qualitative characteristics of transformer oil plays an important role in evaluating the working performance of transformers. The most predominant factors responsible for causing deterioration of transformer oil and subsequently failure of transformers are: 1) Development of internal pressure in the oil. 2) The rise in temperature during operating conditions. 3) Frequent change in operating voltage levels. 4) Rapid deterioration of solid insulating materials such as laminated paper, press board, various kinds of paper/cloth, both electrically and mechanically. The above mentioned causes of deterioration of oil directly or indirectly affect the working condition of the transformers in the field. This paper illustrates the assessment of deterioration level of transformer oil by ferro-graphic technique and thermal ageing failure data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CEIDP.1995.483726 },
  booktitle={ Proceedings of 1995 Conference on Electrical Insulation and Dielectric Phenomena },
  chapter={0}
}

@article{rayyan-352345523,
  title={ Protection of distribution transformers from failure due to lightning  -  Electrical Engineering },
  year={1932},
  author={Opsahl, A. M. and Brookes, A. S. and Southgate, R. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6429600 },
  abstract={USUAL methods of connecting arresters for the protection of distribution transformers often are inadequate, resulting in flashover of bushings or windings due to lightning, even though the arrester in itself is capable of protecting the transformer with a large factor of safety. Such flashover may be attributed to the fact that surge current flowing to ground through the ground leads of the arrester gives rise to inductive drop and resistance drop which add to the arrester voltage.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EE.1932.6429600 },
  booktitle={ Electrical Engineering },
  chapter={0}
}

@article{rayyan-352345524,
  title={ Pre-Requisites For Short Circuit Withstand Test On Transformer & Its Failure Analysis  -  2022 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES) },
  year={2022},
  author={Kumar, K. S. and Sahoo, D. and Agrawal, Y. and Takkher, M. S. and Wadhwani, M. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10080019 },
  abstract={Transformers are always subjected to various electrical, thermal, mechanical and dielectric stresses during its life time under both normal and abnormal conditions. The most onerous and fatal situation that is encountered by the transformer is short circuit condition due to which the transformer has to undergo severe electro-dynamic forces produced by the high currents. Thus in this paper obligations for short circuit withstand test on transformer and its failure analysis has been discussed with reference to various power transformers tested at CPRI as per IS & IEC standards.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PEDES56012.2022.10080019 },
  booktitle={ 2022 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES) },
  chapter={0}
}

@article{rayyan-352345525,
  title={ Voltage transformer failure during routine switching in Drill Site  -  17th International Conference on Developments in Power System Protection (DPSP 2024) },
  year={2024},
  author={Fotiou, G. and Alsuhaibani, A. and Zubair, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542926 },
  abstract={An extensive 34.5kV Drake overhead line network (OHL) supplies power to a group of Drill Sites scattered across a vast desert area. During routine energization in one of these sites, a bus-side voltage transformer experienced an insulation failure at the primary winding neutral point. This paper summarizes the frequency domain analysis to identify the root cause of the failure, as well as the phasor domain methodology to determine the parameter limits of the neutral voltage displacement (ANSI59) and negative sequence overvoltage (ANSI47) as protection functions against transient overvoltage conditions (TOV) and slow front transients (SFO) caused by switching, fault clearance or ferroresonance. As a lesson learned, installing an additional surge arrester at the main incomer, in addition to the one at the riser pole, must always be evaluated against ground faults close to the supply cable termination.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2024.1015 },
  booktitle={ 17th International Conference on Developments in Power System Protection (DPSP 2024) },
  chapter={0}
}

@article{rayyan-352345526,
  title={ Analysis and simulation of the whole failure process of 35kV metal oxide varistor at outlet of main transformer  -  18th International Conference on AC and DC Power Transmission (ACDC 2022) },
  year={2022},
  author={Wen, W. and Hu, T. and Bian, Z. and Wei, D. and Lin, Y. and Guo, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868563 },
  abstract={Equipment failure occurs frequently at the low-voltage side of main transformer, and the most common faults is metal oxide arrestors (MOV) explosion and potential transformers (PT) damage under different ground fault. However, because of the lack for simulation model, it is quite difficult to conduct accurate analysis of the whole fault process, and the fault cannot be effectively prevented. To solve this problem, research on analysis and simulation of the whole fault process of 35kV MOV configured at the outlet of main transformer is carried out in this paper. Basic information and recording waveforms about the field fault in 110kV/35kV/10kV substation and relative theoretical analysis are presented first. Simulation model is established in PSCAD/ETMDC, and the simulation results are consistent with theoretical analysis and recording results. The whole fault process is: C-phase ground fault occurred first. Then, A-phase and B-phase voltage increased to line-line voltage from phase-phase voltage, and this overvoltage caused breakdown of A-phase MOV. As a result, the C-phase ground fault transferred to A-C phase ground fault. After the arc in MOV extinguished, the A-C phase ground fault changed back to Cphase ground fault.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1049/icp.2022.1420 },
  booktitle={ 18th International Conference on AC and DC Power Transmission (ACDC 2022) },
  chapter={0}
}

@article{rayyan-352345527,
  title={ Reliability analysis of premature failed 11/0.433kV hermetically sealed distribution transformers  -  2011 IEEE Colloquium on Humanities, Science and Engineering },
  year={2011},
  author={Ridwan, Mohd Iqbal and Samsudin, Mohd Raffi and Ghazali, Y. Z. Yang},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163742 },
  abstract={There were around 450 units of 11/0.433kV distribution transformers which have found to fail prematurely over the past 15 years. These distribution transformers are vital to power utilities as they supply electricity to respective customers in industrial, commercial or domestic areas. Failure of distribution transformers will result in power interruption which not only reduces the utility's revenue, but also causes loss of customer confidence towards the utility. Hence, it is imperative that power utilities, such as Tenaga Nasional Berhad (TNB) to perform studies to assess the reliability of distribution transformer. The reliability analysis is supported by the internal inspection which was guided by a standardized procedure. This paper presents a reliability analysis method called Life Data Analysis which utilizes statistical distribution, Weibull distribution to analyze and compare the reliability of distribution transformers from 3 different manufacturers. It has been found that the findings of the reliability parameters are consistent with the nature of incipient faults in the transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CHUSER.2011.6163742 },
  booktitle={ 2011 IEEE Colloquium on Humanities, Science and Engineering },
  chapter={0}
}

@article{rayyan-352345528,
  title={ Risk Assessment and Mitigation Strategy of 120 lightly loaded Power Transformers Containing Dibenzyl Disulphide  -  2023 IEEE Electrical Insulation Conference (EIC) },
  year={2023},
  author={Malan, J. D. and Zahrani, R. J. and S.Rowais, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177374 },
  abstract={The paper presents the mitigation strategy of 120 lightly loaded Power Transformers that contains Dibenzyl Disulphide and challenges in terms of failure probability, risk and reliability. A Case Study of the 120 transformers incorporates the guidelines in CIGRE WG A2.40 and applies a statistical method (Weibull distribution) to quantify the risk associated with lightly loaded HVPTs containing DBDS. The results from Insulating oil samples collected over three years were studied, in particularly, the significance of mercaptan, toluene, hydrogen sulphide, peroxide and depletion of DBDS to identify corrosion trends. Based on the failure rate of γ=0.12 % for the most affected batch of transformers from a specific Original Equipment Manufacturer compared to the overall affected population with a failure rate of γ=0.16 %, it is concluded that the risk of failure associated with DBDS is low. Four mitigation solutions were assessed and evaluated from a cost impact and efficiency perspective comprising passivation, oil replacement, selective depolarization and modified alumina-based sorbent. The paper demonstrates the viability of maintenance and risk mitigation strategies at attractive lifecycle cost combined with the collateral benefit of the proposed risk mitigation solution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC55835.2023.10177374 },
  booktitle={ 2023 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345529,
  title={ Reliability Analysis of Three-Phase Transformer-Less UPS Using SiC Devices  -  2024 27th International Conference on Electrical Machines and Systems (ICEMS) },
  year={2024},
  author={Lee, T. -J. and Lee, D. -J. and Kim, R. -Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10921274 },
  abstract={Due to the recent development and production of semiconductor switching devices with a Wide Band Gap, research aimed at reducing power conversion losses and improving efficiency has been actively conducted. Studies are also ongoing to apply SiC MOSFET in Uninterruptible Power Supply (UPS) systems that protect critical load equipment from power distortions and outages, with the goal of achieving high efficiency and high power density. However, research on the reliability of UPS systems, particularly in predicting their operational lifespan and improving availability through preventive maintenance, remains relatively insufficient. In this paper aims to design a Transformer-less UPS based on SiC MOSFET and compare and analyze its reliability with that of conventional Si IGBT-based UPS systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/ICEMS60997.2024.10921274 },
  booktitle={ 2024 27th International Conference on Electrical Machines and Systems (ICEMS) },
  chapter={0}
}

@article{rayyan-352345531,
  title={ When to Replace Aging Transformers, Part 2: Guidelines to Replace Older Transformers Before Failure  -  IEEE Industry Applications Magazine },
  year={2023},
  author={Dixon, F. L. and Robey, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986305 },
  abstract={Part 2 of “When to replace aging transformers” uses the initial case study to define basic problems surrounding transformers that were in service for more than 60 years. This article provides an update on transformers returned to service and that are now 71 years old. It expounds more deeply on the insulation system, testing, and criteria used to determine whether to allow a transformer to remain in service or to be replaced. It explores the technique of using the degree of polymerization (DP) to assess the remaining life of insulation as defined in the standards. With today’s information gathering techniques and database manipulation, the method of online monitoring will be discussed. Additional information is available in the paper “When to Replace Aging Transformers” [3].},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIAS.2022.3214023 },
  booktitle={ IEEE Industry Applications Magazine },
  chapter={0}
}

@article{rayyan-352345532,
  title={ Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries  -  2024 IEEE 18th International Conference on Semantic Computing (ICSC) },
  year={2024},
  author={Ngu, N. and Lee, N. and Shakarian, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475653 },
  abstract={Hallucinations and reasoning errors limit the ability of large language models (LLMs) to serve as a natural language interface for various prompts. Meanwhile, error prediction in large language models often relies on domain-specific information. In this paper, we present domain independent measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt specifically considering components of the response. This results in an approach that is well-suited for prompts where the response can be viewed as an answer set such as semantic prompts, a common natural language interface use-case. We describe how three such measures - based on entropy, Gini impurity, and centroid distance - can be employed. We perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. Additionally, we present empirical results demonstrating how these measures can be applied to few-shot prompting, chain-of-thought reasoning, and error detection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSC59802.2024.00034 },
  booktitle={ 2024 IEEE 18th International Conference on Semantic Computing (ICSC) },
  chapter={0}
}

@article{rayyan-352345533,
  title={ Nonlinear Interpretation Technique for Lightning Impulse Test  -  IEEE Transactions on Power Delivery },
  year={2015},
  author={Velandy, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066880 },
  abstract={The nonlinear interpretation technique is proposed to detect the fault in transformer windings during the impulse test. To prove feasibility of the proposed technique, 90-MVA 220/110-kV, 250-MVA 500/275/33-kV transformers, and a 22-kV interleaved winding are used.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2015.2412681 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345535,
  title={ A Position-Aware Approach to Decomposing God Classes  -  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  year={2024},
  author={Chen, T. and Jiang, Y. and Fan, F. and Liu, B. and Liu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764821 },
  abstract={God classes are widely recognized as code smells, significantly impairing the maintainability and readability of source code. However, resolving the identified God classes remains a formidable challenge, and we still lack automated and accurate tools to resolve God classes automatically. To this end, in this paper, we propose a novel approach (called ClassSplitter) to decompose God classes. The key observation behind the proposed approach is that software entities (i.e., methods and fields) that are physically adjacent often have strong semantic correlations and thus have a great chance of being classified into the same class during God class deposition. We validate this hypothesis by analyzing 54 God class decomposition refactorings actually conducted in the wild. According to the observation, we measure the similarity between software entities by exploiting not only traditional code metrics but also their relative physical positions. Based on the similarity, we customize a clustering algorithm to classify the methods within a given God class, and each of the resulting clusters is taken as a new class. Finally, ClassSplitter allocates the fields of the God class to the new classes according to the field-access-based coupling between fields and classes. We evaluate ClassSplitter using 133 real-world God classes from open-source applications. Our evaluation results suggest that ClassSplitter could substantially improve the state of the art in God class decomposition, improving the average MoJoFM by 47%. Manual evaluation also confirmed that in most cases (77%) the solutions suggested by ClassSplitter were preferred by developers to alternatives suggested by the state-of-the-art baseline approach.CCS CONCEPTS• Software and its engineering → Maintaining software; Soft-ware evolution.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE) },
  chapter={0}
}

@article{rayyan-352345536,
  title={ An Explainable Transformer-Based Deep Learning Model for the Prediction of Incident Heart Failure },
  year={2022},
  journal={ IEEE Journal of Biomedical and Health Informatics },
  author={Rao, S. and Li, Y. and Ramakrishnan, R. and Hassaine, A. and Canoy, D. and Cleland, J. and Lukasiewicz, T. and Salimi-Khorshidi, G. and Rahimi, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706318 },
  abstract={Predicting the incidence of complex chronic conditions such as heart failure is challenging. Deep learning models applied to rich electronic health records may improve prediction but remain unexplainable hampering their wider use in medical practice. We aimed to develop a deep-learning framework for accurate and yet explainable prediction of 6-month incident heart failure (HF). Using 100,071 patients from longitudinal linked electronic health records across the U.K., we applied a novel Transformer-based risk model using all community and hospital diagnoses and medications contextualized within the age and calendar year for each patient's clinical encounter. Feature importance was investigated with an ablation analysis to compare model performance when alternatively removing features and by comparing the variability of temporal representations. A post-hoc perturbation technique was conducted to propagate the changes in the input to the outcome for feature contribution analyses. Our model achieved 0.93 area under the receiver operator curve and 0.69 area under the precision-recall curve on internal 5-fold cross validation and outperformed existing deep learning models. Ablation analysis indicated medication is important for predicting HF risk, calendar year is more important than chronological age, which was further reinforced by temporal variability analysis. Contribution analyses identified risk factors that are closely related to HF. Many of them were consistent with existing knowledge from clinical and epidemiological research but several new associations were revealed which had not been considered in expert-driven risk prediction models. In conclusion, the results highlight that our deep learning model, in addition high predictive performance, can inform data-driven risk factor identification.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JBHI.2022.3148820 },
  chapter={0}
}

@article{rayyan-352345537,
  title={ Quantification of Uncertainty in End-of-Life Failure Models of Power Transformers for Transmission Systems Reliability Studies  -  IEEE Transactions on Power Systems },
  year={2016},
  author={Awadallah, S. K. E. and Milanović, J. V. and Jarman, P. N.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7330050 },
  abstract={Power system components have a relatively long life span and hence there is not enough data to derive an accurate end-of-life failure model. This contributes to the uncertainty in system reliability assessment. This paper discusses the quantification of the effect of uncertainty in end-of-life failure models on system reliability indices. This paper characterizes the uncertainty by a mixed aleatory-epistemic uncertainty model, where the aleatory uncertainty originated from the variability of failure events and the epistemic uncertainty originated from a lack of data. The mixed aleatory-epistemic uncertainty was propagated using two methods: Second Order Probability and Dempster-Shafer Evidence Theory (DSET). Power transformers were chosen as the case study equipment and the methods were applied on a realistic transmission network.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2015.2497969 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345538,
  title={ Cross-correlation aided wavelet network for classification of dynamic insulation failures in transformer winding during impulse test  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2011},
  author={Rajamani, P. and Dey, D. and Chakravorti, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5739458 },
  abstract={Wavelet network based approach for identification of fault characteristics of dynamic insulation failure during impulse test has been proposed. The network identifies the fault characteristics using the significant features extracted from cross-correlation sequence of winding currents of no-fault as well as impulse faulted winding insulation. The required winding current waveforms to extract significant features for identification of various fault characteristics are acquired by emulating different dynamic insulation failures in the analog model of 33 kV winding of 3 MVA transformer using developed analog fault simulator. The results show that the wavelet network using cross-correlation features has successfully identified the dynamic insulation failure characteristics, viz. fault type, condition and location of occurrence of failure along the length of the winding with acceptable accuracy. The efficacy of extracted features and developed wavelet network for fault characteristics identification is also compared with artificial neural network classifier. The concept of emulation of dynamic insulation failure, cross-correlation based feature extraction and wavelet based fault characteristics identification methods are explained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2011.5739458 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345539,
  title={ A Novel Commutation Failure Mitigation Method Based on Transformer-Side Magnetic Coupling Injection  -  IEEE Transactions on Power Delivery },
  year={2023},
  author={Yang, G. and Qi, L. and Zhang, X. and Cui, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878212 },
  abstract={To mitigate the commutation failure (CF), the topology of the line-commutated converter high-voltage direct current (LCC-HVDC) needs to be modified. However, the power loss and capital cost of the modification schemes proposed in the existing literature are relatively high. A novel commutation failure mitigation method based on transformer-side magnetic coupling injection (TMCI) module is proposed in this paper. The topology and working principle of the TMCI module are presented. Considering the CF prediction and turn-off time of the thyristor, the control strategy of the TMCI module is designed. For the TMCI module, the voltage of the capacitor and voltage-current stress of thyristors are analysed, and the method to select parameters is designed. Then, a test system with the TMCI module is developed based on the CIGRE HVDC benchmark model. The simulation results show that the TMCI module can effectively mitigate CFs under AC fault conditions. Furthermore, compared with the enhanced capacitor commutated converter (ECCC) and the evolutional line-commutated converter (ELCC) proposed in the existing literature, the TMCI module can not only offer the best CF immunity with the least capital cost, but also has lower steady-state active power losses and less impact on the system reliability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2022.3204530 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345541,
  title={ IEEE Guide for Failure Investigation, Documentation, Analysis, and Reporting for Power Transformers and Shunt Reactors  -  IEEE Std C57.125-2015 (Revision of IEEE Std C57.125-1991) },
  year={2015},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741317 },
  abstract={A procedure to be used to perform a failure analysis is recommended. The procedure is primarily focused on power transformers used on electric utility systems, although it may be used for an investigation into any ac transformer failure. This document provides a methodology by which the most probable cause of any particular transformer failure may be determined. This document is also intended to encourage the establishment of routine and uniform data collection procedures, consistency of nomenclature and compatibility with similar efforts by other organizations, and cooperative efforts by users and manufacturers during the failure analysis.(Also supersedes IEEE C57.117-1986)},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEESTD.2015.8741317 },
  booktitle={ IEEE Std C57.125-2015 (Revision of IEEE Std C57.125-1991) },
  chapter={0}
}

@article{rayyan-352345542,
  title={ Failure Rate Prediction of a Power Transformer: A Decomposition-Based Bayesian Deep Learning Method },
  year={2025},
  journal={ CSEE Journal of Power and Energy Systems },
  author={Zhang, W. and Shao, C. and Huang, W. and Hu, B. and Yan, J. and Xie, K. and Cao, M. and Wei, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10026211 },
  abstract={Power transformers, as essential equipment for electricity transmission, may fail due to insulation degradation. Predicting the failure rate of power transformers precisely is beneficial to decision-making. Currently, uncertainties of the prediction have not been deeply discussed. Besides, prediction accuracy is not high enough. This paper proposes a decomposition-based Bayesian deep learning (BDL) method to predict the failure rate of power transformers. Both the model uncertainty related to distribution of the model's weights and the inherent uncertainty associated with random noise can be captured by BDL. Uncertainties of prediction results are depicted with confidence intervals. Moreover, prediction accuracy is improved using variational mode decomposition (VMD). Numerical experiments have been carried out based on oil chromatographic data of power transformers from the Chongqing grid to validate effectiveness of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.17775/CSEEJPES.2021.04880 },
  chapter={0}
}

@article{rayyan-352345544,
  title={ A New Online Method Based on Leakage Flux Analysis for the Early Detection and Location of Insulating Failures in Power Transformers: Application to Remote Condition Monitoring  -  IEEE Transactions on Power Delivery },
  year={2007},
  author={Cabanas, M. F. and Melero, M. G. and Pedrayes, F. and Rojas, C. H. and Orcajo, G. A. and Cano, J. M. and Iglesias, J. G. and Nuno, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4265655 },
  abstract={Power transformers figure to be amongst the most costly pieces of equipment used in electrical systems. A major research effort has therefore focused on detecting failures of their insulating systems prior to unexpected machine outage. Although several industrial methods exist for the online and offline monitoring of power transformers, all of them are expensive and complex, and require the use of specific electronic instrumentation. For these reasons, this paper will present online analysis of transformer leakage flux as an efficient alternative procedure for assessing machine integrity and detecting the presence of insulating failures during their earliest stages. A 12-kVA 400-V/400-V power transformer was specifically manufactured for the study. A finite-element model of the machine was designed to obtain the transient distribution of leakage flux lines in the machine's transversal section under normal operating conditions and when shorted turns are intentionally produced. Very cheap and simple sensors, based on air-core coils, were built in order to measure the leakage flux of the transformer, and nondestructive tests were also applied to the machine in order to analyze pre and postfailure voltages induced in the coils. Results point to the ability to detect very early stages of failure, as well as locating the position of the shorted turn in the transformer windings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2006.881620 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345546,
  title={ Data Requisites for Transformer Statistical Lifetime Modelling—Part II: Combination of Random and Aging-Related Failures  -  IEEE Transactions on Power Delivery },
  year={2014},
  author={Zhou, D. and Wang, Z. and Jarman, P. and Li, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6555940 },
  abstract={Statistical lifetime modeling is of importance for replacement management of aged power transformers. Survival data are recognized as important as failure data in improving the accuracy level of the lifetime models since transformer failures are rare events and most of the units are still in operating condition. This paper argues that differentiating random failures and aging-related failures is also important. Different data requisites for modeling random failures and aging-related failures are analyzed and compared through Monte Carlo simulations. The transformer life-cycle failure model can be built by combining the random and aging-related failure models. A case study is presented to show that through postmortem analysis, the two failure modes can be distinguished and, hence, it helps to improve the accuracy of the combined model.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2013.2270116 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345547,
  title={ Temperature Measuring-Based Decision-Making Prognostic Approach in Electric Power Transformers Winding Failures  -  IEEE Transactions on Instrumentation and Measurement },
  year={2020},
  author={Soleimani, M. and Faiz, J. and Nasab, P. S. and Moallem, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004561 },
  abstract={The electric power transformer is a vital apparatus in power systems, and failure prognostics is significant for the protection of this asset. In addition to the asset damage, its unexpected failure would interrupt power delivery and jeopardize the stability of the system. There are several fault diagnosis methods introduced for the detection of this kind of fault; however, their functionality is for the postfault condition when the asset is already damaged, and the operation of the system is interrupted. Electric insulation deteriorations make the transformers susceptive to faults due to thermal and electrical stresses. In this article, the impact of early stages insulation deteriorations on the temperature inside the transformer is studied using a finite-element electromagnetic-thermofluid method and based on the observations an online sensor-based decision-making predictive fault diagnosis approach is proposed. Finally, the results are experimentally verified.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIM.2020.2975386 },
  booktitle={ IEEE Transactions on Instrumentation and Measurement },
  chapter={0}
}

@article{rayyan-352345549,
  title={ Smart Energy Management System: Oil Immersed Power Transformer Failure Prediction and Classification Techniques Based on DGA Data  -  2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET) },
  year={2022},
  author={Laayati, O. and Hadraoui, H. El and Bouzi, M. and Chebak, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9737786 },
  abstract={The power transformer is the key element in the electrical grid. The failures of the power transformer impact critically the grid, can cause energy loss and blackouts. In energy production, transmission, distribution, and industrial applications, the oil immersed power transformer is the most used. The maintenance of this key equipment is highly important which can be done with different techniques such as thermal and vibration analysis, frequency analysis using wavelet transform and dissolved gas analysis. The application of predictive maintenance of the power transformer represents an important feature of the Smart Energy Management System in micro grids, that can reduce the percentage of failure occurrence while increasing the availability of the power transformer and prevents blackouts. This paper represents different failure classification techniques based on dissolved gas analysis data mainly logistic regression, multiclass jungle, multiclass decision tree and artificial neural network. The application can diagnosis the power transformer failures based on the parts-per-million of the different gas generated in the oil. The results of applying different types of classification algorithms shows the best technique to be part of a bigger system of monitoring and diagnostic of different installed equipment in a micro grid. The implementation of such application in real time energy management system requires different type of sensors and the interaction of offline database, the paper also shows the steps to integrate the algorithm in the Smart Energy Management System.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IRASET52964.2022.9737786 },
  booktitle={ 2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET) },
  chapter={0}
}

@article{rayyan-352345550,
  title={ Statistical failure reliability analysis on edible and non edible natural esters based liquid insulation for the applications in high voltage transformers  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2018},
  author={Bakrutheen, M. and Iruthayarajan, M. W. and Narayani, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8484866 },
  abstract={In the recent decades, the natural esters have gained more attention as an alternate liquid insulation instead of the petroleum based mineral oil due to the development on power system networks and their environmental friendly nature. The failure free functioning of high voltage transformer mainly depends on the reliability of insulation used inside it. In this work, edible and non edible natural esters are studied and analyzed by using statistical distribution of the AC breakdown voltage in order to ensure their reliability. In this investigation work, sunflower oil (SFO), palm oil (PO) and sesame oil (SO) are studied under the category of edible natural esters, while honge oil (HO), neem oil (NEO) and punna oil (PAO) are analyzed under the non edible natural esters category. The applicability of investigated esters as liquid insulation is analyzed with distribution models like normal, Weibull and generalized extreme value (GEV) distributions. The statistical failure reliability analysis is carried out with the distribution functions such as survival rate, hazard rate and failure rate from the 100 distributed values of AC breakdown voltages of the investigating natural esters. The statistical analysis reveals the better characteristics for natural esters (edible and non edible) such as superior survival rate at higher value of electric stress, possibility of failure occurrence only at the wear out range and elevated statistical withstand voltage at various failure rates. Comparing both the category of natural esters, non edible natural esters have shown the superior characteristics than the edible natural esters. Consequently, it is evident that the natural esters are reliable and potential surrogate to the conventional liquid insulation for the application in high voltage transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2018.006628 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345551,
  title={ New Algorithm Applied to Transformers' Failures Detection Based on Karhunen–Loève Transform  -  IEEE Transactions on Industrial Informatics },
  year={2023},
  author={de Castro, B. A. and Binotto, A. and Ardila-Rey, J. A. and Fraga, J. R. C. P. and Smith, C. and Andreoli, A. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10036098 },
  abstract={Industry and science have been growing attention to developing systems that ensure the integrity of high voltage devices like power transformers. The goal is to avoid unexpected stoppages by detecting incipient failures before they become a major problem. In this context, the detection of discharge activity is an effective way to assess the condition operation of power transformers since this type of flaw can lead the transformer to total failure. The effectiveness of the fault diagnosis systems is related to their capability to distinguish the types of discharges since different flaws require different maintenance planning. This article proposes a new data analysis, which combined the frequency spectrum of the signals with the Karhunen–Loève Transform to perform self-organization maps. The effectiveness of this analysis was validated by comparing it with the Fundamental Signals Properties Classification Technique, which is widely applied for pattern recognition. Two types of sensing techniques were assessed in order to enhance the capability of the new approach. Results indicated that the new methodology presented lower standard deviation for data classification, being a promising tool to monitoring systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TII.2023.3240590 },
  booktitle={ IEEE Transactions on Industrial Informatics },
  chapter={0}
}

@article{rayyan-352345552,
  title={ Medium voltage switching transient induced potential transformer failures; prediction, measurement and practical solutions  -  48th IEEE Industrial & Commercial Power Systems Conference },
  year={2012},
  author={McDermit, D. and Shipp, D. D. and Dionise, T. J. and Lorch, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6229608 },
  abstract={During commissioning of a large data center, while switching medium voltage circuit breakers without any appreciable load, several potential transformers failed catastrophically. A detailed investigation, including computer simulation was performed. Ferroresonance produced by switching transients associated with opening and closing the vacuum breakers, was determined to be the cause. The analysis also determined that the close-coupled power transformers were also in jeopardy. Field inspections involving grounding improvements coupled with solution simulations were made. High speed switching transient measurements were performed to verify the analysis and the surge protective devices solution (arresters and snubbers). This paper walks the reader through problem recognition, simulation, field measurements and solution implementation. Special focus will be made on the field measurements verification.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2012.6229608 },
  booktitle={ 48th IEEE Industrial & Commercial Power Systems Conference },
  chapter={0}
}

@article{rayyan-352345553,
  title={ Prognostication of Failures Using Signal-to-Noise Ratio to Determine Partial Discharges Activities in Power Transformers  -  IEEE Access },
  year={2022},
  author={Aslam, M. and Rehan, M. S. and Albogamy, F. R. and Murawwat, S. and Basit, A. and Hafeez, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861640 },
  abstract={The increase in number of power transformer necessitates increased awareness among power system engineers to monitor transformer health in order to avoid complete failures that may results in prolonged outages. The utilities, nowadays, are exploring different ways of detecting these faults in an early stage. This paper aims to present a real-time monitoring technique for a three-phase transformer using data analytics. Accordingly, the use of signal to noise ratio (SNR) for fault detection in power transformers has been described. This technique determines the partial discharge with the help of sensors needed for unique identification of failed transformers in different test systems. The SNR for different transformer coils installed in field conditions has been compared and discussed in detail. The technique is expected to enable power transformer operators for detection of incipient faults and thus can avoid catastrophic failures and the resultant losses.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2022.3199873 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345554,
  title={ ConvTrans-TPS: A Convolutional Transformer Model for Disk Failure Prediction in Large-Scale Network Storage Systems  -  2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD) },
  year={2023},
  author={Xu, S. and Xu, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152728 },
  abstract={Disk failure is one of the most important reliability problems in large-scale network storage systems. Disk failure may lead to serious data loss and even disastrous consequences if the missing data cannot be recovered. Therefore, predicting disk failures is an important means of ensuring storage security in network storage systems. However, since the fault data in the fast degradation stage is smaller than the healthy data in the normal state, the mixture of healthy data and faulty data leads to extremely unbalanced data, which brings great challenges to finding hidden fault information, thus making fault prediction more accurate. Aiming at the above problems, a convolutional transformer model ConvTrans-TPS model for disk failure prediction in large-scale network storage systems is proposed. The ConvTrans-TPS model acquires dependencies between long-term sequence data through transformers and uses convolutional projections for attention computation to enhance attention to local contextual information. Data augmentation to predict failures in the next 7 days. Validated by the analysis on the Backblaze dataset, the F1 is 0.96 and the Matthews correlation coefficient (MCC) is 0.92. Compared with the popular CNN-LSTM model in recent years, our proposed method improves F1 and MCC by 4% and 5%, respectively, improving the prediction accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CSCWD57460.2023.10152728 },
  booktitle={ 2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD) },
  chapter={0}
}

@article{rayyan-352345555,
  title={ Application research based on modern technology to investigating causes and detection of failures in transformers on the bases of importance level  -  2011 Annual IEEE India Conference },
  year={2011},
  author={Malik, H. and Kr, B. A. and Kr, M. and Jarial, R. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6139577 },
  abstract={In electrical system, power transformers are as interface between different voltage levels of essential importance. Because of the long manufacture process transformers are one of the most critical and expensive equipment and so this is one of the reasons why condition monitoring becomes more popular. Monitoring systems as basis for diagnostics open the possibility for expanding the operating time, reducing the risk of expensive failures and allows several maintenance strategies. With different monitoring techniques detailed information about the transformer condition can be received and helps to minimize the probability of an unexpected outage. In this paper a methodology has been developed to use information derived from condition monitoring and diagnostics for rehabilitation purposes of transformers. The interpretation and understanding of the test data are obtained from the International Standards.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDCON.2011.6139577 },
  booktitle={ 2011 Annual IEEE India Conference },
  chapter={0}
}

@article{rayyan-352345556,
  title={ Fault-Tolerant Control of Electric-Spring Enabled Solid-State Transformer Under Dual Active Bridge Failure },
  year={2024},
  journal={ IEEE Journal of Emerging and Selected Topics in Power Electronics },
  author={Yuan, H. and Lam, H. S. and Liang, G. and Tan, S. -C. and Pou, J. and Hui, S. Y. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189218 },
  abstract={The electric-spring (ES) technology is recently integrated into a solid-state transformer (SST) to support the power grid at the distribution voltage level and provide an 800-V dc grid for large-scale electric vehicle (EV) charging infrastructure. The ES-enabled SST (ES-SST) studied here consists of a diode-clamped converter (DCC) and several dual active bridges (DABs). The failure of one DAB could pose a big challenge to the balance of the dc-link capacitors and threatens the operation of the whole system. Existing voltage-balancing methods are not suitable for the faulty ES-SST due to the highly uneven distribution of the capacitor output power. In this article, a fault-tolerant control method is proposed to keep the capacitor voltages balanced under the DAB failure and maintain the operation of the system. The proposed control features a modulation algorithm to maximize the balancing capability of the DCC, the insertion of a zero-sequence voltage offset in the ac voltages, and the deliberate generation of reactive power. A numerical tool is also developed to predict the operability of the faulty system and design the controller. Simulation and experiments are conducted to verify the proposed control.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JESTPE.2023.3297518 },
  chapter={0}
}

@article{rayyan-352345557,
  title={ A Hybrid Machine Learning Approach for Predicting Power Transformer Failures Using Internet of Things-Based Monitoring and Explainable Artificial Intelligence  -  IEEE Access },
  year={2025},
  author={Aslan, E. and Özüpak, Y. and Alpsalaz, F. and Elbarbary, Z. M. S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053795 },
  abstract={Power transformers are critical components in ensuring the continuous and stable operation of power systems. Failures in these units can lead to significant power outages and costly downtime. Existing maintenance strategies often fail to accurately predict such failures, highlighting the need for novel predictive approaches. This study aims to improve the reliability of power systems by predicting transformer failures through the integration of IoT technologies and advanced machine learning techniques. The proposed hybrid model combines the LightGBM algorithm with GridSearch optimization to achieve both high predictive accuracy and computational efficiency. In addition, the model enhances interpretability by incorporating SHapley Additive exPlanations (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME) for transparent decision making. The study presents a detailed comparison of different classification algorithms and evaluates their performance using metrics such as accuracy, recall, and F1 score. The results show that the hybrid model outperforms other methods, achieving an accuracy of 99.91%. The SHAP and LIME analyses provide engineers and researchers with valuable insights by highlighting the most influential features in failure prediction. In addition, the model’s ability to efficiently handle large data sets enhances its practicality in real-world power systems. By proposing an innovative approach to failure prediction, this research contributes to both the theoretical foundation and practical advancement of sustainable and reliable energy infrastructures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3583773 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345558,
  title={ Hazard Analysis of Weather Conditions on Distribution Transformer Failures via Cox Proportional Hazard Model  -  IEEE Access },
  year={2025},
  author={Park, C. and Cho, C. and Kim, D. -I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10848080 },
  abstract={As the operational years of power facilities increase, the importance of accurately assessing the remaining lifespan or risk of failures of distribution transformers for the stable power supply has also grown. However, unlike the typical transformer failures, it is not quantified that the failures are also influenced by weather conditions such as temperature, humidity, precipitation, etc. In this regard, we propose the method for investigating the impact of the weather conditions on the failures of distribution transformers to improve the asset management. By employing survival analysis approach, frameworks are employed to quantify the spatial influence of weather conditions on distribution transformer failures, and the weather risk factors are integrated into lifespan indicators to improve maintenance strategies and reliability assessments. Distribution transformer failure cases of over 11 years in South Korea and the corresponding historical weather conditions are configured to enable the survival analysis and derive the meaningful real-world analysis results. Specifically, weather data are quantified and interpolated to configure the spatial data. The notable results underline quantifying significant impact of high summer temperature and humidity in term of hazard ratios. These findings indicate that incorporating historical weather data into asset management indices can significantly enhance the accuracy of transformer lifespan predictions and inform maintenance planning. This study represents the first long-term survival analysis correlating historical weather conditions with transformer failures and provides a guideline for improving power-facility management in the context of environmental changes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3532507 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345559,
  title={ A New Shunt Capacitor-Commutated Converter for Reducing Commutation Failure Probability of HVDC Transmission and Converter Transformer Noise  -  IEEE Access },
  year={2025},
  author={Zhang, H. and Hu, S. and Luo, L. and Lin, J. and Zhao, L. and Zhang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843173 },
  abstract={The HVDC transmission system with a line-commutated converter is prone to commutation failure when connected to a weak AC grid and has disadvantages such as a large footprint of AC filters and high noise from the converter transformer. This paper presents a shunt capacitor-commutated converter (SCCC) without AC filters, using a constant extinction voltage-time area (VTA) control to enhance the performance of the inverter station. First, the topology and the mathematical model of the SCCC are established, with its commutation and frequency characteristics analyzed. Second, the minimum extinction VTA criterion for preventing commutation failure is proposed, revealing how various parameters affect VTA and the mechanism by which the SCCC reduces commutation failure probability. Furthermore, a constant extinction VTA control strategy is designed for the SCCC-based inverter. Then, the reactive power and harmonic characteristics of the SCCC are analyzed. A selection method for the SC is proposed to meet the inverter’s requirements for unit power factor operation and filtering. Simulations in PSCAD/EMTDC and experimental results from a scaled-down rectifier prototype demonstrate that the SCCC and the proposed control strategy effectively reduce commutation failure probability and converter transformer noise.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3530108 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345560,
  title={ Analyzing the Effects of Lightning Strike on Distribution Transformer Failure via Geographically and Temporally Weighted Regression  -  IEEE Transactions on Power Delivery },
  year={2024},
  author={Park, C. and Lee, J. and Cho, C. and Kim, D. -I.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10705047 },
  abstract={Due to the aging of the power systems, it is one of the important issues to identify the remaining useful life (RUL) of the power facilities including the environmental effects for the reliable power system operation. However, it is hard to identify the effects of spatially distributed environmental effects on each individual facility and manage the individual history of millions of distribution facilities. As a practical solution, we propose a spatiotemporal analysis to derive the comprehensive effects of the lightning strike that is one of the environmental effects on the RUL of the distribution transformers, and provides the guideline for the lightning protection through the decision of lightning-prone areas. We acquired the data related to the distribution transformer failures and the lightning strikes in South Korea, and a spatiotemporally weighted regression analysis is applied to the data for deriving the spatially cumulative effects of a lightning, which is hard to be identified through each field post-analysis. In addition, we propose a method for validating the regression model through the model evaluation using the categorized transformer failures by field post-analysis. All the proposed processes are performed through the real-world data analysis, and practical results are presented for the reinforcement of lightning protection within the Korean power system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2024.3474013 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345561,
  title={ IEEE Guide for Reporting Failure Data for Power Transformers and Shunt Reactors on Electric Utility Power Systems  -  ANSI/IEEE Std C57.117-1986 },
  year={1988},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=29145 },
  abstract={The reporting and statistical analysis of reliability of power transformers and shunt reactors used on electric utility power systems are addressed. The following types and applications of transformers are covered: power transformers, autotransformers, regulating transformers, phase-shifting transformers, shunt reactors, HVDC converter transformers, substation transformers, transmission tie transformers, unit transformers, unit auxiliary transformers, and grounding transformers. The format for the collection and reporting of data is presented, and the kinds of reports that may be useful to both users and manufacturers of transformers are illustrated. (This standard has been superseded by IEEE C57.125-2015)},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEESTD.1988.81694 },
  booktitle={ ANSI/IEEE Std C57.117-1986 },
  chapter={0}
}

@article{rayyan-352345562,
  title={ Risk Assessment of Electromagnetic Compatibility Failure for Electronic Instrument Transformers Under Extreme Electromagnetic Transients  -  2024 5th International Conference on Clean Energy and Electric Power Engineering (ICCEPE) },
  year={2024},
  author={Zhu, H. and Zhu, Y. and Deng, X. and Li, H. and Chen, Q. and Ye, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10931596 },
  abstract={The electromagnetic compatibility of electronic transformers faces new challenges due to the strong transient electromagnetic environment caused by the primary and secondary fusion structures. This paper thoroughly examines the scenarios where the fusion structure is applied to electronic transformers. Five disturbance sources are chosen: surges, damping oscillations, fast transient pulses, ground potential rise, and operation overvoltage. An evaluation index system is then constructed, encompassing multiple coupling ports, various disturbance types, and multiple time-frequency characteristics. The Attribute Hierarchical Model (AHM), in combination with the entropy-weight method, is utilized to thoroughly weigh the indices, while the fuzzy comprehensive evaluation method is applied to determine the degrees of index membership. This approach ultimately assesses and classifies risks related to electromagnetic compatibility failures in electronic instrument transformers. Additionally, the method proposed in this paper is implemented on two instrument transformer samples. The results indicate that the suggested hierarchy attribute model can proficiently assess the electromagnetic compatibility of electronic instrument transformers and offer assistance for their monitoring and maintenance of the risk of failures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCEPE62686.2024.10931596 },
  booktitle={ 2024 5th International Conference on Clean Energy and Electric Power Engineering (ICCEPE) },
  chapter={0}
}

@article{rayyan-352345563,
  title={ Corrosive Sulfur in Insulating Oils: Its Detection and Correlated Power Apparatus Failures  -  IEEE Transactions on Power Delivery },
  year={2008},
  author={Scatiggio, F. and Tumiatti, V. and Maina, R. and Tumiatti, M. and Pompili, M. and Bartnikas, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4408697 },
  abstract={Contamination of paper tapes by corrosive sulfur in insulating oils may cause shorting faults between turns. Typically, this occurs at higher temperature in the upper portions of the windings of shunt reactors and power transformers. In many of the tested oils, high amounts of dibenzyl-disulfide (DBDS) were found.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2007.911121 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345564,
  title={ Investigation of premature ESP failures and oil field harmonic analysis  -  2012 Petroleum and Chemical Industry Conference (PCIC) },
  year={2012},
  author={Pragale, R. and Shipp, D. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549650 },
  abstract={Electric submersible pumps (ESP) are used in a wide-range of applications from onshore to complex offshore, deep water, or subsea applications. Premature failures are undesired as they result in repair or replacement costs, but worse - downtime. This paper presents the challenges faced by the authors at an onshore oil field. The site experienced several ESP failures after drilling and operating 10% of the planned 300 wells. The authors were tasked to determine if power quality was a contributing factor in the premature failures and recommend a solution to prevent future occurrences. In addition to the failures, the oil field operator was concerned with the harmonic currents that would be generated once all 300 wells were online. The oil field is in an industrial area where large amounts of harmonic currents would increase voltage distortion to neighboring establishments and possibly lead to process disruption or equipment failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCICON.2012.6549650 },
  booktitle={ 2012 Petroleum and Chemical Industry Conference (PCIC) },
  chapter={0}
}

@article{rayyan-352345565,
  title={ Investigation of Premature ESP Failures and Oil Field Harmonic Analysis  -  IEEE Transactions on Industry Applications },
  year={2017},
  author={Pragale, R. and Shipp, D. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565467 },
  abstract={Electric submersible pumps (ESP) are used in a wide-range of applications from onshore to complex offshore, deep water, or subsea applications. Premature failures are undesired as they result in repair or replacement costs, but worse- downtime. This paper presents the challenges faced by the authors at an onshore oil field. The site experienced several ESP failures after drilling and operating 10% of the planned 300 wells. The authors were tasked to determine if power quality was a contributing factor in the premature failures and recommend a solution to prevent future occurrences. In addition to the failures, the oil field operator was concerned with the harmonic currents that would be generated once all 300 wells were online. The oil field is in an industrial area where large amounts of harmonic currents would increase voltage distortion to neighboring establishments and possibly lead to process disruption or equipment failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2016.2608958 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345566,
  title={ Circulating current paralleling failures— conditions & consequences  -  2008 IEEE Power and Energy Society General Meeting - Conversion and Delivery of Electrical Energy in the 21st Century },
  year={2008},
  author={Jauch, E. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4596595 },
  abstract={When an applied transformer paralleling method is inappropriate, or incorrectly set, the operation of paralleled power transformer tapchangers can result in detrimental effects on system voltages and power transfer capability. In some cases, these operations can also contribute to the premature failure of the power transformer. One of the most popular paralleling methods is the circulating current method of paralleling. There are several conditions that make the circulating current method application inappropriate or to cause it to mis-operate. These conditions include system configurations, transformer construction, or equipment ratings or settings incompatibility. The problems with system configurations can occur during normal or contingency/emergency operation of the power system. The transformer construction issues can be addressed by recognizing the variations that can cause mis-operation and either specifying a suitable transformer design or changing the paralleling method used. Many other problems can be overcome by additional auxiliary equipment or commissioning procedures. This paper discusses the effects of several system configurations and equipment variations on the operation of the circulating current method of paralleling. The effects of automatic operation of system equipment, such as breaker operations or distributed generation, will be considered. Solutions for each condition are suggested.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2008.4596595 },
  booktitle={ 2008 IEEE Power and Energy Society General Meeting - Conversion and Delivery of Electrical Energy in the 21st Century },
  chapter={0}
}

@article{rayyan-352345567,
  title={ CVT Failures and Impact on Synchrophasor based Dynamic Monitoring  -  2023 7th International Conference on Computer Applications in Electrical Engineering-Recent Advances (CERA) },
  year={2023},
  author={Singh, S. and Yadav, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10455700 },
  abstract={Device malfunctions and instrument failures in a power system cause multi-component tripping, prolonged disruptions, and operational irregularities. The high voltage instrument transformers like capacitive voltage transformers (CVTs) are bound to maloperations/failures due to switching transient over-voltages, bushing failure, filter malfunctions, saturation of intermediate voltage transformer, etc. Among these failures, the transient over-voltages induce a ferro-resonance phenomenon in the CVTs, which could impact the phasor measurement accuracy at the synchrophasors. This paper presents a detailed sensitivity analysis of the frequency response of CVT with model parameter changes and discusses the impact of filter failures on the phasor measured at the synchrophasor. The analysis provides a detailed study of CVT frequency response and ferro-resonance phenomenon with a brief impact analysis on phasor measurement and associated applications. The propositions are tested with simulated detailed CVT models in Matlab/Simulink, where we observed predominant oscillatory dynamics in phasor measurements similar to sub-synchronous resonance making distinction and detection challenging.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CERA59325.2023.10455700 },
  booktitle={ 2023 7th International Conference on Computer Applications in Electrical Engineering-Recent Advances (CERA) },
  chapter={0}
}

@article{rayyan-352345568,
  title={ SCR Failure Mode in Soft-Starters Re-Examined: Controlled Experiments and Simulation  -  2022 IEEE IAS Pulp and Paper Industry Conference (PPIC) },
  year={2022},
  author={Simms, S. R. and Braga, G. and Farr, T. A. and Jacobs, A. and Pierce, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888815 },
  abstract={Across the line full-voltage starts of an induction motor produces locked-rotor current and potentially stressful mechanical acceleration while approaching synchronous speed. Reduced voltage starters of several types were introduced to limit the current applied to the motor to effectively lessen this effect and bring the motor shaft up to speed slower while simultaneously lowering sag voltage at the point-of-common coupling. The solid-state silicon controlled rectifier, or thyristor, controller adds stator voltage control options beyond the two-step reduced voltage starting methods and is known in industry as RVSS. However it has some known failure modes linked to the rate of change of current, di/dt, limitations in the SCR device physics where the potential cause has traditionally been linked to amount of load-side parasitic capacitance in the circuit. This paper will further examine how the source and load impedances impact laboratory experiments. Further computer simulations are performed with increased short-circuit available current for comparable results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PPIC52995.2022.9888815 },
  booktitle={ 2022 IEEE IAS Pulp and Paper Industry Conference (PPIC) },
  chapter={0}
}

@article{rayyan-352345569,
  title={ Aging and failure data supporting network usage tariff calculation  -  2022 IEEE Electrical Insulation Conference (EIC) },
  year={2022},
  author={Cselkó, R. and Szabó, D. and Kálecz, G. and Németh, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833184 },
  abstract={With the emergence of distributed and household power generation, the network usage tariffs based on the net energy consumption are becoming more and more unsuitable to express the real value of the service provided by the network operator. Assets are aging and are subjected to external overstresses even when in standby. Novel load patterns, e.g., due to electric vehicle charging, may cause accelerated aging.Accordingly, operators are seeking methods to calculate the real costs associated with asset aging and failures, which can be the basis of fair and realistic network usage tariffs. In this article, a methodology is proposed for such calculation for selected distribution network components. It considers standby aging, insulation life models and statistics of random failures and external overstresses for medium voltage buried cables, overhead line conductors and transformers.The method enables the estimation of the life consumption rate and other associated costs at any operational state, which can be the basis of tariff calculation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC51169.2022.9833184 },
  booktitle={ 2022 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345570,
  title={ Partial Discharge Monitoring to Predict Failures in 230 kV GIS Substation using UHF and Ultrasonic Sensors  -  2024 IEEE Electrical Insulation Conference (EIC) },
  year={2024},
  author={Birla, R. and Mohammad, S. and Hashmi, G. and Zahrani, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10579377 },
  abstract={Partial Discharge (PD) monitoring in Gas Insulated Switchgear (GIS) is one of the leading diagnostic techniques that helps to predict potential failures. Approximately 90% of insulation breakdowns can be attributed to PD activities, which when detected, can help avoid unplanned power interruptions. A recent failure of a voltage transformer (VT) in a GIS substation triggered a recommendation to conduct PD measurements to evaluate the VTs’ insulation healthiness. The incident occurred due to a flashover inside the VT compartment, with noticeable flashover traces on the insulation spacer and around the High Voltage (HV) coil of the VT. This paper presents the outcome of the conducted PD measurements on 186 VTs, installed in four GIS substations, using Ultra High Frequency (UHF) and Ultrasonic Contact (UC) sensors; followed by the measurement outcome, PD data analysis, and corrective actions. In addition to the PD measurements, visual inspection was conducted on the manual Integrated Isolating Device (IID) locking condition, which is used to isolate the VT from other GIS High Voltage systems. Noting that GISs under consideration were not installed with internal PD sensors, hence, external UHF barrier and UC sensors were used to conduct online PD measurements on the subject VTs. The paper further presents the impact of the corrective action that was implemented on the VTs that showed high PD measurements in the vicinity of the IID, which indicate that the IIDs were not in the desired position. The major recommendations issued from analyzing the measurements were, locking the VT IIDs in the end position and including PD measurements in the Preventive Maintenance program. In conclusion, the predictive maintenance of the GIS equipment can be achieved on the basis of online PD monitoring, which is an effective, nondestructive, and noninvasive diagnostic tool to help detect and localize insulation defects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC58847.2024.10579377 },
  booktitle={ 2024 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345571,
  title={ Unwanted operation of differential protection function in T60 relays due to failures in CT/VT modules  -  2018 International Conference on Computer, Control, Electrical, and Electronics Engineering (ICCCEEE) },
  year={2018},
  author={Elkhidir, O. B. and El-Amin, I. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8515870 },
  abstract={T60 relay is one of the new digital relays has been designed to meet the requirements of high sensitivity, reliability and high speed. This development led to notable simplification in transformer differential protection 87T function by reducing cost, cabling and auxiliary equipment. However, still miss-operation cases in transformer differential protection can occur from time to time. This paper reports on two unwanted-operation cases of transformer differential protection happened in Garie power plant in Sudan. In the both cases, failures in the CT/VT module of T60 relays cause unwanted operation of the protection system. These failures could be a result of aging, problems in DC power supply or from the design of these modules. More investigations are needed to find the roots of these failures. In the both cases, the failures are hidden type in which the relay will not operate unless unusual event has happened. The failures could have been detected and removed, if the preventive maintenance was effective. In order to insure reliability and sensitivity of the relays, preventive maintenance should take place from time to time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCCEEE.2018.8515870 },
  booktitle={ 2018 International Conference on Computer, Control, Electrical, and Electronics Engineering (ICCCEEE) },
  chapter={0}
}

@article{rayyan-352345572,
  title={ Leveraging Spatiotemporal Relations for Predicting Potential Link Failures  -  2023 19th International Conference on Network and Service Management (CNSM) },
  year={2023},
  author={Wubete, B. and Esfandiari, B. and Kunz, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10327808 },
  abstract={Being able to predict link failures in advance would be of great benefit to network operators. We use Machine Learning (ML) techniques to extract temporal and spatial relations from real network data and use them to predict link failures. We use Interior Gateway Protocol (IGP) configuration changes as a guide to achieve this. We predict link failures in the next five days based on data collected from the previous five days. We propose a modified Variational Auto Encoder (VAE) model to compress the higher dimensional dataset into a latent space that captures time-based relations in the data. We demonstrate that five days is the smallest look-back window of time required to get satisfactory prediction results. Using feature importance plots, we learned that the VAE model was able to capture intricate time-based dependencies in the error counter features to achieve good performance. In addition, using a Graph Convolutional Network (GCN), we were able to aggregate data from neighboring links to improve the model's performance. Neighbors up to two hops away carried relevant information in IGP metric settings and in traffic metric counter features. The relevance of the correlation of the features in time and space is confirmed using standard feature importance wrapper methods. Finally, by combining the VAE and GCN components, we were able to extract spatial and temporal features in conjunction, leading to further improvements. These ML approaches significantly improve existing manual methods of tracking metrics in time and space currently followed by the operator.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/CNSM59352.2023.10327808 },
  booktitle={ 2023 19th International Conference on Network and Service Management (CNSM) },
  chapter={0}
}

@article{rayyan-352345573,
  title={ LLM4TDD: Best Practices for Test Driven Development Using Large Language Models  -  2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code) },
  year={2024},
  author={Piya, S. and Sullivan, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734613 },
  abstract={In today’s society, we are becoming increasingly dependent on software systems. However, we also constantly witness the negative impacts of buggy software. Program synthesis aims to improve software correctness by automatically generating the program given an outline of the expected behavior. For decades, program synthesis has been an active research field, with recent approaches looking to incorporate Large Language Model. This paper explores the concept of LLM4TDD, where we guide Large Language Models to generate code iteratively using a test-driven development methodology. We conduct an empirical evaluation using ChatGPT and coding problems from LeetCode to investigate the impact of different test, prompt and problem attributes on the efficacy of LLM4TDD.CCS CONCEPTS• Software and its engineering → Software development techniques.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ 2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code) },
  chapter={0}
}

@article{rayyan-352345574,
  title={ A Multi-Agent LLM Environment for Software Design and Refactoring: A Conceptual Framework  -  SoutheastCon 2025 },
  year={2025},
  author={Rajendran, V. and Besiahgari, D. and Patil, S. C. and Chandrashekaraiah, M. and Challagulla, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10971563 },
  abstract={Modern software systems demand continuous evolution to maintain performance, scalability, and security. Traditional single-agent AI-driven code refactoring approaches are often limited in addressing the multi-faceted constraints (e.g., performance, security, maintainability) that emerge during complex software design tasks. In this paper, we propose a novel Multi-Agent Large Language Model (LLM) Environment for automated software design and refactoring. Our conceptual framework comprises specialized LLM “experts,” each trained or fine-tuned on a different aspect of software engineering (performance optimization, security hardening, UI/UX, maintainability). These agents collaborate in a cooperative or competitive fashion-using coordination protocols akin to consensus or auction mechanisms-to synthesize design insights and refactoring recommendations. We present formal definitions of agent interactions (including mathematical notation for termination conditions), a sequence diagram demonstrating agent collaboration, a complexity analysis of the coordination mechanism, and an expanded reference list. Preliminary experimental design is outlined to demonstrate how multi-agent interactions may resolve conflicting design goals more effectively than a single-agent approach. Our aim is to provide a roadmap for integrating multi-agent LLMs into the software development lifecycle, thereby improving development efficiency, reducing technical debt, and enhancing software quality.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SoutheastCon56624.2025.10971563 },
  booktitle={ SoutheastCon 2025 },
  chapter={0}
}

@article{rayyan-352345575,
  title={ Next-Generation Refactoring: Combining LLM Insights and IDE Capabilities for Extract Method  -  2024 IEEE International Conference on Software Maintenance and Evolution (ICSME) },
  year={2024},
  author={Pomian, D. and Bellur, A. and Dilhara, M. and Kurbatova, Z. and Bogomolov, E. and Bryksin, T. and Dig, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795061 },
  abstract={Long methods that encapsulate multiple responsibilities within a single method are challenging to maintain. Choosing which statements to extract into new methods has been the target of many research tools. Despite steady improvements, these tools often fail to generate refactorings that align with developers' preferences and acceptance criteria. Given that Large Language Models (LLMs) have been trained on large code corpora, if we harness their familiarity with the way developers form functions, we could suggest refactorings that developers are likely to accept. In this paper, we advance the science and practice of refactoring by synergistically combining the insights of LLMs with the power of IDEs to perform Extract Method (EM). Our formative study on 1752 EM scenarios revealed that LLMs are very effective for giving expert suggestions, yet they are unreliable: up to 76.3% of the suggestions are hallucinations. We designed a novel approach that removes hallucinations from the candidates suggested by LLMs, then further enhances and ranks suggestions based on static analysis techniques from program slicing, and finally leverages the IDE to execute refactorings correctly. We implemented this approach in an IntelliJ IDEA plugin called EM-Assist. We empirically evaluated EM-Assist on a diverse corpus that replicates 1752 actual refactorings from open-source projects. We found that EM-Assist outperforms previous state of the art tools: EM-Assist suggests the developer-performed refactoring in 53.4% of cases, improving over the recall rate of 39.4% for previous best-in-class tools. Furthermore, we conducted firehouse surveys with 16 industrial developers and suggested refactorings on their recent commits. 81.3% of them agreed with the recommendations provided by EM-Assist. This shows the usefulness of our approach and ushers us into a new era when LLMs become effective AI assistants for refactoring.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICSME58944.2024.00034 },
  booktitle={ 2024 IEEE International Conference on Software Maintenance and Evolution (ICSME) },
  chapter={0}
}

@article{rayyan-352345576,
  title={ Review of ferroresonance in power distribution grids  -  2011 IEEE International Conference on Information Reuse & Integration },
  year={2011},
  author={Hassan, S. and Vaziri, M. and Vadhva, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6009589 },
  abstract={Ferroresonance is a special case of resonance, which can occur when a non-linear inductive reactance is connected in series with a capacitive reactance. In instances of ferroresonance involving electric power distribution facilities, the inductive reactance will be the magnetizing reactance of a single-phase or three-phase transformer. The capacitive reactance will be due ordinarily to the conductor-to-sheath capacitance of primary cable supplying the transformer under favorable conditions. Ferroresonance may be accompanied by abnormally high or low voltages as a result of single pole switching of one or two phases of the source supply to the transformer. Ferroresonance is capable of producing sustained overvoltages with peak magnitudes approaching, or exceeding twice the rated peak voltage, which is harmful and unsafe for the operation of most equipment. In this paper, the various conditions giving rise to occurrence of ferroresonance will be identified. The most prevalent resonance resulting in undesirable voltage conditions will be addressed and analyzed. Also some possible means of preventing occurrence of unsafe ferroresonance in power transformers will be proposed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IRI.2011.6009589 },
  booktitle={ 2011 IEEE International Conference on Information Reuse & Integration },
  chapter={0}
}

@article{rayyan-352345577,
  title={ Assisting tools for a new maintenance planning in a power distribution system  -  IEEE PES General Meeting },
  year={2010},
  author={Sanz-Bobi, M. A. and Palacios, R. and Vieira, R. J. A. and Nicolau, G. and Ferrarons, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588112 },
  abstract={This paper describes a framework in which several tools have been integrated in order to help the maintenance planning in a power distribution network. This framework will help to improve the process of decision making in an asset management context of a power distribution company. Two kinds of tools have been developed, one has been oriented to the identification of possible failure risk according to the history of unavailabilities occurred, and another one has been designed for the continuous monitoring and analysis of the life of main components such as power transformers and circuit breakers of a power distribution network. The information supplied by both tools is useful to perform maintenance actions when they are really required by the components monitored according to their health conditions, and to orient the maintenance efforts to the components with certain risk of failure. The final objective of these tools is to apply the resources needed when they are required, optimizing the maintenance costs and keeping a high quality of the service for the clients.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2010.5588112 },
  booktitle={ IEEE PES General Meeting },
  chapter={0}
}

@article{rayyan-352345578,
  title={ Quick Troubleshooting of Urban Substation Area  -  2022 IEEE 4th International Conference on Power, Intelligent Computing and Systems (ICPICS) },
  year={2022},
  author={Yang, X. and Ge, C. and Zhang, N. and Zhao, C. and Xu, H. and Zhao, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9873691 },
  abstract={With the continuous improvement of urban construction level in China, the reliable operation of power distribution network has attracted more and more attention. However, in view of the high complaint rate caused by power failures, the problem of long power failure time in urban public transformation is found out. By investigating the outage time of public transformer in urban areas, we get the fact that the emergency repair time is long after the failure of public transformer in urban areas. In this paper, by sorting out the types of faults in the urban common transformer areas, the emergency repair time of each type of fault was queried and counted, and the reasons for the long emergency repair time of the common transformer areas were demonstrated and the long repair time of JP cabinet was deeply analyzed. It was determined that the reason for the long emergency repair time of JP cabinet switch fault was long. Through the research and development and experiment, anti-shedding hex socket and special screw fastening device were successfully made. After a lot of practical application, the time of emergency repair is greatly shortened, and the efficiency of emergency repair of failure and power failure in substation area is greatly improved, which has great value of popularization and application.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPICS55264.2022.9873691 },
  booktitle={ 2022 IEEE 4th International Conference on Power, Intelligent Computing and Systems (ICPICS) },
  chapter={0}
}

@article{rayyan-352345579,
  title={ Microbubbling in transformer oil due to vibration  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2013},
  author={Korobeynikov, S. M. and Bychkov, A. L. and Ryzhkina, A. Y. and Sviridenko, M. V. and Darian, L. A. and Melekhov, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6508771 },
  abstract={Vibration is a prevalent process in oil filled power equipment, especially in transformers and electrical reactors. The most common cause of vibration is an alternating action of magnetic forces. If vibration takes place in narrow gaps, pressure inside gap increases and decreases periodically. In some cases pressure becomes negative, which could lead to bubble appearance and gas generation. Experiments and calculations show that there is cavitation inside non-magnetic microgaps. In case of non-degassed transformer oil microbubbles appear inside gap, dash out of gap and then float due to buoyancy force.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2013.6508771 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345580,
  title={ Degree of polymerization estimation of insulation papers in power transformers based on load and temperature histories in Java-Bali Region of Indonesia National Electric company  -  2012 IEEE International Conference on Condition Monitoring and Diagnosis },
  year={2012},
  author={Hanung, N. S. and Suwarno and Nanang, H. and Mizutani, Y. and Takahashi, T. and Okamoto, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416226 },
  abstract={Degree of polymerization (DP) is thought to be a good index to determined deterioration level of insulation paper in power transformers. In practical conditon, using this method is complicated and expensive due to the necessity of disasembling the transformer. Therefore an alternative method has been expected. In this paper a new method to estimate DP from load and temperature histories is proposed. The exsistence of moisture also considered. Mechanical strength of insulation paper of power transformers in Java Bali Region is assesed using the estimated DP based on the real load and temperature data. Furthermore failure probability of those transformers is considered based on the design stresses in a transformer winding generated by fault currents. Finally the estimated DP values are compared with those from furfural test.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2012.6416226 },
  booktitle={ 2012 IEEE International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345581,
  title={ On-line condition monitoring of power transformers: A case history  -  2011 Electrical Insulation Conference (EIC). },
  year={2011},
  author={de Pablo, A. and Ferguson, W. and Mudryk, A. and Golovan, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5996163 },
  abstract={This paper describes how a hydrogen on-line monitor (Hydran®) accompanied with specialist help can assist Asset Managers/ Operational Managers make good decisions regarding critical plant and identify the warning signs of a potentially catastrophic failure in a large power transformers. In October 2006, a hydrogen monitor was installed in a 500 MVA, 19/230 kV step-up transformer. This monitor showed the presence of about 45 ppm of hydrogen, but readings were very stable with time. Unexpectedly, in June 2010, hydrogen readings started to increase at a very high rate in terms of milliliters per hour. Oil was sampled and dissolved gas analysis was carried out in the laboratory indicating a thermal fault type T2 (temperature between 300°C and 700°C) according to standard IEC 60599. For safety reasons, it was recommended to remove the transformer from service. Failure investigation showed bad connections in the conductor leads between the LV windings and the bushings. The molding of individual strands was not properly done and with time, the connection has degraded and reached high temperatures. Connections were repaired and the transformer put back in service again.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC.2011.5996163 },
  booktitle={ 2011 Electrical Insulation Conference (EIC). },
  chapter={0}
}

@article{rayyan-352345582,
  title={ A Fuzzy Modeling Technique to Assist Submersible Inspection Robot for Internal Inspection of Transformers  -  2020 Fourth International Conference on Inventive Systems and Control (ICISC) },
  year={2020},
  author={Singh, A. and Patil, A. J. and Jarial, R. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171136 },
  abstract={Transformers are preeminent units of any power transmission network which are prone to failures due to multiple interrelated factors. For recognition of obscure failure modes leading to severe degradation of the transformer, internal inspection is a necessity. Submersible inspection robots are state of the art devices which are utilized for routine internal inspection of an oil filled transformer for identification, segmentation and assessment of faults. In this research paper, by using data from assorted diagnostic tests, a fuzzified computational algorithm is developed for determining the condition in which performing internal inspection is an absolute necessity. Particular attention is given to establish a decision logic for minimizing the work envelope of internal inspection robot by identifying likely faulty subsystems from diagnostic test results. This algorithm will further reduce the maintenance time and workload of the robot for performing internal inspection of the transformer. This paper will be helpful for researchers and service engineers involved with the maintenance of transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICISC47916.2020.9171136 },
  booktitle={ 2020 Fourth International Conference on Inventive Systems and Control (ICISC) },
  chapter={0}
}

@article{rayyan-352345583,
  title={ Reliability Modelling and Simulation for Assessment of Electric Arc Furnace Transformers  -  2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON) },
  year={2020},
  author={Singh, A. and Patil, A. J. and Tripathi, V. K. and Sharma, R. K. and Jarial, R. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231147 },
  abstract={Transformers are strikingly reliable power transfer devices and are of preeminent importance in the seamless operation of electric arc furnaces. An arc furnace transformer is at a monophonic risk of failure due to the action of different stresses. Reliability is a decisive performance index to ensure that a component will perform the desired function at the coveted time. In this research, beginning with the development of a combined fault tree for arc furnace transformers, a straightforward and conceivable software model is developed to assess reliability. The model incorporates MATLAB Simulink and Fuzzy toolbox for reliability computation and assigning a fuzzified reliability level. Subsequently, reliability indices like availability, unavailability, etc. are computed. Finally, the model is implemented for electric arc furnace transformers installed in different locations of India. This research will be helpful for utilities and researchers associated with enhancing the reliability and availability of the transformer.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GUCON48875.2020.9231147 },
  booktitle={ 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON) },
  chapter={0}
}

@article{rayyan-352345584,
  title={ Investigations on the effect of dynamic fault on impulse fault current waveforms of transformer  -  2009 International Conference on Power Systems },
  year={2009},
  author={Rajamani, P. and Dey, D. and Chakravorti, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5442779 },
  abstract={A novel approach to investigate the changes in the temporal nature of impulse fault current in the transformer winding due to dynamic insulation failures has been proposed. Non-linear bilateral fault simulator circuit is developed and connected in analog model of 3 MVA transformer to simulate static and dynamic faults. The features extracted from cross-correlation of faulted and no-fault impulse currents shows that the features are following some defined patterns. The concepts of cross-correlation based feature extraction and simulation of static and dynamic faults are explained.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPWS.2009.5442779 },
  booktitle={ 2009 International Conference on Power Systems },
  chapter={0}
}

@article{rayyan-352345585,
  title={ A Transformer-based GAN for Bearing Fault Diagnosis Under Limited Data Conditions  -  2024 IEEE 22nd International Conference on Industrial Informatics (INDIN) },
  year={2024},
  author={Guo, X. and Meng, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774341 },
  abstract={Confronted with the challenge of diagnosing bearing faults under limited data conditions, we employ a Transformer-based Generative Adversarial Network aimed at enhancing diagnostic performance through the generation of high-quality samples. This approach incorporates Transformer blocks and Long Short-Term Memory layers into the GAN framework, significantly enhancing the network's capacity for gen-erating complex sequences. Initially, the original data is undergoes denoising using Gramian Noise Reduction to amplify its signal characteristics. Subsequently, the sample data is processed through Trans-GAN for en-hancement, and then a one-dimensional convolutional neural network is applied to analyze the data and diagnose bearing faults. Experimental validation has confirmed that this approach significantly enhances the accuracy of bearing fault diagnosis in scenarios characterized by limited data availability.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INDIN58382.2024.10774341 },
  booktitle={ 2024 IEEE 22nd International Conference on Industrial Informatics (INDIN) },
  chapter={0}
}

@article{rayyan-352345586,
  title={ Calculation model of arc discharge pressure in transformer oil  -  2023 2nd International Conference on Smart Grids and Energy Systems (SGES) },
  year={2023},
  author={Yang, Z. and Xu, H. and Xie, D. and Yu, J. and Ni, Q. and Chen, T. and He, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366989 },
  abstract={Internal short circuit faults in transformers can lead to high-energy arc discharges, resulting in incidents of oil tank rupture, explosion, and fire. The source of transformer explosion accidents is the high-voltage bubbles generated by the gasification and decomposition of transformer oil during high-energy arc discharge. Therefore, studying the mechanism of bubble generation due to arc discharge faults in transformer oil is crucial for understanding the subsequent pressure increase and deformation of the oil tank. In this paper, the evaporation-condensation model is modified to include the chemical reactions of high-temperature decomposed insulating oil. A calculation method based on the modified evaporation-condensation model is proposed to simulate the generation of bubbles in the fluid domain. A three-dimensional simulation model of the oil tank is established to analyze the variation process of bubbles and the pressure changes in the fluid domain after bubble generation. This research provides a reference for studying the mechanism of fault bubble generation in transformer oil and offers a new modeling and calculation method for simulating the change of pressure field during the electric arc discharge process in oil.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SGES59720.2023.10366989 },
  booktitle={ 2023 2nd International Conference on Smart Grids and Energy Systems (SGES) },
  chapter={0}
}

@article{rayyan-352345587,
  title={ Advantages vs. risks with on-line monitoring of transformer bushings  -  2021 IEEE Electrical Insulation Conference (EIC) },
  year={2021},
  author={Jonsson, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612348 },
  abstract={The philosophy of applying monitoring equipment may improve the reliability of an electrical system. However, it should be recognized that most monitoring systems require connection to the main insulation of capacitance graded bushings via the test/voltage tap. Removing the original grounding from the tap exposes it to a different physical environment controlled by the monitoring equipment and its connections, compared to was originally intended. The associated risk factors should be evaluated and mitigated when considering the use of any monitoring system. If the bushing is not solidly grounded, the voltage must be carefully controlled to prevent the operating voltage or transient voltages from reaching dangerous levels. This is particularly important in applications where transient stress and repeated switching surges can be expected. It should be verified that the voltage protection schemes included in monitoring systems provides adequate long-term protection of the bushing and offers sufficiently fast reaction time. The mechanical connection of monitoring equipment is also critical. The seals and construction of the monitoring equipment must prevent contamination, e.g. moisture, from entering the tap or any other connection point. Furthermore, the materials of the monitoring equipment must be compatible with those of the bushing to prevent galvanic corrosion and the monitoring device construction must be such that the components of the bushing are not damaged and that connections are robust.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC49891.2021.9612348 },
  booktitle={ 2021 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345588,
  title={ Remarkable benefit realization by application of strategic management in power transformer condition monitoring and diagnostic systems  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={Fung, Francis and Fung, K. Y. and Chan, Y. T. and Wong, M. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580343 },
  abstract={Power transformers are usually very reliable and durable components of the power supply network. Unfortunately, when a fault occurs in a transformer, it can develop catastrophically and failures are usually very expensive, often resulting in the loss of what is the most expensive plant item in a substation [1]. In order to safeguard this valuable asset, various condition monitoring and diagnostic systems have been applied in CLP Power Hong Kong Limited with remarkable benefit realization in enhancing the system availability, the supply reliability, the implementation of condition-based maintenance, and the improvement in the asset life cycle management with promising results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580343 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345589,
  title={ Effects of parasitic transformer capacitances on switching transients at a HV capacitor bank  -  2008 40th North American Power Symposium },
  year={2008},
  author={Hong, W. and O'Connell, R. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5307363 },
  abstract={ATP-EMTP simulations were conducted to investigate the cause of failure of a 4.5 MVAR capacitor bank at a high voltage switching station. To include the possible role of ferroresonance and other high frequency resonance effects, models of the 161kV/34.5kV transformer and the circuit breaker at the switching station included non-linear inductance and various appropriate parasitic capacitances. The simulation results for the capacitor bank phase currents and their Fourier frequency spectra suggest that excessive switching transients due to resonance effects involving transformer high voltage earth capacitance and inter-winding capacitance, rather than ferroresonance, may be associated with the capacitor bank failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/NAPS.2008.5307363 },
  booktitle={ 2008 40th North American Power Symposium },
  chapter={0}
}

@article{rayyan-352345590,
  title={ Corrosion Analysis and Protection for Grounding Conductor in Transformer Substation  -  2020 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA) },
  year={2020},
  author={Fang, W. and Chen, H. and Liu, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221439 },
  abstract={In the relaying protection of modern power grid system, the safety of grounding grid plays an important role. However, the equalizing voltage conductor has been serving in a complex soil for long time, which is prone to corrode and result in deterioration of electrical connection performance as well as decrease of current diffusion capacity, thus posing a great threat to the reliability of power grid system. Aiming at the corrosion problem of grounding galvanized steel in a 220kV transformer substation, the steel and corrosion products have been analysed by methods of morphology observation, energy spectrum analysis and metallographic examination. The corrosion causes of grounding conductor in transformer substation were studied. In addition, the advantages and disadvantages of using resistance-reducing agent, sacrificial anode method and conductive coating were introduced respectively.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIEA51086.2020.00144 },
  booktitle={ 2020 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA) },
  chapter={0}
}

@article{rayyan-352345591,
  title={ Evaluation on current transformer assessment method based on investigation result  -  2012 IEEE International Conference on Condition Monitoring and Diagnosis },
  year={2012},
  author={Rahmani, D. S. and Muchtar, A. and Gumilang, H. and Siregar, R. and Pharmatrisanti, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416406 },
  abstract={The increase of current transformer (CT) failure rate in PLN P3B Jawa and Bali within the last five years has put CT as a critical asset. In order to prevent existing CTs from the similar failure, the assessment method needs to be evaluated. For this purpose, further investigation was conducted on three sister units of two failed CTs by performing measurements and tear down. The investigations reveal that the insulating medium of the high voltage conductor-to-ground of two investigated CTs were deteriorated due to moisture ingress. The presence of carbonized spots and residual material was also found in particular on the insulating paper. The physical conditions of each investigated CT are analyzed to determine the ageing stage which represents the failure risk. The correlation between the failure risk and its testing results is analyzed to evaluate the assessment method of CT operated under tropical climate.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2012.6416406 },
  booktitle={ 2012 IEEE International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345592,
  title={ Laboratory Model for Evaluation of Incipient Transformer Thermal Fault Involving Insulating  -  2019 IEEE Electrical Insulation Conference (EIC) },
  year={2019},
  author={Wilhelm, H. M. and Fernandes, P. O. and Pereira, T. K. and Santos, G. C. and Filho, D. A. and Mar, A. and Ribeiro, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9046540 },
  abstract={In order to age thermally upgraded kraft paper immersed in insulating oil without aging the oil, an “aging device” was built in which a copper electric resistance was covered with insulating paper and the setup was immersed in insulating oil contained in a vessel. The oil was water cooled to keep its temperature below 60° C, while paper's temperature was raised up to 500 °C. The experiment allowed the determination of the CO2/CO rate variation against aging time and temperature. The generation of other decomposition products, namely furan compounds, methanol and ethanol was also determined against aging time and temperature. Paper aging status was also determined through degree of polymerization (DP). The aging of oil was also monitored.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC43217.2019.9046540 },
  booktitle={ 2019 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345593,
  title={ The challenge and solution of transformer protection under AC-DC hybrid transmission grid  -  2010 International Conference on Power System Technology },
  year={2010},
  author={Suonan, Jiale and Zhang, Jiankang and Jiao, Zaibin and Su, Xiaohua and Zhang, Junmin},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666390 },
  abstract={In AC-DC hybrid transmission grid, Both DC magnetic bias and commutation failure are common circumstances and which have adverse impact on the behavior of transformer protection in adjacent AC side. Taking the ±500kV Bao-Dei and Gui-Guang II HVDC projects as model, and based on a large number of RTDS experiments, the performance of transformer differential protection under those two situations is discussed in detail. Quantitative analysis indicates that the second harmonic produced by DC magnetic bias may cause transformer protection fail to operate in minor internal faults. On the other hand, the AC system can be regarded as a harmonic source under the circumstance of commutation failure, and the high content of the second harmonic may lead to mal-restraint of transformer differential protection especially in slight internal faults. To solve those problems, a novel protection method based on excitation impedance is put forward in this paper. Simulation results show that the proposed scheme is high in sensitivity and reliability even under condition of minor internal fault along with DC magnetic bias or commutation failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/POWERCON.2010.5666390 },
  booktitle={ 2010 International Conference on Power System Technology },
  chapter={0}
}

@article{rayyan-352345594,
  title={ Analysis and Prediction of Power Outage in Transformer Area Based on Deep Neural Network Model  -  2021 International Conference on Electronic Information Engineering and Computer Science (EIECS) },
  year={2021},
  author={Wang, J. and Zhang, B. and Zhang, Y. and Yang, Y. and Li, H. and Fu, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9588036 },
  abstract={Based on the intelligent inspection platform, this paper comprehensively applies the relevant data of SG186 and electricity information acquisition system. Data cleaning and elimination of planned blackout based on rules, it realizes the confirmation of blackout events, the judgment of blackout causes. By applying DDN, and the identification and prediction of frequent blackout. And then, it generates the list of frequent blackout users, which is displayed through data visualization, supporting marketing department management analysis and on-site management.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIECS53707.2021.9588036 },
  booktitle={ 2021 International Conference on Electronic Information Engineering and Computer Science (EIECS) },
  chapter={0}
}

@article{rayyan-352345595,
  title={ Fault Condition Assessment of Transformer On-load Tap-changer Contacts Based on Joint Electromechanical Diagnosis  -  2024 IEEE 5th International Conference on Advanced Electrical and Energy Systems (AEES) },
  year={2024},
  author={Zhang, S. and Xu, Z. and Zhang, Z. and Xu, Y. and Yang, D. and Wu, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10872464 },
  abstract={On-load voltage regulating transformers play a crucial role in power systems, not only connecting to the grid but also regulating reactive power and stabilizing loads. The on-load tap-changer (OLTC), as the key component of the on-load regulator, is the only movable part of the transformer, and its reliability is directly related to the safe and stable operation of the power grid. Therefore, timely identification of operational defects and rapid localization of mechanical faults in OLTCs through online monitoring is crucial for the operation and maintenance of transformers in the field. In this paper, firstly, the mechanism of on-load tap-changer contact faults is analyzed in depth, and on this basis, a diagnostic method for OLTC contact faults is proposed for the joint analysis of electric-vibrational signal features. Secondly, in order to extract high-quality fault features, the Ensemble Empirical Mode Decomposition (EEMD) algorithm is used to process the vibration signals and motor current signals to extract the fault features. Meanwhile, their envelope time-domain features are extracted by the Hilbert transform. Finally, the experimentally obtained electric-vibration joint signal features are utilized to deeply analyze the contact state of OLTC and evaluate its fault state.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AEES63781.2024.10872464 },
  booktitle={ 2024 IEEE 5th International Conference on Advanced Electrical and Energy Systems (AEES) },
  chapter={0}
}

@article{rayyan-352345596,
  title={ A General Method for Assessing the Operation Health of Power Transformer Group  -  2019 IEEE 3rd International Electrical and Energy Conference (CIEEC) },
  year={2019},
  author={Yang, Y. and Guo, H. and Kang, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9077166 },
  abstract={Due to the absence of equipment operation parameters or inaccurate input of basic information, it is impossible to accurately grasp the operation status of transformers, resulting in the current situation of group transformers after fault repair became serious rapidly. This paper proposes a general method of grading management, which is easy for operators to accurately diagnose the operation status of the transformers. By supplementing the basic data such as bad operating conditions and family defects of transformers, screened out the transformers that have experienced more than 70% short-circuit current impulse, and the changing trend of historical test data of both capacitance and reactance is selected as the preferred condition for judging the winding deformation position, and constructed the capacitance-reactance models to equivalent the deformation amount. Through the analysis of historical data of group transformers, the latent danger of non-blackout equipment can be found in advance, and the passive situation of transformer maintenance after long-term faults can be changed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CIEEC47146.2019.CIEEC-2019292 },
  booktitle={ 2019 IEEE 3rd International Electrical and Energy Conference (CIEEC) },
  chapter={0}
}

@article{rayyan-352345597,
  title={ Condition Assessment of Power Transformers: Tools for Correlating Dissolved Gas Analysis and Off-Line Electrical Testing  -  2025 IEEE Electrical Insulation Conference (EIC) },
  year={2025},
  author={Robalino, D. and Meira, M. and Álvarez, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11123400 },
  abstract={Off-line electrical testing is a highly effective tool for evaluating the electromechanical and dielectric condition of power and distribution transformers. However, these tests require taking the transformer out of service, which is often undesirable. In practice, periodic analysis of oil samples, properly collected from the transformer, is commonly performed primarily Dissolved Gas Analysis (DGA). Oil samples are taken at regular intervals, and if a potential defect is detected, the transformer may be taken out of service either under fault conditions or as part of planned maintenance and off-line testing activities. This paper presents case studies with correlation (or lack thereof) between DGA results and off-line electrical test data. The combined use of both techniques enables a more comprehensive and accurate diagnosis, enhancing decision-making in predictive maintenance strategies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIC63069.2025.11123400 },
  booktitle={ 2025 IEEE Electrical Insulation Conference (EIC) },
  chapter={0}
}

@article{rayyan-352345598,
  title={ The Optimal Scheduling of Maintenance and Replacement of Power Transformers: A Risk Based Method  -  2024 9th Asia Conference on Power and Electrical Engineering (ACPEE) },
  year={2024},
  author={Zhou, N. and Ma, G. and Luo, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10532383 },
  abstract={The reliable operation of power equipment in the electrical grid hinges on the proper and efficient scheduling of maintenance and replacement activities. Currently, existing methodologies often lack a comprehensive approach to coordinate these critical tasks. In this paper, an optimal scheduling method for the maintenance and replacement of power transformers has been proposed based on minimizing the total failure risk. To achieve this, we establish a failure model specific to power transformers, enabling us to quantitatively assess the risk of failure. Subsequently, we formulate the scheduling of maintenance and replacement as a Mixed Integer Linear Programming (MILP) problem, aiming to minimize the total cost associated with failure. Case studies is performed with actual transformer data and the results have verified the effectiveness of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACPEE60788.2024.10532383 },
  booktitle={ 2024 9th Asia Conference on Power and Electrical Engineering (ACPEE) },
  chapter={0}
}

@article{rayyan-352345600,
  title={ Power MOSFET failure and degradation mechanisms in flyback topology under high temperature and high humidity conditions  -  2013 9th IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives (SDEMPED) },
  year={2013},
  author={Vaalasranta, I. and Pippola, J. and Frisk, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645691 },
  abstract={This article describes observations about power MOSFET failures and degradation experienced during accelerated testing involving high temperature and high humidity stresses. The examined power MOSFETs were operated in commercial variable speed drives in flyback transformer topology as power switches. Known power MOSFET failure mechanisms are summarized and electrical stresses typical for the flyback topology are reviewed. In addition, effects of electrical stresses due to power interruptions were studied. The power MOSFET failure analysis results are presented. The visual appearance of the samples with catastrophic damage was examined with such analysis methods as X-ray, acoustic microscopy (SAM) and optical microscopy. The samples with no obvious failures were also analyzed in research for electrically measurable failure precursor parameters to characterize the physical degradation of the devices. Under these test circumstances, the power MOSFET channel off-resistance RDS-off was discovered to have degraded. This resistive leakage phenomenon was also visualized with backside OBIRCH technique.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DEMPED.2013.6645691 },
  booktitle={ 2013 9th IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives (SDEMPED) },
  chapter={0}
}

@article{rayyan-352345601,
  title={ Time Machine: Generative Real-Time Model for Failure (and Lead Time) Prediction in HPC Systems  -  2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) },
  year={2023},
  author={Alharthi, K. A. and Jhumka, A. and Di, S. and Gui, L. and Cappello, F. and McIntosh-Smith, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10202658 },
  abstract={High Performance Computing (HPC) systems generate a large amount of unstructured/alphanumeric log messages that capture the health state of their components. Due to their design complexity, HPC systems often undergo failures that halt applications (e.g., weather prediction, aerodynamics simulation) execution. However, existing failure prediction methods, which typically seek to extract some information theoretic features, fail to scale both in terms of accuracy and prediction speed, limiting their adoption in real-time production systems. In this paper, differently from existing work and inspired by current transformer-based neural networks which have revolutionized the sequential learning in the natural language processing (NLP) tasks, we propose a novel scalable log-based, self-supervised model (i.e., no need for manual labels), called Time Machine 11A Time Machine allows us to travel into the future to observe the health state of HPC system and report back. Here, we travel into the log extension to report an upcoming failure., that predicts (i) forthcoming log events (ii) the upcoming failure and its location and (iii) the expected lead time to failure. Time Machine is designed by combining two stacks of transformer-decoders, each employing the self-attention mechanism. The first stack addresses the failure location by predicting the sequence of log events and then identifying if a failure event is part of that sequence. The lead time to predicted failure is addressed by the second stack. We evaluate Time Machine on four real-world HPC log datasets and compare it against three state-of-the-art failure prediction approaches. Results show that Time Machine significantly outperforms the related works on Bleu, Rouge, MCC, and F1-score in predicting forthcoming events, failure location, failure lead-time, with higher prediction speed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DSN58367.2023.00054 },
  booktitle={ 2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN) },
  chapter={0}
}

@article{rayyan-352345602,
  title={ Premature wear and recurring bearing failures in an inverter driven induction motor— Part II: The proposed solution  -  2013 IEEE Industry Applications Society Annual Meeting },
  year={2013},
  author={Araújo, R. S. and Rodrigues, R. A. and de Paula, H. and Filho, B. J. C. and Baccarini, L. M. R. and Rocha, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682570 },
  abstract={In a previous work, a real case of recurring bearing failures in an induction motor had been extensively studied. As a result, the cause of the problem was revealed to be the circulation of electric current through the bearings. In this way, the present paper deals with the high-frequency leakage currents in AC motors fed by PWM inverters, contextualized in the analysis of an actual case. From the parameters of an equivalent circuit in terms of cables, motor and inverter return path, a filter, characterized by a common-mode transformer, is proposed to mitigate the common-mode quantities and the correlated problem. Both simulated and experimental results show that the proposed solution represents an advantageous alternative in comparison to the traditional RC and RLC filters, since, in addition to its effect on the common-mode quantities, it dissipates a negligible amount of power.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAS.2013.6682570 },
  booktitle={ 2013 IEEE Industry Applications Society Annual Meeting },
  chapter={0}
}

@article{rayyan-352345605,
  title={ A Reason for “Corrosive Sulfur” Failures  -  2014 IEEE 18th International Conference on Dielectric Liquids (ICDL) },
  year={2014},
  author={Arvidsson, L. and Ravnemyhr, E. and Haugli, J. -P. and Tandstad, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893140 },
  abstract={It has long been the accepted opinion that it is the DBDS additive that causes the majority of failures in modern transformers manufactured up to 2007 when the use of this antioxidant was discontinued by most of the oil manufacturers that had chosen to use DBDS.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDL.2014.6893140 },
  booktitle={ 2014 IEEE 18th International Conference on Dielectric Liquids (ICDL) },
  chapter={0}
}

@article{rayyan-352345606,
  title={ Medium voltage autotransformer failures: Explaining the unexplained — Continuation of the story  -  2015 IEEE Petroleum and Chemical Industry Committee Conference (PCIC) },
  year={2015},
  author={Farr, L. B. and Shipp, D. and Smith, A. J. and Goodman, P. P. and Johnston, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435125 },
  abstract={When medium voltage autotransformer (RVAT) motor starters fail, also referred to as a Korndorfer starter, the results are almost always catastrophic, particularly ones in which there is no clear failure to the core or tap-to-tap but just layer-to-layer deep down in the windings. An offshore platform is used as an example to explain the techniques and to discuss site specific solutions that are based on recently developed switching transient analysis, sweep frequency response analysis and state-of-the-art EMTP simulation techniques. This paper will explain how the power system, interrupter, and transformer interact and outline the steps to solve this long-standing problem as well as present the newly applied solutions. Since implementation of these new solutions, no further failures have occurred.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCICON.2015.7435125 },
  booktitle={ 2015 IEEE Petroleum and Chemical Industry Committee Conference (PCIC) },
  chapter={0}
}

@article{rayyan-352345607,
  title={ A Dual Power Grid Cascading Failure Model for the Vulnerability Analysis  -  IEEE Transactions on Smart Grid },
  year={2025},
  author={Zhou, T. and Li, X. and Lu, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11175257 },
  abstract={When considering attacks against the power grid, one of the most effective approaches could be the attack to the transmission lines that leads to large cascading failures. Hence, the problem of locating the most critical or vulnerable transmission lines for a Power Grid Cascading Failure (PGCF) has drawn much attention from the research society. There exist many deterministic solutions and stochastic approximation algorithms aiming to analyze the power grid vulnerability. However, it has been challenging to reveal the correlations between the transmission lines for the critical line identification. In this paper, we propose a novel approach that learns such correlations, based on self-supervised learning and the self-attention mechanism, which is inspired by the Transformer model for natural language processing (NLP). Once the correlations are learned, a ranking algorithm is introduced for the critical line identification. With extensive experiments comparing our approach versus 2 other benchmark algorithms, it is proven that the proposed Dual PGCF model provides a novel and effective solution for critical line identification.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TSG.2025.3612371 },
  booktitle={ IEEE Transactions on Smart Grid },
  chapter={0}
}

@article{rayyan-352345608,
  title={ Beyond the Gaze: Peripheral Vision-Aware Visual Detection Failures Recognition Through LLM-Based Fixation Coordinate-Sensitive Analysis  -  IEEE Transactions on Intelligent Transportation Systems },
  year={2025},
  author={Li, Z. and Li, F. and Xu, G. and Li, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11087722 },
  abstract={Visual detection failures are a critical challenge in air traffic control (ATC), where undetected alerts can compromise operational safety and decision-making. Previous studies have primarily assessed detection failures through target fixation patterns, yet this method struggles to identify the more complex “look-but-fail-to-see” and “see-without-looking” scenarios. This underscores the necessity of exploring peripheral vision mechanisms, where dynamic tracking trajectories could better capture the scope of visual attention. Therefore, this study proposes a classification framework for visual detection by integrating peripheral vision tracking and human attentional states, including detection failures such as peripheral vision neglect and look-but-fail-to-see errors. A hierarchical detection failure recognition framework specific to the ATC settings is further developed and validated through an ATC simulation experiment. The framework first employs an Adaptive Symbolic Alert Detection method to identify and annotate ATC-specific alert regions with spatiotemporal uncertainty (achieving 95.24% precision), followed by LLM-based evaluation of operators’ visual attention to these regions to intelligently assign classification labels. Additionally, we introduce a fixation coordinate-sensitive multi-domain feature set that captures spatiotemporal and frequency-domain characteristics across detection types, achieving 93.13% four-class classification accuracy, outperforming traditional feature sets (83.69%) and both single-and dual-domain features (ranging from 76.82% to 90.11% accuracy). These findings demonstrate that our framework effectively captures a broader and structured range of visual detection failures, providing critical insights to improve the reliability of alert detection in ATC and the design of an intelligent human-centered ATC support system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TITS.2025.3588621 },
  booktitle={ IEEE Transactions on Intelligent Transportation Systems },
  chapter={0}
}

@article{rayyan-352345609,
  title={ Adequacy evaluation of residential distribution network with PHEVs penetration  -  2015 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT) },
  year={2015},
  author={Wang, Z. and Wang, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131878 },
  abstract={Plug-in Hybrid Electric Vehicles (PHEVs) are emerging as a new form of distributed energy resources for power grid, and their charging/discharging patterns will inevitably affect the power system reliability. This paper is concerned about the system adequacy after integrating PHEVs into residential distribution systems. To truly reflect the impact of PHEVs charging, a conditions-dependent outage model is applied to calculate the change of probability distribution function (PDF) for the power transformer. A time sequential Monte Carlo simulation is utilized to obtain the reliability indices in system adequacy evaluation. The IEEE-34 feeder system is used to represent the residential distribution system in case studies, and simulation results are presented and discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISGT.2015.7131878 },
  booktitle={ 2015 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT) },
  chapter={0}
}

@article{rayyan-352345610,
  title={ Summary of research on corrosive sulfur in oil-paper insulation system  -  2014 ICHVE International Conference on High Voltage Engineering and Application },
  year={2014},
  author={Quan, Zhou and Jun-xing, Rao and Hui-li, Xie and Shi-zheng, Wang},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7035480 },
  abstract={Oil-paper insulation plays an important role in the internal insulation of power transformers. Aging of transformer insulation is a gradual procedure which can eventually threaten the safe operation of power transformers. During long-term operation of power transformers, oil-paper insulation is exposed to multiple stresses, including electrical, thermal, mechanical factors and so on. Lot of vigor is given to maintenance of the health of transformers in transmission system. Usually the reliability of power transformer is very high and is expected to have a long service life. But according to the recent report and observations, many transformers and reactors have failed prematurely due to the resultant formation of copper sulfide in the windings, which has attracted wide attention. In the past decade, considerable amount of work has been carried out to understand the long term effects of corrosive sulfur in mineral insulating oils, which has been recognized as the culprit of failure of some shunt reactors and power transformers. However, the problem of copper corrosion is very complex because of the complicated existence of sulfur element in transformers. Depending on oil, there are many different sulfur compounds present in oil. Other components of transformer, like pressboard, paper, glue, gasket, contaminated oil deliver hose etc are all potential sources of sulfur of one form or the other, either independently or due their interaction with oil. It is not one single corrosive sulfur compound that is responsible for all corrosive sulfur issues. Therefore the main sources, detection method, corrosive mechanism, damage and suppression measures are still the puzzled research focus. This paper present a comparatively detailed summary of research status about this phenomenon, and some useful research proposals and findings are introduced as well.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2014.7035480 },
  booktitle={ 2014 ICHVE International Conference on High Voltage Engineering and Application },
  chapter={0}
}

@article{rayyan-352345611,
  title={ An approach to power transformer asset management using health index  -  IEEE Electrical Insulation Magazine },
  year={2009},
  author={Jahromi, A. and Piercy, R. and Cress, S. and Service, J. and Fan, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802595 },
  abstract={The Health Index represents a practical tool that combines the results of operating observations, field inspections, and site and laboratory testing to manage the asset and prioritize investments in capital and maintenance plans.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MEI.2009.4802595 },
  booktitle={ IEEE Electrical Insulation Magazine },
  chapter={0}
}

@article{rayyan-352345612,
  title={ Experimental studies of influence of DC and AC electric fields on bridging in contaminated transformer oil  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2015},
  author={Mahmud, S. and Chen, G. and Golosnoy, I. O. and Wilson, G. and Jarman, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033382 },
  abstract={Analysis of real operating condition revealed that HVDC transformers experience combined effect of DC biased AC electric field. The dynamics of pressboard particle in contaminated transformer oil under the influence of DC, AC and DC biased AC electric field has been investigated in this paper. Different levels of particle concentrations are tested at different applied voltages. Optical images of the particles accumulation together with conduction current have been recorded during the experiments. A complete bridge between the electrodes of cellulose particles were observed for all the tests carried out under DC and DC biased AC electric field. Opposite to that, for AC experiments, pressboard particles accumulated on surfaces of both electrodes but did not create a full bridge between the electrodes. It is concluded that a combination of DC and AC voltages in a HVDC transformer could lead to a bridge formation within the equipment which could cause failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2014.004573 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345613,
  title={ Corrosive sulfur effects in transformer oils and remedial procedures  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2009},
  author={Maina, R. and Tumiatti, V. and Pompili, M. and Bartnikas, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361586 },
  abstract={The behavior of corrosive sulfur in mineral oils is examined in terms of the failures observed in transformers, the surfaces of the copper sulfide covered conductors and degraded paper insulating tapes. The role of dissolved gas analysis (DGA) in the evaluation of the risk of copper sulfide formation is described. The degree of corrosiveness of some sulfur compounds is examined and compared using a Kraft paper wrapped-copper test (standard IEC 62535). The occurrence of DBDS as the most relevant corrosive compound is compared with the presence of other corrosive species in insulating mineral oils. A number of mitigation techniques for corrosive sulfur are described and evaluated.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2009.5361586 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345614,
  title={ A Novel Open-Circuit Fault Detection and Localization Scheme for Cascaded H-Bridge Stage of a Three-Stage Solid-State Transformer  -  IEEE Transactions on Power Electronics },
  year={2021},
  author={Gorla, N. B. Y. and Kolluri, S. and Chai, M. and Panda, S. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719999 },
  abstract={A three-stage solid-state transformer (SST) is a preferred replacement for line frequency transformer as it provides ancillary services in addition to stepping-up/down of grid voltages. Each active switch in SST is a potential source of failure, and a quick fault detection and isolation help in reducing the downtime. In this article, a novel fault detection and localization algorithm is proposed to localize the open-circuit (OC) faults (be it a single switch fault or multiple switch faults in multiple modules) in the cascaded H-bridge (CHB) stage of the SST. The proposed method is designed such that only one voltage sensor is needed to measure the grid-side voltage of the CHB for fault detection and localization. By comparing the estimated grid-side voltage of the CHB with the measured values, OC fault is detected. Once the fault is detected, the modulation scheme is switched from phase-shifted unipolar sinusoidal pulsewidth modulation (SPWM) to phase-shifted bipolar SPWM to localize the faults. The difference in the measured grid-side voltage of the CHB before and after each module's state change is calculated and faults are localized. The presented algorithm is substantiated using experimental results from a 1-kVA SST prototype. The main advantage of the proposed algorithm is that it requires only 2n comparisons to localize the faulty modules in a CHB with n H-bridges, which takes less than a line cycle to complete.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPEL.2019.2918148 },
  booktitle={ IEEE Transactions on Power Electronics },
  chapter={0}
}

@article{rayyan-352345616,
  title={ Embedded FBG Sensors in Carbon Fiber for Vibration and Temperature Measurement in Power Transformer Iron Core },
  year={2020},
  journal={ IEEE Sensors Journal },
  author={Kuhn, G. G. and Sousa, K. M. and Martelli, C. and Bavastri, C. A. and d. Silva, J. C. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131700 },
  abstract={This paper presents a new methodology for measuring vibration and temperature using fiber Bragg grating (FBG) sensors embedded in carbon fiber polymer attached directly on the iron core of a power transformer. The device has a quick-coupling clip design and is fabricated from a carbon fiber reinforced composite (CFRP) for robustness and flexibility. Temperature and vibration FBG sensors are embedded in the carbon fiber clip, which is easily and quickly coupled directly to the transformer iron core. In the low frequency ranges, from 0 to 500 Hz, vibrations are mainly generated in the core. Rigidity is controlled by clip thickness and geometry, since the system is designed to have a wide operating frequency range. The embedded strain FBG sensor sensitivity has been improved due to its spring-shaped design static and dynamic simulations applying the Finite Element Method (FEM) were performed to determine the optimal dimensions and structure of the part. The clip's frequency response function (FRF) was assessed and tested by using three techniques: FEM harmonic analysis, mechanical impact testing, and optical FBG sensing. The results demonstrate a 3.94 % differential among the methods. A comparison was made of the power transformer's FRF when fitted with a glued free FBG sensor and an embedded FBG sensor. In both cases, the transformer was subjected to varying electrical load conditions (no-load, linear, and nonlinear load). The results showed a 19 % average sensitivity improvement when the embedded sensor was compared to the free sensor.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JSEN.2020.3005884 },
  chapter={0}
}

@article{rayyan-352345617,
  title={ Modeling the Aging-dependent Reliability of Transformers Considering the Individualized Aging Threshold and Lifetime  -  IEEE Transactions on Power Delivery },
  year={2022},
  author={Huang, W. and Shao, C. and Dong, M. and Hu, B. and Zhang, W. and Sun, Y. and Xie, K. and Li, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721144 },
  abstract={Conventionally, the 2-parameter Weibull model, Arrhenius-Weibull model, has been used vastly for transformer aging-dependent unavailability modeling. However, this model only uses the lifetime feature to describe the transformer's degradation process and to calibrate the Weibull parameters, which harms the accuracy of aging-dependent unavailability forecasting. In response, this paper develops a 3-calibratable-parameter Weibull model for evaluating the transformer aging-dependent unavailability. In the proposed model, both the individualized aging threshold and lifetime are taken into the calibration of the Weibull parameters to accurately characterize the heterogeneity in transformer populations. First, a degree of polymerization (DP) analysis and Monte Carlo Simulation (MCS) based approach is proposed for estimating the transformers’ uncertain aging thresholds and lifetimes. Then, the Maximum Likelihood Estimate and Particle Swarm Optimization are jointly adopted to model the relationship among the calibratable Weibull parameters, aging threshold, and lifetime. Finally, the analytical formula of aging-dependent unavailability is derived from the established 3-calibratable-parameter Weibull model using an integral-discretization method. A real utility application example in China's Chongqing power system has been presented to validate and demonstrate the practicality and usefulness of this method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2022.3152745 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345618,
  title={ A Review on Bidirectional Matrix-Based AC-DC Conversion for Modular Solid-State-Transformers  -  2019 IEEE 4th International Future Energy Electronics Conference (IFEEC) },
  year={2019},
  author={Saha, J. and Yadav, G. N. Brahmendra and Panda, S. Kumar},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9015013 },
  abstract={This paper has presented an extensive review of the bidirectional phase-modular and semi-modular Solid-State- Transformer (SST) topologies, specific to the matrix-type variants with single-stage AC-DC conversion. This includes a qualitative and mathematical explanation of each topology and the corresponding modulation(s). A comparative analysis incorporating the criteria of power density, failure rate, cost and component count is also done among all these topologies along with the conventional Cascaded-Modular-SST (CMSST) topology with two-stage AC-DC conversion. The matrix-based topologies clearly prove to be better than the CMSST topology in terms of power density and reliability, with the entirely phase-modular topologies proving to be superior overall. The AC-DC DAB type submodule has been estimated to have the best characteristics in terms of all the comparison indices and thus it can be considered to be the best among the grid-connected matrix-based SST topologies for the application-type under consideration.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IFEEC47410.2019.9015013 },
  booktitle={ 2019 IEEE 4th International Future Energy Electronics Conference (IFEEC) },
  chapter={0}
}

@article{rayyan-352345619,
  title={ Lightning Performance of Distribution Transformer Feeding GSM Base Station  -  IEEE Transactions on Power Delivery },
  year={2014},
  author={Mikropoulos, P. N. and Tsovilis, T. E. and Koutoula, S. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6862079 },
  abstract={Data on unscheduled electric service interruptions in an extended distribution network (20/0.4 kV) were analyzed in order to examine the causes contributing to distribution substation failures. A distribution substation feeding a Global System for Mobile Communications base station experienced the highest service interruption rate due to transformer sustained failures, the vast majority of which were categorized as lightning related. Thus, with the aid of detailed Alternate Transients Program-Electromagnetic Transients Program simulations, an investigation on the overvoltages surges impinging on the distribution transformer due to direct lightning strokes to the connected MV overhead line and to the nearby telecommunication tower has been made. Transformer failures are caused solely by fast-front overvoltages exceeding the basic insulation level of the LV side of the transformer. This is substantiated by the good agreement between estimated and reported transformer failure rates. The safe operation of the distribution transformer necessitates the installation of surge protective devices at its low-voltage terminals, also overcoming the need for extremely low values of telecommunication tower grounding resistance. Additional line surge arresters should be installed at the penultimate wood pole of the connected overhead line which, besides improving the lightning performance of the transformer, significantly increases the reliability of the distribution substation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2014.2335253 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345620,
  title={ Influence of solar irradiation on power transformer thermal balance  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2012},
  author={Gorgan, B. and Notingher, P. V. and Wetzer, J. M. and Verhaart, H. F. A. and Wouters, P. A. A. F. and Schijndel, A. V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6396939 },
  abstract={In countries with a high ambient temperature and strong solar irradiation, transformer winding hot-spot temperature may increase over its maximum permissible limit. This can considerably reduce the insulation life of the transformer by enhanced degradation of the paper insulation. According to current loading guides, for each 6 K increase in working temperature, the ageing rate increases with approximately a factor two. Therefore, it is important to take into consideration the impact of the sun on the power transformer thermal behavior. In this paper, a modified hot-spot temperature model is presented to account for the effect of transformer winding temperature rise by solar irradiation. The effects of solar irradiation on transformer winding paper insulation are shown by comparing the degree of polymerisation (DP), the fault probability and the remaining life. Here, the fault probability is defined as the probability that the estimated DP-value at a certain moment in time is below a certain end-of-life criterion (threshold value). An additional winding hot-spot temperature rise of 9 K during the summer and a temperature rise of 6 K during the winter may occur in countries with strong solar irradiation. This may result in a reduction of the remaining lifetime by up to 40%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2012.6396939 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345621,
  title={ Module Power Balance Control and Redundancy Design Analysis of Cascaded PV Solid-State Transformer Under Fault Conditions },
  year={2021},
  journal={ IEEE Journal of Emerging and Selected Topics in Power Electronics },
  author={Zhao, T. and Zhang, X. and Wang, M. and Mao, W. and Li, F. and Wang, F. and Wang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952626 },
  abstract={Three-phase photovoltaic (PV) solid-state transformer based on cascaded H-bridge topology has a considerable prospect in high-voltage and high-power applications. Normally, each phase of the three-phase converter is designed to have the same number of modules, each of which is composed of an isolated dc–dc converter in cascade with an HB, and all the modules are able to transmit the same active power. However, if partial modules fail, the number of actual operation modules in three phases may be different, resulting in the active powers of the modules in the fault phase higher than those in the normal phase. The unbalanced active powers cause different heat dissipation requirements, violating the principle of modular design. For this issue, this article proposes a power balance control method which calculates a zero-sequence voltage to be injected into the system based on the number of modules in three phases and is able to ensure that all modules will have almost the same active powers under fault conditions. In addition, combined with redundancy design, it is also analyzed that all modules do not suffer from overmodulation even if the amplitudes of modulation voltages increase after being compensated by the proposed zero-sequence voltage. The validity of the proposed method is verified by simulation and experimental results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JESTPE.2020.2964950 },
  chapter={0}
}

@article{rayyan-352345622,
  title={ Self-Repairable Smart Grids Via Online Coordination of Smart Transformers  -  IEEE Transactions on Industrial Informatics },
  year={2017},
  author={Pournaras, E. and Espejo-Uribe, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7733133 },
  abstract={The introduction of active devices in Smart Grids, such as smart transformers, powered by intelligent software and networking capabilities, brings paramount opportunities for online automated control and regulation. However, online mitigation of disruptive events, such as cascading failures, is challenging. Local intelligence by itself cannot tackle such complex collective phenomena with domino effects. Collective intelligence coordinating rapid mitigation actions is required. This paper introduces analytical results from which two optimization strategies for self-repairable Smart Grids are derived. These strategies build a coordination mechanism for smart transformers that runs in three healing modes and performs collective decision-making of the phase angles in the lines of a transmission system to improve reliability under disruptive events, i.e., line failures causing cascading failures. Experimental evaluation using self-repairability envelopes in different case networks, ac power flows, and varying number of smart transformers confirms that the higher the number of smart transformers participating in the coordination, the higher the reliability and the capability of a network to self-repair.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TII.2016.2625041 },
  booktitle={ IEEE Transactions on Industrial Informatics },
  chapter={0}
}

@article{rayyan-352345623,
  title={ A Two-Stage Framework for Power Transformer Asset Maintenance Management—Part II: Validation Results  -  IEEE Transactions on Power Systems },
  year={2013},
  author={Abiri-Jahromi, A. and Parvania, M. and Bouffard, F. and Fotuhi-Firuzabad, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331587 },
  abstract={A two-stage framework for transformer maintenance management is introduced and formulated in Part I of this two-part paper in the context of transmission asset management strategies (TAMS). The proposed model optimizes maintenance outage schedule over a predefined period of time by taking into account the actual and expected transformer assets' condition dynamics in terms of failure rate and resource limitations in midterm horizons, as well as operating constraints, economic considerations and N-1 reliability in the shorter term. In Part II, a small six-bus system is first used to demonstrate how the two-stage maintenance framework works using a step-by-step procedure. Then, IEEE-RTS is used to investigate the performance of the proposed model in more detail. In addition, the impacts of varying the characteristics of the proposed midterm and short-term maintenance schedulers, such as flexibility in time horizon selection, on maintenance scheduling results and computational efficiency are investigated on IEEE-RTS. The numerical studies indicate that the proposed framework gives appropriate results in terms of economics and technical constraints at a reasonable computational cost.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2012.2216904 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345624,
  title={ Effect of Voltage Waveforms of HVDC Converter Transformer on Lifetime Characteristics  -  IEEE Transactions on Power Delivery },
  year={2021},
  author={Thind, B. S. and Thomas, A. J. and Reddy, C. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238512 },
  abstract={The converter transformers are reported to fail generally on the thyristor-valve side, where complex alternating voltage waveforms superimposed with dc voltages would occur. The effect of these waveforms on the failure and endurance of the valve side winding insulation of the transformers is not yet understood, which is investigated here. In this paper, the voltage waveforms occurring in a converter transformer are obtained through PSCAD/EMTDC for a typical double pole ±500 kV, 1000 MW DC-link HVDC transmission system based on the CIGRE benchmark system. The waveforms are then amplified using a High Voltage amplifier for experimental breakdown investigations. Stepped-stress damage equalization method has been used for obtaining the lifetime characteristics from failure data. A comparison with life curve under pure sinusoidal and actual alternating voltages with superimposed dc and harmonic voltage has been made to understand why the converter transformers generally failed on the valve side. The results first time give fundamental reasons for the possible failure of the converter transformers and put forth important design considerations.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2020.3033447 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345625,
  title={ Adequacy Assessment of Power Distribution Network With Large Fleets of PHEVs Considering Condition-Dependent Transformer Faults  -  IEEE Transactions on Smart Grid },
  year={2017},
  author={Tan, J. and Wang, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7491332 },
  abstract={As a new form of distributed energy resources, massive plug-in hybrid electric vehicles (PHEVs) could affect the power distribution system adequacy considering their intermittent charging loads and the load recovery ability during system outages. This paper proposes a comprehensive framework for adequacy evaluation of power distribution networks with PHEVs penetration. A condition-dependent outage model is used in this paper to obtain the time sequential failure rate of the transformer. Also, a business model for the PHEVs is developed to encourage the PHEV owners to charge their vehicles in such a way that the distribution system adequacy is enhanced. Based on this model, a smart charging algorithm is proposed for the PHEVs to minimize their charging cost and enhance the adequacy of the distribution network at the same time. Various simulation studies are carried out to verify the effectiveness of the proposed smart charging approach. The simulation results show that the proposed approach is effective in enhancing both the adequacy of the distribution network and economic profits of PHEVs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TSG.2016.2580622 },
  booktitle={ IEEE Transactions on Smart Grid },
  chapter={0}
}

@article{rayyan-352345626,
  title={ Performance requirements of present-day distribution transformers for Smart Grid  -  2013 IEEE Innovative Smart Grid Technologies-Asia (ISGT Asia) },
  year={2013},
  author={Rao, N. M. and Narayanan, R. and Vasudevamurthy, B. R. and Das, S. K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698769 },
  abstract={One of the main objectives of Smart grid is to provide service that is reliable, secure and efficient. As a part of smart grid it is very essential to evaluate each and every element separately in the grid level to ensure reliable operation of the grid. In this paper, distribution transformer (DTR) requirements for smart grid have been considered. Distribution transformer is one of the most important elements of electrical distribution network. For smart grid to operate efficiently there is a need for smartening the transformers, which are the hub for collection and distribution of energy. As part of the distribution network, there are millions of distribution transformers in the national network that do not have any monitoring and communication capabilities. Smartening the transformers will require development and deployment of wide range of technologies. This paper attempts to present the features needed in distribution transformers to realize a smarter grid. Required technologies to transform the present day distribution transformers to smart transformers are discussed. Analysis has been carried out on the performance requirements and evaluation of distribution transformers when they are integrated to grid level. Some applications of wireless sensors and communication to enhance condition monitoring and maintenance practices in the distribution grid are recommended. The paper also studies compliance needed to the existing standards such as IEC 60076-7 [3].},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISGT-Asia.2013.6698769 },
  booktitle={ 2013 IEEE Innovative Smart Grid Technologies-Asia (ISGT Asia) },
  chapter={0}
}

@article{rayyan-352345627,
  title={ Optimized models for overload monitoring of power transformers in real time moisture migration model  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2013},
  author={Linan, R. and Ponce, D. and Betancourt, E. and Tamez, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6678844 },
  abstract={In this paper a mathematical model, based on experimentation, to estimate the axial moisture distribution in power transformer windings was developed. The model considers the variables of moisture content in oil, top oil temperature, as well as the transformer's design parameters and ageing of the insulation system. The model was validated using a small-scale experimental setup, which represents a 75 MVA transformer. The developed model proved to be more accurate than existing models. It considers the axial moisture distribution in paper, in 4 thermal zones equidistantly distributed along the height of the winding. This paper compares the results of the proposed model with those provided by other authors.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2013.6678844 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345628,
  title={ Current Limitation Experiments on a 1 MVA-Class Superconducting Current Limiting Transformer  -  IEEE Transactions on Applied Superconductivity },
  year={2019},
  author={Hellmann, S. and Abplanalp, M. and Elschner, S. and Kudymow, A. and Noe, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675321 },
  abstract={We designed, built, and tested a single phase 577 kVA transformer demonstrator, optimized for high current limiting capability and low loss operation. The transformer demonstrator consists of a conventional warm iron core and a normal conducting primary winding operated at 20 kV / 28.9 A in combination with a superconducting secondary winding at 1 kV / 577.4 A composed of 12 parallel ReBCO-tapes.To demonstrate the short-circuit behavior we present in detail a current limitation experiment. The results show that the current limiting transformer design is capable of limiting short-circuit currents in the first half-wave of a fault to 67.6% and in the sixth half-wave to 29.1% of the prospective current. The current distribution among the parallel tapes was analyzed and showed different current sharing patterns for the nominal transformer operation and during the current limitation. The experimental results are further compared to numerical simulations to predict the current limitation behavior under short-circuit conditions with parameters different to the conducted experiments. In addition to the successful current limitation, we also present and explain a mechanism during a current limitation measurement that lead to a failure of the superconducting winding of the transformer demonstrator. The reason for this failure is discussed and we give a recommendation for changes in the transformer design to prevent similar failures in future generations of superconducting transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TASC.2019.2906804 },
  booktitle={ IEEE Transactions on Applied Superconductivity },
  chapter={0}
}

@article{rayyan-352345629,
  title={ A relevant condition monitoring of corrosive sulphur deposition on the windings of oil-filled electrical transformers  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2020},
  author={Jadim, R. and Kans, M. and Rehman, S. and Alhems, L. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9215129 },
  abstract={The purpose of this study is to determine whether the currently applied condition monitoring (CM) techniques are sufficient and effective for early detection of copper corrosion fault in transformers and to establish a more relevant CM technique for early detection of such fault. In this study, experimental work is carried out by applying appropriate methods on different commercial insulating mineral oils for the detection and identification of additional related by-products of copper corrosion process, if any. The major finding of this experimental investigation includes identification of additional by-products, which could be useful to establish a more effective CM technique. Furthermore, the role of sulphur compounds in copper corrosion fault is considered, and a relevant reaction mechanism of formation CSD is developed based on the findings of the related by-products. It is concluded that, the application of a relevant CM technique is necessary for establishing a cost-effective condition based maintenance (CBM) to minimize the economic losses, hazardous effects on human life and the environment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2020.008955 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345630,
  title={ Improvements to the Construction of Bubble Inception Formulae for Use With Transformer Insulation  -  IEEE Access },
  year={2019},
  author={Hill, J. P. and Wang, Z. and Liu, Q. and Matharage, S. and Hilker, A. and Walker, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911497 },
  abstract={Moisture in transformer insulation is a topic of major interest to power system equipment operators. Moisture plays a large role in the degradation of insulation within the transformer, impacting on the longevity and the failure rate of this crucial asset. Therefore, understanding of how moisture behaves in the transformer insulation has been the focus of many studies. One particular matter that can occur during high-temperature events is the formation of bubbles of water vapor which are released from the cellulosic paper wrapped on the transformer windings. During such events, the presence of these bubbles could lead to an electrical failure of the transformer, and so it is desirable to be able to set operational criteria which prevent such occurrences. A formula which can predict the temperature at which bubbles will form from the paper insulation can allow operators to restrict transformer operation in order to avoid such situations. However, it has proven difficult to generate a formula with global applicability that is simplistic enough for generic use. This paper assesses the current formula against existing data in literature and compares a suggested alternative, drawing on fundamental science to assist in development of both formulae. The alternative formula is based on a better representation of bubbling activity and requires fewer input variables. Finally, adjustments are suggested to the formulae which allow them to be used more generally throughout the transformer fleet, including on service-aged transformers and with alternative insulation materials.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2019.2955802 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345631,
  title={ Automatic detection of frequency ranges of power transformer transfer functions for evaluation by mathematical indicators  -  2012 Sixth IEEE/PES Transmission and Distribution: Latin America Conference and Exposition (T&D-LA) },
  year={2012},
  author={Gonzales, J. C. and Mombello, E. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6319080 },
  abstract={Sweep Frequency Response Analysis (SFRA) has gained notorious popularity in recent years, due to its high sensitivity to detect electrical failures or winding deformations in transformers. Due to its high sensitivity to several failures and its good reproducibility, this technique is being widely studied, and several contributions to the evaluation and detection have been proposed, which use mathematical indicators for the comparison of frequency response traces. The differences are normally evaluated using fixed frequency ranges, leading to results that are not always accurate. The application of dynamic ranges to the analysis produce a more robust diagnosis, showing that a suitable definition of the frequency ranges improves the ability of the mathematical indicators to detect failures. A smoothing technique can be applied to the SFRA measurements in order to avoid disturbances in the measuring process at high frequencies. This paper integrates the mentioned features and proposes a new improved automatic methodology for dynamic frequency range detection, mathematical indicators evaluation and the subsequent failure interpretation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDC-LA.2012.6319080 },
  booktitle={ 2012 Sixth IEEE/PES Transmission and Distribution: Latin America Conference and Exposition (T&D-LA) },
  chapter={0}
}

@article{rayyan-352345632,
  title={ Method for Internal Fault Testing of Instrument Transformers With Sectioned Active Parts  -  IEEE Access },
  year={2021},
  author={Gazivoda, D. and Žiger, I. and Novko, I. and Župan, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580847 },
  abstract={Relevant international instrument transformer standards specify internal arc testing to prove the transformer behavior under internal fault conditions. However, the test is defined in a way that does not recognize that it is possible to limit and reduce the total fault energy. For such instances, testing, as currently defined, is mostly inapplicable. The purpose of this paper is to address this issue by presenting a testing sequence that is applicable for verifying the behavior of transformers with sectioned active parts that contain energy-limiting features. Furthermore, the acceptance criteria for the successful completion of the test are also introduced. Every step of the proposed test sequence is discussed in detail and presented on a 145 kV inductive transformer, selected specifically for this purpose. This paper is a part of a continuous broad research with the aim of developing and specifying adequate routine, type and special testing sequences for qualifying paper-oil insulation systems that limit internal arc energy, with the aim of improving the performance of such systems and introducing test methods and criteria that exceed the practices of current standards.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2021.3121429 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345634,
  title={ Condition Monitoring Techniques of Dielectrics in Liquid Immersed Power Transformers - A Review  -  2018 IEEE Industry Applications Society Annual Meeting (IAS) },
  year={2018},
  author={Balamurugan, S. and Ananthanarayanan, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8544650 },
  abstract={With the developments in transformer design, their methods of maintenance also need to be updated. A shift from the traditional time-based maintenance to condition based maintenance is required for lifetime economic management of transformers. As the aging of a transformer is directly related to insulation deterioration, the estimation of insulation health is required to analyze the condition of the transformer. This paper reviews various methods of dielectric analysis, including chemical based methods such as Dissolved Gas Analysis, and dielectric response analysis. Several techniques for interpretation of results is also analyzed here. The present trends in condition monitoring with both online and offline monitoring techniques are also presented here. With the active research being conducted in this field, the current developments in this field are identified and surveyed, which are required for future advancements in this subject.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAS.2018.8544650 },
  booktitle={ 2018 IEEE Industry Applications Society Annual Meeting (IAS) },
  chapter={0}
}

@article{rayyan-352345635,
  title={ Decompositional Rule Extraction from Artificial Neural Networks and Application in Analysis of Transformers  -  2009 15th International Conference on Intelligent System Applications to Power Systems },
  year={2009},
  author={Amora, M. A. B. and Almeida, O. M. and Braga, A. P. S. and Barbosa, F. R. and Lima, S. S. and Lisboa, L. A. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5352932 },
  abstract={The artificial neural networks represent efficient computational models that are widely used to solve problems of difficult solution in Artificial Intelligence. The greatest difficulty associated with the use of Artificial Neural Networks (ANN) is in obtaining knowledge about its behavior, because of that ANNs are also considered as black-box methods. This paper presents a brief history of methods of extraction of knowledge, and in detail a method of interpreting the behavior of an artificial neural network by establishing a relation of equality between certain classes of neural networks and systems based on fuzzy rules, with modifications that allow the acquisition of rules coherent with the domain of the variables of the problem. An example of application is used to illustrate the method, considering the identification of incipient faults in transformers by using data from gas dissolved in transformer oil.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ISAP.2009.5352932 },
  booktitle={ 2009 15th International Conference on Intelligent System Applications to Power Systems },
  chapter={0}
}

@article{rayyan-352345636,
  title={ Deriving Transformer Equivalent Age for Power System Reliability Assessment from Asset Condition Score  -  2020 International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  year={2020},
  author={Awadallah, S. K. E. and Milanovic, J. and Jarman, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183412 },
  abstract={The paper proposes a method to derive an equivalent age from asset condition scores in order to incorporate asset condition into existing reliability assessment techniques. The method is related to end-of-life failure to inform replacement decision-making process. The paper projects the age cumulative distribution function (CDF) of a fleet of power transformers into the cumulative distribution function (CDF) of their condition scores. A relationship between condition score and age was formulated by using curve fitting techniques. Case studies were performed on a generic test system to compare system and load point reliability indices using the chronological age and the derived equivalent age. The results showed that using equivalent age resulted in different critical load points than the ones identified when using chronological age.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PMAPS47429.2020.9183412 },
  booktitle={ 2020 International Conference on Probabilistic Methods Applied to Power Systems (PMAPS) },
  chapter={0}
}

@article{rayyan-352345637,
  title={ Retiring strategies of transformer LCC with reliability of power transmission system considered  -  IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society },
  year={2017},
  author={Zhu, M. and Jia, L. and Hu, H. and Chen, J. and Wu, Z. and Zhang, D. and He, Y. and Ye, H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8217036 },
  abstract={In order to elevate equipment-oriented traditional asset management to system-oriented advanced asset management (AAM) decision-making for smart power grid, for the problem that influence of different positions of the equipment in network topology on system reliability is not taken into consideration in retiring strategies of transformer LCC (life cycle cost), which may cause overestimation or underestimation of outage cost and premature or excessively late transformer retiring, retiring strategies of transformer LCC with reliability of power transmission system was proposed. This method used historical data to calculate time-varying aging fault and unavailability rate of transformer and used reliability index of power transmission system - expected energy not supplied (EENS) - to measure outage cost caused by transformer fault so as to obtain LCC of transformers at different topological positions. Retiring time obtained through this method could maximize economic benefit of the transformers and guarantee reliability of system operation. IEEE-14 test system analyzed, effectiveness of this method was verified.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IECON.2017.8217036 },
  booktitle={ IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society },
  chapter={0}
}

@article{rayyan-352345638,
  title={ Bubble Motion Characteristics in the Transformer Oil Gap at the Top of HV Winding  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2024},
  author={Zhao, T. and Liu, Y. and Liu, Y. and Yang, C. and Zheng, Y. and Zhu, W. and Gu, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10423071 },
  abstract={The bubbles generated in the oil-paper insulation and their movement will reduce the dielectric strength and lead to insulation failure in power transformers. To explore bubble motion characteristics and the possible accumulation location, a bubble motion simulating model is established coupling with the electric field and the oil flow. The motion and deformation of the bubble in the oil gap at the top of high-voltage winding are simulated under ac electric field. The results show that the bubble motion trajectory presents an S-shape during the rising period near the T-cross oil gap driven by the electric field force and pressure from the oil flow. During the motion process, the bubble undergoes periodic deformation with a frequency of 100 Hz. The presence of the bubble changes the electric field distribution, bringing about a more significant distortion of the electric field. In the L-shaped oil gap near the electrostatic ring, the bubble motion is mainly driven by pressure from the oil flow. Moreover, if the oil flow velocity is very slow, the bubbles may accumulate on the inner wall of the angle ring, which will give rise to further deterioration of insulation. A test platform is built to observe the bubble trajectory in the oil gap and the results are consistent with simulated in the model. The results obtained are of great significance to present a better understanding of the bubble dynamics in the transformer oil gaps. Insulation failure risk caused by bubble motion and accumulation in oil gap needs to be paid attention to and further explored by researchers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2024.3361848 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345639,
  title={ Reliability Comparison of Two Deterministic Criteria for Planning High Voltage Auto-Transformer Stations  -  IEEE Transactions on Power Delivery },
  year={2021},
  author={Hamoud, G. and Nahas, I. El and Faried, S. O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174760 },
  abstract={This paper describes a reliability study that has been performed at Hydro One to compare the reliability of two deterministic criteria used in the planning of high voltage auto-transformer stations. One criterion calls for designing the station to withstand the loss of one unit transformer (single contingency criterion) while the other calls for designing it to withstand the loss of two units (double contingency criterion). Two system reliability measures are used in the comparison namely the system availability index and the loss of energy index. The study proposed a number of Markov models to evaluate the probability of system failures under each criterion. Examples are provided to illustrate these models and see how the two deterministic planning criteria are compared from the reliability point of view.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2020.3018938 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345640,
  title={ Open-Circuit Fault Diagnosis and Tolerant Control of Matrix-Type Solid-State Transformer  -  IEEE Transactions on Industrial Electronics },
  year={2024},
  author={Wang, H. and Yu, T. and Jiang, L. and Chen, X. and Zhang, G. and Su, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10527399 },
  abstract={The solid-state transformer (SST) is expected to play a critical role in modern power systems, serving as a key component for efficient and flexible energy transformation. The reliability of the SST is crucial. However, active switches are prone to failures, which can have severe consequences. For the matrix-type SST (MT-SST), the time-varying dc-link voltage poses challenges for accurate and rapid fault diagnosis. This article proposes a comprehensive fault diagnosis and fault-tolerant control method for the open-circuit (OC) fault of a single switch in MT-SST. By comparing the estimated and measured values of the resonant capacitor voltages, the algorithm identifies the OC fault. Additionally, a reduction in the duty cycle of specific switches is introduced to assist in fault localization through monitoring of voltage changes. However, this method can only identify the OC fault on one side of MT-SST when the direction of power flow remains constant. To ensure fault tolerance, the primary and secondary side full-bridge is reconfigured into a quasi-half-bridge structure. The developed methods have the advantages simplicity and reliability. Finally, a 1.5 kW prototype is built, and the validity and feasibility of the proposed methods are verified.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIE.2024.3390715 },
  booktitle={ IEEE Transactions on Industrial Electronics },
  chapter={0}
}

@article{rayyan-352345641,
  title={ Study on High Energy Discharge Characteristics Caused by Arc Faults in Transformer Turret  -  IEEE Access },
  year={2023},
  author={Hu, S. and Huang, Z. and Liu, X. and Chen, J. and Wang, Y. and Zhao, T. and Yang, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10267992 },
  abstract={The power transformer is an essential equipment in the UHV transmission system. High energy discharge resulting from arc faults in the transformer turret can lead to an explosion, posing a serious threat to the safe and stable operation of the power system. At present, there is a lack of experimental research on arc discharge faults in the transformer turret. The ignition and explosion process remains unclear, which limits the improvement of transformer explosion-proof performance. To address this issue, a test platform of arc discharge fault in the transformer turret was constructed. High-current and high-deflagration capacity simulation short-circuit tests were carried out, and the voltage and current waveforms in the arc discharge process were obtained. This facilitated the quantitative characterization of discharge energy and analysis of the arc energy flow conversion. The test results highlighted that arc energy and arc current are the important factors affecting the voltage boost in the riser. The arc process of casing rupture under high current (1400 A) can be divided into two stages: “smooth” and “sudden”. The insulating oil after high energy discharge and the gas escaping from the oil were analyzed by chromatographic methods. The results revealed that the oil cracking occurs after high energy discharge, significantly increasing various fault characteristic gases in the oil. Among these gases, H2, CH4, C2H2, and C2H4 exhibited the highest total content in the oil, while H2, CH4, and C2H4 presented the greatest range in the escaped gas, accounting for more than 75% of the total volume. This work elucidates the physical mechanism of the internal short-circuit fault of the transformer turret, and holds crucial guiding significance for the transformer explosion-proof design.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2023.3320806 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345642,
  title={ Improving Transformer Performance for French Clinical Notes Classification Using Mixture of Experts on a Limited Dataset },
  year={2025},
  journal={ IEEE Journal of Translational Engineering in Health and Medicine },
  author={Le, T. -D. and Jouvet, P. and Noumeir, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11023574 },
  abstract={Transformer-based models have shown outstanding results in natural language processing but face challenges in applications like classifying small-scale clinical texts, especially with constrained computational resources. This study presents a customized Mixture of Expert (MoE) Transformer models for classifying small-scale French clinical texts at CHU Sainte-Justine Hospital. The MoE-Transformer addresses the dual challenges of effective training with limited data and low-resource computation suitable for in-house hospital use. Despite the success of biomedical pre-trained models such as CamemBERT-bio, DrBERT, and AliBERT, their high computational demands make them impractical for many clinical settings. Our MoE-Transformer model not only outperforms DistillBERT, CamemBERT, FlauBERT, and Transformer models on the same dataset but also achieves impressive results: an accuracy of 87%, precision of 87%, recall of 85%, and F1-score of 86%. While the MoE-Transformer does not surpass the performance of biomedical pre-trained BERT models, it can be trained at least 190 times faster, offering a viable alternative for settings with limited data and computational resources. Although the MoE-Transformer addresses challenges of generalization gaps and sharp minima, demonstrating some limitations for efficient and accurate clinical text classification, this model still represents a significant advancement in the field. It is particularly valuable for classifying small French clinical narratives within the privacy and constraints of hospital-based computational resources. Clinical and Translational Impact Statement—This study highlights the potential of customized MoE-Transformers in enhancing clinical text classification, particularly for small-scale datasets like French clinical narratives. The MoE-Transformer's ability to outperform several pre-trained BERT models marks a stride in applying NLP techniques to clinical data and integrating into a Clinical Decision Support System in a Pediatric Intensive Care Unit. The study underscores the importance of model selection and customization in achieving optimal performance for specific clinical applications, especially with limited data availability and within the constraints of hospital-based computational resources},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/JTEHM.2025.3576570 },
  chapter={0}
}

@article{rayyan-352345643,
  title={ Converter Embedded Testing of Inter-Laminar Core Insulation of Step-Up Transformers for Wind Energy Applications  -  IEEE Transactions on Power Delivery },
  year={2025},
  author={Battulga, B. and Shaikh, M. F. and Osama, M. and Lee, S. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10729648 },
  abstract={Transformers used in wind power applications for stepping up the low voltage output of wind generators are known to have high failure rate due to the harsh operating conditions and environment. It is a challenge to perform on-site tests regularly because wind turbines are difficult to access due to their remote location. This makes remote and automated condition assessment of wind turbine transformers (WTT) crucial for preventing failure. In this paper, the feasibility of a new off-line method for testing the quality of the inter-laminar insulation of the step-up transformer core using the back-to-back converter is evaluated. The idea is to use the converter available in the wind turbine as the test equipment for injecting test signals into the WTT for remote and automated testing, whenever the wind turbine is disconnected from the grid. It is shown that inter-laminar core faults can be clearly detected with sensitivity comparable to the core loss test and commercial FRA equipment. An experimental study was performed on a 380/690 V transformer under emulated inter-laminar insulation fault conditions to verify the new test concept. It is shown that the proposed method can provide remote, automated testing of WTTs for reliable detection of core faults.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2024.3485090 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345644,
  title={ Power Transformers Insulation Faults Identification With DGA: A Molecular Dynamics-Assisted Method  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2024},
  author={Zhou, N. and Luo, L. and Sheng, G. and Jiang, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10643596 },
  abstract={The accurate and effective identification of power transformer insulation fault is critical in implementing corrective actions and preventing problem reoccurrence. While the dissolved gas analysis (DGA) forms the basis for fault identification, certain challenges still remain, including the absence of clear theoretical principles, conflict results, and the oversight of multiple faults. This article addresses these issues by employing molecular dynamics (MD) simulations to investigate the decomposition of mineral oil under various insulation fault conditions. Identification is eventually achieved by a clustering-based method with MD results as initial centers. To achieve this, the molecular model of transformer mineral oil is first constructed, and its decomposition mechanism and results are studied under different insulation fault conditions. Afterward, based on the MD results, certain ratios between the decomposed gases are selected and calculated, which are utilized as the initial centers of the clustering. Finally, the fault identification can be achieved by substituting the DGA data into the established clustering classifier. The proposed method is tested with both the IEC TC 10 database and the local DGA dataset. The results show a respective 83.4% and 89% success rate in identifying single or multiple faults, verifying the effectiveness of the proposed method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2024.3447616 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345645,
  title={ An Opportunity Cost Based Replacement Strategy for Transformers  -  2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2) },
  year={2021},
  author={Hu, J. and Xu, Y. and Wen, F. and Huang, G. and Chen, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713438 },
  abstract={Accurately evaluating the economic life of a transformer not only plays an important role in appropriately scheduling its secure and economic operation, but also provides the basis for determining its replacement strategy. Considering the characteristics of the transformer failure rate in its life cycle, the Arrhenius-Weibull model which is widely employed for describing the transformer temperature aging failure is first presented to model the loss failure stage in the failure rate bathtub curve. A transformer age reduction factor is next introduced to characterize the effect of transformer maintenance. Then, the opportunity costs are calculated through comprehensively considering the economic factors of the transformer maintenance and replacement. Finally, the opportunity costs of the transformer maintenance and replacement are used as the criteria for determining the optimal replacement timing of the concerned transformer. A sample example is served for demonstrating the essential features of the presented method.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EI252483.2021.9713438 },
  booktitle={ 2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2) },
  chapter={0}
}

@article{rayyan-352345646,
  title={ Vision Transformer Reliability Evaluation on the Coral Edge TPU  -  IEEE Transactions on Nuclear Science },
  year={2025},
  author={Coelho, B. Loureiro and Bodmann, P. Rafael and Cavagnero, N. and Frost, C. and Rech, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786384 },
  abstract={Vision transformers (ViTs) outperform convolutional neural networks (CNNs) in tasks such as image classification, and, despite their high computational complexity, they can still be mapped to low-power EdgeAI accelerators, such as the Coral tensor processing unit (TPU). In this article, through accelerated neutron beam experiments, we study the reliability of six ViTs on the Coral TPU and four microbenchmarks. According to our data, the internal size of attention heads (the main computational block in ViTs) has negligible impact on the failure-in-time (FIT) rate of the model compared to increasing the number of heads in the model; furthermore, our results show that employing convolutions in the patch embedding reduces the FIT rate of the model. Additionally, we decompose ViTs into four basic computational blocks that represent the main operators of the model, showing that, although the transformer layer [with multihead self-attention and multilayer perceptron (MLP)] presents the highest FIT rate, it is actually the patch embedding that is more likely to cause misclassifications. These results can be leveraged to design hardening techniques that improve the resilience of the critical blocks of a ViT, identified in our evaluation while minimizing the additional overhead.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TNS.2024.3513774 },
  booktitle={ IEEE Transactions on Nuclear Science },
  chapter={0}
}

@article{rayyan-352345647,
  title={ TI-Former: End-to-End Useful Life Prediction Model Based on Transformer-Informer  -  2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS) },
  year={2024},
  author={Hangjun, W. and Zhao, L. and Zhang, N. and Gang, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10606610 },
  abstract={In recent years, the advent of Transformer and Informer models has catalyzed a paradigm shift in the domain of Remaining Useful Life (RUL) prediction, showcasing unparalleled predictive proficiency. However, despite their prowess, each model is encumbered with intrinsic limitations. To mitigate these deficiencies, the present study introduces the Transformer-Informer (TI-former), an innovative end-to-end methodology for the prediction of Remaining Useful Life (RUL). The TI-former ingeniously amalgamates the Transformer's exemplary global feature extraction capabilities with the Informer's adeptness in modeling long-range dependencies. This potent synergy aims to equal or surpass the RUL prediction accuracy of the CNN-Informer, while necessitating reduced computational resources, thereby rendering the TI-former more accessible to researchers and practitioners with limited computational infrastructure. Rigorous empirical assessment on two authentic datasets substantiates that the TI-former outperforms, manifesting marginal superiority over the CNN-Informer in accuracy metrics, and a marked improvement in computational efficiency and GPU resource utilization.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DDCLS61622.2024.10606610 },
  booktitle={ 2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS) },
  chapter={0}
}

@article{rayyan-352345648,
  title={ Research on the Influence of Temperature Rise on Partial Discharge and Lifespan of Insulation of Medium Frequency Transformer  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2025},
  author={Zheng, C. and Wang, P. and Ma, S. and Liu, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11173698 },
  abstract={Medium frequency transformer would face transient overvoltage in the winding brought by fast rising edge of the PWM working voltage, which may cause partial discharge in the winding insulation structure. With temperature rise that is a common phenomenon for medium frequency transformer, this risk of partial discharge generation can even be greater. Changing of temperature also has impact on the partial discharge features and lead to different insulation endurance behavior. In this paper, a test system based on pulse voltage generator is built. By using this system, partial discharge inception voltage, partial discharge features and endurance lifetime experiments are conducted on a kind of medium frequency transformer’s insulation structure under different temperatures. The results show that with temperature rise, partial discharge is easier to be triggered, partial discharge intensity becomes stronger, partial discharge number grows, endurance lifetime reduces and the discharge eroded area becomes larger. Mechanisms of these results are discussed in details and some methods for improving the medium frequency transformer’s long term insulation reliability are suggested.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2025.3611925 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345649,
  title={ Methodological Proposal to Determine the Mobile Reserve of Power Transformers Considering Risks and Uncertainties  -  2022 5th Asia Conference on Energy and Electrical Engineering (ACEEE) },
  year={2022},
  author={Quintana, R. and Quispe, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851833 },
  abstract={In this article, it's proposed to analyze and present an alternative that allows to determine the transformation reserve in the electric transmission, through a methodology based on the Poisson distribution associated with the economic justification criterion; proposing it as a proposal to be applied in the planning processes of the expansion of the sub-transmission. One of the key issues in planning the expansion of the transmission system, is reliability and safety, which has recently been included in the regulation of transmission in Peru; Risk assessment is an effective instrument to help the decision process for the management of power transformers. There are few practical methodologies for evaluating spare transformers. In addition, such proposals do not necessarily take into account the costs that represent the system, either by under-sizing or over-sizing the reserve. According to the above, it is necessary to establish a methodology to balance the cost that would represent to make investments for the acquisition of the reserve transformers, and the benefits that would provide the reliability of the system against such purchases. Consequently, a methodology is proposed to determine the reserve of power transformers, considering risks and uncertainties, this proposal could contribute to the development of the planning of the expansion of the sub transmission in Peru.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACEEE56193.2022.9851833 },
  booktitle={ 2022 5th Asia Conference on Energy and Electrical Engineering (ACEEE) },
  chapter={0}
}

@article{rayyan-352345650,
  title={ A Practical Methodology for Determining the Retrofit Prioritization of Aged GSU Transformers  -  2025 International Conference of Clean Energy and Electrical Engineering (ICCEEE) },
  year={2025},
  author={Huang, W. and Li, J. and Zhou, Y. and Chen, L. and Xiang, J. and Jiang, Z. and Wang, X. and Zhang, Q. and Xiang, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11156212 },
  abstract={Generator Step-Up (GSU) transformers are critical equipment in composite generation and transmission systems, yet they are prone to aging failures due to long-term exposure to multiple stress factors. Therefore, the reasonable prioritization ranking of these aged GSU transformers is essential for timely and cost-effective retrofitting to ensure system reliability. In light of this issue, this paper presents a practical methodology that considers both the transformers’ contributions to system risk and their structural vulnerability when determining the retrofit prioritization of aged GSU transformers. First, the analytical formula for the unavailability of transformer aging failures is derived for system risk evaluation. Proportional sharing theory is then applied to calculate the allocated risk value for each GSU transformer, characterizing its contribution to system risk. Subsequently, the electrical betweenness of each transformer branch is calculated to represent its structural vulnerability within the system topology. On this basis, the fuzzy entropy weight (FEW) algorithm is employed to calculate the weights for both the system risk contribution index and the structural vulnerability index, establishing a comprehensive index that can be used to rank the retrofit prioritization of aged GSU transformers. Case studies are conducted on the IEEE RTS-79 system to illustrate and validate the effectiveness and practicality of the proposed retrofit prioritization ranking methodology.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCEEE63357.2025.11156212 },
  booktitle={ 2025 International Conference of Clean Energy and Electrical Engineering (ICCEEE) },
  chapter={0}
}

@article{rayyan-352345651,
  title={ Root Cause Analysis and Prevention of Unnecessary Outage for an Abnormally Noisy 220MVA 400kV Power Transformer using Comprehensive Condition Monitoring Framework  -  2022 International Conference on Electrical Machines (ICEM) },
  year={2022},
  author={Mani, S. and Asadi, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910843 },
  abstract={Being extremely critical components of power grids, power transformers' considerable capital cost, long and expensive repairs and more importantly, tremendous network outages and stoppages of production plants upon their probable failures highlight the importance of their condition monitoring and fault diagnosis programs. While it is important to prevent transformers from failures and to shut them down immediately in case of serious threats, their prominent role in the grid and hence in production plants necessitates minimization of unnecessary outages and shutdowns; from both technical and economical perspectives. This paper investigates an actual case study of a 220MVA 400kV power transformer with an abnormal nonstandard sound noise and elaborately decides whether to shut it down immediately in a very critical production condition. Visual inspections, dissolved gas analysis, frequency response analysis, thermal imaging together with the novel less frequently used transformer vibration and sound measurements are utilized in this comprehensive analysis.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEM51905.2022.9910843 },
  booktitle={ 2022 International Conference on Electrical Machines (ICEM) },
  chapter={0}
}

@article{rayyan-352345652,
  title={ Case studies of lightning related injuries and property damage in Zambia  -  2012 International Conference on Lightning Protection (ICLP) },
  year={2012},
  author={Lubasi, F. Chileshe and Gomes, C. and Kadir, M. Z. A. A. and Cooper, M. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6344242 },
  abstract={This is the first investigation and analysis of lightning related incidents in Zambia. Two case studies on both human injuries and equipment damage at five sites are reported. Lightning injuries were mostly attributed to the lack of proper structural protection systems, although lack of awareness among the public may also contribute to the situation. Many injury mechanisms, including unsuccessful upward streamers, may cause injuries. Design of lightning protection schemes should take social structures and affordability by the affected public into account. Losses in the power sector are excessively high in the region and seriously affect the operation of both business and domestic life. Replacement cost incurred by the power companies can be prohibitive. Lightning density and pattern in the localized areas, grounding systems of the installations, and specification and installation techniques of lightning arresters should be revisited in giving proper solutions to transformer and power line failures.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICLP.2012.6344242 },
  booktitle={ 2012 International Conference on Lightning Protection (ICLP) },
  chapter={0}
}

@article{rayyan-352345653,
  title={ Electrical breakdown properties of oil-paper insulation under AC-DC combined voltages  -  2010 IEEE International Power Modulator and High Voltage Conference },
  year={2010},
  author={Wang, Y. and Li, J. and Wang, Y. and Grzybowski, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5958308 },
  abstract={Oil-impregnated paper is a major type of insulation in oil-filled power transformers. In converter transformers, windings connected with converter valves have to withstand AC and DC combined voltages. This paper presented the experimental research on electrical breakdown properties of oil paper insulation under AC-DC combined voltages. Electrical breakdown strength of oil-paper insulation specimens was measured through short-time tests under AC, DC, and AC-DC combined voltages. The combined voltages consisted of two different ratios of the AC to DC voltages. Through the constant stress tests, the times-to-breakdown of oil-paper specimens were measured. Weibull parameters of the times-to-breakdown of specimens were estimated and the inverse power and exponential failure models of the specimens were presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IPMHVC.2010.5958308 },
  booktitle={ 2010 IEEE International Power Modulator and High Voltage Conference },
  chapter={0}
}

@article{rayyan-352345654,
  title={ Improvement of power quality and reliability in the distribution system of petrochemical plants using active power filters  -  2018 IEEE International Conference on Industrial Technology (ICIT) },
  year={2018},
  author={Kamala, S. and Reddy, B. D. and Sen, B. and Panda, S. K. and Amaratunga, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352214 },
  abstract={Variable speed drives (VSDs) are used extensively for pumping/compressor operations in petrochemical plants of the Jurong Island in Singapore. The VSDs draws harmonic current from the mains which causes power quality issues in the system. Passive harmonic mitigation techniques, 12-pulse/24-pulse transformers are being used in the petrochemical plant to minimize the voltage/current harmonics because of their lower cost and higher reliability, but these methods are less efficient. This paper investigates the power quality and reliability improvement in the petrochemical plants by using active power filters (APFs). The study has been conducted in the petrochemical plant distribution system by connecting an active front end (AFE) converter and shunt active power filter (SAF) with the 6-pulse drive system in place of conventional 12-pulse rectifier-drive system. Simulation were carried out in MATLAB/Simulink environment for 1 MW drive system with 12-pulse rectifier, 6-pulse rectifier with the SAF and the system with AFE. Subsequently, reliability assessment has been carried out for the three test systems under study in DIgSILENT Power Factory simulation software. Harmonic mitigation methodologies are verified through a down scale experimental laboratory setup of 7.5 kW motor drive system to check the effectiveness active harmonic mitigation methodologies.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICIT.2018.8352214 },
  booktitle={ 2018 IEEE International Conference on Industrial Technology (ICIT) },
  chapter={0}
}

@article{rayyan-352345655,
  title={ Fuzzy dynamic model of power equipment state assessment  -  2016 IEEE NW Russia Young Researchers in Electrical and Electronic Engineering Conference (EIConRusNW) },
  year={2016},
  author={Dmitriev, S. A. and Khalyasmaa, A. I. and Doroshenko, V. O. and Romanov, A. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448242 },
  abstract={There is a strong growths of equipment fleet with expired specified standard service life in Russia. Substations equipment repair is necessary for no-break power supply to consumers. Optimal selection of equipment to be removed out of service leads to the whole power supply system reliability improvement. Equipment state assessment is an important task for determination of elements which fail to meet technical criteria necessary for power system successful operation with the purpose of reliable power supply to consumers. Transformer state assessment model development based on nondestructive testing data available at the moment is the objective of the present work. Developed model verification was performed on the base of data obtained during inspection of equipment being in operation. State assessment of TRDCN-63000/110 type power transformer installed at 110 kV substation located in the Sverdlovsk Region was performed in the context of the present paper. The results analysis was carried out and assessment model adequacy was confirmed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EIConRusNW.2016.7448242 },
  booktitle={ 2016 IEEE NW Russia Young Researchers in Electrical and Electronic Engineering Conference (EIConRusNW) },
  chapter={0}
}

@article{rayyan-352345656,
  title={ Improving the Factual Accuracy of Abstractive Clinical Text Summarization using Multi-Objective Optimization  -  2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC) },
  year={2022},
  author={Alambo, A. and Banerjee, T. and Thirunarayan, K. and Cajita, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871798 },
  abstract={While there has been recent progress in abstractive summarization as applied to different domains including news articles, scientific articles, and blog posts, the application of these techniques to clinical text summarization has been limited. This is primarily due to the lack of large-scale training data and the messy/unstructured nature of clinical notes as opposed to other domains where massive training data come in structured or semi -structured form. Further, one of the least explored and critical components of clinical text summarization is factual accuracy of clinical summaries. This is specifically crucial in the healthcare domain, cardiology in particular, where an accurate summary generation that preserves the facts in the source notes is critical to the well-being of a patient. In this study, we propose a framework for improving the factual accuracy of abstractive summarization of clinical text using knowledge-guided multi-objective optimization. We propose to jointly optimize three cost functions in our proposed architecture during training: generative loss, entity loss and knowledge loss and evaluate the proposed architecture on 1) clinical notes of patients with heart failure (HF), which we collect for this study; and 2) two benchmark datasets, Indiana University Chest X-ray collection (IU X-Ray), and MIMIC-CXR, that are publicly available. We experiment with three transformer encoder-decoder architectures and demonstrate that optimizing different loss functions leads to improved performance in terms of entity-level factual accuracy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EMBC48229.2022.9871798 },
  booktitle={ 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC) },
  chapter={0}
}

@article{rayyan-352345657,
  title={ Bubble Formation from Non-Thermally Upgraded Kraft Paper in Alternative Insulating Liquids  -  2023 IEEE 22nd International Conference on Dielectric Liquids (ICDL) },
  year={2023},
  author={Pößniker, C. and Matharage, S. and Wang, Z. and Walker, D. and Hilker, A. and Gyore, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10209292 },
  abstract={Bubble formation in transformers could lead to their failure, resulting in severe outages in the electricity network. Hence, understanding the parameters that impact the bubble formation process is crucial to maintain the transformer’s dependable operation. Commonly, mineral oil and non-thermally upgraded Kraft paper have been used as the insulating materials for power transformers, and the risk of bubble formation has been studied for this material combination. However, new insulating liquids such as esters and gas-to-liquid technology-based oils are recently gaining more popularity and studies on bubble formation for these alternative liquids are limited. In this paper, the impact of alternative liquids on bubble formation has been investigated by using a small-scale test tube-based system. Studies have shown that when considering the water content in the paper at the time of bubble formation, the bubble formation temperature is comparable across different liquid types.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICDL59152.2023.10209292 },
  booktitle={ 2023 IEEE 22nd International Conference on Dielectric Liquids (ICDL) },
  chapter={0}
}

@article{rayyan-352345658,
  title={ Study on the interfacial properties at the OTS treated SiO2 film  -  2008 International Conference on Condition Monitoring and Diagnosis },
  year={2008},
  author={Oh, Teresa and Kim, Jong Wook},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4580280 },
  abstract={n-octadecyltrichlorosilane treated the SiO2 film was prepared by the mixed solution of chloroform and hexane. The leakage current decreased by the treatment of organic diluted solutions, but the leakage current of samples with various ratios was in proportion to increase the content of n-octadecyltrichlorosilane. The FTIR spectra of SiO2 film showed the various wave forms below 800 cm-1, and the FTIR spectra of 720 and 745 cm-1 did not disappear after organic treatment. The FTIR spectra below 800 cm-1 became weak according to the increase of the content of of n-octadecyltrichlorosilane. The FTIR spectra below 800 cm-1 between samples 6 and 7 varied abruptly and the sample 6 showed the lowest leakage current.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CMD.2008.4580280 },
  booktitle={ 2008 International Conference on Condition Monitoring and Diagnosis },
  chapter={0}
}

@article{rayyan-352345659,
  title={ Mitigation of power supply disturbance in electronic loads  -  2011 International Conference on Energy, Automation and Signal },
  year={2011},
  author={Basu, K. P. and Nor, N. M. and Hafidz, S. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6147127 },
  abstract={An alternate power supply guarantees the performance of loads during voltage disturbances in the normal supply. It is proposed to implement a quick change over of the power supply of single-phase electronic loads from the faulty phase to a healthy phase in a 3-phase system. Supercapacitors maintain the dc voltage during the period of disturbance. A zigzag transformer may also be used to rebuild a balanced 3-phase load voltage by isolating the faulty phase from the load. Both the 3-phase and single-phase loads may be supplied with the rated voltage during the period of disturbance. Use of a static transfer switch reduces the change over time to 0.02 second.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICEAS.2011.6147127 },
  booktitle={ 2011 International Conference on Energy, Automation and Signal },
  chapter={0}
}

@article{rayyan-352345660,
  title={ Feasibility Study on Condition Monitoring of Power Network Asset Using PMU Measurements  -  2022 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia) },
  year={2022},
  author={Bai, F. and Cui, Y. and Zhang, G. and Dart, D. and Yaghoobi, J. and Zillmann, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9949946 },
  abstract={Current asset management for distribution networks has adopted a passive strategy - either run to failure or perform field inspection of limited assets within a fixed period. This paper aims to study the feasibility of using high-resolution data recorded by phasor measurement units (PMUs) for real-time asset monitoring. Accelerated ageing experiment on a laboratory transformer and the insulator pollution experiment have been performed. The PMU measurements collected from both experiments are used to evaluate the asset health conditions by examing the standard deviation of the signal to noise ratio (SNR) after the statistical analysis and noise segregation of the original PMU measurements. A comparative study between the traditional condition assessment method and the proposed method demonstrates the feasibility of using the PMU data to evaluate the asset health conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPSAsia55496.2022.9949946 },
  booktitle={ 2022 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia) },
  chapter={0}
}

@article{rayyan-352345661,
  title={ Inventory management for high voltage equipment using statistical distribution techniques  -  2012 9th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology },
  year={2012},
  author={Suwanasri, T. and Suwanasri, C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6254241 },
  abstract={To minimize maintenance cost, the optimum number of items kept in stock needs primary concern, especially high voltage equipment in electrical system. This paper proposes the method to optimize number of spare parts for effective inventory control. By using Pareto analysis, components of power transformer in the stock are classified into ABC classes. Class A means the few most expensive ones that need special care. Class B means ordinary ones that need standard care. Class C means the large number of cheap items that need little care. Since class A items occupy most of the total inventory cost, the optimum number of class A items, which are bushing and arrester, is of prime interest and can be determined from the failure records of power transformer's components by applying statistical distribution techniques. Therefore, the proposed method can effectively reduce the total inventory cost and can also apply with the other high voltage equipment in the system.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECTICon.2012.6254241 },
  booktitle={ 2012 9th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology },
  chapter={0}
}

@article{rayyan-352345662,
  title={ Combined heat and power plant electrical equipment incident rate and unavailability empirical expression  -  2019 IEEE 7th IEEE Workshop on Advances in Information, Electronic and Electrical Engineering (AIEEE) },
  year={2019},
  author={Oļekšijs, R. and Olekshii, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8976989 },
  abstract={This paper presents approach to estimate combined heat and power plant main electrical equipment incident rate and unavailability time basing on statistical data. Empirical expressions were provided. Economical effect of unplanned incidents and unavailability is briefly discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/AIEEE48629.2019.8976989 },
  booktitle={ 2019 IEEE 7th IEEE Workshop on Advances in Information, Electronic and Electrical Engineering (AIEEE) },
  chapter={0}
}

@article{rayyan-352345663,
  title={ FERRORESONANCE MEASUREMENTS AND MODELING; A WAVEFORM IS WORTH A THOUSAND WORDS  -  2018 Petroleum and Chemical Industry Conference Europe (PCIC Europe) },
  year={2018},
  author={Mahayni, R. El and Gheeth, A. and Thomai, J. and Sudhir, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491401 },
  abstract={Over the last few decades, artificial lifting using Electrical Submersible Pumps (ESPs) became dominant in the oil and gas industry. ESP systems became essential for oil producing countries like Saudi Arabia to meet the global energy demand. Therefore, failures in such systems shall be minimized by proper upfront design. This paper describes the efforts made by the authors to address chronic failures in ESP systems. Numerous ESP transformers have failed in two of the major Saudi Aramco fields with 34.5kV networks. Power quality measurements were conducted to capture ferroresonance during single phase switching. Electromagnetic transient simulation was conducted to address similar installations without having to do the measurements at every location of concern. Mitigation solutions were recommended for existing installations as well as best design practices for new projects.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/PCICEurope.2018.8491401 },
  booktitle={ 2018 Petroleum and Chemical Industry Conference Europe (PCIC Europe) },
  chapter={0}
}

@article{rayyan-352345664,
  title={ IEEE Approved Draft Guide for Protective Relay Applications to Power System Buses  -  IEEE PC37.234/D11.1, August 2021 },
  year={2021},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9526576 },
  abstract={Principles of power bus protection are discussed. The availability and location of breakers, current sensing devices, and disconnect switches are addressed, as well as bus configurations and switching schemes and their impact on the selection and application of bus protection. Bus protection schemes are presented, and their characteristics, strengths, and limitations are examined. Bus protection applications are presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IEEE PC37.234/D11.1, August 2021 },
  chapter={0}
}

@article{rayyan-352345665,
  title={ Characteristic analysis of HVDC system with shunt capacitance commutated converter  -  2017 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  year={2017},
  author={Zhai, C. and Zhang, Z. and Luo, L. and Sun, X. and Sun, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8308902 },
  abstract={In this paper, a novel HVDC system is proposed for using Shunt Capacitance Commutated Converter (SCCC), and analysis of work and wiring method are given. The basic idea of the SCCC is connect the capacitors in parallel between the converter transformers and the converters at the valve winding. The parallel capacitor is used to compensate for the vast majority of the inductive reactive power which can be required during the operation time. It is proved that the SCCC not only has the advantages of reducing the failure chance in commutation of the inverter, but also can makes the capacity of the converter transformer be utilized fully. The 500 kV HVDC monopole operation system about Huizhou City, Guangdong Province Echeng as an example, conducted by simulation of the system software (MATLAB). Gotting the AC side voltage and current waveforms and the DC side voltage and current waveforms during the operation of the SCCC. It is shown that the SCCC can not only overcomes the inherent defects of the traditional HVDC converter, but also can optimizes the operation state of the converter transformer and the whole systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APPEEC.2017.8308902 },
  booktitle={ 2017 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  chapter={0}
}

@article{rayyan-352345666,
  title={ Study on the Analysis and Diagnosis of Dissolved Gases in Camellia Insulating Oil  -  2018 IEEE International Conference on High Voltage Engineering and Application (ICHVE) },
  year={2018},
  author={Wang, H. and Li, J. and Xiang, C. and Huang, Z. and Wang, F. and He, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642083 },
  abstract={Recently, as a kind of transformer oil with lots of outstanding characteristics such as high ignition point, reproducible, and natural degradation, vegetable insulating oil has becomes more and more popular in the oil-filled transformers. Thermal ageing as well as thermal and electrical faults, which can lead to the decomposition of insulating oil and insulating paper, will occur in operating transformers, then dissolved gases are formed and reach equilibrium in oil through diffusion process. In this paper, camellia oil as sample oil, thermal ageing as well as thermal and electrical faults simulation experiments of transformers were conducted, main characteristic gases decomposed by camellia insulating oil were obtained, and the changing rules of gas content with the changing of thermal ageing time, thermal fault temperature and discharge energy were also analyzed. Which indicated that if we increase the thermal ageing time, thermal faults temperature and discharge energy, the decomposition processes of camellia insulating oil could also be accelerated. And also the decomposition processes of camellia insulating oil and insulation paper under thermal and electrical stress were analyzed. Simulation results explained the gas production rules of thermal ageing and thermal faults as well as electrical faults of camellia insulating oil at microcosmic level. The result of above study provides theoretic support for condition assessment and operating maintenance of vegetable insulating oil-filled transformers, and also has great theoretical reference value and practical guiding significance for ensuring safe operation of vegetable insulating oil-filled transformers.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICHVE.2018.8642083 },
  booktitle={ 2018 IEEE International Conference on High Voltage Engineering and Application (ICHVE) },
  chapter={0}
}

@article{rayyan-352345667,
  title={ Investigation of a Damaged Filter-Compensation Unit  -  2020 21st International Scientific Conference on Electric Power Engineering (EPE) },
  year={2020},
  author={Nowak, S. and Kocman, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269199 },
  abstract={Nowadays, almost 50% of steel is made from steel scrap by electric heating and melting, mostly in arc furnaces. The electric arc furnace with all its equipment is often a key unit in the entire steel manufacturing process. Therefore, all electric arc furnace equipment must be designed with respect to the requirement of high reliability for long-term operation under very hard conditions in the steel mill. A very important part of the furnace installation is the device that compensates the undesirable reactive power and also reduces the voltage distortion in the supply grid. A filter-compensation unit is used for this purpose. During the operation of the filter-compensation unit in an investigated furnace installation a failure occurred, whose causes are described in this paper.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EPE51172.2020.9269199 },
  booktitle={ 2020 21st International Scientific Conference on Electric Power Engineering (EPE) },
  chapter={0}
}

@article{rayyan-352345668,
  title={ Research on the construction of substation fault diagnosis and early warning technology based on big data  -  2025 7th International Conference on Energy Systems and Electrical Power (ICESEP) },
  year={2025},
  author={Ma, J. and Mu, L. and Sun, J. and Wang, Y. and Li, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11155251 },
  abstract={With the wide application of big data technology in all walks of life, it has shown great potential in the maintenance and fault prediction of power systems, especially substation equipment. This research focuses on developing a fault prediction and maintenance strategy for substation equipment based on big data, and constructs and validates a fault prediction model by analyzing historical data sets, so as to optimize the maintenance plan of equipment. The results show that the proposed se efficiency and equipment stability, and have a positive impact on reducing operation and trategy can effectively predict potential equipment failures, significantly improve maintenancmaintenance costs.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICESEP66633.2025.11155251 },
  booktitle={ 2025 7th International Conference on Energy Systems and Electrical Power (ICESEP) },
  chapter={0}
}

@article{rayyan-352345669,
  title={ The Multi-Scenario Capacity Demands Calculation and Evaluation Method Considering the Power Supply Ability of 220kV Substation  -  2025 IEEE 12th Joint International Information Technology and Artificial Intelligence Conference (ITAIC) },
  year={2025},
  author={Liu, X. and Yue, Y. and Fan, C. and Liu, Y. and Xie, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11163107 },
  abstract={To obtain the conclusions of power grid substation capacity planning with certain universal applicability in engineering practice, based on the "N-1" security criterion of main transformers and the power supply ability of 220kV substations, the capacity demands of 220kV substations under different scenarios are analyzed and evaluated. In this paper, the substation capacity demands under normal operation mode and the N-1 failure of the maximum capacity main transformer are analyzed. Next, the substation capacity demands, capacity expansion schemes, and the improvement of power supply ability after expansion under different scenarios, such as different numbers of transformers, different transferred load quantities, and different transformer capacity combinations, are further analyzed. Then, considering the economic benefits and long-term adaptability of substation capacity expansion, comprehensive evaluation indicators are proposed. Finally, the effectiveness and adaptability of the proposed method are verified through an actual power grid.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ITAIC64559.2025.11163107 },
  booktitle={ 2025 IEEE 12th Joint International Information Technology and Artificial Intelligence Conference (ITAIC) },
  chapter={0}
}

@article{rayyan-352345670,
  title={ Working with customers to control electrical pollution national grid’s approach  -  2008 IEEE/PES Transmission and Distribution Conference and Exposition },
  year={2008},
  author={Dagher, F. and Roughan, T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4517253 },
  abstract={Momentary disturbances on the electric transmission or distribution system do impact the productivity of electric utility customers and the performance of the power distribution and transmission (T&D) system. The T&D system is exposed to unavoidable events such as: animal contact, motor vehicle accidents, tree contacts, lightning, and etc.. These unavoidable events are a major source to momentary disturbances. Computer controlled machinery and appliances are intolerant to these disturbances. In addition, the operating characteristics of some devices connected to the T&D system could generate power disturbances that negatively affect the operation of other devices on the system and inside customers' facilities. To minimize the impact of the disturbances, preventive measures need to be taken. Utilities and their customers benefit immensely in sharing with one another the measures they are taking to minimize the effect of momentary disturbances.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDC.2008.4517253 },
  booktitle={ 2008 IEEE/PES Transmission and Distribution Conference and Exposition },
  chapter={0}
}

@article{rayyan-352345671,
  title={ IEEE Draft Guide for Protective Relay Applications to Power System Buses  -  IEEE PC37.234/D11.0, July 2021 },
  year={2021},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499002 },
  abstract={Principles of power bus protection are discussed. The availability and location of breakers, current sensing devices, and disconnect switches are addressed, as well as bus configurations and switching schemes and their impact on the selection and application of bus protection. Bus protection schemes are presented, and their characteristics, strengths, and limitations are examined. Bus protection applications are presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IEEE PC37.234/D11.0, July 2021 },
  chapter={0}
}

@article{rayyan-352345672,
  title={ Analysis Report of A Phase CVT Fault in 220kV Auxiliary Section I of 500kV Substation  -  2021 6th International Conference on Integrated Circuits and Microsystems (ICICM) },
  year={2021},
  author={Bing, Y. and Zhi, Y. and Luyao, Z. and Lin, Z. and Haofan, L. and Yong, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660270 },
  abstract={An accident occurred in the substation due to a 220 kV voltage transformer failure that caused a bus differential protection alarm. This article comprehensively analyzes the cause of the failure based on the cause of the incident, the on-site test and inspection situation and the disassembly situation of the factory. The article comprehensively uses protection monitoring waveform analysis, infrared temperature measurement and field test to carry out failure mechanism analysis, and provides reference opinions for subsequent maintenance and repair of related products of the same type to improve equipment operation and maintenance level.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICICM54364.2021.9660270 },
  booktitle={ 2021 6th International Conference on Integrated Circuits and Microsystems (ICICM) },
  chapter={0}
}

@article{rayyan-352345673,
  title={ Reliability Availability and Sensitivity Analysis of a Power distribution System  -  2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  year={2024},
  author={Rizwan, S. M. and Tanavade, S. and Sachdeva, K. and Taj, S. Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10796315 },
  abstract={This paper presents a reliability and availability analysis of a power distribution system comprising transformers, aiming to obtain reliability indices that reflect the overall system's operational capabilities. It investigates causes of power unavailability, such as severe weather and electrical faults. Results demonstrate the impact of environmental conditions and electrical faults on transformer reliability, with sensitivity analysis revealing how variations in failure and repair rates affect overall system reliability. The analysis utilizes five years of data from a power distribution system. The findings offer insights for enhancing power distribution system robustness and suggest future research directions to address reliability challenges, contributing to more resilient power infrastructure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICECCME62383.2024.10796315 },
  booktitle={ 2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME) },
  chapter={0}
}

@article{rayyan-352345674,
  title={ Research on Acoustic Diagnosis Method of Wind Turbine Gearbox Fault Based on ITGAN-SVM  -  2024 7th International Conference on Mechatronics and Computer Technology Engineering (MCTE) },
  year={2024},
  author={He, S. and Zhong, W. and Zhang, J. and Jiang, R. and Ma, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11117734 },
  abstract={The wind turbine gearbox is a key part of the wind turbine transmission system. The random occurrence of its faults and the insufficient number of fault samples seriously affect the accuracy of fault diagnosis. Mechanical fault detection based on acoustic pattern has become a current research hotspot because of its high accuracy. However, the processing speed of acoustic signal analysis is slow and the fault data is difficult to obtain. Therefore, how to realize the accurate recognition of mechanical fault sound pattern in the case of small samples is the current research difficulty. In this paper, the Meier acoustic spectrogram of the acoustic signal of the wind turbine gearbox is extracted. The acoustic spectrogram is input to Improved Transformer Generative Adversarial Network (ITGAN) for sample expansion. The classifier adopts Support Vector Machine (SVM) to shorten the training time and improve the recognition speed. Compared with the traditional data generation model (SMOTE, GAN), the method proposed in this paper has significant improvement in all indicators. Experiments show that the method proposed in this paper provides a reliable solution for mechanical fault identification of wind turbine gearboxes.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MCTE62870.2024.11117734 },
  booktitle={ 2024 7th International Conference on Mechatronics and Computer Technology Engineering (MCTE) },
  chapter={0}
}

@article{rayyan-352345675,
  title={ Increasing Automotive Electrical Equipment Effectiveness with Enhanced Iron Loss Estimation Techniques  -  2023 6th International Conference on Contemporary Computing and Informatics (IC3I) },
  year={2023},
  author={Gupta, N. and Singh, A. and Saxena, N. and Ravivarman, G. and Gajendran, P. and Deshpande, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398109 },
  abstract={For improved transformer design in car uses, precise modeling of ferrous failures of flexible superconductors for a variety of frequency bands and eddy currents concentrations is essential. [1] For this reason, various empirical iron-loss models were put forth that describe the processes that cause loss. The majority of these have issues with magnetization flux concentrations and bad precision for longer wavelengths. The usual iron loss formulas and a sophisticated iron loss algorithm are compared in this article. By including a high order component for the flux density of magnetic matter, the suggested Formula addresses a problem with the widely used metal models. To determine the iron losses of an electrical machine for the driveline of a fully electric car, for example, one uses the iron-loss algorithm.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IC3I59117.2023.10398109 },
  booktitle={ 2023 6th International Conference on Contemporary Computing and Informatics (IC3I) },
  chapter={0}
}

@article{rayyan-352345676,
  title={ Evaluation Method of Alternative Benefit of Energy Storage in 220kV Substation  -  2024 IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC) },
  year={2024},
  author={Xie, Y. and Jiang, S. and Chen, J. and Lu, P. and Jiang, J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10574904 },
  abstract={The continuing increase in the penetration of renewable energy and the increase in regional power load has led to the inability of the main transformer capacity of some substations to satisfy the capacity demand brought about by renewable energy access and load growth. Two solutions are usually adopted: the capacity expansion of the substation main transformer and energy storage configuration. Based on the current main transformer capacity of the 220kV substation, the N-1 failure of the main transformer of the substation and the load rate constraints in the case of load transfer are considered and analyzed in this paper. The transferred load of the 220kV substation is calculated. Then, according to the non-transferable load, considering the power constraints of energy storage, the power constraint of energy storage as a load and the charge and discharge constraint of energy storage, whether the energy storage configuration on the grid side can satisfy the main transformer N-1 demand of 220kV substation is analyzed. Finally, the efficiency index of the replacement capacity of the main transformer capacity is proposed, and its critical value is given. The benefit of configuring energy storage and expanding a main transformer in the substation is analyzed. The effectiveness and adaptability of the proposed method are verified by a practical regional power grid.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IMCEC59810.2024.10574904 },
  booktitle={ 2024 IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC) },
  chapter={0}
}

@article{rayyan-352345678,
  title={ Interpretation of turn-to-turn insulation fault by dissolved gas analysis  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2018},
  author={Kweon, D. and Kim, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424396 },
  abstract={The purpose of dissolved gas analysis (DGA) in utilities is to help detect the presence of abnormality within transformer. When faults occur in transformers, transformer engineers need to determine the location and risk of the faults. Ultimately, they have to decide, based on DGA, whether to continue operating or not, perform internal inspection, or dispose the transformer. In this study, the fault and failure types in the transformer are suggested to determine the location and risk of the faults. In particular, turn-to-turn insulation faults are classified as degradation and breakdown. These faults are difficult to identify during internal inspection, and have a high possibility of failure. Urgent decision and action are thus required to avoid failure. In degradation of turn-to-turn insulation faults, failures may occur by generating thermal gases in paper during a long period of time. In breakdown of turn-to-turn insulation faults, thermal gases are not generated in paper, and failures are rather due to sudden breakdown of insulation. This study also presents a typical example of a turn-to-turn insulation fault. This example shows the progress of the fault from thermal to discharge, which is common phenomena in winding fault. Based on the findings of this work, transformer engineers can determine by DGA if transformers can be operated with or without internal inspection, or disposed when the fault has not been identified during internal inspection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2018.007477 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345679,
  title={ IEEE Guide for Protection System Redundancy for Power System Reliability  -  IEEE Std C37.120-2021 },
  year={2022},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726141 },
  abstract={This guide is developed to assist users in selecting the appropriate level of protection system redundancy for power system reliability based on the best industry practices. It defines protection system redundancy and examines the effect of protection system components on redundancy. Different concepts of redundancy as related to physical location, instrument transformer, relay scheme, and communication systems are discussed. Redundancy application considerations for various power system elements are presented. (An errata for this standard is available at https://standards.ieee.org/wp-content/uploads/2022/12/C37.120-2021_errata.pdf)},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEESTD.2022.9726141 },
  booktitle={ IEEE Std C37.120-2021 },
  chapter={0}
}

@article{rayyan-352345680,
  title={ IEEE Draft Standard for Protection System Redundancy for Power System Reliability  -  IEEE PC37.120/D11.0, January 2021 },
  year={2021},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9337285 },
  abstract={This guide is developed to assist users in selecting the appropriate level of protection system redundancy for power system reliability based on the best industry practices. It defines protection system redundancy and examines the effect of protection system components on redundancy. Different concepts of redundancy as related to physical location, instrument transformer, relay scheme, and communication systems are discussed. Redundancy application considerations for various power system elements are presented.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IEEE PC37.120/D11.0, January 2021 },
  chapter={0}
}

@article{rayyan-352345681,
  title={ Failures, Monitoring and New Trends of Power Transformers  -  IEEE Potentials },
  year={2011},
  author={Metwally, I. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5764361 },
  abstract={This article presents a survey on failures, monitoring, and new trends of power transformers. There are three main types of power transformers, namely, oil immersed, gas-insulated, and dry-type transformers with or without cast coil insulation system. Operating stresses of power transformers have increased due to the load growth and the increased bulk power transactions, where recent and imminent alternating current (AC) systems are rated 1,100 kV and 1,200 kV, respectively. Failures of windings, onload tap changers (OLTC), and bushings are the main defective components as they represent about 84% of the failure statistics. Online and offline diagnostic monitoring of power transformers can be used to detect faults at an early stage, prevent degeneration into catastrophic phenomena, and monitor the aging process of the insulating systems. Many of the well-known preventive maintenance techniques are discussed. New trends of power transformers have recently taken many steps forward in different dimensions, e.g., Powerformer, Dryformer and Windformer utilizing high-voltage (HV) cross-linked polyethylene (XLPE) cables, gas-insulated transformers (GIT), converter transformers rated ±800 kV, and high-temperature super conducting (HTS) transformers. The latter type represents a key technology for future power systems engineering as they offer many advantages over the others.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MPOT.2011.940233 },
  booktitle={ IEEE Potentials },
  chapter={0}
}

@article{rayyan-352345682,
  title={ Transformer Failure Due to Circuit-Breaker-Induced Switching Transients  -  IEEE Transactions on Industry Applications },
  year={2011},
  author={Shipp, D. D. and Dionise, T. J. and Lorch, V. and MacFarlane, B. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674081 },
  abstract={Switching transients associated with circuit breakers have been observed for many years. Recently, this phenomenon has been attributed to a significant number of transformer failures involving primary circuit-breaker switching. These transformer failures had common contributing factors such as the following: 1) primary vacuum or SF-6 breaker; 2) short cable or bus connection to transformer; and 3) application involving dry-type or cast-coil transformers and some liquid-filled ones. This paper will review these recent transformer failures due to primary circuit-breaker switching transients to show the severity of damage caused by the voltage surge and discuss the common contributing factors. Next, switching transient simulations in the electromagnetic transients program will give case studies which illustrate how breaker characteristics of current chopping and restrike combine with critical circuit characteristics to cause transformer failure. Design and installation considerations will be addressed, particularly the challenges of retrofitting a snubber to an existing facility with limited space. Finally, several techniques and equipment that have proven to successfully mitigate the breaker switching transients will be presented, including surge arresters, surge capacitors, snubbers, and these in combination.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2010.2101996 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345683,
  title={ Improving the IEC table for transformer failure diagnosis with knowledge extraction from neural networks  -  IEEE Transactions on Power Delivery },
  year={2005},
  author={Miranda, V. and Castro, A. R. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1514498 },
  abstract={The paper describes how mapping a neural network into a rule-based fuzzy inference system leads to knowledge extraction. This mapping makes explicit the knowledge implicitly captured by the neural network during the learning stage, by transforming it into a set of rules. By applying the method to transformer fault diagnosis using dissolved gas-in-oil analysis, one could not only develop intelligent diagnosis systems, providing better results than the application of the IEC 60599 Table, but also generate a new rule table whose application also leads to better diagnosis results.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2005.855423 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345684,
  title={ Knowledge discovery in neural networks with application to transformer failure diagnosis  -  IEEE Transactions on Power Systems },
  year={2005},
  author={Castro, A. R. G. and Miranda, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1425565 },
  abstract={The paper describes a new methodology for mapping a neural network into a rule-based fuzzy inference system. This mapping makes explicit the knowledge implicitly captured by the neural network during the learning stage, by transforming it into a set of rules. The method is applied in transformer fault diagnosis using dissolved gas-in-oil analysis. Studies on transformer failure diagnosis are reported, illustrating the good results obtained and the knowledge discovery made possible.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRS.2005.846074 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345685,
  title={ Failure analysis of EHV transformers  -  IEEE Transactions on Power Delivery },
  year={1988},
  author={Kogan, V. I. and Fleeman, J. A. and Provanzana, J. H. and Shih, C. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4306 },
  abstract={Failure activity of different samples of AEP extra high voltage (EHV) transformers is analyzed using estimations of the time-dependent failure rate. This analysis can be applied to investigation of the failure mechanism of 765 kV transformers. A novel method for the probabilistic estimation of the number of future failures is introduced. Results are compared with those of traditional computations of the number of future failures conducted using different average failure-rate approaches.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.4306 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345686,
  title={ Mitigating Transformer Loss of Life and Reducing the Hazard of Failure by the Smart EV Charging  -  IEEE Transactions on Industry Applications },
  year={2020},
  author={Soleimani, M. and Kezunovic, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064677 },
  abstract={The impact of uncoordinated charging of electrical vehicles (EVs) under high penetration on distribution transformers is studied. It was shown that EV charging may cause prolonged transformer overload condition, that may in turn result in transformer loss of life and increased hazard of failure. To mitigate the impact, a fuzzy logic-based system for determining EV charging schedule is devised. It uses four main inputs: 1) EV battery state of charge; 2) required state of charge for the next trip; 3) estimated time of EV departure; and 4) customer comfort level. The resulting output is a performance index that the distribution system operators can utilize in a decision-making tool to determine whether to delay the charging of given EV and pay the incentive to the EV owner. The data for the city of College Station, Texas, USA including temperature, price of electricity and load profile are collected from various sources to simulate different use cases. The example illustrates how the proposed EV management approach could mitigate the impact of EV charging on the transformer loss of life and hazard of failure. The main advantage of the proposed approach is the low cost due to simple design implementation. The information that needs to be sent from the consumer to the distribution system operator is minimized, which helps in maintaining costumers' privacy.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2020.2986990 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345687,
  title={ On the significance of recent EHV transformer failures involving winding resonance  -  IEEE Transactions on Power Apparatus and Systems },
  year={1975},
  author={McElroy, A. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1601570 },
  abstract={The recent failures of four EHV auto-transformer no load tap changers is interpreted. The failures were a direct and immediate consequence of transmission line faults as far as 340 miles away. The related system transient behavior is analyzed, and the transformer response to these transients is presented on a quantitative basis. It is demonstrated for these transformers that the ANSI standard dielectric surges offer an inadequate test of winding insulation remote from the line terminals where significant winding resonance is known to occur. The extent of these test limitations to other transformers is discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/T-PAS.1975.31968 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345688,
  title={ Substation distribution transformers failures and spares  -  IEEE Transactions on Power Systems },
  year={1996},
  author={Kogan, V. I. and Roeger, C. J. and Tipton, D. E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544662 },
  abstract={Electric utilities should have a sufficient number of spare transformers to backup substation distribution transformers to replace transformers that fail and require factory rebuild or replacement. To identify such a number, the statistical methodology was developed to analyze available failure data for different groups of transformer. That methodology enables the estimation of future numbers of failures with associated probabilities, recommends the proper number of spares, identifies the necessity and shows the means to shorten the transformer's replacement time.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/59.544662 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345689,
  title={ Reduction in distribution transformer failure rates and nuisance outages using improved lightning protection concepts  -  IEEE Transactions on Power Delivery },
  year={1995},
  author={Plummer, C. W. and Goedde, G. L. and Pettit, E. L. and Godbee, J. S. and Hennessey, M. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=400854 },
  abstract={This paper presents a case study of an overhead distribution feeder in a very high keraunic area. The feeder was experiencing approximately twice the number of lightning caused transformer failures per year than any other distribution feeder in the area. In an attempt to lower the outage rate and the repair costs, the lightning protection for this feeder was studied and a new protection system was installed. The first section of this paper discusses the outage history of this feeder and existing transformer overvoltage protection. It then details the steps that were taken to improve the protection so acceptable customer service could be achieved. The interruption data results for one year after the protection changes were implemented are then presented. The results from the field trial of the new lightning protection scheme exhibit a significant improvement in the feeder service reliability. The last section of this paper is a compilation of teardown data of failed distribution transformers. The analysis includes failed transformers from the study feeder, and failed transformers from the same electric utility, but not part of the feeder study. The causes of the transformer failures were tabulated. The results from the teardowns indicate that a high percentage of distribution transformers with interlaced and noninterlaced secondary windings fail from low-side voltage surges.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.400854 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345690,
  title={ An Analysis of VEPCO'S 34.5 KV Distribution Feeder Faults as Related to Through Fault Failures of Substation Transformers  -  IEEE Transactions on Power Apparatus and Systems },
  year={1978},
  author={Johnston, L. and Tweed, N. B. and Ward, D. J. and Burke, J. J.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4181631 },
  abstract={A study of Vepco's 34.5 kV distribution feeder faults was conducted by installing fault recording equipment in some of their substations. The data was analyzed on a statistical basis and provided information relating to the magnitude, frequency, duration and types of faults seen by the substation transformers. Consideration of the high number of substation transformer failures, the cumulative aging effects of short circuits and their operating experience with instantaneous reclosing brought about changes in Vepco's standard reclosing practices. These changes should reduce the number of short circuits on these transformers and thereby decrease the probability of failure.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1978.354683 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345691,
  title={ Lightning induced failures in distributed transformers  -  IEEE Transactions on Power Delivery },
  year={1988},
  author={Puri, J. L. and Abi-Samra, N. C. and Dionise, T. J. and Smith, D. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=193985 },
  abstract={The findings of other investigators of transformer and distribution system response to lightning strokes are briefly reviewed and discussed. Digital studies performed to evaluate the effects of system and transformer parameters on service entrance phase-to-neutral voltage and on transformer currents due to lightning strokes are discussed. The effects of pertinent parameters are illustrated with curves. The results of full-scale tests confirming the digital simulations are presented. Based on this analysis, an approach for evaluating the impact of various low-voltage winding configurations on lightning-induced failures in distribution transformers is proposed.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.193985 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345692,
  title={ Susceptibility of Distribution Transformers to Low-Voltage Side Lightning Surge Failure  -  IEEE Transactions on Power Apparatus and Systems },
  year={1982},
  author={McMillen, C. J. and Schoendube, C. W. and Caverly, D. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4111762 },
  abstract={The susceptibility of common designs of single-phase overhead distribution transformers to failure caused by lightning current surges entering the transformer via the normally unprotected low-voltage terminals has been investigated. Evidence from examination of transformers that have failed in service, transient analysis measurements of scaled surges applied to the high-and low-voltage windings, and a full-scale current surge impulse test, indicate that the shell-type designs ut'ilizing a non-interlaced 120/ 240-volt rating are most susceptible to failure. Shell-type and core-type designs with interlaced low-voltage windings are least susceptible. Susceptibility is inversely related to kVA rating, or more specifically, to the volts per turn employed by the designer. With the increasing trend to lower core loss transformers, reducing the volts per turn will increase this hazard on noninterlaced windings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1982.317573 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345693,
  title={ Short-Time Failure Mode Considerations Associated With Power Transformer Overloading  -  IEEE Transactions on Power Apparatus and Systems },
  year={1980},
  author={j. McNutt, W. and Kaufmann, G. H. and Vitols, A. P. and MacDonald, J. D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4113915 },
  abstract={Model structures representative of power transformer conductors and metallic components have been tested at elevated hot-spot temperatures to simulate operation at overloads. Three different types of cellulosic insulation in contact with hot-spots evolved visible gas bubbles at temperatures as low as 140°C, while hot metal in contact with oil alone produced no visible gas bubbles up to approximately 350°C. The dielectric strength of insulated conductors was observed to deteriorate moderately at temperatures in the 100°C to 150 °C range, but more rapidly at temperatures above 150°C. The experimental results have been analyzed and are discussed with relation to their potential significance to transformer loading practices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPAS.1980.319749 },
  booktitle={ IEEE Transactions on Power Apparatus and Systems },
  chapter={0}
}

@article{rayyan-352345694,
  title={ A Case Study of Voltage Transformer Failures: Solution Implementation in a Modern Data Center  -  IEEE Industry Applications Magazine },
  year={2018},
  author={Mellik, T. A. and Dionise, T. J. and Yanniello, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8026030 },
  abstract={While preparing a modern data center for startup, the commissioning process involved primary circuit switching that resulted in two voltage transformer (VT) failures. As a result, we conducted a comprehensive investigation of the VT failures. As the investigation proceeded, VT ferroresonance on circuit opening and high-frequency switching transients on closing emerged as possible root causes of the failures. After incorporating extensive transient simulations and three rounds of field transient measurements, we designed and implemented a complete solution that included the sizing of snubbers to overcome excessive switching transients and the development of a saturable reactor to protect VTs against the effects of ferroresonance. This article describes the root causes, simulations, field measurements, recommended solutions, and solution implementation for this event. The correlation between field measurements and simulation results shows the effectiveness of modeling the implemented solutions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/MIAS.2016.2600682 },
  booktitle={ IEEE Industry Applications Magazine },
  chapter={0}
}

@article{rayyan-352345695,
  title={ Experience with Transformer Impulse Failure Detection Methods  -  Transactions of the American Institute of Electrical Engineers },
  year={1948},
  author={Aicher, L. C.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5059868 },
  abstract={nan},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/T-AIEE.1948.5059868 },
  booktitle={ Transactions of the American Institute of Electrical Engineers },
  chapter={0}
}

@article{rayyan-352345696,
  title={ Continuous, online monitoring of freestanding, oil-filled current transformers to predict imminent failure  -  IEEE Transactions on Power Delivery },
  year={1988},
  author={Cummings, H. B. and Boyle, J. R. and Arp, B. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=193984 },
  abstract={A power-factor-monitoring scheme used successfully to predict catastrophic failures of current transformers on the Tennessee Valley Authority's system is discussed. The method permits removal of the equipment from service before a failure occurs. Other monitoring and relaying schemes have also been evaluated, and the results are compared.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.193984 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345697,
  title={ Experimental investigation of internal short circuit faults leading to advanced incipient behavior and failure of a distribution transformer  -  IEEE PES Power Systems Conference and Exposition, 2004. },
  year={2004},
  author={Butler-Purry, K. L. and Bagriyanik, M. and Mousavi, M. J. and Palmer-Buckle, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1397483 },
  abstract={Transformer fault detection and diagnosis is becoming more important due to the restructuring of the electric power industry. In this era of deregulation, loading transformers to their optimum capacity is becoming normal practice, which in turn applies high stresses on the insulation of the transformers and increases the probability of occurrence of internal short circuit winding faults. Such faults can lead to catastrophic failure and hence cause outages. Utilities and other entities in the electric power business are therefore exploring ways of detecting these faults in transformers in the incipient stage. Terminal values, primary and secondary currents and voltages of the transformer convey information that can be used to detect internal transformer failures before developing a detection method. The behavior of these terminal values should be understood. In an effort to characterize the behavior of the terminal values of a transformer during internal short circuit and incipient faults, short circuit faults were staged on a 25 kVA, 7200 V/240 V/120 V two winding custom-built transformer. This paper discusses the results of the field experiments performed over a 19-month period. It presents time domain results of selected short circuit experiments. It also presents recordings of advance incipient-like behavior during the last set of experiments.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PSCE.2004.1397483 },
  booktitle={ IEEE PES Power Systems Conference and Exposition, 2004. },
  chapter={0}
}

@article{rayyan-352345698,
  title={ Transformer failure prediction using Bayesian analysis  -  IEEE Transactions on Power Systems },
  year={1990},
  author={Gulachenski, E. M. and Besuner, P. M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=99387 },
  abstract={A procedure is described for predicting transformer failures in order to quantify the expected impacts on service reliability. The procedure is designed to get the most out of sparse data by formal incorporation of engineering experience. The method is particularly well adapted to failure frequency forecasts and outage predictions for large, expensive apparatus for which accelerated life testing is not appropriate and for which historical failure data is limited because of an inherent low failure rate. The procedure makes use of a systematic method for combining only the most credible features of engineering models with real-world experience and has been referred to as both calibrated engineering analysis and combined analysis (CA). Bayesian methods are utilized to formalize the statistical aspects of CA. An application example is presented which demonstrates how the procedure was used to predict the economics of adding redundant transformer capacity at 20 single-transformer substations for the purpose of improving service availability.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/59.99387 },
  booktitle={ IEEE Transactions on Power Systems },
  chapter={0}
}

@article{rayyan-352345699,
  title={ Analysis of a generator step-up transformer failure following faulty synchronization  -  IEEE Transactions on Power Delivery },
  year={1988},
  author={Pasternack, B. M. and Provanzana, J. H. and Wagenar, L. B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=193886 },
  abstract={An analysis was carried out to investigate an out-of-phase synchronizing condition which resulted in the failure of a 725 MVA GSU (generator step-up) transformer. Using a technique described, the circuit breaker closing angle was estimated from oscillograph traces. This information was used with the Electromagnetic Transients Program (EMTP) to simulate the disturbance events and thereby produce a complete set of probable synchronizing currents and generator electrical torques experienced during the disturbance. The analysis of the simulation results, and the analysis of the failure of the GSU transformer have been viewed in light of the large number of prior system faults in the vicinity of the transformer. A review of the ANSI/IEEE standards on transformer fault withstand capabilities as related to this type of analysis is presented.<>},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/61.193886 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345700,
  title={ Transformer failure due to circuit breaker induced switching transients  -  2011 IEEE Industrial and Commercial Power Systems Technical Conference },
  year={2011},
  author={Shipp, D. D. and Dionise, T. J. and Lorch, V. and MacFarlane, B. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5890893 },
  abstract={Switching transients associated with circuit breakers have been observed for many years. Recently this phenomenon has been attributed to a significant number of transformer failures involving primary circuit breaker switching. These transformer failures had common contributing factors such as 1) primary vacuum or SF-6 breaker, 2) short cable or bus connection to transformer, and 3) application involving dry-type or cast coil transformers and some liquid filled. This paper will review these recent transformer failures due to primary circuit breaker switching transients to show the severity of damage caused by the voltage surge and discuss the common contributing factors. Next, switching transient simulations in the electromagnetic transients program (EMTP) will give case studies which illustrate how breaker characteristics of current chopping and re-strike combine with critical circuit characteristics to cause transformer failure. Design and installation considerations will be addressed, especially the challenges of retrofitting a snubber to an existing facility with limited space. Finally, several techniques and equipment that have proven to successfully mitigate the breaker switching transients will be presented including surge arresters, surge capacitors, snubbers and these in combination.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2011.5890893 },
  booktitle={ 2011 IEEE Industrial and Commercial Power Systems Technical Conference },
  chapter={0}
}

@article{rayyan-352345701,
  title={ A new on-line method based on leakage flux analysis for the early detection and location of insulating failures in power transformers  -  4th IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives, 2003. SDEMPED 2003. },
  year={2003},
  author={Cabanas, M. F. and Melero, M. G. and Glez, F. Pedrayes and Orcajo, G. A. and Cano, J. M. and Rojas, C. H.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1234563 },
  abstract={Power transformers are among the most expensive pieces of equipment used in electrical systems. For this reason, major research effort has focused on detecting failures of their insulating systems prior to unexpected machine outage. Although several industrial methods exist for the on-line and off-line monitoring of power transformers, all of them are expensive and complex, and require the use of specific electronic instrumentation. For these reasons, in this paper the on-line analysis of transformer leakage flux is presented as an alternative and efficient procedure for assessing machine integrity and detecting the presence of insulating failures during their earliest stages. A 12 kVA 400 V/400 V power transformer was specifically manufactured for the study. A finite element model of the machine was designed to obtain the transient distribution of leakage flux lines in the machine's transversal section under normal operating conditions and when shorted turns are intentionally produced. Very cheap and simple sensors, based on air core coils, were built in order to measure the leakage flux of the transformer, and nondestructive tests were also applied to the machine in order to analyse voltages induced in the coils before and after the failure. The obtained results revealed the possibility of detecting very early stages of failure, as well as of locating the position of the shorted turn in the transformer windings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/DEMPED.2003.1234563 },
  booktitle={ 4th IEEE International Symposium on Diagnostics for Electric Machines, Power Electronics and Drives, 2003. SDEMPED 2003. },
  chapter={0}
}

@article{rayyan-352345703,
  title={ Transformer failure due to circuit breaker induced switching transients  -  Conference Record of 2010 Annual Pulp & Paper Industry Technical Conference },
  year={2010},
  author={Shipp, D. D. and Dionise, T. J. and Lorch, V. and MacFarlane, B. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5556501 },
  abstract={Switching transients associated with circuit breakers have been observed for many years. Recently this phenomenon has been attributed to a significant number of transformer failures involving primary circuit breaker switching. These transformer failures had common contributing factors such as 1) primary vacuum or SF-6 breaker, 2) short cable or bus connection to transformer, and 3) application involving dry-type or cast coil transformers and some liquid filled. This paper will review these recent transformer failures due to primary circuit breaker switching transients to show the severity of damage caused by the voltage surge and discuss the common contributing factors. Next, switching transient simulations in the electromagnetic transients program (EMTP) will give case studies which illustrate how breaker characteristics of current chopping and re-strike combine with critical circuit characteristics to cause transformer failure. Design and installation considerations will be addressed, especially the challenges of retrofitting a snubber to an existing facility with limited space. Finally, several techniques and equipment that have proven to successfully mitigate the breaker switching transients will be presented including surge arresters, surge capacitors, snubbers and these in combination.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PAPCON.2010.5556501 },
  booktitle={ Conference Record of 2010 Annual Pulp & Paper Industry Technical Conference },
  chapter={0}
}

@article{rayyan-352345704,
  title={ Cascading Transformer Failure Probability Model Under Geomagnetic Disturbances  -  2023 Winter Simulation Conference (WSC) },
  year={2023},
  author={Shukla, P. and Nutaro, J. and Yoginath, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10408098 },
  abstract={This paper develops a probabilistic model to assess the cascading failure of transformers in an electric power grid experiencing geomagnetic disturbances caused by a solar storm. We propose a model in which the probability of failure is a function of the intensity of the solar storm, the physical properties of the transformer, the geographical location of the transformer, and the flow of electrical power. We demonstrate the proposed model using the IEEE 14-bus system and several notional solar storms. The model quickly computes the initial and cascading failure probabilities of the transformers in the system as a first step towards quantifying the risks posed by future solar storms.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WSC60868.2023.10408098 },
  booktitle={ 2023 Winter Simulation Conference (WSC) },
  chapter={0}
}

@article{rayyan-352345705,
  title={ Transformer failure due to circuit breaker induced switching transients appplicable to the cement industry  -  2013 IEEE-IAS/PCA Cement Industry Technical Conference },
  year={2013},
  author={Shipp, D. D. and Dionise, T. J. and Lorch, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525287 },
  abstract={Switching transients associated with circuit breakers have been observed for many years. Recently this phenomenon has been attributed to a significant number of transformer failures involving primary circuit breaker switching. These transformer failures had common contributing factors such as 1) primary vacuum or SF-6 breaker, 2) short cable or bus connection to transformer, and 3) application involving dry-type or cast coil transformers and some liquid filled. This paper will review these recent transformer failures due to primary circuit breaker switching transients to show the severity of damage caused by the voltage surge and discuss the common contributing factors. Next, switching transient simulations in the electromagnetic transients program (EMTP) will give case studies which illustrate how breaker characteristics of current chopping and re-strike combine with critical circuit characteristics to cause transformer failure. Design and installation considerations will be addressed, especially the challenges of retrofitting a snubber to an existing facility with limited space. For the cement industry, situations where circuit breaker induced switching transients are likely to damage transformers will be discussed. Finally, several techniques and equipment proven to successfully mitigate the breaker switching transients will be presented including surge arresters, surge capacitors, snubbers and these in combination.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CITCON.2013.6525287 },
  booktitle={ 2013 IEEE-IAS/PCA Cement Industry Technical Conference },
  chapter={0}
}

@article{rayyan-352345706,
  title={ Design Comparison and Investigations into Thermal Failure of HF Transformers in Isolated DC-DC Converters  -  2024 IEEE International Communications Energy Conference (INTELEC) },
  year={2024},
  author={Roja, P. and Ansari, M. S. and Venkatramanan, D. and John, V.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10679044 },
  abstract={Ferrite transformer magnetics in high-frequency ap-plication space are traditionally designed to meet the desired power-handling capability through a selection process cognizant of core saturation limits and conductor ampacity, while being aware of the power loss incurred. While the electro-magnetic behavior of the device is typically treated as the key performance thrust for design verification, the thermal characteristics of the structure, especially from a dynamic standpoint and its impact on the operational performance, are seldom investigated. Recognizing this, the paper focuses on the thermal behavior of a ferrite core-based high-frequency (HF) transformer using a phase-shifted full-bridge (PSFB) converter as a use case. First, we examine two widely popular methodologies leveraged in literature for HF-transformer sizing and selection and share perspectives on their outcomes against the backdrop considered here. Next, we experimentally report a thermal failure mode that is induced by the dynamics of temperature rise rather than the quantum of temperature rise itself, which is typically unanticipated and never accounted for in the upfront design considerations. We present pertinent theoretical perspectives on the same, furnish 3D FEA simulation outcomes in ANSYS, and provide experimental results from a 1.5kW hardware setup.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/INTELEC60315.2024.10679044 },
  booktitle={ 2024 IEEE International Communications Energy Conference (INTELEC) },
  chapter={0}
}

@article{rayyan-352345707,
  title={ Failure analysis of a 1500 kVA 13.2 kV/480 volt, delta-delta transformer  -  2000 IEEE Industrial and Commercial Power Systems Technical Conference. Conference Record (Cat. No.00CH37053) },
  year={2000},
  author={Massey, G. W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=854357 },
  abstract={This paper discusses the events surrounding the catastrophic failure of a 1500 kVA, 13.2 kV/480 V, delta-delta cast-coil transformer. The transformer supplied a 480 V, three-phase, three-wire distribution switchboard serving HVAC and miscellaneous motor loads. Both utility feeders supplying the 15 kV switchboard suffered faulted operating conditions exterior to the building and were de-energized. The transformer subsequently failed after switching operations in the 15 kV switchboard supplying the transformer. The pages that follow examine the final condition of the transformer and enclosure, along with the 15 kV switchboard serving the transformer and the 480 V switchboard served by the transformer, to speculate how the transformer failed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS.2000.854357 },
  booktitle={ 2000 IEEE Industrial and Commercial Power Systems Technical Conference. Conference Record (Cat. No.00CH37053) },
  chapter={0}
}

@article{rayyan-352345708,
  title={ Performance of Edited Nearest Neighbour for Multi-Class Classification of Transformer Failure in Dissolved Gas Analysis  -  2024 5th International Conference on Computational Science & Information Management (ICoCSIM) },
  year={2024},
  author={Azmi, P. A. R. and Yusoff, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169548 },
  abstract={An imbalanced dataset happens when one class has significantly more samples than the others, which might bias classification algorithm results. Some transformer states are far more prevalent than others in dissolved gas analysis data, making it more difficult to categorise the less frequent states reliably. This research analyses the Edited Nearest Neighbours approach for identifying transformer faults based on dissolved gas measurement to overcome this issue. This study employed data from the UK's National Grid and DGALab, which included 790 transformer failure samples with six gas attributes and fault labelling. Then, several classifiers were evaluated, including XGBoost, Support Vector Machines, Convolutional Neural Networks, and Decision Trees. The Edited Nearest Neighbour and Decision Tree model outperforms other models in terms of accuracy (89.36%), recall (92.07%), and F1-score (89.25%). This technique performs well in managing the imbalance of multi-class data. Future research is to create adaptive undersampling approaches that modify based on the dataset's properties to improve classification performance. The study shows that the Edited Nearest Neighbors technique improves transformer fault classification accuracy on imbalanced datasets and highlighting its potential for robust fault detection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICoCSIM65098.2024.00047 },
  booktitle={ 2024 5th International Conference on Computational Science & Information Management (ICoCSIM) },
  chapter={0}
}

@article{rayyan-352345709,
  title={ A Novel Four-Wire Offgrid DFIG-BES Wind Microgrid for Remote Areas With Neutral Current Compensation For Reduced Transformer Failure  -  IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society },
  year={2024},
  author={Chakraborty, S. and Singh, B. and Panigrahi, B. K. and Chandra, A. and Al-Haddad, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10905944 },
  abstract={Community and residential loads connected to low voltage AC distribution networks require a neutral point connection. Neutral point forms return path for single-phase loads. Presence of neutral wire reduces effect of unbalanced loading of one phase to get reflected on other load phases. It helps during fault conditions to minimize effect of circulating current by providing low impedance path. However, in case of harmonically polluted load currents, rating of neutral conductor increases, leading to additional losses and unwanted heating effecting other components of network. Wind energy conversion systems (WECS) use transformer for connection to AC network to reduce requirement of higher rating and size of DC link capacitor. Neutral current and harmonic currents of load are processed through the transformer, which leads to additional heating of transformer ands which is detrimental for connected loads. Such conditions can lead to failure of WECS operation and damage transformer and connected sensitive loads due to flow of circulating currents. Hence, this work presents design and control of a novel four wire topology of a WECS comprising of a doubly fed induction generator (DFIG) and a battery energy storage (BES). A grid forming converter (GFC) is deployed to provide independent compensation for load neutral and harmonic currents without affecting the WECS transformer, reducing its failure and heating rate. WECS converters are controlled to improve power quality of stator current and point of common coupling (PCC) voltage as per the IEEE 519-2022 std. Simulation results present MPPT operation of WECS with neutral and harmonic compensation even during dynamic conditions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IECON55916.2024.10905944 },
  booktitle={ IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society },
  chapter={0}
}

@article{rayyan-352345712,
  title={ How Well Can Masked Language Models Spot Identifiers That Violate Naming Guidelines?  -  2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation (SCAM) },
  year={2023},
  author={Villmow, J. and Campos, V. and Petry, J. and Abbad-Andaloussi, A. and Ulges, A. and Weber, B.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356698 },
  abstract={Using meaningful identifiers in source code reduces the risk of errors, the cognitive load of developers, and speeds up the development process. Therefore, recent research has looked into an AI-based analysis of identifiers, for which large-scale language models appear to offer great potential. Based on tokens’ probabilities, such models can suggest identifiers that are likely to appear in a given context. While current research has used language models to predict the most likely identifier names, studies on assessing the quality of given identifiers are scarce. To this end, we explore adherence to identifier naming guidelines as a proxy for identifier quality and propose and evaluate two unsupervised approaches for spotting violations: First, a generative approach, which uses the probability distribution of the language model directly without fine-tuning. Second, a discriminative method, which fine-tunes the model’s encoder to discriminate between original identifiers and similar drop-in replacements suggested by a weak AI. We demonstrate that the proposed approaches can successfully detect violations of common guidelines for identifier naming. To do so, we have developed a dataset built on widely accepted identifier naming guidelines. The manually annotated dataset contains more than 6000 dense annotations of identifiers for 28 common guidelines. Using the data, we show that the generative approach achieves the best results, but that the particular masking strategy and scoring method matter substantially. Also, we demonstrate our approach to outperform other recent code transformers. In a per-guideline analysis, we highlight the potential and limitations of language models, and provide a blue-print for training and evaluating their ability to identify bad identifier names in source code. We make our dataset and models’ implementation publicly available to encourage future research on AI-based identifier quality assessment.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SCAM59687.2023.00023 },
  booktitle={ 2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation (SCAM) },
  chapter={0}
}

@article{rayyan-352345713,
  title={ A Comparative Study of Failure-Tolerant Three-phase RTRUs for More Electric Aircrafts  -  2019 IEEE Applied Power Electronics Conference and Exposition (APEC) },
  year={2019},
  author={Singh, A. and Mallik, A. and Khaligh, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8722048 },
  abstract={The increased adoption of more electric aircrafts has been spurred by the development of onboard converters with high-efficiency and high gravimetric power density. Taking the example of a modular Regulated Transformer Rectifier Unit (RTRU) using GaN switches, this paper provides a comprehensive comparison of two possible design pathways for efficient conversion with higher power density - (i) high-frequency cascaded two-stage AC-DC conversion, and (ii) single-stage AC-DC conversion at a relatively lower frequency. The detailed system modeling and design methodology for the two converter topologies are laid out. As one of the key contributions of this work, a direct comparison of the two converter concepts based on achievable volumetric and gravimetric power densities and efficiencies has been presented. Using the developed model framework, an extensive analysis is done to gain greater insight into the effect of key design parameters on efficiency and power density. As a proof-of-concept, experimental results are presented to validate the theoretical predictions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APEC.2019.8722048 },
  booktitle={ 2019 IEEE Applied Power Electronics Conference and Exposition (APEC) },
  chapter={0}
}

@article{rayyan-352345714,
  title={ A Novel Transfer Learning Approach for State-of-Health Prediction of Lithium-Ion Batteries in the Absence of Run-to-Failure Data  -  IEEE Transactions on Instrumentation and Measurement },
  year={2024},
  author={Song, L. and Gui, X. and Du, J. and Fan, Z. and Li, M. and Guo, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10648816 },
  abstract={Accurate and reliable state-of-health (SOH) prediction becomes increasingly vital to ensure the safe and reliable operation of lithium-ion batteries (LIBs). The existing data-driven methods for LIBs’ SOH prediction are developed with an ideal database, i.e., a huge run-to-failure data with a consistent distribution of training and testing sets. However, due to individual quality differences and complex operating conditions, data distribution shifts among different batteries may be obvious, and the entire life-cycle samples are difficult to collect in real world. Therefore, there exists a distribution discrepancy between source and target domains. Besides, temporal distribution shift may also exist with incomplete target domain, called time covariate shift (TCS). Thus, the model trained with source and incomplete target domains will cause prediction bias in unseen target data. To address such issues, a novel transfer learning (TL) approach using multiple feature alignment transformer (MFA-Transformer) model is conducted for the SOH prediction of LIBs. First, a multilayer feature alignment is performed via encoder-decoder structure of transformer framework, and multikernel maximum mean discrepancy (MK-MMD) is adopted to tackle data distribution discrepancy. Then, a new loss item based on Weibull distribution is utilized to enhance the data alignment effect. Moreover, a shift compensation strategy using shape-based distance (SBD) estimation is designed to dynamically eliminate the prediction bias resulting from TCS. Finally, experiments on two public LIBs datasets validate the effectiveness of the proposed method, which can offer a promising solution for industrial prognostic without entire life-cycle data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIM.2024.3450095 },
  booktitle={ IEEE Transactions on Instrumentation and Measurement },
  chapter={0}
}

@article{rayyan-352345715,
  title={ Single-Phase Ferroresonance in an Ungrounded System Causing Surge Arresters Failure during the System Energization  -  2021 IEEE/IAS 57th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  year={2021},
  author={Pordanjani, I. R. and Liang, X. and Wang, Y. and Schneider, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416609 },
  abstract={Ferroresonance often occurs in power systems during system switching actions, which can create overvoltages and pose great risks to the equipment safety. In this paper, a single-phase ferroresonance incident during a system energization is presented, which occurred at a single-phase station service transformer in an ungrounded system, causing surge arresters' failure. The incident is investigated through PSCAD simulations and analytical analysis. The relay field record is used to compare with the simulation results in order to validate the PSCAD simulation model. Several case studies are conducted using PSCAD simulations to evaluate various contributing factors to this ferroresonance incident. The root cause of the incident is found to be the lack of ground during energization in the system. Field practices are recommended to be implemented before the system energization to avoid such incidents, which were proved to be effective by successfully energizing the system in the field following these practices.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPS51807.2021.9416609 },
  booktitle={ 2021 IEEE/IAS 57th Industrial and Commercial Power Systems Technical Conference (I&CPS) },
  chapter={0}
}

@article{rayyan-352345716,
  title={ TransformerFusionNet: A Real-Time Multimodal Framework for ICU Heart Failure Mortality Prediction Using Big Data Streaming  -  2024 International Conference on Computer and Applications (ICCA) },
  year={2024},
  author={Saleh, H. and McCann, M. and El-Sappagh, S. and Breslin, J. G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10927742 },
  abstract={This paper presents a real-time multimodal frame-work to enhance ICU mortality prediction for heart disease patients by integrating structured data, clinical notes, and big data streaming platforms. The proposed framework comprises two components: an offline multimodal model and a real-time pipeline. In the offline component, we proposed the Transformer-FusionNet model leverages BioBERT-Transformer for clinical notes and a Recurrent Neural Network (RNN) for structured data. The model integrates outputs through a concatenation layer to make predictions and is rigorously evaluated using the MIMIC-III dataset. It demonstrates superior performance across evaluation metrics and achieves an accuracy of 91.720%, precision of 91.85%, recall of 91.720%, and F1-score of 91.693%, outperforming other single and multimodal models. The real-time pipeline component incorporates Apache Spark and Apache Kafka for ingesting, preprocessing, and streaming structured data and clinical notes. This integration enables real-time mor-tality prediction with TransformerFusionNet, addressing critical gaps in the utilization of clinical notes in healthcare analytics. The framework significantly advances multimodal deep learning applications in healthcare by combining state-of-the-art models with scalable streaming technologies, offering a practical solution for improving clinical decision support systems and patient outcomes in real-time, especially in intensive care unit settings.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICCA62237.2024.10927742 },
  booktitle={ 2024 International Conference on Computer and Applications (ICCA) },
  chapter={0}
}

@article{rayyan-352345717,
  title={ Trial calculation of the AC test voltage using a new cumulative failure probability model  -  IEEE Transactions on Dielectrics and Electrical Insulation },
  year={2012},
  author={Tsuboi, T. and Takami, J. and Okabe, S. and Inami, K. and Aono, K.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6260017 },
  abstract={In the condition settings of a power-frequency withstand voltage test for substation equipment, an approach based on insulation reliability evaluation using Weibull distribution is available. In this method, temporary overvoltage is evaluated using an “independence model”. This “independence model” assumes no remaining influence of voltage application (i.e. the model obeys the failure probability distribution starting at time 0 each time the voltage is applied). However, the authors have conducted insulation characteristics tests by applying a voltage multiple times at intervals and clarified that the influence of voltage application remains to a certain extent (i.e. the effect assumed in the “accumulation model” appears) as well as the degree of influence depending on the conditions for oil-immersed transformer. The present paper proposes an evaluation method with the degree of influence of voltage application history taken into consideration. In the proposed method, the portions following an “independence model” and an “accumulation model” are respectively assumed and combined after multiplying the relevant coefficient representing the respective degrees of influence. According to the trial calculation based on the proposed method, the required withstand voltage decreased by several percentage points, while it was confirmed that the existing method is on the safer side as a means of evaluating the insulation reliability of temporary overvoltage.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TDEI.2012.6260017 },
  booktitle={ IEEE Transactions on Dielectrics and Electrical Insulation },
  chapter={0}
}

@article{rayyan-352345718,
  title={ Leveraging Multi-Task Learning to Improve the Detection of SATD and Vulnerability  -  2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC) },
  year={2025},
  author={Russo, B. and Melegati, J. and Mock, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025930 },
  abstract={Multi-task learning is a paradigm that leverages information from related tasks to improve the performance of machine learning. Self-Admitted Technical Debt (SATD) are comments in the code that indicate not-quite-right code introduced for short-term needs, i.e., technical debt (TD). Previous research has provided evidence of a possible relationship between SATD and the existence of vulnerabilities in the code. In this work, we investigate if multi-task learning could leverage the information shared between SATD and vulnerabilities to improve the automatic detection of these issues. To this aim, we implemented VulSATD, a deep learner that detects vulnerable and SATD code based on CodeBERT, a pre-trained transformers model. We evaluated VulSATD on MADE-WIC, a fused dataset of functions annotated for TD (through SATD) and vulnerability. We compared the results using single and multi-task approaches, obtaining no significant differences even after employing a weighted loss. Our findings indicate the need for further investigation into the relationship between these two aspects of low-quality code. Specifically, it is possible that only a subset of technical debt is directly associated with security concerns. Therefore, the relationship between different types of technical debt and software vulnerabilities deserves future exploration and a deeper understanding.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ICPC66645.2025.00017 },
  booktitle={ 2025 IEEE/ACM 33rd International Conference on Program Comprehension (ICPC) },
  chapter={0}
}

@article{rayyan-352345719,
  title={ Fusionformer: A Novel Adversarial Transformer Utilizing Fusion Attention for Multivariate Anomaly Detection  -  IEEE Transactions on Neural Networks and Learning Systems },
  year={2025},
  author={Wang, C. and Wang, Z. and Dong, H. and Lauria, S. and Liu, W. and Wang, Y. and Fadzil, F. and Liu, X.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922726 },
  abstract={Multivariate time series forecasting (MTSF) is of significant importance in the enhancement and optimization of real-world applications. The task of MTSF poses substantial challenges due to the unpredictability of temporal patterns and the complexity in modeling the influence of all nonpredictive sequences on the target sequence at different time stages. Recent research has demonstrated the potential held by the Transformer algorithm to augment long-term forecasting capability. However, certain obstacles considerably obstruct the direct application of the Transformer to MTSF, such as an unsuitable embedding method, inadequate consideration of intervariable associations, and the intrinsic restriction of the point-wise objective function. To overcome these challenges, the Fusionformer, an effective Transformer-based forecasting model, is put forth in this article, which is characterized by three distinctive features: 1) the introduction of a segment-wise sequence embedding (SWSE) method allows for the conversion of the input sequence into multiple informative segments; 2) the implementation of a fusion attention mechanism (FAM), designed to capture predominant features across the time dimension and to model intricate intervariable dependencies; and 3) the development of an adversarial learning method, equipped with an auxiliary discriminator, facilitates the learning of data distribution, instead of progressively correcting the prediction error, thus substantially enhancing the MTSF’s accuracy. Furthermore, a Fusionformer-based risk assessment (FRA) method is structured for open-pit mine slope failure early warning issue (SFEW), which aims to prevent potential disasters by accurately predicting future slope movement trends and assessing the probabilities of landslide occurrences. Experimental outcomes validate that Fusionformer outperforms existing forecasting methods, while the FRA framework provides valuable insights and practical guidance for real-world applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TNNLS.2025.3542719 },
  booktitle={ IEEE Transactions on Neural Networks and Learning Systems },
  chapter={0}
}

@article{rayyan-352345720,
  title={ Lightning Strike Identification Algorithm of an All-Parallel Auto-Transformer Traction Power Supply System Based on Morphological Fractal Theory  -  IEEE Transactions on Power Delivery },
  year={2023},
  author={Zhong, H. and Chen, J. and Fu, Q. and Hua, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004006 },
  abstract={Lightning strikes are one of the major causes leading to faults in the traction power supply systems. Quick identification of the lightning shielding and backflashover failures is a complex task. In this paper a lightning strike identification model based on morphological fractal theory is constructed. A simulation model of lightning-struck tractive network faults is developed aiming at investigating the influence of the structure of the all-parallel AT tractive network on the waveform characteristics. The differences in the waveform characteristics under lightning shielding and backflashover failures are studied. Further, the fault analysis of lightning strike signals is carried out based on mathematical morphology. The influence of different structural elements and basic operations on the effect of morphological transformation is obtained. The classification effects of single- and multi-scale fractal dimensions of voltage and current waveforms are compared based on fractal theory. Moreover, a neural network framework is employed using the fractal dimensions of samples at different scales as feature vectors and the fault state as the output for establishing a lightning-strike identification model. The result shows that this method can effectively identify lightning strike faults in all-parallel AT traction power supply system with an accuracy of more than 95%.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2022.3233107 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345721,
  title={ Tuning guaranteed time slots of IEEE 802.15.4 for transformer health monitoring in the smart grid  -  2014 IEEE Wireless Communications and Networking Conference (WCNC) },
  year={2014},
  author={Al-Anbagi, I. and Erol-Kantarci, M. and Mouftah, H. T.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6953132 },
  abstract={Wireless Sensor Networks (WSNs) are anticipated to become the preferred tools of choice for monitoring and controlling power utility assets in the smart grid due to their versatility. However, in some smart grid monitoring applications, data generation rates could fluctuate rapidly due to the sudden occurrence of critical faults or failures in the monitored equipment. As a consequence, critical data could experience excessive delays because of this increase in the packet arrival rates. In this paper, we present an Adaptive Guaranteed Time Slot (GTS) allocation scheme (AGTS) for IEEE 802.15.4-based WSNs used in high traffic intensity smart grid monitoring applications. AGTS scheme can adaptively reduce the end-to-end delay and flexibly tune the GTS to provide the required Quality of Service (QoS) differentiation to delay critical smart grid monitoring applications. The proposed scheme can adaptively allocate the needed GTS to nodes transmitting high priority traffic or draw back the unneeded GTS.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/WCNC.2014.6953132 },
  booktitle={ 2014 IEEE Wireless Communications and Networking Conference (WCNC) },
  chapter={0}
}

@article{rayyan-352345722,
  title={ Mechanical Modeling of Oil-Immersed Louver Contacts on the Valve Side of a Converter Transformer  -  IEEE Access },
  year={2024},
  author={Huang, Z. and Liu, F. and Tu, Y. and Chen, J. and Hu, S. and Zhao, T. and Liu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10380561 },
  abstract={Degradation of the mechanical properties of oil-immersed louver contacts is an important cause of exceeding the DC resistance on the valve side of extra-high voltage converter transformers. In this paper, the mapping relationship between force-deformation and force-contact resistance of oil-immersed louver contacts is measured and obtained by utilizing the performance test platform of oil-immersed louver contacts. Based on the stress-strain curves of the stainless steel of the strap under different temperature conditions, a mechanical simulation model of the oil-immersed louver contacts was established. Based on this model, the effects of the plastic deformation temperature of the louver contacts and the stainless steel keel structure on the heating power of the strap are investigated. The results show that the mechanical properties of the louver contacts decrease with the increase in temperature, and the permanent plastic deformation of the strap occurs when the operating temperature reaches 400 °C. Appropriately increasing the torsion angle and thickness of the stainless steel keel can slow down the local overheating of the louver contacts caused by eccentricity. The research results are helpful to understand the mechanism of local overheating failure of oil-immersed electric contact parts, and provide a reference for the design, fault analysis and further research of oil-immersed electric contact parts.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2024.3349945 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345723,
  title={ Active Detection And Identification Of Incipient Faults In Liquid Filled Transformers  -  2022 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC) },
  year={2022},
  author={Cruz, E. M. and Udrescu, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181258 },
  abstract={The failure of power transformers is always an area of significant concern because it can result in millions of dollars in costs, interruption of power, and possible environmental and safety impacts. Therefore, it is desirable to detect the existence of abnormal changes in the transformer’s internal condition and determine whether the changes could lead to a failure. Active detection and identification of incipient faults is now possible through online monitoring of abnormal changes in some parameters and the use of diagnostic methods. This paper gives an overview of a transformer monitoring system and measured signals for the diagnosis of incipient faults.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PCIC42668.2022.10181258 },
  booktitle={ 2022 IEEE IAS Petroleum and Chemical Industry Technical Conference (PCIC) },
  chapter={0}
}

@article{rayyan-352345724,
  title={ Tensor Protection System Application in Transformer Protection  -  2025 IEEE Industry Applications Society Annual Meeting (IAS) },
  year={2025},
  author={Arias-Guzman, S. and Ustariz-Farfan, A. J. and Cano-Plata, E. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11061703 },
  abstract={This paper presents the current challenges of protection systems, starting from the different physical considerations of its implementation, setting selection, coordination, and logic verification. This description allows to identify research objectives in the field of protection systems. These protection challenges are shown for an industrial user, allowing for an assessment of physical requirement considerations, the use of different protection functions, coordination, and logic verification. This example is used to show different conditions that lead to hidden failures and could lead to catastrophic safety conditions. Lastly, this paper shows the benefits of a new method proposed by the authors of this paper that helps to overcome these challenges.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IAS62731.2025.11061703 },
  booktitle={ 2025 IEEE Industry Applications Society Annual Meeting (IAS) },
  chapter={0}
}

@article{rayyan-352345725,
  title={ Study on the Influence of Temperature on Tanδ Measurement of 110kV Cascade Voltage Transformer  -  2023 2nd Asia Power and Electrical Technology Conference (APET) },
  year={2023},
  author={Longshan, Y. and Tianxiang, C. and Shuyue, W. and Xun, W.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10489684 },
  abstract={Cascade voltage transformers (hereinafter referred to as CTV) are widely used in power grids, and a good insulation condition is a prerequisite for their safe and reliable operation. 110kV CTV tan δ can be affected by changes in environmental factors (such as temperature and humidity), and sometimes the tanδ can be abnormal or even fail to reflect the actual state of the equipment. This paper takes a JCC6-110 CTV which has been operated for many years as the research object, and makes a comprehensive and detailed study on the influence of temperature on CTV tanδ, and researches the change of CTV tanδ under different temperature conditions, proposes the CTV insulation equivalent circuit model, obtains tanδ and capacity data through different wiring methods and derives the model parameters, and establishes the insulation equivalent circuit model influenced by temperature factors. The insulation equivalent circuit model with the influence of temperature factors is proposed, and the method of correcting tanδ to the standard atmospheric conditions is proposed. The model was simulated using MATLAB/Simulink software to verify the correctness of the insulation equivalent circuit model considering the effect of temperature on tanδ under fault conditions, and the model can be applied to the conversion and correction of the effect of temperature on CTV tanδ during field testing.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APET59977.2023.10489684 },
  booktitle={ 2023 2nd Asia Power and Electrical Technology Conference (APET) },
  chapter={0}
}

@article{rayyan-352345726,
  title={ Electrical Supply Reliability of Circuits with Transformer Substations in Technical and Economic Decisions  -  2025 7th Global Power, Energy and Communication Conference (GPECOM) },
  year={2025},
  author={Valtchev, S. and Petrova, R. M. and Gracheva, E. I. and Gospodinova, D. and Sinyukova, T. and Miceli, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11061870 },
  abstract={The proposed article is assessing the reliability parameters of power supply systems with $\mathbf{1 0 / 0. 4 ~ k V}$ transformer substations. The paper examines the reliability of the power supply system for the following circuit options: without redundancy; with redundancy at medium and low voltages; with double redundancy: when reserving the entire MV-LV circuit. Graphical dependences of the operating time for failure of power supply circuits on the different rated power of transformers for four variants are obtained: without redundancy; with redundancy for LV; with redundancy for MV; with double redundancy of the entire MV-LV circuit. The optimal condition is found to use a smaller number of transformer substations, and, accordingly, distribution transformers, while observing the value of the 0.8 load factor. When comparing the graphs, it was found that the longest operating time to failure is achieved with double redundancy, the shortest with no redundancy. The payback period of the options is calculated considering the inflation index. According to the calculation results, it is found that the variant of redundancy for LV is optimal, with the shortest payback period of 5.77 years. Next, there is a no-redundancy scheme with a payback period of 5.86 years, but with a higher failure rate. The dual redundancy pays off in 5.92 years. The research results can be used in the designing of power supply systems, improving the reliability and efficiency of equipment operation.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/GPECOM65896.2025.11061870 },
  booktitle={ 2025 7th Global Power, Energy and Communication Conference (GPECOM) },
  chapter={0}
}

@article{rayyan-352345727,
  title={ A Particle Filtering Based Approach for Transformer Winding Degradation Prognostics  -  2018 Prognostics and System Health Management Conference (PHM-Chongqing) },
  year={2018},
  author={Guo, H. and Xu, A. and Wang, K. and Han, X. and Liu, Y. and Zhang, X. and Lv, D.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8603433 },
  abstract={When the transformer works for a long time, its winding is gradually deteriorated with time, and the fault phenomena such as winding short circuit or circuit break lead to serious power supply accidents. Under high temperature conditions, this paper analyzes the degradation process of the winding, and determines that the resonant frequency can be used as testing index of its degradation process. Therefore, the resonant frequency is used to monitor the performance degradation state of the transformer winding and realize the advance prediction, which can effectively avoid accidents. Accurate prediction of system reliability is of plenty of importance to engineering systems for accomplishing the designate function and system safety management. As the concerned system is getting complicated and more sufficient health monitoring measurement is available, the traditional reliability prediction schemes resorting to only one kind of prediction approaches, model-based or data-driven, begin to show their limitations. This paper proposes a PF prognostic method by combining traditional model approaches. The effectiveness of the proposed method is verified by thermal degradation experiments. This method improves the reliability of power system and is conducive to the rapid development of smart grid.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PHM-Chongqing.2018.00125 },
  booktitle={ 2018 Prognostics and System Health Management Conference (PHM-Chongqing) },
  chapter={0}
}

@article{rayyan-352345728,
  title={ A Wireless Weatherproof Acoustic Sensor System to Detect Anomalies in Substation Power Transformers  -  2023 36th SBC/SBMicro/IEEE/ACM Symposium on Integrated Circuits and Systems Design (SBCCI) },
  year={2023},
  author={Gialluca, G. T. and Gialluca, G. T. and Masiero, B. and Lima, E. R. De and Almeida, L. M. and Fruett, F.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10261660 },
  abstract={Power transformers are essential components in electrical substations. Depending on the operating conditions, they can have failures capable of damaging the functioning of the power grid. To mitigate these problems, it is suitable for the transmission and distribution companies to implement a sensor system capable of monitoring the equipment and detecting anomalies in its operation. Acoustic measurements and signal processing present a promising non-invasive method for monitoring the working condition of power transformers. To achieve this goal, the authors developed an acoustic sensor system, featuring a suitable microphone, battery power supply, weatherproof enclosure, signal processing unit, and Wi-Fi connectivity. Additionally, they proposed an audio processing algorithm and a machine learning model for anomaly detection that analyzes the audio parameters and provides the transformer diagnosis. The proposed sensor system with anomaly detection approach can aid in preventing power transformer failures by analyzing audio parameters and providing valuable insights into the equipment's health. With this information, maintenance teams can intervene before critical failures occur, avoiding financial losses and interruptions in the power supply. The proposed approach can be readily integrated into existing substation infrastructures, enhancing the overall reliability of the power grid.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/SBCCI60457.2023.10261660 },
  booktitle={ 2023 36th SBC/SBMicro/IEEE/ACM Symposium on Integrated Circuits and Systems Design (SBCCI) },
  chapter={0}
}

@article{rayyan-352345729,
  title={ Planar Rogowski Coil Based Short-Circuit Detection and Partial Open-Circuit Recovery of the Resonant Capacitor in Series-Resonant DC Transformers  -  IEEE Transactions on Power Electronics },
  year={2025},
  author={Pradhan, R. and Shah, S. B. and Wang, Y. and Elezab, A. and Hemming, S. and Pietrini, G. and Hassan, M. I. and Suntharalingam, P. and Cruz, M. F. and Emadi, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097890 },
  abstract={The 10 kW Series-Resonant DC Transformer (SR-DCX) enables both switch and resonant element count reduction and is a building block of a bidirectional two-stage dc–dc converter for 600–28 V MIL-PRF-GCS600 A and MIL-STD-704F compliant applications. The dc–dc converter is constructed with its first stage as a buck converter and the second stage as the SR-DCX. Failure mode assessment of the SR-DCX indicates a single-point failure on the resonant capacitor that will either prohibit or degrade the operation of the dc–dc converter, depending upon the failure mode. This article discusses the design of a planar Rogowski coil in accordance with MIL-PRF-31032 and its signal chain optimization for the measurement of ac current on the high-frequency link. We introduce a novel failure detection method to simultaneously identify both partial open-circuit (OC) and short-circuit failures in the resonant capacitor network by re-purposing the ac link current measurement, conventionally used for over-current protection. The method also enables recovery from partial OC failures to restore normal operation. The proposed scheme aids in raising system-level warnings for redundancy activation prior to catastrophic failures in the dc–dc converter for high-reliability applications.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPEL.2025.3593181 },
  booktitle={ IEEE Transactions on Power Electronics },
  chapter={0}
}

@article{rayyan-352345730,
  title={ The Impact of LoRA Adapters on LLMs for Clinical Text Classification Under Computational and Data Constraints  -  IEEE Access },
  year={2025},
  author={Le, T. -D. and Nguyen, T. Ti and Ha, V. Nguyen and Chatzinotas, S. and Jouvet, P. and Noumeir, R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048527 },
  abstract={Fine-tuning Large Language Models (LLMs) for clinical Natural Language Processing (NLP) poses significant challenges due to domain gap, limited data, and stringent hardware constraints. In this study, we evaluate four adapter techniques—Adapter, Lightweight, TinyAttention, and Gated Residual Network (GRN) - equivalent to Low-Rank Adaptation (LoRA), for clinical note classification under real-world, resource-constrained conditions. All experiments were conducted on a single NVIDIA Quadro P620 GPU (2 GB VRAM, 512 CUDA cores, 1.386 TFLOPS FP32), limiting batch sizes to  $\leq 8$  sequences and maximum sequence length to 256 tokens. Our clinical corpus comprises only 580 000 tokens, several orders of magnitude smaller than standard LLM pre-training datasets. We fine-tuned three biomedical pre-trained LLMs (CamemBERT-bio, AliBERT, DrBERT) and two lightweight Transformer models trained from scratch. Results show that 1) adapter structures provide no consistent gains when fine-tuning biomedical LLMs under these constraints, and 2) simpler Transformers, with minimal parameter counts and training times under six hours, outperform adapter-augmented LLMs, which required over 1000 GPU-hours. Among adapters, GRN achieved the best metrics (accuracy, precision, recall, F1 = 0.88). These findings demonstrate that, in low-resource clinical settings with limited data and compute, lightweight Transformers trained from scratch offer a more practical and efficient solution than large LLMs, while GRN remains a viable adapter choice when minimal adaptation is needed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2025.3582037 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345731,
  title={ PV-YOLO: Lightweight YOLO for Photovoltaic Panel Fault Detection  -  IEEE Access },
  year={2023},
  author={Yin, W. and Lingxin, S. and Maohuan, L. and Qianlai, S. and Xiaosong, L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032147 },
  abstract={The rapid development of the photovoltaic industry in recent years has made the efficient and accurate completion of photovoltaic operation and maintenance a major focus in recent studies. The key to photovoltaic operation and maintenance is the accurate multifault identification of photovoltaic panel images collected using drones. In this paper, PV-YOLO is proposed to replace YOLOX’s backbone network, CSPDarknet53, with a transformer-based PVTv2 network to obtain local connections between images and feature maps to extract more edge-detail features of similar faults. The CBAM attention mechanism is added to enhance the effective features and improve the detection accuracy of small objects. The label assignment mechanism is optimized, and the SIoU loss functionis used to improve the uneven distribution of samples and accelerate network convergence. Experiments on the dataset prove that this method is superior to the existing technology, as the highest mAP value is 92.56%. This value is 10.46% higher than that of YOLOX, and the mAP is optimal under the same parameter magnitude,proving the model’s effectiveness.Moreover, mAP is increased by over 10%, especially for small targets. In this paper, we implemented a lightweight design for the model, and proposes four models of different sizes to be-sized models that are suitable for different detection scenarios.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ACCESS.2023.3240894 },
  booktitle={ IEEE Access },
  chapter={0}
}

@article{rayyan-352345733,
  title={ Power system unbalance due to railway electrification: Review of challenges and outlook of the Danish case  -  2016 IEEE International Energy Conference (ENERGYCON) },
  year={2016},
  author={Stamatopoulos, A. and Vikelgaard, H. and da Silva, F. F. and Bak, C. L.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7514008 },
  abstract={The decision to electrify the main part of the Danish railway at the same time where the supply and generation of electrical power in Denmark moves to a more decentralized structure, raises concerns regarding the balanced and secure operation of the power grid. Adverse effects include, among others, the lifetime reduction of rotating machines and the malfunction of HVDC converters. Toward this direction, this paper aims to review the challenges and mitigation solutions with respect to voltage unbalance, focusing on the conditions relevant to the electrification of the Danish railway.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ENERGYCON.2016.7514008 },
  booktitle={ 2016 IEEE International Energy Conference (ENERGYCON) },
  chapter={0}
}

@article{rayyan-352345734,
  title={ Digital Twin Assisted Degradation Assessment of Bearing Cage Performance  -  IEEE Transactions on Industrial Informatics },
  year={2025},
  author={Fan, C. and Wang, P. and Zhang, Y. and Ma, H. and Li, X. and Wang, Q.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10959316 },
  abstract={The construction of a digital twin model for the full life cycle of rolling bearings is of great significance for analyzing their degradation performance and health management. However, existing researches primarily concentrate on the degradation of the outer ring of bearings. The cage, as an important component of bearings, lacks extensive research. Therefore, this article proposes a digital twin assisted assessment method for the degradation of bearing cages. First, a dynamic model including bearing cage fracture is established to generate simulation degradation signals. Second, the simulation signal is modified based on the squeeze and excitation cycle generative adversarial network (SECycleGAN) to minimize the characteristic distribution differences between the simulation and real signals. Finally, the corrected high-fidelity signal is used to train the proposed selective kernel transformer (SKformer) model to assess the degradation stage of the bearing cage. This model can simultaneously capture the long-range temporal correlation features and local mutation multiscale features of the input signals, thus improving the model's recognition ability and generalization performance. The effectiveness of the proposed method is demonstrated through signals collected on real and open-source bearing cage degradation test rigs. The results indicate that the proposed method can produce high-fidelity bearing cage degradation signals and achieve better classification accuracy with limited data.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TII.2025.3552655 },
  booktitle={ IEEE Transactions on Industrial Informatics },
  chapter={0}
}

@article{rayyan-352345735,
  title={ 2-D Finite-Element Electromagnetic Analysis of an Autotransformer Experiencing Ferroresonance  -  IEEE Transactions on Power Delivery },
  year={2009},
  author={Charalambous, C. A. and Wang, Z. D. and Jarman, P. and Osborne, M.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4895297 },
  abstract={The key concern for transformers experiencing ferroresonance is whether the energy transferred into the transformer body during core saturation by the nonsinusoidal currents is damaging. Saturation and the consequent incompetency of the core to contain the flux manifests itself as current induced in parts of the transformer body not foreseen to conduct current. Sustained ferroresonance may last for minutes (or even hours), when no intervening operations are carried out, and may cause local overheating and thermally degrade surrounding insulation. In this paper, transient electromagnetic analysis was conducted by using 2-D finite-element models of a 240-MVA 400/132/13-kV autotransformer. As a continuing effort, the main objective of modeling is to visualize the flux flow in parts where transformer designers have not anticipated its presence. A quantitative assessment of the flux, the induced currents, and the power dissipated in these parts has been carried out to determine the degree of risk imposed on a transformer under ferroresonance.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2009.2016629 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345736,
  title={ A Collective Condition Monitoring Algorithm for On-Load Tap-Changers  -  2019 IEEE International Conference on Environment and Electrical Engineering and 2019 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe) },
  year={2019},
  author={Feizifar, B. and Müller, Z. and Fandi, G. and Usta, O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8783320 },
  abstract={Transformer units are widely utilized to transfer the electric power over transmission and distribution networks efficiently. These units can be equipped with an on-load tap- changer (OLTC) to regulate the voltage level of power grids by tap changing operations between different steps of transformer winding to compensate unpredicted fluctuations of voltage. An OLTC is the solely moving and switching component of power transformers, thus it is highly prone to electrical, mechanical, and dielectric defects. Some international surveys indicate that the majority of the failures and outages with respect to power transformers are originated from malfunctions of OLTCs. This paper contains an analytical review of the existing methods for condition monitoring (CM) of OLTCs and proposes a collective CM algorithm, which considers the mechanical, electrical, and dielectric defects and degradations of OLTCs. The algorithm is designed to provide a comprehensive CM output for OLTCs by collecting different types of measurements from certain sensors used by different CM methods.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/EEEIC.2019.8783320 },
  booktitle={ 2019 IEEE International Conference on Environment and Electrical Engineering and 2019 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I&CPS Europe) },
  chapter={0}
}

@article{rayyan-352345737,
  title={ The Experience Acquired Sizing Snubbers to Mitigate Switching Transients in Industrial Power Systems  -  IEEE Transactions on Industry Applications },
  year={2016},
  author={Mardegan, C. S. and Shipp, D. D. and Melo, L. A. R. and Santana, M. R.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7465770 },
  abstract={This paper was written to share the experience acquired in the specification of surge suppressors (snubbers) for protection against switching transients’ overvoltage resulting primarily in dry-type transformers failures in some plants in Brazil and North America. This paper will also explain about the snubber ratings (damping resistor, surge capacitor, and surge arrester), the assembly special cares, system modeling, and simulations using the software Alternative Transient Program.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TIA.2016.2563392 },
  booktitle={ IEEE Transactions on Industry Applications },
  chapter={0}
}

@article{rayyan-352345738,
  title={ IEEE Guide for Protective Relay Applications to Power System Buses  -  IEEE Std C37.234-2009 },
  year={2009},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5325912 },
  abstract={Concepts of power bus protection are discussed in this guide. Consideration is given to availability and location of breakers, current transformers, and disconnectors as well as bus-switching scenarios, and their impact on the selection and application of bus protection. A number of bus protection schemes are presented; their adequacy, complexity, strengths, and limitations with respect to a variety of bus arrangements are discussed; specific application guidelines are provided. Breaker failure protection is discussed as pertaining to bus protection. Means of securing bus protection schemes against corrupted relay input signals are also included.;Concepts of power bus protection are discussed in this guide. Consideration is given to availability and location of breakers, current transformers, and disconnectors as well as bus-switching scenarios, and their impact on the selection and application of bus protection. A number of bus protection schemes are presented; their adequacy, complexity, strengths, and limitations with respect to a variety of bus arrangements are discussed; specific application guidelines are provided. Breaker failure protection is discussed as pertaining to bus protection. Means of securing bus protection schemes against corrupted relay input signals are also included.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEESTD.2009.5325912 },
  booktitle={ IEEE Std C37.234-2009 },
  chapter={0}
}

@article{rayyan-352345739,
  title={ Exploring the IEEE C37.234 Guide for Protective Relay Application to Power System Buses  -  2011 64th Annual Conference for Protective Relay Engineers },
  year={2011},
  author={Kasztenny, B. and Conrad, S. and Beaumont, P. and Behrendt, K. and Bolado, O. and Boyle, J. and Brunello, G. and Burger, J. and Calero, F. and Chano, S. and Dalke, G. and Darlington, A. and DoCarmo, H. and Fontana, D. and Gajic, Z. and Holbach, J. and Kojovic, L. and Lopez, F. and Lukach, D. and McGinn, D. and Miller, J. and Mysore, P. and O'Brien, J. and Pickett, B. and Sambasivan, S. and Sessler, G. and Skendzic, V. and Smith, J. and Tholomier, D. and Thompson, M. and Uchiyama, J. and Ware, D. and Weers, D. and Whittaker, R. and Young, R. and Zocholl, S.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035602 },
  abstract={This paper summarizes the IEEE C37.234-2009 Guide for Protective Relay Applications to Power System Buses. In the Guide, concepts of power bus protection are discussed. Consideration is given to availability and location of breakers, current transformers, and disconnectors as well as bus switching scenarios, and their impact on the selection and application of bus protection. A number of bus protection schemes are presented; their adequacy, complexity, strengths and limitations with respect to a variety of bus arrangements are discussed; specific application guidelines are provided for a variety of situations. Breaker failure protection is discussed as pertaining to bus protection. Means of securing bus protection schemes against corrupted relay input signals are also included.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/CPRE.2011.6035602 },
  booktitle={ 2011 64th Annual Conference for Protective Relay Engineers },
  chapter={0}
}

@article{rayyan-352345740,
  title={ Open Transistors Fault-Tolerant Schemes of Three-Phase Dual Active Bridge DC-DC Converters  -  IEEE Latin America Transactions },
  year={2021},
  author={Sosa, J. E. Ochoa and Núñez, R. O. and Oggier, G. G. and García, G. O.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447587 },
  abstract={This work proposes fault-tolerant schemes for open-transistor faults applied to three-phase dual active bridge converters (TPDABC), using different transformers: star-star, delta-delta, and delta-star. The proposal consists of operating the TPDABC as a single-phase dual active bridge converter, modifying the modulation strategy. This strategy avoids the need for additional components, which allows the converter to continue operating after an event of open transistor failure. The expressions of the average power when the converter operates in the fault-tolerant modes are determined. The analysis determines that the maximum power that can be transferred using the transformer delta-star is larger than the power obtained for star-star and delta-delta connections. Simulation results allow the proposed schemes to be validated.;Please fix the Article's Index Terms (Bidirectional DC-DC Converter,Converter Failures,Fault Tolerance,Three-Phase Dual Active Bridges Converter,Three-Phase Transformers). The PDF delivered is correct so fix the XML to match the delivered PDF.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TLA.2021.9447587 },
  booktitle={ IEEE Latin America Transactions },
  chapter={0}
}

@article{rayyan-352345742,
  title={ Loss-of-Voltage Detection for Relays Protecting Systems With Inverter-Based Resources  -  IEEE Transactions on Power Delivery },
  year={2022},
  author={Banaiemoqadam, A. and Hashemi, S. M. and Hooshyar, A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385973 },
  abstract={Reliable voltage measurement is a pre-requisite for correct operation of a relay's voltage-dependent functions. The secondary circuit of a relay's voltage transformer (VT) is usually fuse-protected. The blowing of a VT's three-phase fuses prevents correct voltage measurement, commonly referred to as the loss-of-voltage (LOV) condition. Relays are equipped with different methods to detect the LOV conditions and avoid confusing them with grid faults. However, this paper shows that existing LOV detection methods are prone to misoperation in the presence of inverter-based resources (IBRs). The paper's findings are corroborated by hardware-in-the-loop testing of relays with the state-of-the-art LOV detection methods. This paper also develops a new LOV detection method for transmission system relays that addresses the unveiled problem. The proposed method considers the fault behavior of IBRs and detects LOVs by examining certain conditions in three stages, namely phase-voltage-check, phase-current-check, and current-transients-check. Simulation studies are used to verify the dependable and secure operation of this new method for different LOVs, faults, IBRs, and VT configurations. The obtained results demonstrate that this method performs successfully regardless of the type of generation units. Moreover, it is sufficiently fast to prevent relay misoperation during LOV conditions and does not require extra hardware.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TPWRD.2021.3068557 },
  booktitle={ IEEE Transactions on Power Delivery },
  chapter={0}
}

@article{rayyan-352345743,
  title={ Impact of Radiation-Induced Effects on Embedded GPUs Executing Large Machine Learning Models  -  IEEE Transactions on Nuclear Science },
  year={2025},
  author={Coelho, B. L. and dos Santos, F. F. and Saveriano, M. and Allen, G. and Daniel, A. and Guertin, S. and Vartanian, S. and Wyrwas, E. and Frost, C. and Rech, P.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10839068 },
  abstract={Large machine learning (ML) models can outperform previous state-of-the-art ML models such as convolutional neural networks (CNNs). In this article, we study the impact of radiation-induced effects on large ML models executing on the NVIDIA TX2 system-on-chip (SoC). In addition to characterizing the SoC hardware, we compare the radiation response of a popular CNN, ResNet-50, to two recent large ML models: vision transformers (ViTs) and data-efficient image transformers (DeiTs). Our evaluation includes experiments with both heavy ions and high-energy protons at three different facilities. No single-event latchup (SEL) was observed in our heavy-ion experiments with a linear energy transfer (LET) of 37 MeV/ $\text {cm}^{2}$ /mg at up to 80 °C. Furthermore, we investigate how high-energy protons and heavy ions at low LET affect the correct application output and limit the availability of ML applications. Our analysis reveals not only how radiation-induced errors propagate internally through the ML models all the way to the output but also the main causes of fatal errors that lead to crashes in the operating system kernel. Particularly, the cross sections measured for crashes were roughly  $4{\times }$  higher than the ones measured for silent data corruptions (SDCs) for every application tested with heavy ions. Additionally, our evaluation of ML applications showed that general matrix multiplications (GeMMs) present a higher SDC cross section than all the ML models tested (ResNet, ViTs, and DeiTs), roughly 21% higher with protons and 59% higher with heavy ions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/TNS.2025.3528764 },
  booktitle={ IEEE Transactions on Nuclear Science },
  chapter={0}
}

@article{rayyan-352345744,
  title={ IEEE Guide for Protective Relaying of Utility-Consumer Interconnections  -  IEEE Std C37.95-2002 (Revision of IEEE Std C37.95-1989) },
  year={2003},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1195710 },
  abstract={Protective relay applications involving electric service to consumers that requires a transformation between the utilitys supply voltage and the consumers utilization voltage are covered in this guide. This guide describes the factors that need to be considered in the design of adequate protection facilities, outlines modern relay practices, and provides several examples of the protection of typical utility-consumer interconnections.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/IEEESTD.2003.94248 },
  booktitle={ IEEE Std C37.95-2002 (Revision of IEEE Std C37.95-1989) },
  chapter={0}
}

@article{rayyan-352345746,
  title={ Reliability Assessment Tools For Utilities in the De-regulated Electricity Market  -  2007 IEEE Power Engineering Society General Meeting },
  year={2007},
  author={Hamoud, G.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4275717 },
  abstract={Many utilities in the de-regulated electricity market are using a variety of reliability assessment tools (reliability programs) to assist them in managing effectively their assets with regard to new investment decisions. These assessment tools can be simple or complicated depending on the problems at hand and can be used for operating, planning and asset management purposes. This paper describes in brief three reliability assessment tools that have been in use at Hydro One for assessing the reliability of bulk transmission and customer delivery (regional supply) systems. Some important applications of these tools to the IEEE reliability test system and the Hydro One network system will also be discussed.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PES.2007.385951 },
  booktitle={ 2007 IEEE Power Engineering Society General Meeting },
  chapter={0}
}

@article{rayyan-352345748,
  title={ Effect of System Grounding, AC-DC Converter Topology and Inverter Modulation on Motor Insulation Voltage Stress  -  2020 IEEE Energy Conversion Congress and Exposition (ECCE) },
  year={2020},
  author={Sizov, G. Y. and Vrankovic, Z. and Melfi, M. J. and Skibinski, G. L. and Liu, Z.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9235646 },
  abstract={This paper analyzes major sources of motor voltage stresses on the motor stator line-to-ground and line-to-line insulation systems. Root causes of motor insulation over-voltages produced as a result of the type of the power system grounding scheme, type of dc-bus power supply (diode front end or regenerative active converter), inverter switching schemes, and long motor power cables are analyzed and discussed. Limitations of the existing definition of the low-voltage definite-purpose inverter duty motors are highlighted in relation to the line-to-ground insulation system requirements.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/ECCE44975.2020.9235646 },
  booktitle={ 2020 IEEE Energy Conversion Congress and Exposition (ECCE) },
  chapter={0}
}

@article{rayyan-352345749,
  title={ Artificial intelligence based techniques for remaining useful life assessment of electrical power distribution & transmission equipments: Comparative study  -  2016 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  year={2016},
  author={Janjua, J. I. and Munawar, U. and Jawadullah and Khan, Z. A.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779495 },
  abstract={This study investigates the parameters of power transformer to estimate and predict the remaining useful life of electrical power transformer using prognostics and artificial intelligence techniques. This paper presents the literature survey of techniques and parameters used. These investigations before time will improve the maintenance and quality of services of electrical power systems and distributions.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/APPEEC.2016.7779495 },
  booktitle={ 2016 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC) },
  chapter={0}
}

@article{rayyan-352345751,
  title={ IEEE Draft Guide for Protective Relaying of Utility-Consumer Interconnections  -  IEEE PC37.95/D3, January 2024 },
  year={2024},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10530605 },
  abstract={Described in this guide are protective relay applications involving electric service to consumers that requires a transformation between the utility’s supply voltage and the consumer’s utilization voltage. It describes the factors that need to be considered in the design of adequate protection facilities, outlines modern relay practices, and provides several examples of the protection of typical utility-consumer interconnections.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IEEE PC37.95/D3, January 2024 },
  chapter={0}
}

@article{rayyan-352345753,
  title={ Hydrogen Leakage Fault Diagnosis in PEMFC Systems Based on Synchronous Heterogeneous Characteristics of Multiple Physical Fields  -  2025 IEEE International Conference on Pattern Recognition, Machine Vision and Artificial Intelligence (PRMVAI) },
  year={2025},
  author={Zhuo, Y. and Huang, X. and Xie, J. and Chen, W. and Gu, Y.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108490 },
  abstract={Conventional hydrogen leakage fault diagnosis methods for proton exchange membrane fuel cell systems based on a single physical field are characterised by insufficient sensitivity and a high false alarm rate. This is due to limitations in sensor response speed and the dynamic operating conditions of the fuel cell system. This paper proposes a hydrogen leakage fault diagnosis method based on synchronous heterogeneous features of multi-physical fields. This method aims to realise efficient extraction and correlation analysis of the coupled features of multi-physical fields. It is achieved by constructing an electric-thermal-gas multi-sensor collaborative monitoring network, combined with the Fusion Convolutional Transformer Neural Network. The experimental results demonstrate that the proposed method achieves a diagnostic accuracy of 99.24% for hydrogen leakage faults, outperforming single-physical-field approaches (which reach a maximum of 94.99%) by at least 4.25 percentage points. This enhancement significantly improves diagnostic robustness under complex operating conditions. This study provides a theoretical foundation for selecting hydrogen leakage detection technologies in fuel cell systems, offering significant reference value for enhancing the safety performance of such systems.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.1109/PRMVAI65741.2025.11108490 },
  booktitle={ 2025 IEEE International Conference on Pattern Recognition, Machine Vision and Artificial Intelligence (PRMVAI) },
  chapter={0}
}

@article{rayyan-352345754,
  title={ IEEE Guide for Protective Relay Applications to Power System Buses  -  IEEE Unapproved Draft Std PC37.234-2009/D9.07, Mar 2009 },
  year={2009},
  author={nan},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810972 },
  abstract={Concepts of power bus protection are discussed in this guide. Consideration is given to availability and location of breakers, current transformers, and disconnectors as well as bus-switching scenarios, and their impact on the selection and application of bus protection. A number of bus protection schemes are presented; their adequacy, complexity, strengths, and limitations with respect to a variety of bus arrangements are discussed; specific application guidelines are provided. Breaker failure protection is discussed as pertaining to bus protection. Means of securing bus protection schemes against corrupted relay input signals are also included.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ nan },
  booktitle={ IEEE Unapproved Draft Std PC37.234-2009/D9.07, Mar 2009 },
  chapter={0}
}

@article{rayyan-352345757,
  title={ Effects of Arc-Back Fault in VSD Systems and How to Protect against Them  -  2019 Petroleum and Chemical Industry Conference Europe (PCIC EUROPE) },
  year={2019},
  author={Ojalammi, H. and Västi, M. and der Merwe, W. Van and Virtanen, E.},
  url={ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9011556 },
  abstract={VSD related arc-back faults have been discussed in technical forums without detailed explanation. However, the consequences of this fault mechanism is generally unknown by the engineers working in the industry. Scientific literature generally tend to ignore it. The phenomena is described in IEEE 551 but only for a theoretically ideal system without losses, saturation of the transformer or other overall system components. This technical paper aims to explain the theoretical background of arc-back and, by simulations, to demonstrate the actual performance of the real system where the stresses are reduced by system resistances. This type of single diode failure causes high thermal and dynamic stresses on the drive input transformers being known to be behind transformers failures with production loss and long recovery times. This paper also explains the principles how to protect the VSD drive transformer against this detrimental mode of component failure by rectifier monitoring. The aim of the authors is to get this phenomena know and understood. It shall also be noticed in international and national standards and specifications of VSD drives. The overall target is to improve the reliability of these important industrial work horses by increasing the understanding of the importance of the correct specifications of drive transformers and drive protection.},
  note={RAYYAN-INCLUSION: {"Brahim"=>"Excluded"}},
  doi={ 10.23919/PCICEurope46863.2019.9011556 },
  booktitle={ 2019 Petroleum and Chemical Industry Conference Europe (PCIC EUROPE) },
  chapter={0}
}

