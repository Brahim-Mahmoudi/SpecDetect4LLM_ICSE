# Smell: Unstructured LLM Output in Pipeline

## Motivation

When using LLM models within data processing pipelines, it's important to enforce structured outputs to ensure reliable downstream processing. Not having structured outputs can lead to:

```python
#  Unstructured output in pipeline
chain = LLMChain(llm=ChatOpenAI(), prompt=PromptTemplate(...))
result = chain.run("Generate data")  # Free-form text output

#  Structured output with parser
parser = PydanticOutputParser(pydantic_object=MyDataClass)
chain = LLMChain(
    llm=ChatOpenAI(),
    prompt=PromptTemplate(...),
    output_parser=parser  # Enforces structure
)
result = chain.run("Generate data")  # Validated structured data
```

Not enforcing structured outputs can cause:

- Brittle downstream processing
- Runtime errors from unexpected formats
- Data validation failures
- Inconsistent pipeline behavior
- Hard to maintain code


---

## Detection strategy (highâ€‘level view)

1. **AST parsing**  
   Parse the source and enrich nodes with parent pointers `(add_parent_info)`.

2. **dentify pipeline LLM calls**  
    `isUnstructuredLLMCallInPipeline(node)` detects:

    Direct API calls (create/generate_content)
    LangChain chain runs
    Pipeline calls
    Text generation pipelines

3. **Check output structuring**
    Verifies absence of:

    response_format/format = "json"
    Parser arguments
    Output formatters
    Structured data handlers
4. **Smart exclusions**
    Ignores asyncio.run() calls
    Skips arbitrary .run() methods
    Conservative on unknown origins

5. **Reporting**  

   REPORT: LLM call without structures output at line `n `.

---


## Examples 

```python

# Unstructured pipeline outputs

# Direct API call without format
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Extract data"}]
)

# LangChain without parser
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(input)

# Pipeline without structure
pipe = pipeline('text-generation')
text = pipe("Generate info")
```

```python

# Structured pipeline outputs

# Direct API with JSON format
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Extract data"}],
    response_format={"type": "json_object"}
)

# LangChain with parser
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    output_parser=StructuredOutputParser.from_response_schemas([...])
)

# Custom pipeline with structure
def process_llm(text):
    response = llm.generate(text, format="json")
    return MySchema.parse_obj(response)
```

## Limitations 

- Cannot detect variable-based formatters
- Misses custom structuring methods
- Conservative on dynamic pipelines
- May not catch all output handlers